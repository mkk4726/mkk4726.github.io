---
title: "Portfolio"
lastUpdated: "2025-08-20"
---

제가 진행했던 프로젝트들에 대한 내용입니다.
프로젝트가 진행된 상황과 진행하면서 고민했던 문제들, 그리고 이 문제들을 어떻게 해결했는지와 해결한 결과를 담고 있습니다.
저의 경험들은 스타트업에서 근무하면서 회사에 안정적인 ML 시스템을 구축하고 서비스를 운영했던 경험들입니다.

가장 최적의 판단을 내렸다고는 자신할 수 없지만, 해당 상황에서 제가 할 수 있는 최선을 선택을 해왔다고 생각합니다.
제가 어떻게 문제를 정의하고, 이를 해결하기 위해 어떤 선택을 했는지 살펴봐주시면 감사하겠습니다.

---

# OCR Pipeline System
- 기간 : 2024.06 ~ 2024.09 (4개월)
- 역할 : 시스템 기획부터 구현까지 모든 과정
- 결과 (성과) : 정확도 99%, 에러율 1% 미만의 안정적인 OCR 파이프라인 구축
- 비즈니스에 주는 영향 : 안정적인 데이터 수집 기반을 구축하여 서비스 개발 및 운영의 안정성 확보

## 프로젝트 개요 : 

병원 검사 결과 이미지에서 실시간으로 검사 결과 데이터를 추출해 데이터베이스에 적재하는 OCR 파이프라인 시스템을 설계하고 구현하는 프로젝트를 진행했습니다.
환자의 검사 결과를 바탕으로 "시력 교정 수술 추천 서비스"나 "렌즈 사이즈 추천 서비스"를 운영하고 있었기 떄문에, 안정적인 파이프라인을 구축해야만 안정적인 서비스를 운영할 수 있는 상황이었습니다.

<figure>
<img src="/post/Portfolio/OCR_pipeline.png" alt="OCR Pipeline" width="100%" />
<figcaption>그림1. OCR Pipeline 구조</figcaption>
</figure>

제가 구성한 파이프라인 구조는 그림1과 같습니다.
6가지 종류, 총 40~50대의 검사장비에서 검사를 진행하고 이를 실시간으로 OCR하고 추출된 데이터를 DB에 적재하게 됩니다. 

**파이프라인을 설계하면서 정의했던 목표는 크게 2가지입니다.**

1. 에러가 발생하지 않고 안정적인 상태
   - 안정적인 서비스 개발 및 운영을 위해서
2. 99% 이상의 OCR 정확도
   - "검사 결과"이기 때문에 OCR 오류가 치명적일 수 있음

**프로젝트가 끝나고 결과 혹은 성과는 다음과 같습니다.**

1. 에러율 1% 미만의 안정적인 파이프라인 구조
   - 기능과 역할이 명확하게 구분된 객체지향적인 코드 구조
   - 문제 이유와 범위가 명확하게 보이는 에러 로그
   - 지속적인 모니터링 시스템
   - 비동기구조 적용으로 속도 향상
   - 유닛 테스트와 타입 검증
2. 99% 이상의 OCR 정확도
   - 이미지 전처리를 통해 정확도 향상
   - 테스크의 특성을 활용해 최적화된 모델 사용 및 후처리 로직으로 목표 정확도 달성

이러한 결과를 얻기 위해 어떤 선택들을 했는지에 대해 정리했습니다.

## 프로젝트 시작할 때의 상황 : 

처음 프로젝트를 시작할 때의 상황은 전임자가 프로젝트르 진행하다가 중간에 떠난 상황이었습니다.
알 수 없는 에러로그가 쌓이고 있었고, OCR 모델의 정확도는 알 수 없었습니다.
어떤 문제를 해결하려고 해도 어디서 발생한 에러인지, 그 범위는 어디까지인지 알 수 없었습니다.
또 절차지향적으로, 정확히는 하나의 .py에 구조없이 구현된 코드들은 기능과 역할이 모호했습니다.

**목표를 달성하기 위해서는 코드 구조를 개선하며 에러를 잡아나가야 했고, OCR 모델 개선해야 했습니다.**

## 맞으면서 배우다, 객체지향 설계의 중요성 :

무자비하게 쌓인 코드들을 보면서, 머리로 이해했던 1기능 1함수 원칙이나 디자인 패턴 등 코드를 잘 짜기 위한 방법들을 마음으로 이해할 수 있었습니다.
여러 기능이 하나의 함수에 작성되어있고, 타입힌트도 전혀 작성되어있지 않은 코드를 이해하고 디버깅하는 과정은 굉장히 어려웠습니다.

하지만 이런 코드를 이해하고 고쳐나가는 과정은 코드를 작성하는 능력을 키우는데 굉장히 큰 도움이 됐습니다.
이해하기 쉽고 디버깅이 쉬운 코드를 작성하기 위한 나름의 규칙들을 세울 수 있었습니다.

1. 함수에는 꼭 하나의 기능만, 객체에는 하나의 역할만 부여하기
2. 객체 지향의 꽃은 추상화, 입력과 출력만 신경쓸 수 있도록

이를 고려해 코드를 작성했고 문제를 하나씩 고쳐나갈 수 있었습니다.
에러의 범위와 원인을 파악하기 쉬워졌고, 전체 문제를 작은 문제들로 쪼갤 수 있었습니다.

## 문제를 정확히 이해하기, 비동기 구조로 속도 향상 :

<figure>
<img src="/post/Portfolio/OCR_server_threadpool.png" alt="OCR Server 구조" width="80%" />
<figcaption>그림2. OCR Server 구조</figcaption>
</figure>

client와 server에서 실행되는 로직은 그림2와 같습니다.
처음 프로젝트를 인수인계 받을 때 동시에 여러 이미지를 처리하더라도 OCR 속도가 1초 미만이어야 한다고 했습니다.
그 이유는 Client 프로그램에서 Server로부터 응답이 늦게 오면, 그 다음에 진행되는 작업도 늦어지게 되고, 이는 고객에게 불편함을 주기 때문입니다.

Client에서 OCR 성공 여부를 확인할 필요가 있나? 에 대한 의문에서 시작했습니다.
이미지 송수신 여부만 확인하면 되기 때문에 주고 받을 성공여부에 대한 의미를 재정의했습니다.
그리고 Server에서의 역할을 구분했고, **OCR 과정이 속도가 오래걸리더라도 Client에는 영향을 미치지 않는 구조**로 재정의할 수 있었습니다.

## 런타임 에러 줄이기, pytest를 활용한 unit test와 mypy를 활용한 타입 검증 : 

안정적인 파이프라인을 운영하기 위해 런타임 에러를 줄일 수 있는 방법에 대해 고민했습니다.

런타임 에러를 줄이기 위해 사용한 방법은, pytest를 통한 unitest와 mypy를 이용한 타입 검증입니다.
작게 쪼개놓은 기능이나 역할들이 잘 수행되는지 unit test를 통해 미리 확인하고, 주고 받는 값들의 타입들이 맞는지 미리 확인하는 작업을 CI과정에서 진행했습니다.

이를 통해 어떤 기능을 추가하거나 수정했을 때 발생할 수 있는 런타임 에러들을 미리 검증하고 사전에 파악할 수 있었습니다.

## 문제에 특화된 모델 사용하기, OCR 정확도 확보 :

<figure>
<img src="/post/Portfolio/OCR_tritonserver.png" alt="OCR Model" width="50%" />
<figcaption>그림3. OCR Model</figcaption>
</figure>

안정적인 파이프라인이 어느정도 완성된 다음에는 99%이상의 OCR 정확도를 어떻게 달성할 수 있을지에 대한 고민을 했습니다.
이를 위해서 문제의 특징을 사용했습니다.

OCR은 크게 2단계로 구분됩니다. 위치를 찾는 Text Detection과 텍스트를 인식하는 Text Recognition입니다.
검사장비에서 생성되는 검사 이미지는 고정되니까 위치 정보를 사전에 정의해놓을 수 있었습니다.
따라서 텍스트를 인식하는 부분에 특화된 모델만이 필요했습니다.
여러 모델을 찾던 중 TrOCR이라는 오픈소스 모델을 발견했고, 이 모델이 개발된 동기가 Text Detection은 추후로미루고 Text Recognition에 특화된 모델 먼저 만들겠다는 것입니다.

이미지 전처리와 결과 후처리 작업을 추가하니, 200건정도로 구성한 테스트 셋에서 99%이상, 거의 100%에 가까운 정확도를 확인할 수 있었습니다.

모델 배포는 온프레미스로 진행했고, TritonServer를 사용했습니다.
TritonServer를 선택한 주요 이유는 동적 배치 처리와 동시성 관리를 쉽게 구현할 수 있고, 이를 통해 처리량을 달성할 수 있기 때문입니다.

---

# ML 시스템 설계 및 구현
- 기간 : 2024.09 ~ 2024.10 (2개월)
- 역할 : 문제정의, 프로젝트 설계, 구현까지 모든 과정
- 결과 (성과) : 데이터 일관성 확보, 실제 성능 모니터링 구축
- 비즈니스에 주는 영향 : 실제 서비스 상황에서의 성능 확인

입사했을 때 회사에서는 시력교정술 수술 추천이라는 ML을 이용한 서비스를 운영 중이었습니다.
이를 살펴봤을 때 몇가지 문제점들이 보였습니다. 이를 정의하고 해결해나가면서 ML system을 설계하고 구현하는 프로젝트를 진행했습니다.

제가 정의한 문제는 다음과 같습니다.

**1. 데이터 일관성 확보가 안되고 있다.**
학습 및 실험에서 사용하는 데이터와 추론에서 사용하는 데이터가 다르다.
데이터 웨어하우스에서 데이터를 조합하는 방식 등의 전처리 방식, 불러오는 로직 차이 등으로 인해 실험과 추론 상황에 사용되는 데이터가 달랐습니다.
이런 상황에서는 실험에서 판단한 일반화 성능이 추론 상황에서 보장이 안될 수 있는, 치명적인 상황입니다.

**2. 모델에 대한 모니터링을 하고 있지 않다.**
모델이 실제 서비스 상황에서 어떤 성능을 보이는지, data shift 같은 건 없는지 등을 확인하고 있지 않았습니다.
데이터는 계속 바뀌고, 이에 따라 모델의 성능이 변할 수 있기 때문에 이를 지속적으로 확인하고 재학습시키는 과정이 필요하다고 판단했습니다.

이 2가지 문제를 해결하고자 했고, Feature store와 Moninitoring 기능을 개발하여 전체적인 ML 시스템을 완성했습니다.

## 대략적인 구조 : 

<figure>
<img src="/post/Portfolio/ML_system.png" alt="ML system" width="100%" />
<figcaption>그림4. ML system</figcaption>
</figure>

- 개별적으로 외부 데이터에서 추출해서 사용하던 부분을 Aiflow DAG를 활용해 지속적으로 DW에 업데이트되게 수정
- Feature Store를 통해 데이터 일관성을 확보
- Monitoring 기능을 통해 추론 상황에서 성능 확인, Data shift 모니터링

## 데이터 일관성을 확보하자, Feature Store 구현 : 

가장 중요하게 생각하고, 이 프로젝트를 시작하게 된 이유입니다.

기존에는 실험 환경과 추론 환경에서 서로 다른 데이터 전처리 로직을 사용하고 있었습니다. 데이터 웨어하우스에서 데이터를 조합하는 방식, 불러오는 로직의 차이로 인해 학습 시와 추론 시 사용되는 피처가 달랐습니다. 이는 모델의 일반화 성능을 보장할 수 없는 치명적인 문제였습니다.

이 문제를 해결하기 위해 Feature Store를 구축하여 데이터 일관성을 확보했습니다. 중앙화된 피처 저장소를 만들어 모든 피처를 Feature Store에 저장하여 실험과 추론에서 동일한 데이터를 사용할 수 있게 했습니다. 피처 정의와 값의 버전을 관리하여 재현 가능성을 확보했고,일관된 피처 생성 프로세스를 구축했습니다. 

결과적으로 실험 환경과 추론 환경에서 100% 동일한 피처를 사용할 수 있게 되어, 모델의 일반화 성능을 신뢰할 수 있게 되었습니다. 또한 피처 재사용성과 개발 효율성도 크게 향상되었습니다.


## 데이터 분포 변화는 없나? Monitoring 구현 :

모델이 실제 서비스 상황에서 어떤 성능을 보이는지, 데이터 분포 변화가 있는지 등을 지속적으로 모니터링하는 것은 ML 시스템 운영의 핵심입니다. 데이터는 계속 변화하고, 이에 따라 모델의 성능이 변할 수 있기 때문에 이를 지속적으로 확인하고 재학습시키는 과정이 필요했습니다.

구현한 모니터링 기능으로는 실시간 성능 모니터링이 있습니다. 추론 요청에 대한 예측 결과와 실제 결과를 비교하여 모델의 성능을 실시간으로 추적합니다. 정확도, 정밀도, 재현율 등의 메트릭을 지속적으로 계산하고, 성능 저하 시 즉시 알림을 발생시킵니다.

데이터 Drift 감지 기능도 구현했습니다. 입력 데이터의 분포 변화를 감지하여 모델 성능 저하의 원인을 사전에 파악합니다. 피처별 통계량(평균, 표준편차, 분포)을 학습 시점과 비교하고, 임계값을 초과하는 변화가 있을 때 경고를 발생시킵니다.

모델 Drift 모니터링도 지속적으로 수행합니다. 모델의 예측 분포가 학습 시점과 비교하여 얼마나 달라졌는지를 추적합니다. 예측값의 분포 변화, 신뢰도 점수 변화 등을 모니터링하여 모델의 안정성을 평가합니다.

자동화된 알림 시스템도 구축했습니다. 성능 지표나 drift 지표가 임계값을 초과할 때 담당자에게 자동으로 알림을 보내는 시스템으로, Slack, 이메일 등을 통해 즉시 상황을 파악할 수 있도록 했습니다.

결과적으로 모델의 성능 변화를 사전에 감지할 수 있게 되어, 성능 저하 시 즉시 대응할 수 있었습니다. 데이터 drift가 발생했을 때도 원인을 빠르게 파악하고 적절한 조치를 취할 수 있어 모델의 안정성을 크게 향상시켰습니다.

---

# Lens Size Recommendation System
- 기간 : 2025.03 ~ 현재 (5개월)
- 역할 : 문제정의, 프로젝트 설계, 구현까지 모든 과정
- 결과 (성과) : 
- 비즈니스에 주는 영향 : 

<figure>
<img src="/post/Portfolio/Lenze_size_reco.png" alt="lenze size reco" width="100%" />
<figcaption>그림5. 렌즈 사이즈 추천 서비스</figcaption>
</figure>

렌즈 삽입술 후의 결과를 예측해서, 렌즈 사이즈를 선택하는데 도움을 주는 서비스를 개발하는 프로젝트를 진행했습니다.
프로젝트는 다음의 의문을 해결하는 것부터 시작했습니다.

## 예측 성능을 어떻게 평가할 수 있을까? :

<figure>
<img src="/post/Portfolio/Lenze_size_evaluate.png" alt="how to evalute" width="100%" />
<figcaption>그림6. 예측값 평가 방법</figcaption>
</figure>

그림 6처럼 고객은 4개의 렌즈 사이즈 중 하나에 대해서 수술을 받게 됩니다.
따라서 4개의 예측 결과 중 하나에 대한 실제 결과값을 알 수 있으며, 나머지 3개에 대한 실제 값은 알 수 없습니다.
이러한 선택의 문제에서 예측 성능은 어떻게 평가할 수 있을지에 대한 고민이 있었습니다.

이에 대한 해답을 "인과추론"에서 얻을 수 있었습니다.

<figure>
<img src="/post/Portfolio/Lenze_size_RCT.png" alt="RCT" width="80%" />
<figcaption>그림7. RCT 상황에서의 평가</figcaption>
</figure>

만약 고객이 랜덤으로 사이즈를 선택해 수술을 받았다면, 이 고객과 비슷한 환자는 다른 사이즈로 수술을 받았다고 생각할 수 있습니다. 그리고 이를 통해 A에 대한 결과를 간접적으로 평가할 수 있습니다.
즉, 처치(사이즈)별로 분포가 겹쳐있다면 선택하지 않은 사이즈에 대한 예측값도 간접적으로 평가가 가능합니다.

<figure>
<img src="/post/Portfolio/Lenze_size_OS.png" alt="Observaional Study" width="80%" />
<figcaption>그림8. 실제 상황에서의 평가</figcaption>
</figure>

하지만 실제 상황에서는 모든 처치의 분포가 겹쳐 있지 않습니다.
왜냐하면 환자의 눈의 조건을 보고 의사가 사이즈를 결정하기 때문입니다.

그림8처럼 13.2만을 사용할 환자의 경우에는 13.2외에 다른 사이즈에 대한 예측값을 신뢰하기 어렵습니다.
이러한 불확실성을 어떻게 수치적으로 표현할 수 있을지에 대해 고민했습니다.

## 보장할 수 있는 예측값의 범위는? :

가장 먼저 예측 평가지표 (MSE, MAE)로 성능을 확인한 예측의 범위를 정해야 합니다.
이는 성향 점수 (propensity score)를 추정함으로써 정할 수 있습니다.
성향 점수는 처치를 선택할 확률을 의미하며, $P(T|X)$을 추정하는 문제입니다.

성햠 점수 추정 모델로 고객별로 데이터에서 처치의 분포가 겹치는 범위를 정할 수 있습니다.
(인과추론의 가장 기본적인 가정인 양수성을 만족하는 범위를 찾는다고도 할 수 있습니다)

<figure>
<img src="/post/Portfolio/Lenze_size_propensity.png" alt="Positivity" width="80%" />
<figcaption>그림9. 양수성 조건 만족하는 범위</figcaption>
</figure>

그림9에서 고객 A는 12.1, 12.6, 13.2에 대한 예측 성능을 신뢰할 수 있고, 고객 B는 12.6에 대한 예측 성능을 신뢰할 수 있습니다.

## 신뢰할 수 없는 처치의 예측은? :

신뢰할 수 있는 정도를 예측 범위로 나타낼 수 있고, 따라서 양수성이 보장되지 않는 예측 범위의 예측 범위를 넓게 그려주고자 했습니다.
양수성이 보장되는 처치의 예측값은 신뢰구간을 예측해 보여주고, 나머지 처치에 대해서는 "partial identification"과 같은 개념을 사용해 예측 범위를 추정했습니다.

<figure>
<img src="/post/Portfolio/Lenze_size_PI.png" alt="Prediction Interval" width="80%" />
<figcaption>그림10. 양수성 조건에 따른 예측 구간</figcaption>
</figure>

고객 A에 대한 예시입니다. 양수성이 보장되는 12.1, 12.6, 13.2보다 13.7의 예측 범위가 더 넓고, 이를 통해 불확실성을 표현하고 있습니다.

---

# AI Chatbot Project
- 기간 : 2024.11 ~ 2025.02 (4개월)
- 역할 : 
- 결과 (성과) : 
- 비즈니스에 주는 영향 : 



RAG 기반 챗봇 운영


## RAG Pipeline 구조







---

# Diabetic Retinal Disease Segmentation

병변 탐지 모델 개발

- 기간 : 2024.04 ~ 2024.06 (3개월)
- 역할 : 문제정의, 프로젝트 설계, 구현까지 모든 과정
- 결과 (성과) : 정확도 99%, 에러율 1% 미만의 안정적인 OCR 파이프라인 구축
- 비즈니스에 주는 영향 : 안정적인 데이터 수집 기반을 구축하여 서비스 개발 및 운영의 안정성 확보


