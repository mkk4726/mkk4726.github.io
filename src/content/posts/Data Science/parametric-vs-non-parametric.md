---
title: "Parametric vs Non-Parametric, GBDT는 왜 non-parametric일까?"
date: "2025-07-22"
excerpt: "Parametric과 Non-Parametric에 대한 간단한 설명"
category: "Data Science"
tags: ["parametric", "non-parametric", "machine-learning", "statistics"]
---


# Parametric이란?

| 영어                        | 한국어         | 설명                               |
| ------------------------- | ----------- | -------------------------------- |
| **parametric model**      | **모수적 모델**  | 고정된 수의 파라미터(모수)를 갖는 모델           |
| **parametric assumption** | **모수적 가정**  | 데이터가 특정한 분포 형태(예: 정규분포)를 따른다는 가정 |
| **non-parametric model**  | **비모수적 모델** | 파라미터 수나 함수 형태를 가정하지 않는 유연한 모델    |

데이터에서 패턴을 근사해내는게 Machine Learning의 핵심이라고 할 수 있습니다.
이때 데이터가 특정한 함수 형태를 따른다고 가정하거나, 모델의 구조(예: 선형 회귀처럼)가 고정되어 있는 경우를 모수적(parametric) 모델이라고 합니다.

# Parametric vs Non-Parametric

| 구분                  | Parametric     | Non-parametric           |
| ------------------- | -------------- | ------------------------ |
| **모델 구조**           | 사전에 고정됨        | 유연하고 데이터 기반              |
| **모수(parameter) 수** | 고정             | 데이터가 많아지면 증가함            |
| **복잡도 제어**          | 파라미터 조정        | 모델 자체의 구조 변화로 조정         |
| **예시**              | 선형 회귀, 로지스틱 회귀 | GBDT, KNN, 랜덤포레스트, 커널 회귀 |

반대로 Non-parametric 모델은 모델의 형태나 구조를 사전에 가정하지 않고, 데이터를 통해 모델의 구조를 유연하게 만들어나가는 것을 의미합니다.

# 왜 GBDT는 non-parametric일까?

| 이유        | 설명                                |
| --------- | --------------------------------- |
| 파라미터 수 증가 | 데이터가 늘면 트리 개수나 깊이가 커져서 구조 자체가 변화함 |
| 구조 유연성    | 특정 함수 형태를 가정하지 않음 (예: 선형성)        |
| 자유도       | 과적합 위험도 있지만, 그만큼 복잡한 함수도 학습 가능    |
| 학습 대상     | 데이터가 가르쳐주는 방식에 따라 함수 구조 자체가 결정됨   |

GBDT는 잔차를 보완하는 방식으로 여러 개의 약한 결정 트리를 순차적으로 학습하고 누적하는 구조를 가지지만, 
트리의 개수, 깊이, 노드 수, 분할 규칙 등은 데이터 양과 복잡도에 따라 계속 늘어나거나 바뀔 수 있습니다.
이런 점에서 GBDT는 non-parametric 모델이라고 할 수 있습니다.




