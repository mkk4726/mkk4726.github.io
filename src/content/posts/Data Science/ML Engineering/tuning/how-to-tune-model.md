---
title: "내가 모델을 튜닝해나가는 방식"
date: "2025-09-15"
excerpt: "모델을 튜닝하는 방법에 대한 생각 정리"
category: "Engineering"
tags: ["Tuning"]
---

# 모델 튜닝을 위한 체계적인 접근법

tabular data, image 등의 데이터에 대한 모델들을 만들 때 내가 가져가는 사고흐름을 정리해보자. 나의 사고방식에 가장 영향을 많이 준 책은 흔히 "케창딥"이라고 부르는 책이다.

## 기본 원칙: 과적합 우선, 그 다음 일반화

모델 튜닝에서 내가 따르는 핵심 원칙은 간단하다. 첫째, 과적합을 먼저 시킨다. 둘째, 규제를 가하면서 일반화 성능을 확보한다.

과적합을 먼저 시키는 이유는 학습할 수 있는 패턴 자체가 존재하는지 확인하기 위해서다. 모델이 학습 데이터조차 제대로 못 배운다면, 이건 모델의 capacity가 부족하거나 데이터에 패턴이 없을 가능성이 높다. 그래서 먼저 모델이 학습 데이터를 완벽하게 학습할 수 있도록 과적합 상태를 만든 다음, 그 다음에 regularization, dropout, subsampling 같은 규제 기법을 써서 학습 셋과 테스트 셋 사이의 차이를 줄여나간다.

결국 가장 기본적인 개념인 bias-variance tradeoff 사이에서 중간지점을 찾아나가는 과정이다. ML이나 DL의 목표는 일반화된 패턴을 찾아서 일반화된 성능을 확보하는 것이다. 학습하지 않은 데이터셋에서의 성능을 일반화된 성능이라고 표현할 수 있겠다.

## 데이터 중심 접근법의 중요성

프로젝트하면서 느끼는 건 새로운 모델 구조를 제시하는 정도의 수준이 아닌 이상, 대부분 데이터가 95% 이상 역할을 한다는 것이다. 모델의 성능이 일정 이상 값보다 안 줄어들 때, 일반화된 패턴이 없는, 데이터가 가지고 있는 노이즈 자체가 굉장히 크다는 의심이 들 때가 있다.

이런저런 것들을 시도할 때 일정 이상 값보다 안 줄어들면 데이터를 뜯어보면서 노이즈가 발생하는 부분이 있는지, 패턴 자체가 없는지를 뜯어봐야 한다.

이번에 렌즈 추천 프로젝트도 데이터를 뜯어보면서 고쳤던 부분이 많았다. 측정 기기의 오류로 임상적 기준을 벗어나는 값들, 전처리 과정에서의 이슈로 사람이 수작업으로 입력하는 값들, 더러운 데이터 처리할 때의 문제들, 의학적 지식에 기반해서 새로운 피처를 찾아낸 적도 있다(나이 - 렌즈 두께). 렌즈 자체가 가지고 있는 특성, 두께 등도 고려했다.

모델 튜닝, 데이터 전처리 등을 거쳐서 기존에 사용하던 모델보다 약 20% 성능향상을 보였다. (MAE 기준)

## Data Leakage 방지의 중요성

튜닝할 때 가장 주의해야 할 점이 data leakage다. 모델이 테스트 데이터셋을 보진 않지만, 결국 테스트 셋을 통해 하이퍼파라미터를 정하게 되기 때문에 과적합이 될 수 있다.

이를 방지하려면 반드시 validation set을 별도로 분리해서 하이퍼파라미터 튜닝에만 사용하고, 테스트 셋은 최종 평가할 때만 써야 한다. cross-validation을 적절히 활용해서 모델의 일반화 성능을 더 정확하게 평가하고, early stopping 같은 기법으로 과적합을 방지하는 것도 중요하다.

이런 체계적인 접근을 통해 데이터의 본질적인 패턴을 발견하고, 실제 운영 환경에서도 안정적인 성능을 보이는 모델을 개발할 수 있다.