---
title: UMAP 에 대해 정리"
date: "2025-09-11"
excerpt: "UMAP에 대해 이해해보기"
category: "Data Science"
tags: ["statistics"]
---

참고자료
- 1: [블로그](https://velog.io/@stella_y/%EC%B0%A8%EC%9B%90-%EC%B6%95%EC%86%8C-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98%EC%9D%84-%EB%B9%84%EA%B5%90%ED%95%B4%EB%B3%B4%EC%9E%90-PCA-T-sne-UMAP)
- 2: [유튜브](https://www.youtube.com/watch?v=eN0wFzBA4Sc)

---

Uniform Manifold Approximation and Projection

> 고차원에서 그래프(topology)를 만들고, 이를 저차원으로 투영한다.

dimension reduction 중 가장 성능이 좋다고 알려져 있다.



## UMAP 개요

UMAP(Uniform Manifold Approximation and Projection)은 고차원 데이터를 저차원으로 축소하는 비지도 학습 알고리즘입니다. 데이터의 지역적 구조(near structure)와 전역적 구조(global structure)를 모두 보존하는 것이 특징입니다.

## UMAP의 주요 특징

### 1. 매니폴드 학습 기반
- 데이터가 저차원 매니폴드에 존재한다고 가정
- 데이터의 근본적인 구조를 학습하여 차원을 축소

### 2. 지역적 구조 보존
- 가까운 데이터 포인트들이 저차원에서도 가깝게 유지
- t-SNE와 유사한 클러스터 보존 능력

### 3. 전역적 구조 보존
- 데이터의 전체적인 위상적 구조를 유지
- PCA와 같은 전역적 차원 축소 알고리즘의 장점도 가짐

## 차원 축소 알고리즘 비교

다음은 PCA, t-SNE, UMAP의 주요 차이점과 특징을 비교한 표입니다:

| 특징 | PCA | t-SNE | UMAP |
|------|-----|-------|------|
| **원리** | 선형 변환 (분산 최대화) | 확률적 접근 (KL 발산 최소화) | 매니폴드 학습 기반 그래프 투영 |
| **속도** | 매우 빠름 | 느림 | 빠름 (t-SNE보다 2-10배 빠름) |
| **구조 보존** | 전역적 구조 강함 | 지역적 구조 강함 | 지역적 + 전역적 구조 균형 |
| **재현성** | 완전 결정적 | 랜덤성 존재 | 랜덤 시드 고정시 결정적 |
| **파라미터** | n_components | perplexity, learning_rate | n_neighbors, min_dist |
| **확장성** | 우수 | 제한적 (메모리 제약) | 우수 (대규모 데이터 가능) |
| **시각화 품질** | 보통 | 우수 (클러스터 분리) | 우수 (구조 보존) |
| **주요 용도** | 초기 탐색, 특징 추출 | 시각화, 클러스터링 | 시각화, 일반적인 차원 축소 |
| **단점** | 비선형 구조 파악 어려움 | 전역 구조 왜곡, 느림 | 하이퍼파라미터 튜닝 필요 |

### 비교 분석

- **PCA vs UMAP**: PCA는 선형적이고 빠르지만 비선형 구조를 잘 파악하지 못함. UMAP은 비선형 구조도 잘 보존하면서 속도도 빠름
- **t-SNE vs UMAP**: 두 알고리즘 모두 지역적 구조를 잘 보존하지만, UMAP은 전역적 구조도 유지하고 속도면에서 우위에 있음
- **활용 시 고려사항**: 빠른 탐색에는 PCA, 세밀한 시각화에는 t-SNE나 UMAP, 균형잡힌 접근에는 UMAP 추천

## UMAP의 장점과 한계점

UMAP은 강력한 차원 축소 알고리즘으로 많은 장점을 가지고 있지만, 모든 상황에서 최고의 선택은 아닙니다. 데이터셋의 특성, 분석 목적, 그리고 필요한 트레이드오프에 따라 최적의 알고리즘 선택이 달라집니다.

### UMAP의 강점

#### 1. 속도와 확장성
- t-SNE에 비해 훨씬 빠른 학습 속도로 대규모 데이터셋에 실용적임
- 더 많은 데이터 포인트를 처리할 수 있어 확장성에서 우위

#### 2. 전역적 구조 보존
- t-SNE와 달리 지역적 관계뿐만 아니라 전역적 데이터 구조도 유지
- 클러스터 간 간격이 더 의미있게 표현되어 데이터의 전체적인 그림을 잘 보여줌

#### 3. 다목적 활용 가능성
- 단순 시각화뿐만 아니라 다른 머신러닝 모델의 입력으로도 활용 가능
- t-SNE와 달리 임베딩 결과의 재사용성이 높음

#### 4. 강력한 이론적 기반
- 리만 기하학과 대수 토폴로지의 원리에 기반한 견고한 수학적 토대
- t-SNE보다 더 탄탄한 이론적 뒷받침을 가짐

### UMAP의 한계점

#### 1. 하이퍼파라미터 민감성
- `n_neighbors`와 `min_dist` 같은 하이퍼파라미터 선택이 결과에 큰 영향
- 낮은 값은 지역적 세부사항을 과도하게 강조할 수 있음
- 높은 값은 서로 다른 클러스터를 병합할 위험이 있음
- 최적값을 찾기 위해 많은 시행착오가 필요할 수 있음

#### 2. 거리 보존의 한계
- 클러스터 간 상대적 관계는 t-SNE보다 잘 보존하지만,
- 클러스터 간 구체적 거리와 클러스터 크기는 오해의 소지가 있음
- 저차원 플롯의 거리가 원래 고차원 공간의 거리를 정확히 반영하지 않을 수 있음

#### 3. 확률적 특성
- 확률적 알고리즘으로 동일한 데이터에 대해도 실행마다 약간씩 다른 결과 생성
- 특정 랜덤 시드를 설정하지 않으면 재현성에 영향을 미침
- 결과의 신뢰성과 일관성에 영향을 줄 수 있음

#### 4. 해석상의 위험
- 시각적으로 매력적인 플롯이 과도한 해석을 유발할 수 있음
- 클러스터의 특정 모양과 간격이 알고리즘의 인공물일 수 있음
- 2024년 Nature 기사에서 제기된 바와 같이 유전체학 커뮤니티에서 논란이 된 바 있음

## 다른 차원 축소 알고리즘과의 비교

최적의 알고리즘 선택은 구체적인 작업에 따라 달라집니다:

### PCA (주성분 분석)
- **장점**: 매우 빠르고 해석이 용이한 직교 성분 생성, 선형 관계 파악에 적합
- **단점**: 비선형 관계를 잘 포착하지 못함
- **추천 용도**: 빠른 탐색과 해석이 필요한 경우

### t-SNE
- **장점**: 밀집된 클러스터 시각화에 탁월
- **단점**: 전역 구조 왜곡, 대규모 데이터에서 느림
- **추천 용도**: 지역적 클러스터 구조 탐색이 주요 목적일 때

### 최신 알고리즘 (예: PaCMAP)
- **특징**: 지역적 구조와 전역적 구조 보존의 균형을 더 개선한 알고리즘들 등장
- **고려사항**: 특정 상황에서 UMAP보다 더 나은 선택지로 활용 가능

결론적으로 UMAP은 매우 강력한 도구이지만, 데이터의 특성과 분석 목적을 고려한 신중한 선택이 중요합니다. 각 알고리즘의 장단점을 이해하고 적절한 하이퍼파라미터 튜닝을 통해 최상의 결과를 얻을 수 있습니다.

## UMAP의 작동 원리

### 1단계: 고차원 공간에서 그래프 구성
- 각 데이터 포인트의 k-최근접 이웃을 찾아 그래프 생성
- 거리 척도와 이웃 개수를 조절하여 그래프의 밀도 설정

### 2단계: 저차원 공간으로 투영
- 고차원 그래프와 유사한 저차원 그래프를 생성
- 확률적 방법으로 그래프 간의 연결을 최적화

### 3단계: 최적화
- 그래프 구조를 유지하면서 저차원 공간에서의 거리를 최소화

## UMAP의 장점

1. **속도**: t-SNE에 비해 빠른 학습 속도
2. **확장성**: 대규모 데이터셋에도 적용 가능
3. **재현성**: 랜덤 시드 고정 시 동일한 결과 생성
4. **파라미터 조절**: `n_neighbors`, `min_dist` 등 직관적인 파라미터

## 주요 하이퍼파라미터

- `n_neighbors`: 고려할 이웃의 수 (지역 구조 vs 전역 구조 조절)
- `min_dist`: 저차원 공간에서 포인트 간 최소 거리
- `n_components`: 목표 차원 수
- `metric`: 거리 계산 방법

## 활용 분야

- 데이터 시각화 (2D, 3D 산점도)
- 클러스터링 전처리
- 이상치 탐지
- 생물정보학 (단일세포 RNA 시퀀싱 데이터)
- 자연어 처리 (워드 임베딩 시각화)

## 코드 예시 (Python)

```python
from sklearn.datasets import make_swiss_roll
import umap

# 데이터 생성
X, _ = make_swiss_roll(n_samples=1000, random_state=42)

# UMAP 적용
reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, random_state=42)
X_reduced = reducer.fit_transform(X)

# 시각화
import matplotlib.pyplot as plt
plt.scatter(X_reduced[:, 0], X_reduced[:, 1])
plt.show()
```

UMAP은 현대적인 차원 축소 알고리즘으로, 데이터 과학과 머신러닝 분야에서 점점 더 널리 사용되고 있습니다.
