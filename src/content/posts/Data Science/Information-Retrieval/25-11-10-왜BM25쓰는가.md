---
title: "BM25 vs Semantic Search"
date: "2025-11-10"
excerpt: "아직도 BM25를 쓰는 이유 정리해보기"
category: "Information Retrieval"
tags: ["IR"]
---

기본적인 검색 도구는 단어기반 검색 (TF-IDF, BM25)랑 의미적 검색 (Embedding).
단어기반 검색에서 의미적 검색으로 발전되어온 흐름에서, 아직도 단어기반 검색을 쓰는 이유가 뭐지?

> **Semantic Search(문장 임베딩 검색)** 은 “의미”를 잘 잡지만,
> **BM25** 는 “정확한 키워드 일치·효율·통제성”에서 여전히 강력하기 때문이에요.
>
> 그래서 실전에서는 둘을 **결합(Hybrid Search)** 해서 씁니다.

---

## BM25 vs Semantic Search의 본질 차이


BM25는 쿼리에 가장 잘 맞는 문서를 "단어" 기반으로 검색.
시멘틱 서치는 쿼리와 문서 모두 임베딩 벡터로 변환하고, 벡터의 유사도를 통해 계산.

| 구분          | **BM25 (Lexical Search)** | **Semantic Search (Embedding)** |
| ----------- | ------------------------- | ------------------------------- |
| **기반**      | 단어(lexical) 일치            | 의미(semantic) 유사도                |
| **입력 표현**   | 단어 단위 → TF, DF, 문서 길이     | 문장 전체 → 벡터 (768차원 등)            |
| **모델**      | 수식 기반 (IDF, TF, b, k₁)    | 신경망 기반 (Transformer 등)          |
| **언어 능력**   | 동의어, 문장 구조를 이해 못함         | 의미 유사, 동의어 인식 가능                |
| **효율**      | 매우 빠름 (역색인 + 정렬)          | 상대적으로 느림 (고차원 벡터 연산)            |
| **설명 가능성**  | 높음 (term weight 확인 가능)    | 낮음 (embedding 의미 해석 어려움)        |
| **데이터 요구량** | 없음 (통계 기반)                | 많음 (pretrained model 필요)        |

---

## “시멘틱 서치를 안 쓰는 이유” 정리 (현실적인 관점)

### 🧮 **정확한 키워드 매칭이 필요한 경우**

* 법률, 의학, 논문, 코드 검색처럼
  **단어 하나의 존재 여부가 매우 중요할 때**
* 예: `"NOT diabetic"` / `"Python 3.11"` / `"ICL vault"`
* 임베딩은 문맥 유사성 때문에 **"diabetic"과 "not diabetic"**도 유사하게 보이기도 해요 → **치명적 오탐**

📘 → BM25는 "단어가 포함되면 무조건 잡음"
→ **recall이 높음** (관련 문서를 놓치지 않음)

반면 semantic search는:
- 의미 기반이라 관련 문서를 놓칠 수 있음 (recall 낮음)
- 하지만 찾은 것들은 의미적으로 관련성이 높음 (precision 높음)

요즘 context를 길게 넣어줘도 되니까, 정확한 키워드 매칭으로 recall을 확보하는 BM25가 더 유리할 수 있겠다.
근데 그냥 단어가 포함된 것만 필터링 해주면 안되는건가?

> "쿼리 단어가 포함된 문서들만 필터링하고, 그 안에서 semantic search로 정렬하면 되지 않나?"

직관적인 발상이지만, 실제로는 **장점도 있고 치명적인 한계도** 있다.

```
사용자 쿼리 → 단어 포함 문서 필터링 (BM25의 역할 일부) → 필터링된 문서들만 임베딩 유사도 계산
```

즉 "키워드로 후보를 줄이고, 의미로 정렬"하는 방식. 이는 사실상 **하이브리드 검색의 축소형**이며, BM25를 정렬용이 아니라 필터용으로만 쓰는 형태.

| 장점 | 설명 |
|-----|------|
| **검색 범위 축소** | 임베딩 비교를 전 문서에 안 하고, "단어가 들어있는 문서만" 대상으로 함 → 속도 개선 |
| **의미 기반 정렬 유지** | 단순 키워드 매칭보다 의미 유사도가 반영되어 더 자연스러운 순서 가능 |
| **구현 단순** | BM25 점수 안 써도 되고, "must contain" 필터만 있으면 됨 (`match` query + vector search) |

→ 이 구조는 Elasticsearch나 OpenSearch에서 `"must"` 조건과 `"knn"`을 동시에 쓰는 전형적인 패턴

> 하지만 "그렇게만 하면" 생기는 치명적 한계가 존재

1. 문제 1: 키워드가 조금만 달라져도 문서가 누락됨
- `"diabetes medication"` 쿼리에서 `"diabetic drugs"` 문서는 **단어가 다르다**는 이유로 필터 단계에서 **제외됨**
- 하지만 의미는 완전히 같습니다
- → **의미 검색의 강점(동의어 처리, 문장 이해)** 을 초반 필터가 차단해버림

> 📘 **"단어 필터링"은 semantic search의 핵심 장점(의미 확장)을 잘라먹습니다.**

2. 문제 2: 필터가 너무 강하면 recall(검색률) 급락**
- 예: 쿼리가 `"machine learning applications"`인데 문서가 `"uses of ML"`이라면
- 키워드 매칭은 실패하지만, 의미상으론 완전히 관련된 문서
- → 찾고 싶은 문서가 필터에서 잘려나가는 문제 발생

3. 문제 3: 필터가 너무 약하면 속도 이점 사라짐**
- 필터 조건을 너무 느슨하게 하면 "임베딩 계산 대상"이 많아짐
- 결국 전수 검색과 다를 바 없어서 오히려 느려짐

4. 문제 4: 필드별 중요도 조정 불가**
- BM25는 "title 3배, body 1배, tags 2배" 같은 필드 가중치 조절이 쉬움
- 임베딩 검색은 이런 fine control이 거의 불가능
- → title과 body가 같은 임베딩으로 섞이면 "컨트롤 불가 블랙박스"가 됨

5. 문제 5: 정량적 순위가 없음**
- 필터링은 이진법적 판단(in/out)만 가능
- BM25는 0~100점 같은 점수를 주고, **상위 K개만 선택** 가능
  → 예: BM25 상위 1000개만 시멘틱 rerank

6. 문제 6: 단어 중요도를 무시함**
- 단순 필터링은 "the"와 "quantum"을 동등하게 취급
- BM25는 IDF, TF, 문서 길이를 고려해서 **점수**를 매김

> BM25는 단순 필터링이 아니라 **scoring system**이라서, "얼마나 관련 있는지" 정량화 + 효율적인 후보 선정이 가능

---

### ⚡ (2) **속도와 효율**

* BM25는 **역색인 구조** → 쿼리 단어 등장 문서만 스코어 계산
* 임베딩은 **모든 문서 벡터와 cosine 계산** 필요 (O(n))
* 규모가 수백만 문서 이상이면 BM25는 **밀리초(ms)**,
  임베딩 검색은 **수백 ms~초 단위**

📘 → 벡터 검색은 효율화를 위해 FAISS, HNSW 등의 인덱싱이 필요함

---

### 🔍 (3) **설명 가능성과 디버깅**

* BM25는 왜 그 문서가 선택됐는지 이유를 알 수 있음 (term weight, field boost 등)
* 임베딩은 “의미상 비슷해서”라고밖에 설명할 수 없음

📘 → 서비스 운영 시 “왜 이게 검색돼요?” 질문에 BM25는 답 가능, 임베딩은 불투명

---

### 🧩 (4) **언어 / 도메인 한정성**

* 임베딩은 **언어, 도메인**에 따라 성능이 달라짐
  (ex. 의학, 법률, 기술 문서에서는 일반 모델이 약함)
* BM25는 언어 불문, 단어 일치만으로 동작
  (한국어든 영어든 동일하게 작동)

---

### ⚙️ (5) **데이터 업데이트의 편리함**

* BM25: 새 문서 추가 시 term-frequency만 갱신
* 임베딩: 새 문서 추가 시 **모델 inference + 벡터 삽입 + 인덱스 재빌드**

📘 → 대규모 데이터셋에서는 BM25가 유지 비용 훨씬 낮음

---

## 💡 3️⃣ 그래서 현실적인 결론: **둘을 "하이브리드"로 결합한다**

> 현대의 검색 시스템(Elasticsearch, OpenSearch, Pinecone, Vespa 등)은
> 거의 모두 **BM25 + Embedding Hybrid Search** 구조입니다.

### 🧠 실제 엔진들의 전략 선택

| 전략 | 설명 | 대표 사례 |
|-----|------|----------|
| **A. BM25 only** | 빠르고, 키워드 중심 검색 | Elasticsearch 기본 설정 |
| **B. Semantic only** | 의미 중심, recall ↑ precision ↓ | Pinecone, FAISS 벡터DB |
| **C. Keyword filter + Semantic rerank** | "단어 포함 문서"만 후보로, 의미로 정렬 | OpenSearch hybrid, Vespa, ChatGPT Retrieval Plugin 등 |
| **D. Full hybrid (BM25 + Embedding score 가중합)** | 둘 다 점수로 반영 | Google, Bing, HuggingFace search |

앞서 논의한 "단어 포함 필터 + 시멘틱 서치"는 **C번 전략**에 해당합니다. 실제로 "초기 Hybrid"의 가장 흔한 형태이지만, 대형 검색엔진들은 최종적으로 **D번 Full Hybrid**로 갑니다.

### 🔸 구조 개념 (Full Hybrid)

```text
사용자 쿼리
   │
   ├─► BM25 (Lexical) → 키워드 기반 상위 1000문서 (점수 계산)
   ├─► Embedding Search → 의미 기반 상위 1000문서 (점수 계산)
   │
   └─► Score 가중합 / Reranking (Hybrid)
       → 0.7 * bm25_score + 0.3 * semantic_score
```

### 🔸 실전 구현 예시

**전략 C: Keyword filter + Semantic rerank**
```python
# 1단계: 키워드 필터링 (단어 포함 여부만 체크)
filtered_docs = keyword_filter(query, must_contain=True)

# 2단계: 필터된 문서만 시멘틱 서치로 정렬
final_results = semantic_search(filtered_docs, query, top_k=10)
```

**전략 D: Full Hybrid (가중합)**
```python
# 1단계: BM25로 상위 1000개 추출 (점수 기반)
bm25_results = bm25_search(query, top_k=1000)

# 2단계: 같은 1000개에 대해 시멘틱 점수 계산
semantic_results = semantic_search(bm25_results, query)

# 3단계: 점수 가중합으로 최종 순위 결정
for doc in documents:
    doc.final_score = 0.7 * doc.bm25_score + 0.3 * doc.semantic_score

final_results = sorted(documents, key=lambda x: x.final_score, reverse=True)[:10]
```

→ 빠르고, 의미도 유지하고, 품질도 좋음 ✅

### 📊 전략별 비교

| 접근 방식 | 장점 | 단점 | 사용 예시 |
|----------|------|------|----------|
| **필터 후 semantic 정렬** | 빠르고 구현 간단 | 의미 확장력 손실, recall 감소 | OpenSearch `must + knn` |
| **완전 semantic search** | 의미 유사도 극대화 | 느림, 오탐 많음 | Pinecone pure vector DB |
| **BM25 + semantic score 가중합** | 정확도 + 의미 둘 다 확보 | 계산 복잡 | Google, Bing, ChatGPT Retrieval |

---

## ✅ 5️⃣ 정리 요약

| 항목        | BM25                                 | Semantic Search   |
| --------- | ------------------------------------ | ----------------- |
| **강점**    | 빠름, 정확한 키워드, 설명 가능                   | 의미 유사, 동의어 처리     |
| **약점**    | 의미 파악 불가                             | 속도 느림, 불투명, 구축 비용 |
| **좋은 전략** | Hybrid: BM25로 후보, Embedding으로 rerank |                   |

---

## 🎯 최종 결론

> **"단어 포함 필터 후 semantic ranking"** 은 성능과 효율 사이에서 좋은 타협점이긴 하지만,
> **semantic search의 진짜 강점(동의어, 의미 확장)** 을 제한해버립니다.
>
> 그래서 실제 대형 검색엔진들은 이 구조를 **부분적으로만 사용**하고,
> 최종적으로는 BM25 점수와 semantic score를 **가중합 rerank** 하는 **Full Hybrid**로 갑니다.

### 핵심 포인트

1. **BM25는 단순 필터가 아닌 scoring system**
   - "the"와 "quantum"의 중요도를 구분
   - 상위 K개를 정량적으로 선정 가능

2. **단순 키워드 필터링의 한계**
   - "diabetes medication" vs "diabetic drugs" 같은 동의어 놓침
   - recall 급락 또는 속도 이점 상실

3. **실전 전략**
   - 초기: Keyword filter + Semantic rerank (C 전략)
   - 최종: BM25 score + Semantic score 가중합 (D 전략)

4. **BM25는 여전히 필수**
   - 빠르고 통제 가능한 키워드 검색 엔진
   - Semantic Search는 완전 대체가 아니라 **보완 관계**

---

# multi-stage 느낌으로 구성한 것도 있네

논문 [“Learning-to-Rank with BERT in TF-Ranking” (Han et al., Google Research)](https://research.google/pubs/learning-to-rank-with-bert-in-tf-ranking)
- 먼저 **BM25**(lexical retriever)로 상위 1,000개 패시지 후보를 빠르게 추출  
- 이후 **BERT 기반 모델**로 이 1,000개를 정교하게 리랭킹  
- 즉, **“query → BM25(1,000개) → BERT rerank”** 방식이 실제 현업·학술적으로 표준 구조임
