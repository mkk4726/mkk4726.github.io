{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeba7aaf",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"TF-IDF와 BM25 구현\"\n",
    "date: \"2025-11-10\"\n",
    "category: \"Information Retrieval\"\n",
    "tags: [\"IR\"]\n",
    "excerpt: \"TF-IDF, BM25랑 역색인 구현하기\"\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "267bbca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = {\n",
    "    \"D1\": \"I love machine learning\",\n",
    "    \"D2\": \"machine learning is powerful\",\n",
    "    \"D3\": \"I love deep learning\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29515371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': ['D1', 'D3'],\n",
       " 'love': ['D1', 'D3'],\n",
       " 'machine': ['D1', 'D2'],\n",
       " 'learning': ['D1', 'D2', 'D3'],\n",
       " 'is': ['D2'],\n",
       " 'powerful': ['D2'],\n",
       " 'deep': ['D3']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_inverted_index(docs):\n",
    "    \"\"\"\n",
    "    역색인(inverted index)을 구축합니다.\n",
    "    \n",
    "    Args:\n",
    "        docs: 문서 딕셔너리 {doc_id: text}\n",
    "    \n",
    "    Returns:\n",
    "        역색인 딕셔너리 {term: [doc_ids]}\n",
    "    \"\"\"\n",
    "    inverted_index = {}\n",
    "    \n",
    "    for doc_id, text in docs.items():\n",
    "        # 텍스트를 소문자로 변환하고 단어로 분리\n",
    "        terms = text.lower().split()\n",
    "        \n",
    "        for term in terms:\n",
    "            if term not in inverted_index:\n",
    "                inverted_index[term] = []\n",
    "            \n",
    "            # 문서 ID가 이미 리스트에 없으면 추가\n",
    "            if doc_id not in inverted_index[term]:\n",
    "                inverted_index[term].append(doc_id)\n",
    "    \n",
    "    return inverted_index\n",
    "\n",
    "# 역색인 구축\n",
    "inverted_index = build_inverted_index(docs)\n",
    "inverted_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10988dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term = 'love'\n",
    "\n",
    "terms = docs['D1'].lower().split()\n",
    "terms.count(term.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d13f681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 단어 사전 (Vocabulary): ['deep', 'i', 'is', 'learning', 'love', 'machine', 'powerful']\n",
      "차원 수: 7\n",
      "\n",
      "TF-IDF 벡터 (DataFrame):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deep</th>\n",
       "      <th>i</th>\n",
       "      <th>is</th>\n",
       "      <th>learning</th>\n",
       "      <th>love</th>\n",
       "      <th>machine</th>\n",
       "      <th>powerful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>D1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D3</th>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        deep         i        is  learning      love   machine  powerful\n",
       "D1  0.000000  0.405465  0.000000       0.0  0.405465  0.405465  0.000000\n",
       "D2  0.000000  0.000000  1.098612       0.0  0.000000  0.405465  1.098612\n",
       "D3  1.098612  0.405465  0.000000       0.0  0.405465  0.000000  0.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "def term_frequency(term: str, doc_text: str) -> int:\n",
    "    \"\"\"\n",
    "    Term Frequency (TF)를 계산합니다.\n",
    "    문서 내에서 특정 단어가 나타나는 빈도입니다.\n",
    "    \n",
    "    Args:\n",
    "        term: 단어\n",
    "        doc_text: 문서 텍스트\n",
    "    \n",
    "    Returns:\n",
    "        TF 값 (단어 빈도)\n",
    "    \"\"\"\n",
    "    terms = doc_text.lower().split()\n",
    "    return terms.count(term.lower())\n",
    "\n",
    "def inverse_document_frequency(term: str, docs: dict, inverted_index: dict) -> float:\n",
    "    \"\"\"\n",
    "    Inverse Document Frequency (IDF)를 계산합니다.\n",
    "    전체 문서 집합에서 특정 단어가 나타나는 문서의 역수를 로그로 계산합니다.\n",
    "\n",
    "    IDF 공식:\n",
    "        IDF(term) = log(N / df)\n",
    "        - N: 전체 문서 수 (total_docs)\n",
    "        - df: 해당 단어를 포함하는 문서 수 (doc_frequency)\n",
    "    \n",
    "    Args:\n",
    "        term: 단어\n",
    "        docs: 문서 딕셔너리\n",
    "        inverted_index: 역색인\n",
    "    \n",
    "    Returns:\n",
    "        IDF 값\n",
    "    \"\"\"\n",
    "    total_docs = len(docs)\n",
    "    \n",
    "    # 역색인에서 해당 단어가 나타나는 문서 수(df)\n",
    "    if term.lower() in inverted_index:\n",
    "        doc_frequency = len(inverted_index[term.lower()])\n",
    "    else:\n",
    "        doc_frequency = 0\n",
    "    \n",
    "    # IDF 계산: log(전체 문서 수 / 해당 단어를 포함하는 문서 수)\n",
    "    # 공식: IDF(term) = log(N / df)\n",
    "    # 분모(df)가 0이 되는 것을 방지하기 위해 0이면 0 반환\n",
    "    if doc_frequency == 0:\n",
    "        return 0\n",
    "    \n",
    "    return math.log(total_docs / doc_frequency)\n",
    "\n",
    "def tf_idf(term: str, doc_id: str, docs: dict, inverted_index: dict) -> float:\n",
    "    \"\"\"\n",
    "    TF-IDF 점수를 계산합니다.\n",
    "    TF * IDF\n",
    "    \n",
    "    Args:\n",
    "        term: 단어\n",
    "        doc_id: 문서 ID\n",
    "        docs: 문서 딕셔너리\n",
    "        inverted_index: 역색인\n",
    "    \n",
    "    Returns:\n",
    "        TF-IDF 점수\n",
    "    \"\"\"\n",
    "    tf = term_frequency(term, docs[doc_id])\n",
    "    idf = inverse_document_frequency(term, docs, inverted_index)\n",
    "    return tf * idf\n",
    "\n",
    "def build_vocabulary(docs: dict) -> list:\n",
    "    \"\"\"\n",
    "    전체 문서 집합에서 단어 사전(vocabulary)을 구축합니다.\n",
    "    \n",
    "    Args:\n",
    "        docs: 문서 딕셔너리\n",
    "    \n",
    "    Returns:\n",
    "        정렬된 단어 리스트 (전체 vocabulary)\n",
    "    \"\"\"\n",
    "    vocabulary = set()\n",
    "    for doc_text in docs.values():\n",
    "        terms = doc_text.lower().split()\n",
    "        vocabulary.update(terms)\n",
    "    return sorted(vocabulary)\n",
    "\n",
    "def compute_tf_idf_scores(\n",
    "    docs: dict,              # 문서 딕셔너리 {doc_id: doc_text}\n",
    "    inverted_index: dict,    # 역색인 {term: [doc_id, ...]}\n",
    "    vocabulary: list         # 전체 단어 사전 (정렬된 단어 리스트)\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    모든 문서에 대한 TF-IDF 벡터를 계산합니다.\n",
    "    전체 vocabulary에 맞춰 벡터를 생성합니다.\n",
    "    \n",
    "    Args:\n",
    "        docs: 문서 딕셔너리\n",
    "        inverted_index: 역색인\n",
    "        vocabulary: 전체 단어 사전\n",
    "    \n",
    "    Returns:\n",
    "        TF-IDF 벡터 딕셔너리 {doc_id: {term: tf_idf_score}}\n",
    "        모든 문서 벡터는 동일한 vocabulary 차원을 가집니다.\n",
    "    \"\"\"\n",
    "    tf_idf_scores = {}\n",
    "    \n",
    "    # 모든 문서에 대해\n",
    "    for doc_id in docs.keys():\n",
    "        tf_idf_scores[doc_id] = {}\n",
    "        \n",
    "        # 전체 vocabulary의 각 단어에 대해\n",
    "        for term in vocabulary:\n",
    "            # 해당 문서에 단어가 있으면 TF-IDF 계산, 없으면 0\n",
    "            tf_idf_scores[doc_id][term] = tf_idf(term, doc_id, docs, inverted_index)\n",
    "    \n",
    "    return tf_idf_scores\n",
    "\n",
    "# 전체 단어 사전 구축\n",
    "vocabulary = build_vocabulary(docs)\n",
    "print(f\"전체 단어 사전 (Vocabulary): {vocabulary}\")\n",
    "print(f\"차원 수: {len(vocabulary)}\\n\")\n",
    "\n",
    "# TF-IDF 벡터 계산 (전체 vocabulary에 맞춰)\n",
    "tf_idf_scores = compute_tf_idf_scores(docs, inverted_index, vocabulary)\n",
    "\n",
    "# DataFrame으로 변환\n",
    "tf_idf_df = pd.DataFrame(\n",
    "    [[tf_idf_scores[doc_id][term] for term in vocabulary] \n",
    "     for doc_id in sorted(docs.keys())],\n",
    "    columns=vocabulary,\n",
    "    index=sorted(docs.keys())\n",
    ")\n",
    "\n",
    "print(\"TF-IDF 벡터 (DataFrame):\")\n",
    "tf_idf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a946b52",
   "metadata": {},
   "source": [
    "1. query도 하나의 문서라고 생각하고 tf-idf vector 계산\n",
    "2. 이걸 사용해서 cosine similarity 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4019a411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 'I love you'\n",
      "\n",
      "검색 결과 (유사도 순):\n",
      "  D1: 0.8165 - I love machine learning\n",
      "  D3: 0.4627 - I love deep learning\n",
      "  D2: 0.0000 - machine learning is powerful\n",
      "\n",
      "쿼리 TF-IDF 벡터 (전체 vocabulary 기준):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'deep': 0,\n",
       " 'i': 0.4054651081081644,\n",
       " 'is': 0,\n",
       " 'learning': 0,\n",
       " 'love': 0.4054651081081644,\n",
       " 'machine': 0,\n",
       " 'powerful': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def query_tf_idf(\n",
    "    query: str,\n",
    "    docs: dict,\n",
    "    inverted_index: dict,\n",
    "    vocabulary: list\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    쿼리에 대한 TF-IDF 벡터를 계산합니다.\n",
    "    전체 vocabulary에 맞춰 벡터를 생성합니다.\n",
    "    \n",
    "    Args:\n",
    "        query: 쿼리 문자열\n",
    "        docs: 문서 딕셔너리\n",
    "        inverted_index: 역색인\n",
    "        vocabulary: 전체 단어 사전\n",
    "    \n",
    "    Returns:\n",
    "        쿼리 TF-IDF 벡터 {term: tf_idf_score}\n",
    "        전체 vocabulary 차원을 가집니다.\n",
    "    \"\"\"\n",
    "    query_terms = query.lower().split()\n",
    "    query_tf_idf_vector = {}\n",
    "    \n",
    "    # 전체 vocabulary의 각 단어에 대해\n",
    "    for term in vocabulary:\n",
    "        if term in query_terms:\n",
    "            # 쿼리 내에서의 TF (빈도)\n",
    "            tf = query_terms.count(term)\n",
    "            # 문서 집합에서의 IDF\n",
    "            idf = inverse_document_frequency(term, docs, inverted_index)\n",
    "            query_tf_idf_vector[term] = tf * idf\n",
    "        else:\n",
    "            # 쿼리에 없는 단어는 0\n",
    "            query_tf_idf_vector[term] = 0\n",
    "    \n",
    "    return query_tf_idf_vector\n",
    "\n",
    "def cosine_similarity(\n",
    "    vec1: dict, \n",
    "    vec2: dict, \n",
    "    vocabulary: list\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    두 벡터 간의 코사인 유사도를 계산합니다.\n",
    "    두 벡터는 동일한 vocabulary 차원을 가집니다.\n",
    "    \n",
    "    Args:\n",
    "        vec1: 첫 번째 벡터 (딕셔너리, vocabulary의 모든 단어 포함)\n",
    "        vec2: 두 번째 벡터 (딕셔너리, vocabulary의 모든 단어 포함)\n",
    "        vocabulary: 전체 단어 사전\n",
    "    \n",
    "    Returns:\n",
    "        코사인 유사도 (0~1)\n",
    "    \"\"\"\n",
    "    # 벡터의 내적 계산 (동일한 차원에서)\n",
    "    dot_product = sum(vec1[term] * vec2[term] for term in vocabulary)\n",
    "    \n",
    "    # 벡터의 크기 계산\n",
    "    magnitude1 = math.sqrt(sum(vec1[term] ** 2 for term in vocabulary))\n",
    "    magnitude2 = math.sqrt(sum(vec2[term] ** 2 for term in vocabulary))\n",
    "    \n",
    "    # 코사인 유사도\n",
    "    if magnitude1 == 0 or magnitude2 == 0:\n",
    "        return 0\n",
    "    \n",
    "    return dot_product / (magnitude1 * magnitude2)\n",
    "\n",
    "def search_documents(\n",
    "    query: str,\n",
    "    docs: dict,\n",
    "    inverted_index: dict,\n",
    "    tf_idf_scores: dict,\n",
    "    vocabulary: list\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    쿼리에 대해 가장 관련성 높은 문서를 검색합니다.\n",
    "    \n",
    "    Args:\n",
    "        query: 검색 쿼리 문자열\n",
    "        docs: 문서 딕셔너리\n",
    "        inverted_index: 역색인\n",
    "        tf_idf_scores: 문서들의 TF-IDF 벡터\n",
    "        vocabulary: 전체 단어 사전\n",
    "    \n",
    "    Returns:\n",
    "        (doc_id, similarity_score) 튜플의 리스트, 유사도 순으로 정렬\n",
    "    \"\"\"\n",
    "    # 쿼리 TF-IDF 벡터 계산 (전체 vocabulary에 맞춰)\n",
    "    query_vector = query_tf_idf(query, docs, inverted_index, vocabulary)\n",
    "    \n",
    "    # 각 문서와의 유사도 계산\n",
    "    similarities = []\n",
    "    for doc_id in docs.keys():\n",
    "        doc_vector = tf_idf_scores[doc_id]\n",
    "        similarity = cosine_similarity(query_vector, doc_vector, vocabulary)\n",
    "        similarities.append((doc_id, similarity))\n",
    "    \n",
    "    # 유사도 순으로 정렬 (내림차순)\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return similarities\n",
    "\n",
    "# \"I love you\" 쿼리로 검색\n",
    "query = \"I love you\"\n",
    "results = search_documents(query, docs, inverted_index, tf_idf_scores, vocabulary)\n",
    "\n",
    "print(f\"쿼리: '{query}'\")\n",
    "print(\"\\n검색 결과 (유사도 순):\")\n",
    "for doc_id, similarity in results:\n",
    "    print(f\"  {doc_id}: {similarity:.4f} - {docs[doc_id]}\")\n",
    "\n",
    "print(\"\\n쿼리 TF-IDF 벡터 (전체 vocabulary 기준):\")\n",
    "query_vector = query_tf_idf(query, docs, inverted_index, vocabulary)\n",
    "query_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e613aed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f00507b9",
   "metadata": {},
   "source": [
    "# BM25 구현\n",
    "\n",
    "BM25는 TF-IDF의 한계를 개선한 ranking function입니다.\n",
    "\n",
    "**주요 개선점:**\n",
    "1. **문서 길이 정규화**: `b` 파라미터로 긴 문서의 불이익 방지\n",
    "2. **TF 포화 효과**: `k₁` 파라미터로 단어 반복의 비선형 증가\n",
    "\n",
    "**BM25 공식:**\n",
    "\n",
    "$$\n",
    "\\text{BM25}(t, d) = \\text{IDF}(t) \\cdot \\frac{f(t, d) \\cdot (k_1 + 1)}{f(t, d) + k_1 \\cdot (1 - b + b \\cdot \\frac{|d|}{\\text{avgdl}})}\n",
    "$$\n",
    "\n",
    "여기서:\n",
    "- $f(t, d)$: 문서 $d$에서 단어 $t$의 빈도 (TF)\n",
    "- $|d|$: 문서 $d$의 길이 (단어 개수)\n",
    "- $\\text{avgdl}$: 전체 문서의 평균 길이\n",
    "- $k_1$: TF 포화를 조절하는 파라미터 (보통 1.2~2.0, 기본값 1.5) -> 작을수록 포화가 더 빨리됨. 억제효과가 커짐\n",
    "- $b$: 문서 길이 정규화 파라미터 (0~1, 기본값 0.75) -> 커질수록 긴 문서에 높은 패널티\n",
    "- $\\text{IDF}(t) = \\log\\left(\\frac{N - df(t) + 0.5}{df(t) + 0.5} + 1\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad939571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def bm25_idf(term: str, docs: dict, inverted_index: dict) -> float:\n",
    "    \"\"\"\n",
    "    BM25의 IDF를 계산합니다.\n",
    "    \n",
    "    IDF(t) = log((N - df(t) + 0.5) / (df(t) + 0.5) + 1)\n",
    "    \n",
    "    Args:\n",
    "        term: 단어\n",
    "        docs: 문서 딕셔너리\n",
    "        inverted_index: 역색인\n",
    "    \n",
    "    Returns:\n",
    "        BM25 IDF 값\n",
    "    \"\"\"\n",
    "    N = len(docs)  # 전체 문서 수\n",
    "    \n",
    "    # 해당 단어를 포함하는 문서 수\n",
    "    if term.lower() in inverted_index:\n",
    "        df = len(inverted_index[term.lower()])\n",
    "    else:\n",
    "        df = 0\n",
    "    \n",
    "    # BM25 IDF 공식\n",
    "    idf = math.log((N - df + 0.5) / (df + 0.5) + 1)\n",
    "    return idf\n",
    "\n",
    "\n",
    "def document_length(doc_text: str) -> int:\n",
    "    \"\"\"\n",
    "    문서의 길이(단어 개수)를 계산합니다.\n",
    "    \n",
    "    Args:\n",
    "        doc_text: 문서 텍스트\n",
    "    \n",
    "    Returns:\n",
    "        문서 길이 (단어 개수)\n",
    "    \"\"\"\n",
    "    return len(doc_text.lower().split())\n",
    "\n",
    "\n",
    "def average_document_length(docs: dict) -> float:\n",
    "    \"\"\"\n",
    "    전체 문서의 평균 길이를 계산합니다.\n",
    "    \n",
    "    Args:\n",
    "        docs: 문서 딕셔너리\n",
    "    \n",
    "    Returns:\n",
    "        평균 문서 길이\n",
    "    \"\"\"\n",
    "    total_length = sum(document_length(doc_text) for doc_text in docs.values())\n",
    "    return total_length / len(docs)\n",
    "\n",
    "\n",
    "def bm25_score(\n",
    "    term: str,\n",
    "    doc_id: str,\n",
    "    docs: dict,\n",
    "    inverted_index: dict,\n",
    "    avgdl: float,\n",
    "    k1: float = 1.5,\n",
    "    b: float = 0.75\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    특정 단어에 대한 BM25 점수를 계산합니다.\n",
    "    \n",
    "    BM25(t, d) = IDF(t) * (f(t,d) * (k1 + 1)) / (f(t,d) + k1 * (1 - b + b * |d|/avgdl))\n",
    "    \n",
    "    Args:\n",
    "        term: 단어\n",
    "        doc_id: 문서 ID\n",
    "        docs: 문서 딕셔너리\n",
    "        inverted_index: 역색인\n",
    "        avgdl: 평균 문서 길이\n",
    "        k1: TF 포화 파라미터 (기본값 1.5)\n",
    "        b: 문서 길이 정규화 파라미터 (기본값 0.75)\n",
    "    \n",
    "    Returns:\n",
    "        BM25 점수\n",
    "    \"\"\"\n",
    "    # IDF 계산\n",
    "    idf = bm25_idf(term, docs, inverted_index)\n",
    "    \n",
    "    # TF 계산 (문서에서 단어 빈도)\n",
    "    tf = term_frequency(term, docs[doc_id])\n",
    "    \n",
    "    # 문서 길이\n",
    "    doc_len = document_length(docs[doc_id])\n",
    "    \n",
    "    # BM25 공식\n",
    "    numerator = tf * (k1 + 1)\n",
    "    denominator = tf + k1 * (1 - b + b * (doc_len / avgdl))\n",
    "    \n",
    "    bm25 = idf * (numerator / denominator)\n",
    "    \n",
    "    return bm25\n",
    "\n",
    "\n",
    "def bm25_search(\n",
    "    query: str,\n",
    "    docs: dict,\n",
    "    inverted_index: dict,\n",
    "    k1: float = 1.5,\n",
    "    b: float = 0.75\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    BM25를 사용하여 문서를 검색합니다.\n",
    "    \n",
    "    Args:\n",
    "        query: 검색 쿼리\n",
    "        docs: 문서 딕셔너리\n",
    "        inverted_index: 역색인\n",
    "        k1: TF 포화 파라미터\n",
    "        b: 문서 길이 정규화 파라미터\n",
    "    \n",
    "    Returns:\n",
    "        (doc_id, bm25_score) 튜플의 리스트, 점수 순으로 정렬\n",
    "    \"\"\"\n",
    "    # 평균 문서 길이 계산\n",
    "    avgdl = average_document_length(docs)\n",
    "    \n",
    "    # 쿼리 단어들\n",
    "    query_terms = query.lower().split()\n",
    "    \n",
    "    # 각 문서에 대한 BM25 점수 계산\n",
    "    scores = {}\n",
    "    for doc_id in docs.keys():\n",
    "        score = 0\n",
    "        for term in query_terms:\n",
    "            score += bm25_score(term, doc_id, docs, inverted_index, avgdl, k1, b)\n",
    "        scores[doc_id] = score\n",
    "    \n",
    "    # 점수 순으로 정렬\n",
    "    results = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7924e74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 'I love machine learning'\n",
      "\n",
      "평균 문서 길이: 4.00\n",
      "\n",
      "검색 결과 (BM25 점수 순):\n",
      "  D1: 1.5435 - I love machine learning\n",
      "  D3: 1.0735 - I love deep learning\n",
      "  D2: 0.6035 - machine learning is powerful\n",
      "\n",
      "\n",
      "각 문서별 상세 점수:\n",
      "\n",
      "D1: I love machine learning\n",
      "  문서 길이: 4\n",
      "    'i': 0.4700\n",
      "    'love': 0.4700\n",
      "    'machine': 0.4700\n",
      "    'learning': 0.1335\n",
      "  총 BM25 점수: 1.5435\n",
      "\n",
      "D2: machine learning is powerful\n",
      "  문서 길이: 4\n",
      "    'machine': 0.4700\n",
      "    'learning': 0.1335\n",
      "  총 BM25 점수: 0.6035\n",
      "\n",
      "D3: I love deep learning\n",
      "  문서 길이: 4\n",
      "    'i': 0.4700\n",
      "    'love': 0.4700\n",
      "    'learning': 0.1335\n",
      "  총 BM25 점수: 1.0735\n"
     ]
    }
   ],
   "source": [
    "# BM25로 검색 실행\n",
    "query = \"I love machine learning\"\n",
    "\n",
    "results = bm25_search(query, docs, inverted_index)\n",
    "\n",
    "print(f\"쿼리: '{query}'\")\n",
    "print(f\"\\n평균 문서 길이: {average_document_length(docs):.2f}\")\n",
    "print(\"\\n검색 결과 (BM25 점수 순):\")\n",
    "for doc_id, score in results:\n",
    "    print(f\"  {doc_id}: {score:.4f} - {docs[doc_id]}\")\n",
    "    \n",
    "print(\"\\n\\n각 문서별 상세 점수:\")\n",
    "avgdl = average_document_length(docs)\n",
    "query_terms = query.lower().split()\n",
    "\n",
    "for doc_id in docs.keys():\n",
    "    print(f\"\\n{doc_id}: {docs[doc_id]}\")\n",
    "    print(f\"  문서 길이: {document_length(docs[doc_id])}\")\n",
    "    total_score = 0\n",
    "    for term in query_terms:\n",
    "        score = bm25_score(term, doc_id, docs, inverted_index, avgdl)\n",
    "        if score > 0:\n",
    "            print(f\"    '{term}': {score:.4f}\")\n",
    "        total_score += score\n",
    "    print(f\"  총 BM25 점수: {total_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a57d139",
   "metadata": {},
   "source": [
    "## TF-IDF vs BM25 비교\n",
    "\n",
    "같은 쿼리로 두 방법을 비교해보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2caa9939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 'machine learning'\n",
      "\n",
      "Document                         Text  TF-IDF Score  BM25 Score  TF-IDF Rank  BM25 Rank\n",
      "      D1      I love machine learning      0.577350    0.603535            1          1\n",
      "      D2 machine learning is powerful      0.252515    0.603535            2          2\n",
      "      D3         I love deep learning      0.000000    0.133531            3          3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 비교를 위한 데이터 수집\n",
    "query = \"machine learning\"\n",
    "\n",
    "# TF-IDF 검색\n",
    "tfidf_results = search_documents(query, docs, inverted_index, tf_idf_scores, vocabulary)\n",
    "\n",
    "# BM25 검색\n",
    "bm25_results = bm25_search(query, docs, inverted_index)\n",
    "\n",
    "# 결과를 데이터프레임으로 정리\n",
    "comparison_data = []\n",
    "for i, doc_id in enumerate(docs.keys()):\n",
    "    tfidf_score = next((score for did, score in tfidf_results if did == doc_id), 0)\n",
    "    bm25_score = next((score for did, score in bm25_results if did == doc_id), 0)\n",
    "    \n",
    "    comparison_data.append({\n",
    "        'Document': doc_id,\n",
    "        'Text': docs[doc_id],\n",
    "        'TF-IDF Score': tfidf_score,\n",
    "        'BM25 Score': bm25_score,\n",
    "        'TF-IDF Rank': next((idx+1 for idx, (did, _) in enumerate(tfidf_results) if did == doc_id), 0),\n",
    "        'BM25 Rank': next((idx+1 for idx, (did, _) in enumerate(bm25_results) if did == doc_id), 0)\n",
    "    })\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "print(f\"쿼리: '{query}'\\n\")\n",
    "print(df_comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc49d84",
   "metadata": {},
   "source": [
    "## k1과 b 파라미터의 영향 확인\n",
    "\n",
    "BM25의 두 파라미터가 검색 결과에 어떤 영향을 주는지 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d26f524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k1 파라미터 변화 (b=0.75 고정)\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m k1_values \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m1.5\u001b[39m, \u001b[38;5;241m2.0\u001b[39m, \u001b[38;5;241m3.0\u001b[39m]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k1 \u001b[38;5;129;01min\u001b[39;00m k1_values:\n\u001b[0;32m----> 9\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mbm25_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minverted_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.75\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mk1=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m doc_id, score \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "Cell \u001b[0;32mIn[1], line 132\u001b[0m, in \u001b[0;36mbm25_search\u001b[0;34m(query, docs, inverted_index, k1, b)\u001b[0m\n\u001b[1;32m    130\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m term \u001b[38;5;129;01min\u001b[39;00m query_terms:\n\u001b[0;32m--> 132\u001b[0m         score \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mbm25_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mterm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minverted_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mavgdl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     scores[doc_id] \u001b[38;5;241m=\u001b[39m score\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# 점수 순으로 정렬\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not callable"
     ]
    }
   ],
   "source": [
    "# k1 파라미터 변화 (TF 포화 효과)\n",
    "print(\"k1 파라미터 변화 (b=0.75 고정)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "query = \"machine learning\"\n",
    "k1_values = [0.5, 1.0, 1.5, 2.0, 3.0]\n",
    "\n",
    "for k1 in k1_values:\n",
    "    results = bm25_search(query, docs, inverted_index, k1=k1, b=0.75)\n",
    "    print(f\"\\nk1={k1}:\")\n",
    "    for doc_id, score in results:\n",
    "        print(f\"  {doc_id}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987bf8f9",
   "metadata": {},
   "source": [
    "## 더 큰 문서 집합으로 테스트\n",
    "\n",
    "문서 길이 차이가 큰 경우 BM25의 장점을 더 명확히 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dec7cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리: 'machine learning'\n",
      "평균 문서 길이: 8.00\n",
      "\n",
      "문서 정보:\n",
      "  D1 (길이= 2, 'machine learning' 출현=1회): machine learning...\n",
      "  D2 (길이= 9, 'machine learning' 출현=1회): machine learning is a powerful tool for data analy...\n",
      "  D3 (길이=17, 'machine learning' 출현=4회): machine learning machine learning machine learning...\n",
      "  D4 (길이= 4, 'machine learning' 출현=0회): deep learning neural networks...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "TF-IDF 검색 결과:\n",
      "  D1 (길이= 2): 1.0000\n",
      "  D3 (길이=17): 0.2776\n",
      "  D2 (길이= 9): 0.0827\n",
      "  D4 (길이= 4): 0.0000\n",
      "\n",
      "BM25 검색 결과:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# BM25 검색\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBM25 검색 결과:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 42\u001b[0m bm25_results_long \u001b[38;5;241m=\u001b[39m \u001b[43mbm25_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocs_long\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minverted_index_long\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc_id, score \u001b[38;5;129;01min\u001b[39;00m bm25_results_long:\n\u001b[1;32m     44\u001b[0m     doc_len \u001b[38;5;241m=\u001b[39m document_length(docs_long[doc_id])\n",
      "Cell \u001b[0;32mIn[1], line 132\u001b[0m, in \u001b[0;36mbm25_search\u001b[0;34m(query, docs, inverted_index, k1, b)\u001b[0m\n\u001b[1;32m    130\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m term \u001b[38;5;129;01min\u001b[39;00m query_terms:\n\u001b[0;32m--> 132\u001b[0m         score \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mbm25_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mterm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minverted_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mavgdl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     scores[doc_id] \u001b[38;5;241m=\u001b[39m score\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# 점수 순으로 정렬\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not callable"
     ]
    }
   ],
   "source": [
    "# 길이가 다른 문서들\n",
    "docs_long = {\n",
    "    \"D1\": \"machine learning\",  # 짧은 문서\n",
    "    \"D2\": \"machine learning is a powerful tool for data analysis\",  # 중간 문서\n",
    "    \"D3\": \"machine learning machine learning machine learning is used in many applications and machine learning continues to grow\",  # 긴 문서 (반복 많음)\n",
    "    \"D4\": \"deep learning neural networks\",  # 관련 없는 짧은 문서\n",
    "}\n",
    "\n",
    "# 역색인 구축\n",
    "inverted_index_long = build_inverted_index(docs_long)\n",
    "\n",
    "# Vocabulary 구축\n",
    "vocabulary_long = build_vocabulary(docs_long)\n",
    "\n",
    "# TF-IDF 계산\n",
    "tf_idf_scores_long = compute_tf_idf_scores(docs_long, inverted_index_long, vocabulary_long)\n",
    "\n",
    "# 검색 쿼리\n",
    "query = \"machine learning\"\n",
    "\n",
    "print(f\"쿼리: '{query}'\")\n",
    "print(f\"평균 문서 길이: {average_document_length(docs_long):.2f}\\n\")\n",
    "\n",
    "# 각 문서 정보\n",
    "print(\"문서 정보:\")\n",
    "for doc_id, text in docs_long.items():\n",
    "    doc_len = document_length(text)\n",
    "    ml_count = text.lower().count(\"machine learning\")\n",
    "    print(f\"  {doc_id} (길이={doc_len:2d}, 'machine learning' 출현={ml_count}회): {text[:50]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# TF-IDF 검색\n",
    "print(\"\\nTF-IDF 검색 결과:\")\n",
    "tfidf_results_long = search_documents(query, docs_long, inverted_index_long, tf_idf_scores_long, vocabulary_long)\n",
    "for doc_id, score in tfidf_results_long:\n",
    "    doc_len = document_length(docs_long[doc_id])\n",
    "    print(f\"  {doc_id} (길이={doc_len:2d}): {score:.4f}\")\n",
    "\n",
    "# BM25 검색\n",
    "print(\"\\nBM25 검색 결과:\")\n",
    "bm25_results_long = bm25_search(query, docs_long, inverted_index_long)\n",
    "for doc_id, score in bm25_results_long:\n",
    "    doc_len = document_length(docs_long[doc_id])\n",
    "    print(f\"  {doc_id} (길이={doc_len:2d}): {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b02cbaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b 파라미터 변화 (k1=1.5 고정)\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m b_values \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.25\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.75\u001b[39m, \u001b[38;5;241m1.0\u001b[39m]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m b_values:\n\u001b[0;32m----> 9\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mbm25_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minverted_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mb=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mb\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m doc_id, score \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "Cell \u001b[0;32mIn[1], line 132\u001b[0m, in \u001b[0;36mbm25_search\u001b[0;34m(query, docs, inverted_index, k1, b)\u001b[0m\n\u001b[1;32m    130\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m term \u001b[38;5;129;01min\u001b[39;00m query_terms:\n\u001b[0;32m--> 132\u001b[0m         score \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mbm25_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mterm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minverted_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mavgdl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     scores[doc_id] \u001b[38;5;241m=\u001b[39m score\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# 점수 순으로 정렬\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not callable"
     ]
    }
   ],
   "source": [
    "# b 파라미터 변화 (문서 길이 정규화)\n",
    "print(\"b 파라미터 변화 (k1=1.5 고정)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "query = \"machine learning\"\n",
    "b_values = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "\n",
    "for b in b_values:\n",
    "    results = bm25_search(query, docs, inverted_index, k1=1.5, b=b)\n",
    "    print(f\"\\nb={b}:\")\n",
    "    for doc_id, score in results:\n",
    "        doc_len = document_length(docs[doc_id])\n",
    "        print(f\"  {doc_id} (길이={doc_len}): {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9286399",
   "metadata": {},
   "source": [
    "## 핵심 정리\n",
    "\n",
    "**TF-IDF의 문제점:**\n",
    "1. D3처럼 \"machine learning\"이 4번 반복되는 긴 문서가 TF-IDF에서 가장 높은 점수를 받음\n",
    "2. 문서 길이를 고려하지 않아 단순 반복이 유리함\n",
    "\n",
    "**BM25의 개선:**\n",
    "1. **TF 포화 효과**: 단어가 여러 번 반복되어도 점수 증가가 완만해짐\n",
    "2. **문서 길이 정규화**: 긴 문서에 패널티를 줘서 공정한 비교 가능\n",
    "3. 결과적으로 D1(짧고 정확한 문서)이나 D2(적절한 길이)가 더 높은 순위를 받음\n",
    "\n",
    "**파라미터 설정:**\n",
    "- `k₁`: 1.2~2.0 (기본값 1.5) - 높을수록 TF의 영향이 커짐\n",
    "- `b`: 0~1 (기본값 0.75) - 높을수록 문서 길이 정규화가 강해짐\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7179cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59db5fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4bb95b2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7f075e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3859828c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
