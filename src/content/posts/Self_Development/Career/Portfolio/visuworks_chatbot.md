---
title: "AI Chatbot Project"
date: ""
excerpt: "고객상담용 챗봇 개발"
category: "Career"
tags: ["RAG"]
---

- 기간 : 2024.11 ~ 2025.02 (4개월)
- 역할 : 문제정의, RAG pipeline 구현 및 배포, 모니터링 시스템 구축
- 결과 (성과) : 일평균 100~200건정도의 상담을 자동화해 상담사의 상담 효율성 향상

---

# 프로젝트 개요

## 1. 프로젝트 배경 및 목표

반복되는 고객상담업무는 상담사가 필요한 상담업무를 하지 못하게 만드는 요인이었습니다. 이를 해결하기 위해 FAQ 데이터셋을 기반으로 RAG pipeline을 구축해 고객 질문에 자동으로 답변하는 챗봇을 개발했습니다. 답변 후 만족/불만족 피드백을 수집하고, 이를 분석해 지속적으로 만족도를 개선하는 방식으로 프로젝트를 진행했습니다.

## 2. 주요 성과

- **상담 자동화** : 일평균 100~200건의 반복 상담을 자동화해 상담사의 업무 효율성 향상
- **사용자 만족도 개선** : 불만족 원인 분석 후 질문 분류 모델 도입으로 불만족도 80% 이상 감소
- **검색 성능 개선** : 대화 맥락 반영, 질문 분리, 키워드 추출을 통해 검색 정확도 90% 이상 달성
- **모니터링 자동화** : LLM 기반 자동 평가 시스템 구축으로 모니터링 시간 83% 단축 (30분 → 5분)

## 3. 핵심 학습 내용

- **RAG pipeline 구축 경험** : 질문 재정의, 문서 검색, 답변 생성까지 전체 파이프라인 설계 및 최적화 경험
- **사용자 피드백 기반 개선** : 실제 서비스 운영을 통해 사용자 불만족 요인을 파악하고, 이를 해결하며 만족도를 높이는 과정 경험
- **LLM 기반 자동화** : 반복적이고 시간이 많이 드는 모니터링 업무를 LLM을 활용해 자동화하고 운영 비용을 절감하는 방법 학습

자세한 문제 해결과정은 아래에 정리했습니다.

---

# 문제 해결 과정

RAG 파이프라인은 다음과 같이 구성되어있습니다.

<figure>
<img src="/post/Portfolio/chatbot_pipeline1.png" alt="RAG pipeline" width="50%" />
</figure>
<figure>
<img src="/post/Portfolio/chatbot_pipeline2.png" alt="RAG pipeline" width="100%" />
<figcaption>그림1. RAG pipeline</figcaption>
</figure>

각각의 구성 요소들을 어떻게 구성했으며, 어떻게 최적화했는지 설명드리겠습니다.

---

## 1. 사용자 불만족 요인 분석 및 해결

### 배경

서비스를 운영하면서 만족도를 높여나가는 방향으로 프로젝트를 진행했습니다. 만족도는 대답 후에 "만족", "불만족" 버튼을 통해 수집했습니다. 

실제 서비스를 배포해 사용해본 결과, 사용자 피드백을 통해 불만족이 발생하는 지점을 확인할 수 있었습니다. 분석 결과, 불만족은 답변의 정확도 부족에서 비롯된 것이 아니라, 답변할 수 없는 질문에 대해 엉뚱한 대답을 하거나, 사용자가 비정상적인 질문을 이어갈 때 주로 발생한다는 점을 발견했습니다.

사용자들이 가장 불만족스러워했던 부분은 LLM이 명확히 답변할 수 없는 질문에 대해 모호한 답변을 생성하는 것이었습니다. 특히, 답변할 수 없는 내용임에도 불구하고 계속해서 재질문만 하며 대화를 이어가는 불필요한 상황이 빈번하게 발생했습니다. 주민번호와 전화번호를 입력하며 예약에 대한 문의를 하는 것과 같은 상황입니다.

### 과정

사용자 불만족의 주요 원인이 답변 불가능한 질문에서 비롯된다는 점을 해결하기 위해, RAG 파이프라인에 질문 분류 단계를 추가했습니다. 이 과정을 통해 LLM이 답변을 생성해야 하는 질문과 그렇지 않은 질문을 구분하여 흐름을 분리했습니다.

예를 들어 "상담사 연결해줘"와 같은 질문은 모델이 불필요한 답변을 생성하지 않고, 대신 관련 버튼을 제공하도록 설계하여 사용자 경험을 개선했습니다. 또한 고객사에서 원하는 메뉴얼이 있었지만, 이를 LLM에게 명령하기에는 쉽지 않았기 때문에, 질문 분류를 통해 특정 유형의 질문에 대해서는 정해진 흐름을 따르도록 구현했습니다.

파이프라인의 맨 앞단에 분류 모델을 배치해, 질문의 종류를 분류하여 적절한 대응을 할 수 있도록 했습니다. 분류 모델은 LLM에 분류 프롬프트를 적용해 구현했습니다.

### 성과

문제의 원인 분석을 통해, 질문 분류 단계를 추가해 불필요하거나 부적절한 답변을 줄여 사용자 경험을 개선할 수 있었고, 실제로 불만족도를 80% 이상 감소시킬 수 있었습니다.

### 배운점

실제 서비스를 운영해보니 생각지 못한 부분에서 불만족 피드백을 받을 수 있었습니다. 이를 해결하기 위해 문제를 정의하고, 이를 해결하면서 실제 사용자의 만족도를 개선하는 경험을 할 수 있었습니다.

---

## 2. RAG 파이프라인 개발 및 검색 성능 개선

### 배경

RAG 파이프라인에서 가장 핵심적인 부분은 검색 단계이며, 이 성능이 전체 응답 품질에 직접적으로 영향을 미칩니다. 데이터셋은 FAQ 형태로 구성되어 있었고, 기본적으로 시멘틱 서치를 적용했습니다. 

그러나 도메인 특화된 단어가 검색에 잘 반영되지 않는 문제, 하나의 문장에 여러 질문이 섞여 있는 경우의 처리 한계, 그리고 과거 대화 기록을 반영하여 문서를 검색해야 하는 필요성이 존재했습니다. 이러한 문제를 해결하기 위해 검색 성능 개선을 목표로 RAG 파이프라인을 고도화했습니다.

### 과정

먼저 검색 성능을 객관적으로 평가할 수 있는 데이터셋을 구성하고, 이를 활용해 시멘틱 서치에 적합한 모델을 선정했습니다. 이후 대화 기록을 반영하여 사용자의 질문을 재정의하고, 하나의 문장에 포함된 복수의 질문을 분리해 각각 처리했습니다. 질문별 핵심 키워드를 추출해 문서를 필터링하는 과정을 추가함으로써 검색의 정확도를 높이고, 도메인 특화 질의에 대한 대응력을 강화했습니다.

#### 대화의 맥락을 고려한 질문 재정의

대화의 흐름을 고려해 답변을 생성해야 했습니다. 이때 맥락을 고려해 문서를 검색하는 부분이 중요했습니다.

예를 들어
Q: 라식 가격은 얼마야?
A: 라식 가격은 ~~
이후에 
Q: 라섹은?

이라고 묻는다면 "라섹의 가격은 얼마야?"에 대한 문서를 검색해 대답을 해야합니다. 이를 위해 질문을 재정의하는 부분이 필요했습니다. redis로 관리하는 짧은 기간의 대화기록을 불러와 대화 맥락에 맞는 질문으로 재정의하도록 구현했습니다.

#### 질문 쪼개기 + 키워드 추출

하나의 질문에 2개의 의미가 담겨있는 경우가 있습니다.

"라식과 라섹의 가격 알려줘"라는 질문을 답변하기 위해서는 "라식의 가격"과 "라섹의 가격"이라는 2개의 질문으로 쪼개서, 각각에 대한 문서를 검색할 필요가 있습니다.

또한 시멘틱 서치의 한계와 사용하는 embedding model이 원장 이름과 같은 도메인 특화 단어를 모르기 때문에 발생하는 한계점 등을 극복하기 위해, 질문에서 키워드를 추출한 후 이를 사용해 필터링을 진행했습니다.

"김민규 원장님에 대한 정보 알려줘"와 같은 질문에는 임베딩 벡터로는 적절한 문서를 찾기 어려웠지만, "김민규"라는 단어를 추출해 문서를 필터링하게 된다면 관련된 정보를 찾을 수 있게 됩니다. 또한 사용하는 데이터셋이 FAQ이기 때문에, FAQ의 장점을 살릴 수도 있습니다.

#### 문서 검색 모델 선정

문서 검색을 잘하기 위해서는 질문 재정의와 쪼개기 과정도 중요했지만, 결국 시멘틱 서치에 사용될 임베딩 벡터를 잘 만드는 것이 중요했습니다. 따라서 FAQ를 바탕으로 테스트셋을 구성하고 이를 통해 모델들을 비교해 선택했습니다.

테스트셋을 만드는 과정은 LLM을 통해 생성했고, 답변에 적절한 질문을 생성하도록 설정했습니다.

VectorDB는 Qdrant로 구성했고, 사용자가 문서를 수정하거나 추가했을 때 바로 반영되도록 구현해 유지비용을 최소화했습니다. 또한 참조 문서 버전별로 명확히 구분되게 하기 위해서 멀티테넌시 기능을 이용했습니다.

### 성과

구축한 평가용 데이터셋과 개선된 파이프라인을 통해 검색 정확도 90% 이상을 달성했습니다. 단순히 수치상의 향상뿐 아니라, 도메인 특화 용어에 대한 검색 누락 문제를 해결하고, 복합 질문을 분리·처리함으로써 실제 사용자 질의에 대한 응답 품질을 크게 개선할 수 있었습니다.

### 배운점

검색 성능 개선은 단순히 모델의 성능 문제가 아니라, 사용자의 복잡한 질의를 올바르게 정의하고 구조화하는 과정이 핵심임을 배울 수 있었습니다.

---

## 3. 답변 생성

답변 생성 시 중점을 둔 부분은 두 가지였습니다. 첫째, 참조된 문서의 내용만을 바탕으로 답변하도록 제한한 것이고, 둘째, 사용자가 친근하고 이해하기 쉽다고 느끼는 답변을 생성하도록 한 것입니다.

프롬프트 엔지니어링을 통해 LLM이 참조 문서의 내용만을 바탕으로 답변하도록 제한하고, 동시에 친근하고 이해하기 쉬운 톤으로 응답하도록 설계했습니다. 이를 통해 정확성과 사용자 경험을 모두 향상시킬 수 있었습니다.

---

## 4. 모니터링 자동화를 통해 운영비용 감소

### 배경

에러를 발생하지 않고 조용한 실패(silent failure)를 발생하는 서비스의 특성상 대화 기록을 모니터링 해야 했습니다. 하지만 평균 150건 정도의 대화 기록을 모니터링하는 것은 꽤나 큰 시간적인 비용이 발생했습니다.

사용자 채팅 로그를 자동으로 모니터링해, silent failure를 감지하고 유지보수 비용을 최소화하기 위해 모니터링 기능을 구현할 필요가 있었습니다.

### 과정

모니터링을 자동화하기 위해 새로운 평가지표를 설계하고 이를 시스템에 적용했습니다. 구체적으로, 모델의 답변이 검색된 문서에 얼마나 근거하고 있는지를 평가하도록 했으며, 이 계산은 LLM을 통해 자동으로 수행했습니다.

오픈소스인 RAGAS 프레임워크의 프롬프트를 뜯어보면서 구현했고, 답변이 검색된 문서에 기반한 것인지에 대한 점수를 냈습니다. 이를 통해 LLM이 문서 기반으로 답변을 생성하는 정도를 손쉽게 모니터링할 수 있었습니다.

Airflow를 통해 로그가 쌓이는 스프레드 시트에서 점수를 냈고, 결과는 요약된 형태로 일별 혹은 주별 점수와 점수가 낮은 대화를 Slack을 통해 확인했습니다. 이를 통해 문제가 의심되는 사례만 선별적으로 확인할 수 있도록 했습니다. 이 과정을 통해 사람이 직접 모든 대화 기록을 검수하던 비효율을 제거하고, 모니터링에 소요되는 시간적 비용을 크게 절감할 수 있었습니다.

### 성과

모니터링 프로세스를 자동화하여 작업 시간을 약 30분에서 5분으로 단축, 전체 모니터링 비용을 83% 절감했습니다. 이를 통해 시간적인 비용을 크게 줄이며 안정적인 서비스 모니터링 체계를 구축할 수 있었습니다.

### 배운점

지표를 정의하고 LLM을 통해 반복적이고 시간이 많이 드는 업무를 자동화·대체하는 경험을 할 수 있었습니다.