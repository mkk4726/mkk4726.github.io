---
title: "AI Chatbot Project"
date: ""
excerpt: "고객상담용 챗봇 개발"
category: "Career"
tags: ["RAG"]
---

- 기간 : 2024.11 ~ 2025.02 (4개월)
- 역할 : 문제정의, RAG pipeline 구현 및 배포, 모니터링 시스템 구축
- 결과 (성과) : 일평균 100~200건정도의 상담을 자동화해 상담사의 상담 효율성 향상

---

# 프로젝트 개요

반복되는 고객상담업무는 상담사가 필요한 상담업무를 하지 못하게 만드는 요인 중 하나입니다.
이를 대체하기 위해 챗봇을 개발하는 프로젝트를 진행했습니다.

FAQ (자주 묻는 질문)에 대한 데이터셋을 제공 받았고, 이를 통해 답변을 생성하려고 했습니다.
이를 위해 RAG pipeline을 구축해 문서를 참조해 답변을 생성하도록 했습니다.

답변 후에 만족/불만족 여부를 선택할 수 있도록 해 사용자의 피드백을 수집했고, 
이를 통해 만족도를 높여나가는 방식으로 개발을 진행했습니다.
특히 불만족도가 가장 높은 부분을 분류 모델을 앞단에 붙여 해결할 수 있었고, 불만족도를 50%이상 감소시킬 수 있었습니다.

RAG pipeline을 완성한 후에는 모니터링 시스템을 구현해 silent failure를 확인하고 유지비용을 최소화할 수 있었습니다.

프로젝트를 통해 RAG에 대한 이해와 사용자의 피드백을 받으며 만족도를 높여나가는 경험을 할 수 있었습니다.

자세한 문제 해결과정은 아래에 정리했습니다.

---

# 문제 해결 과정

RAG 파이프라인은 다음과 같이 구성되어있습니다.

<figure>
<img src="/post/Portfolio/chatbot_pipeline1.png" alt="RAG pipeline" width="50%" />
</figure>
<figure>
<img src="/post/Portfolio/chatbot_pipeline2.png" alt="RAG pipeline" width="100%" />
<figcaption>그림1. RAG pipeline</figcaption>
</figure>

각각의 구성 요소들을 어떻게 구성했으며, 어떻게 최적화했는지 설명드리겠습니다.

---

## 1. 사용자 만족도를 높이기 위한 방법 : 분류 모델

서비스를 운영하면서 만족도를 높여나가는 방향으로 프로젝트를 진행했습니다.
만족도는 대답 후에 "만족" , "불만족" 버튼을 통해 수집했습니다. 
대답에 대한 피드백은 보통 불만족하는 경우에 많이 누르기 때문에, 만족도를 높이기 위해서 "불만족"하는 포인트들을 없애려고 노력했습니다.

사용자들이 가장 불만족스러워했던 부분은 LLM이 명확히 답변할 수 없는 질문에 대해 모호한 답변을 생성하는 것이었습니다. 
특히, 답변할 수 없는 내용임에도 불구하고 계속해서 재질문만 하며 대화를 이어가는 불필요한 상황이 빈번하게 발생했습니다.
주민번호와 전화번호를 입력하며 예약에 대한 문의를 하는 것과 같은 상황입니다.
또한 고객사에서 원하는 메뉴얼이 있지만, 이를 LLM에게 명령하기에는 쉽지 않았습니다.

이러한 부분들을 해결하기 위해 파이프라인의 맨 앞단에 분류모델을 배치해, 질문의 종류를 분류하여 적절한 대응을 할 수 있도록 했습니다.
분류 모델은 LLM에 분류 프롬프트를 적용해 구현했습니다.

이를 통해 "불만족" 피드백을 50%이상 감소시킬 수 있었습니다.

---

## 2. 대화의 맥락을 고려해 문서를 검색하자 : 질문 재정의

대화의 흐름을 고려해 답변을 생성해야 했습니다. 
이때 맥락을 고려해 문서를 검색하는 부분이 중요했습니다.

예를 들어
Q: 라식 가격은 얼마야?
A: 라식 가격은 ~~
이후에 
Q: 라섹은?

이라고 묻는다면 "라섹의 가격은 얼마야?"에 대한 문서를 검색해 대답을 해야합니다.
이를 위해 질문을 재정의하는 부분이 필요했습니다.
redis관리하는 짧은 기간의 대화기록을 불러와 대화 맥락에 맞는 질문으로 재정의하도록 구현했습니다.

---

## 3. 검색 성능 향상을 위해 : 질문 쪼개기 + 키워드 추출

하나의 질문에 2개의 의미가 담겨있는 경우가 있습니다.

"라식과 라섹의 가격 알려줘" 라는 질문을 답변하기 위해서는 "라식의 가격"과 "라섹이 가격"이라는 2개의 질문으로 쪼개서, 각각에 대한 문서를 검색할 필요가 있습니다.

또한 시멘틱 서치의 한계와 사용하는 embedding model이 원장이름과 같은 단어를 모르기 때문에 발생하는 한계점 등을 극복하기 위해, 질문에서 키워드를 추출한 후 이를 사용해 필터링을 진행했습니다.

"김민규 원장님에 대한 정보 알려줘"와 같은 질문에는 임베딩 벡터로는 적절한 문서를 찾기 어려웠지만, "김민규"라는 단어를 추출해 문서를 필터링하게 된다면 관련된 정보를 찾을 수 있게 됩니다.
또한 사용하는 데이터셋이 FAQ 이기 때문에, FAQ의 장점을 살릴 수도 있습니다.

---

## 4. 문서 검색

문서 검색을 잘하기 위해서는 2, 3번의 과정도 중요했지만, 결국 시멘틱 서치에 사용될 임베딩 벡터를 잘 만드는게 중요했습니다.
따라서 FAQ를 바탕으로 테스트셋을 구성하고 이를 통해 모델들을 비교해 선택했습니다.

테스트셋을 만드는 과정은 LLM을 통해 생성했고, 답변에 적절한 질문을 생성하도록 설정했습니다.

VectorDB는 Qdrant로 구성했고, 사용자가 문서를 수정하거나 추가했을 때 바로 반영되도록 구현해 유지비용을 최소화했습니다.
또한 참조 문서 버전별로 명확히 구분되게 하기 위해서 멀티테넌시 기능을 이용했습니다.

---

## 5. 답변 생성

답변 생성 시 중점을 둔 부분은 두 가지였습니다. 첫째, 참조된 문서의 내용만을 바탕으로 답변하도록 제한한 것이고, 둘째, 사용자가 친근하고 이해하기 쉽다고 느끼는 답변을 생성하도록 한 것입니다.

프롬프트 엔지니어링을 통해 LLM이 참조 문서의 내용만을 바탕으로 답변하도록 제한하고, 동시에 친근하고 이해하기 쉬운 톤으로 응답하도록 설계했습니다. 이를 통해 정확성과 사용자 경험을 모두 향상시킬 수 있었습니다.

---

## 6. 모니터링

사용자 채팅 로그를 자동으로 모니터링해, silent failure 감지하고 유지보수 비용을 최소화하기 위해 모니터링 기능을 구현했습니다.
오픈소스인 RAGAS 프레임워크의 프롬프트를 뜯어보면서 구현했고, 답변이 검색된 문서에 기반한 것인지에 대한 점수를 냈습니다.

Airflow를 통해 로그가 쌓이는 스프레드 시트에서 점수를 냈고, 일별 혹은 주별 점수와 점수가 높은 대화를 슬랙을 통해 확인했습니다.