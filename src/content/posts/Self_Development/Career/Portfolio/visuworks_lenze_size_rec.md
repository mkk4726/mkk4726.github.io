---
title: "Lens Size Recommendation System"
date: ""
excerpt: "머신러닝을 활용한 맞춤형 렌즈 사이즈 추천 시스템"
category: "Career"
tags: ["Python", "Machine Learning", "Causal Inference", "Flask", "BentoML"]
---

- 기간 : 2025.03 ~ 현재 (6개월)
- 역할 : 문제정의, 프로젝트 설계, 구현까지 모든 과정

---

# 프로젝트 개요

렌즈 삽입을 통한 시력교정 수술시 "렌즈의 크기"를 결정하는건 의사의 노하우와 감에 의존하는 일이라고 합니다.
따라서 경험이 적은 의사는 선택에 어려움을 느끼고, 경험이 많더라도 판단에 어려움이 있다고 합니다.

<figure>
<img src="/post/Portfolio/Lenze_size_reco.png" alt="lenze size reco" width="100%" />
<figcaption>그림1. 렌즈 사이즈 추천 서비스</figcaption>
</figure>
이러한 선택을 도와주기 위해 렌즈 삽입 후 결과 (렌즈 후면과 수정체 전면까지의 거리) 를 예측해 렌즈 사이즈를 추천하는 프로젝트를 진행했습니다.
기존에 제공하던 서비스의 전체적인 부분을 개선했습니다.

데이터 수집부터 모델 개발, 서빙, 모니터링까지 ML 서비스를 위한 모든 부분을 개발한 프로젝트입니다.
전 과정을 개발하면서 전체적인 흐름을 명확히 할 수 있었고, 문제를 해결해 나가는 과정에서 각 부분에서 중요하게 생각해야 하는 점들을 배울 수 있었습니다.
매단계별로 고민했던 부분들은 아래에 정리했습니다.

아직 모델에 대한 연구는 계속 진행 중이며, 관련한 내용을 논문으로 작성 중입니다.

---

# 문제 해결 과정

크게 데이터 관련 / 모델링 관련 / 서빙과 모니터링 관련 에 대한 문제 해결과정을 구분할 수 있습니다.

---

# 데이터 일관성을 문제 : data pipeline, feature store 구현 : 

모델을 개발하면서 첫번째로 마주한 문제는 데이터 일관성 문제입니다.
기존에 회사에서 ML을 개발하고 서빙할 때는 개별적으로 DW (데이터웨어하우스)에서 데이터를 불러왔습니다.

이는 학습과 추론 상황에서의 데이터 일관성을 보장하지 못하며, 실제로 코드를 뜯어봤을 때 서로 다른 전처리 로직을 사용하고 있었습니다.
또한 실험하는 사람마다 다른 데이터 전처리 로직을 사용했기에 일관된 모델 성능을 파악하기도 어려웠습니다.

이를 해결하기 위해 데이터 파이프라인을 설계하고 구현했고, 피처 스토어를 통해 데이터 일관성을 확보할 수 있었습니다.
데이터 파이프라인 구조는 아래와 같습니다.

<figure>
<img src="" alt="data pipelien" width="100%" />
<figcaption>그림2. 데이터 파이프라인 구조</figcaption>
</figure>

피처 스토어는 in-house로 개발했고 이는 필요한 기능만 구현하기 위해서 였습니다.
데이터가 많지 않고 요청이 많지 않았기 때문에 online과 offline을 구분하지 않아도 됐고, 
이를 위해서는 피처 테이블을 두고 이를 관리하는 api만 개발하면 됐기에 복잡한 툴이나 프레임워크를 적용하지 않았습니다.

---

# 모델링 

모델링 부분이 가장 어려웠습니다. 
답을 알려줄 사람이 없다보니, 문제를 풀기 위해 이런저런 논문이나 내용도 찾아보고 세미나에 가서 조언도 구했습니다.
그러다가 "인과추론"이라는 키워드를 알게되고 이를 통해 문제를 정의하고 하나씩 해결해나갈 수 있었습니다.

이 과정을 요약하면 선택의 문제를 예측의 문제로 정의했을 때의 한계점을 알아갔다고 표현할 수 있겠습니다.

어떤 문제인지, 어떻게 해결방안을 정의했는지 정리했습니다.

## 예측 성능을 어떻게 평가할 수 있을까? :

<figure>
<img src="/post/Portfolio/Lenze_size_evaluate.png" alt="how to evalute" width="100%" />
<figcaption>그림3. 고민했던 문제 : 어떻게 평가할 것인가</figcaption>
</figure>

렌즈사이즈는 3가지 정도가 있습니다. 의사는 고객에게 3가지 중 하나를 선택해 수술을 진행하게 됩니다.
그림3처럼 3개의 결과를 예측하지만, 실제 결과는 1개만 알 수 있습니다.
이때 실제 결과가 없는 나머지 2개에 대한 예측은 어떻게 평가할 수 있을지에 대한 의문이 들었습니다.

이에 대한 답을 "양수성" 혹은 "분포의 겹침"에서 찾을 수 있었습니다.
- [양수성에 대해 정리한 글](/posts/Data%20Science/Causal%20Inference/what-is-positivity)

선택하는 값을 처치라고 정의할 수 있습니다.
선택의 문제에서는 최적의 선택을 찾는 것, 최적의 처치를 찾는 것이 목표가 됩니다.







## 보장할 수 있는 예측값의 범위는? :

가장 먼저 예측 평가지표 (MSE, MAE)로 성능을 확인한 예측의 범위를 정해야 합니다.
이는 성향 점수 (propensity score)를 추정함으로써 정할 수 있습니다.
성향 점수는 처치를 선택할 확률을 의미하며, $P(T|X)$을 추정하는 문제입니다.

성햠 점수 추정 모델로 고객별로 데이터에서 처치의 분포가 겹치는 범위를 정할 수 있습니다.
(인과추론의 가장 기본적인 가정인 양수성을 만족하는 범위를 찾는다고도 할 수 있습니다)

<figure>
<img src="/post/Portfolio/Lenze_size_propensity.png" alt="Positivity" width="80%" />
<figcaption>그림9. 양수성 조건 만족하는 범위</figcaption>
</figure>

그림9에서 고객 A는 12.1, 12.6, 13.2에 대한 예측 성능을 신뢰할 수 있고, 고객 B는 12.6에 대한 예측 성능을 신뢰할 수 있습니다.

## 신뢰할 수 없는 처치의 예측은? :

신뢰할 수 있는 정도를 예측 범위로 나타낼 수 있고, 따라서 양수성이 보장되지 않는 예측 범위의 예측 범위를 넓게 그려주고자 했습니다.
양수성이 보장되는 처치의 예측값은 신뢰구간을 예측해 보여주고, 나머지 처치에 대해서는 "partial identification"과 같은 개념을 사용해 예측 범위를 추정했습니다.

<figure>
<img src="/post/Portfolio/Lenze_size_PI.png" alt="Prediction Interval" width="80%" />
<figcaption>그림10. 양수성 조건에 따른 예측 구간</figcaption>
</figure>

고객 A에 대한 예시입니다. 양수성이 보장되는 12.1, 12.6, 13.2보다 13.7의 예측 범위가 더 넓고, 이를 통해 불확실성을 표현하고 있습니다.


---

# silent failure 감지 :  Monitoring 구현

모델이 실제 서비스 상황에서 어떤 성능을 보이는지, 데이터 분포 변화가 있는지 등을 지속적으로 모니터링하는 것은 ML 시스템 운영의 핵심입니다. 데이터는 계속 변화하고, 이에 따라 모델의 성능이 변할 수 있기 때문에 이를 지속적으로 확인하고 재학습시키는 과정이 필요했습니다.

구현한 모니터링 기능으로는 실시간 성능 모니터링이 있습니다. 추론 요청에 대한 예측 결과와 실제 결과를 비교하여 모델의 성능을 실시간으로 추적합니다. 정확도, 정밀도, 재현율 등의 메트릭을 지속적으로 계산하고, 성능 저하 시 즉시 알림을 발생시킵니다.

데이터 Drift 감지 기능도 구현했습니다. 입력 데이터의 분포 변화를 감지하여 모델 성능 저하의 원인을 사전에 파악합니다. 피처별 통계량(평균, 표준편차, 분포)을 학습 시점과 비교하고, 임계값을 초과하는 변화가 있을 때 경고를 발생시킵니다.

모델 Drift 모니터링도 지속적으로 수행합니다. 모델의 예측 분포가 학습 시점과 비교하여 얼마나 달라졌는지를 추적합니다. 예측값의 분포 변화, 신뢰도 점수 변화 등을 모니터링하여 모델의 안정성을 평가합니다.

자동화된 알림 시스템도 구축했습니다. 성능 지표나 drift 지표가 임계값을 초과할 때 담당자에게 자동으로 알림을 보내는 시스템으로, Slack, 이메일 등을 통해 즉시 상황을 파악할 수 있도록 했습니다.

결과적으로 모델의 성능 변화를 사전에 감지할 수 있게 되어, 성능 저하 시 즉시 대응할 수 있었습니다. 데이터 drift가 발생했을 때도 원인을 빠르게 파악하고 적절한 조치를 취할 수 있어 모델의 안정성을 크게 향상시켰습니다.