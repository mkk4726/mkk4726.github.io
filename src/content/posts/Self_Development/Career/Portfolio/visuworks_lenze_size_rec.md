---
title: "Lens Size Recommendation System"
date: ""
excerpt: "머신러닝을 활용한 맞춤형 렌즈 사이즈 추천 시스템"
category: "Career"
tags: ["Portfolio"]
---

- 기간 : 2025.03 ~ 현재 (7개월)
- 역할 : 문제정의, 프로젝트 설계, 구현까지 모든 과정

---

# 프로젝트 개요

렌즈 삽입을 통한 시력교정 수술시 "렌즈의 크기"를 결정하는건 의사의 노하우와 감에 의존하는 일이라고 합니다.
따라서 경험이 적은 의사는 선택에 어려움을 느끼고, 경험이 많더라도 판단에 어려움이 있다고 합니다.

<figure>
<img src="/post/Portfolio/Lenze_size_reco.png" alt="lenze size reco" width="100%" />
<figcaption>그림1. 기본적인 렌즈 사이즈 추천 서비스 컨셉</figcaption>
</figure>

이러한 선택을 도와주기 위해 렌즈 삽입 후 결과 (렌즈 후면과 수정체 전면까지의 거리) 를 예측해 렌즈 사이즈를 추천하는 서비스를 운영하고 있습니다.
기존에 진행되던 프로젝트를 이어서 진행했고, 서비스를 발전시키기 위해 기술적으로 해결해야하는 부분과 사용자의 만족도를 높이기 위한 부분들에 대한 문제를 정의하고 해결해나갔습니다.

그 과정을 요약하면 다음과 같습니다.

1. 기본적인 ML system 설계하고 개발하기
   - 데이터 수집부터 모델 개발, 서빙, 모니터링까지 ML 서비스를 위한 모든 부분에 대해 문제를 정의하고 해결했습니다.
   - 이 과정에서 데이터 파이프라인 개발 (피처 스토어)을 통해 데이터 불일치 문제에서 발생하는 성능 저하 문제를 20% 정도 개선했습니다.
   - 실제 추론 상황에서 성능을 확인하기 위해 모니터링 기능을 개발해 silent failure를 사전에 감지할 수 있게 되었습니다.
   - 전체적인 흐름에 대해 배울 수 있었고, 문제를 해결해 나가는 과정에서 각 부분에서 중요하게 생각해야 하는 점들을 배울 수 있었습니다.

2. 모델 고도화하기
   - 기존에 정의되어있던 방향에서 모델을 고도화하려고 시도했습니다. (기존에 사용하던 평가지표인 MAE를 낮추기 위한 방향)
   - 도메인 지식에 기반한 가설들을 통계적으로 검증하고, 이를 피처로 녹여내 성능을 향상시켰습니다.

3. 양수성 개념을 도입해보기 (실패했던 경험)
   - 눈이 작은 사람에게 큰 렌즈를 넣지 않는데, 추론 상황에서 이를 잘 추론 할 수 있을까? 에 대한 의문을 문제로 정의하고 해결하고자 했습니다.
   - [연구 방향에 대해 정리한 글 - 외삽 문제를 어떻게 다뤄야할까?](/posts/Data%20Science/Causal%20Inference/Industry%20Application/what-can-I-do-in-extrapolation-problem)

4. 문제를 재정의하고, 이에 맞춰 모델 및 평가지표 설계하기
   - 사용자의 요구사항을 수집 및 분석하고, 이를 ML의 관점에서 문제로 정의했습니다. (예측값 -> 예측구간을 추정)
   - 기존과 다르게 문제를 재정의했고, 이를 풀기 위한 모델과 평가지표를 설계했습니다.
   - 이를 통해 사용자의 만족도를 높일 수 있었습니다. (긍정적인 피드백을 받을 수 있었습니다)

5. 예측구간 추정 문제를 고도화하는 모델 개발 (진행 중)
   - 예측구간은 quantile 을 추정함으로써 추정할 수 있는데, 이때 발생하는 quantile crossing problem을 모델 안에서 해결할 수 있는 모델을 개발하고 있습니다.


---

# 문제 해결 과정

문제를 해결했던 과정을 시간 순서대로 정리했습니다.

## 1. 기본적인 ML system 구축하기

### 배경

서비스를 고도화하기 위해 기존에 배포되어 있는 모델의 성능을 확인하려고 했습니다. 

하지만 여러 문제들을 발견했습니다. 추론 상황에서의 로그와 이를 모니터링할 수 있는 기능이 없어서 실제 서비스에서의 성능을 확인할 수 없었습니다. 또한 기존에는 raw database에서 바로 데이터를 가져왔고, 이 과정에서 학습 상황과 추론 상황에서의 데이터가 일치하지 않는 문제도 발견했습니다. 그리고 실험이 단순히 notebook 형태로만 존재해서 모델의 형상관리나 실험 추적이 어려웠습니다.

이러한 문제들을 해결하기 위해 End-to-End ML system을 설계하고 구현했습니다.

<figure>
<img src="/post/Portfolio/lenze_size_ml_system.png" alt="data pipeline" width="100%" />
<figcaption>그림2. ML pipeline</figcaption>
</figure>

제가 구성하고 개발한 ML 파이프라인은 그림2와 같습니다.
1번 OCR 파이프라인에 대한 내용은 다음 포스트에서 확인할 수 있습니다.
- [portfolio - OCR pipeline 구현](/posts/Self_Development/Career/Portfolio/visuworks_ocr_pipeline)

어떤 문제가 있었는지, 이를 해결하기 위해 어떤 선택을 했는지를 정리했습니다.

### 1.1 데이터 일관성을 확보하자 : data pipeline, feature store 구현 

모델을 개발하면서 첫번째로 마주한 문제는 데이터 일관성 문제입니다.

기존에 회사에서 실험, 모델을 만들고 서빙할 때 개별적으로 DW (데이터웨어하우스)에서 데이터를 불러왔습니다.
이는 학습과 추론 상황에서의 데이터 일관성을 보장하지 못하며, 실제로 코드를 뜯어봤을 때 서로 다른 전처리 로직을 사용하고 있었습니다.
이렇게 사용했을 때 학습 상황에서 확인한 성능과 추론 성능이 굉장히 달라질 수 있습니다.
또한 실험하는 사람마다 다른 데이터 전처리 로직을 사용했기에 일관된 모델 성능을 파악하기도 어려웠습니다.

이를 해결하기 위해 데이터 파이프라인을 통해 데이터 전처리 과정을 통일했고, 피처 스토어를 통해 학습과 추론 상황에서의 데이터 일관성을 보장했습니다.

구현할 때는 유명한 프레임워크나 툴을 사용하기보다 현재 필요한 기능에 맞도록 구현했습니다.
필요없는 기술을 위해 복잡성을 증가시키지 않고, 해결하고자 하는 문제에 집중했습니다.


### 1.2 모델 서빙은 어떻게 하면 좋을까?

모델을 서빙할 때 고려했던 핵심 요소는 배포 환경의 일관성과 모델 업데이트의 용이성이었습니다. 

컨테이너화를 통해 개발 환경과 운영 환경 간의 차이를 최소화하고, FastAPI를 사용하여 간단하면서도 효율적인 API 서버를 구축했습니다. 

Docker를 활용한 배포로 인프라 관리의 복잡성을 줄이고, S3를 통해 모델 파일을 중앙 집중식으로 관리하여 새로운 모델 버전을 쉽게 배포할 수 있도록 했습니다. 이는 특히모델 성능 개선 시 빠른 반영이 가능하게 해주었습니다.


### 1.3 추론 상황에서의 성능은? :  Monitoring 구현

모델이 실제 서비스 상황에서 어떤 성능을 보이는지, 데이터 분포 변화가 있는지 등을 지속적으로 모니터링하는 것이 중요했습니다. 

데이터는 시간이 지남에 따라 계속 변화하기 때문에, 학습 시점의 성능과 현재 성능 간의 차이가 발생할 수 있습니다. 이러한 변화를 놓치면 모델이 조용히 성능이 저하되는 silent failure* 상황이 발생할 수 있어, 지속적인 모니터링과 필요시 재학습 과정이 필수적이었습니다.

구현한 모니터링 시스템은 크게 세 가지였습니다. 
먼저 성능 모니터링은 서비스 로그에 저장된 모델 추론값과 수술 후 실제 측정 결과값을 비교해서 평가지표들을 주기적으로 계산했습니다. 
두 번째로 Data Drift 감지는 입력 데이터의 분포 변화를 감지해서 모델 성능 저하의 조기 경고 신호를 포착했습니다. 특히 피처별 통계량 변화와 분포 변화를 학습 시점과 비교했습니다.
마지막으로 자동 알림 시스템을 통해 성능지표와 data drift에 대한 지표들을 지속적으로 확인했습니다.

결과적으로 모델의 성능 변화를 사전에 감지할 수 있게 되어서, 성능 저하 시 즉시 대응할 수 있었습니다. 
데이터 drift가 발생했을 때도 원인을 빠르게 파악하고 적절한 조치를 취할 수 있어서 모델의 안정성과 신뢰성을 크게 향상시킬 수 있었습니다.

개념에 대해서 제가 이해한 부분들을 정리한 내용입니다.
- [data drfit란?](/posts/Data%20Science/Statistics/what-is-data-drift/)
- [silent failure에 대해서](/posts/Data%20Science/ML%20Engineering/about-silent-failures/)

### 1.4 체계적인 실험 관리 : Hydra & W&B

기존에는 실험이 notebook 형태로만 존재해서 재현성을 보장하기 어렵고, 여러 실험을 비교하거나 추적하는 것이 어려웠습니다. 

이를 해결하기 위해 Hydra를 활용해 실험 설정을 체계적으로 관리하고, W&B(Weights & Biases)를 통해 실험 결과를 추적하고 비교할 수 있도록 했습니다. Hydra를 통해 hyperparameter, 데이터 설정, 모델 설정 등을 config 파일로 관리하여 실험의 재현성을 보장했고, W&B를 통해 여러 실험의 성능 지표, 학습 곡선, 모델 artifact 등을 중앙에서 관리할 수 있게 되었습니다.

이를 통해 팀 내에서 실험 결과를 공유하고, 어떤 설정이 가장 좋은 성능을 냈는지 쉽게 비교할 수 있었습니다. 또한 서비스에 배포된 모델의 실험 결과를 언제든 확인할 수 있어, 추가적인 실험과 재학습의 과정이 훨씬 수월해졌습니다.

### 1.5 성과 및 배운 점

ML system을 End-to-End로 구축하면서 다음과 같은 성과를 달성할 수 있었습니다.

먼저 데이터 불일치에서 발생한 성능 저하 문제를 해결했습니다. 학습과 추론 상황에서 서로 다른 전처리 로직을 사용하면서 발생했던 약 20%의 성능 저하를 데이터 파이프라인과 feature store를 통해 해결할 수 있었습니다.

또한 실제 서비스 상황에서의 성능을 지속적으로 모니터링할 수 있게 되면서, 사용자의 만족도를 낮추는 silent failure 등을 사전에 감지하고 대응할 수 있게 되었습니다. 실험 관리 시스템을 통해 모델 개발과 재학습 과정도 체계화되어, 빠르게 모델을 개선하고 배포할 수 있는 환경을 구축했습니다.

이 과정을 통해 ML 서비스를 운영하기 위해 필요한 요소들을 깊이 이해할 수 있었습니다. 단순히 모델을 개발하는 것을 넘어서, 데이터 파이프라인, 모델 서빙, 모니터링, 실험 관리까지 End-to-End로 시스템을 개발하면서 각 단계에서 중요하게 고려해야 할 점들을 배울 수 있었습니다. 특히 실제 문제 상황을 마주하고 해결하면서 이론과 실무의 차이를 체감하고, 실용적인 해결책을 찾아가는 경험을 쌓을 수 있었습니다.

---

## 2. 모델 고도화하기 

기존에 사용하던 평가지표인 MAE를 낮추는 방향으로 모델을 고도화하는 작업을 진행했습니다. 
이 과정에서 단순히 모델만 튜닝하는 것이 아니라, 도메인 지식을 활용한 피처 개발과 서비스의 신뢰도를 측정할 수 있는 새로운 평가지표를 개발하는 작업까지 함께 진행했습니다.

### 2.1 도메인 지식 기반 피처 개발

성능 향상을 위해 도메인 지식에 기반한 가설을 세우고, 이를 데이터 분석과 실험을 통해 검증하는 방식으로 새로운 피처를 개발했습니다. 

예를 들어, 나이가 들수록 수정체 두께가 두꺼워질 수 있다는 가설을 세우고 데이터로 확인했습니다. 나이를 기준으로 집단을 나누어 분석한 결과 뚜렷한 차이를 발견했고, 이를 피처로 활용하여 실제 성능 향상을 확인할 수 있었습니다.

이러한 방식으로 도메인 전문가와 지속적으로 소통하며 여러 가설을 검증하고 피처로 개발하는 과정을 반복했습니다.

### 2.2 모델 비교 및 튜닝

여러 모델을 비교하고 튜닝을 진행하는 과정에서 R² 값이 0.4 이상으로 오르지 않는 한계를 확인했습니다. 이를 통해 측정 불가능한 렌즈의 고유 특성이나 눈의 개별적 특성이 분산의 주요 원인임을 해석할 수 있었습니다. 

이러한 이해는 단순히 모델 성능을 높이는 것만으로는 서비스의 신뢰도를 보장할 수 없다는 인사이트로 이어졌고, 이후 예측 구간 추정 방식으로 문제를 재정의하는 계기가 되었습니다.

### 2.3 Data Leakage 방지

실험 과정에서 가장 주의한 점은 data leakage입니다. 

데이터 자체가 모델에 직접 노출되지 않도록 주의했을 뿐 아니라, test set을 반복적으로 확인함으로써 hyperparameter가 과적합되는 문제도 방지해야 했습니다. 이를 위해 실험 주기를 사전에 정의하고, 배포 직전에만 test set을 검증하는 방식으로 진행했습니다.

이러한 엄격한 검증 프로세스를 통해 실험 환경에서의 성능과 실제 서빙 환경에서의 성능 차이를 최소화할 수 있었습니다.

### 2.4 신뢰도 평가지표 개발

단순 성능 지표(MAE, R²)만으로는 서비스의 신뢰도를 평가하기 어렵다는 문제를 인식했습니다. 

예측 결과가 도메인 지식 및 직관과 얼마나 일치하는지를 평가할 수 있는 신뢰도 지표를 새롭게 개발했습니다. 이 지표는 예측값이 물리적으로 타당한 범위 내에 있는지, 유사한 환자군에서 일관된 예측을 하는지 등을 종합적으로 평가합니다.

개발한 신뢰도 지표는 팀 내에서 채택되어 모델 평가의 표준 지표로 사용되고 있으며, 사용자의 신뢰도를 확보하는 데 기여했습니다.

### 2.5 성과 및 배운 점

이러한 과정을 통해 기존 모델 대비 **성능을 30% 향상**시킬 수 있었습니다.

이 과정을 통해 데이터와 모델 양측을 깊이 이해하는 경험을 쌓을 수 있었습니다. 특히 단순한 예측 성능이 곧 서비스의 신뢰도나 사용자 만족도로 이어지지 않을 수 있다는 점을 깊이 고민하게 되었습니다. 이를 해결하기 위해 신뢰도 평가지표를 직접 개발하고, 보다 신뢰도 있는 모델을 만들 수 있었습니다.

---

## 3. 양수성 개념 도입해서 문제 해결해보기

다음과 같은 의문을 문제로 정의해서 풀고자 했습니다.
- 측정하지 않은 값에 대한 예측 성능을 어떻게 평가할 수 있을까?
- 눈이 작은 환자에게는 큰 렌즈를 넣은 데이터가 없는데, 추론상황에서 이를 신뢰할 수 있을까?

이를 해결하기 위해 인과추론의 관점에서 "양수성"이라는 개념을 사용해 문제를 정의했습니다.

<figure>
<img src="/post/Portfolio/Lenze_size_evaluate.png" alt="how to evalute" width="100%" />
<figcaption>그림3. 고민했던 문제 : 어떻게 평가할 것인가, 어디까지 신뢰할 수 있는지</figcaption>
</figure>

문제 상황을 그려보면 그림 3과 같습니다.
선택할 수 있는 "렌즈 사이즈"는 3가지가 있고, 의사는 3가지 중 하나를 선택해 수술을 진행하게 됩니다.

3가지에 대한 예측값을 모두 생성하지만, 실제 결과는 1개만 알 수 있습니다.
이때 실제 결과가 없는 나머지 예측들은 어떻게 평가할 수 있을지에 대한 의문이 들었습니다.

> 즉, 학습 데이터셋에는 고객별로 1개의 렌즈 사이즈에 대한 결과만 존재하는데, 나머지 사이즈에 대한 예측값은 어떻게 신뢰할 수 있지? 라는 의문이 들었습니다.

이에 대한 답을 "양수성" 혹은 "분포의 겹침"에서 찾을 수 있었습니다.
- [양수성에 대해 정리한 글](/posts/Data%20Science/Causal%20Inference/what-is-positivity)

양수성은 모든 개체가 모든 처치(treatment)를 받을 수 있는 가능성이 있어야 한다는 가정입니다. 
렌즈 사이즈 선택 문제에서 각 환자가 각 렌즈 사이즈를 받을 수 있는 **가능성** 이 있어야 한다는 의미입니다.
만약 특정 환자에게는 절대 사용하지 않은 렌즈 사이즈가 있다면, 예측값을 신뢰할 수 없을 것입니다.

양수성을 만족한다면 **관찰되지 않은 사이즈에 대한 예측도 신뢰할 수 있다** 고 이야기할 수 있습니다.

---

### 3.1 추론 로직 구조

<figure>
<img src="/post/Portfolio/Lenze_size_inference1.png" alt="Positivity" width="80%" />
<figcaption>그림4. 추론할 때의 로직</figcaption>
</figure>

양수성을 고려한 추론 로직부터 그려보면 그림4와 같습니다.
propensity score를 추정해, 고객에 대해 신뢰할 수 있는 처치범위와 그렇지 않은 범위를 정하고, 각각에 따라 다른 예측 모델을 사용하고 있습니다.

<figure>
<img src="/post/Portfolio/Lenze_size_PI.png" alt="Prediction Interval" width="80%" />
<figcaption>그림5. 양수성 조건에 따른 예측</figcaption>
</figure>

양수성 혹은 분포의 겹침이 보장되어 신뢰할 수 있는 처치의 범위는 CQR을 통해 예측 범위를 추정하고,
그렇지 않은 곳은 partial identification의 아이디어를 차용해 예측 범위를 추정할 수 있습니다.
이를 통해 예측의 불확실성을 구간으로 표현할 수 있을 것이라고 생각했습니다.

### 3.1 신뢰할 수 있는 처치의 범위는 어떻게 구할까 : Propensity Estimator

가장 먼저 예측 평가지표 (MSE, MAE)로 성능을 확인한 예측의 범위를 정해야 합니다.
이는 성향 점수 (propensity score)를 추정함으로써 정할 수 있습니다.
성향 점수는 처치를 선택할 확률을 의미하며, $P(T|X)$을 추정하는 문제입니다.

성햠 점수 추정 모델로 고객별로 데이터에서 처치의 분포가 겹치는 범위를 정할 수 있습니다.
(인과추론의 가장 기본적인 가정인 양수성을 만족하는 범위를 찾는다고도 할 수 있습니다)

<figure>
<img src="/post/Portfolio/Lenze_size_propensity.png" alt="Positivity" width="70%" />
<figcaption>그림6. 양수성 조건 만족하는 범위</figcaption>
</figure>

그림6은 고객별로 성향점수를 추정하고, 이를 통해 양수성이 보장되는 처치의 범위를 정한 예시입니다.

고객 A는 12.1, 12.6, 13.2에 대한 예측 성능을 신뢰할 수 있고, 고객 B는 12.6에 대한 예측값을 신뢰할 수 있다고 판단할 수 있습니다.

### 3.2 신뢰할 수 없는 범위의 예측은 어떻게 할까 : Partial Identification

신뢰할 수 있는 정도를 예측 범위로 나타낼 수 있고, 따라서 양수성이 보장되지 않는 예측 범위의 예측 범위를 넓게 그려주고자 했습니다.
양수성이 보장되는 처치의 예측값은 신뢰구간을 예측해 보여주고, 나머지 처치에 대해서는 "partial identification"과 같은 개념을 사용해 예측 범위를 추정했습니다.

개념에 대해서 제가 이해한 부분들을 정리한 내용입니다.
- [Partial Identification이란?](/posts/Data%20Science/Causal%20Inference/what-is-partial-identification)
- [Manski Bounds란?](/posts/Data%20Science/Causal%20Inference/what-is-manski-bounds)

---

## 4. 문제 재정의하기

### 배경

서비스의 만족도를 높이기 위해 사용자의 요구사항을 더 깊게 이해하려고 했습니다.

기존에는 단순히 예측값(평균)을 제공하고 MAE 개선에 집중했지만, 사용자의 요구사항을 자세히 듣고 분석한 결과 단순히 하나의 예측값을 제공받는 것보다 실제로 가능한 값의 범위를 알고 싶어 한다는 점을 확인했습니다. 

그러나 기존 접근은 MAE를 개선하는 데만 초점을 맞추고 있었고, 2번 섹션에서 확인했듯이 모델의 R² 값이 약 0.4 수준으로 전체 분산의 40%만 설명할 수 있었습니다. 결과적으로 단일 예측값만 제공하는 것은 모델의 한계를 드러내고 사용자의 신뢰도를 오히려 떨어뜨릴 수 있었습니다.

이러한 문제를 해결하기 위해 예측값 대신 일정 신뢰수준을 만족하는 예측 구간을 제시하는 방향으로 접근을 전환했습니다. 
이는 아래의 그림 7과 같은 형태입니다, 신뢰수준 0.9를 만족하기 위해 0.05와 0.95 quantile을 예측해 예측구간을 추정합니다.

<figure>
<img src="/post/Portfolio/lenze_size_CQR_1.png" alt="Quantile Regression" width="100%" />
<figcaption>그림7. CQR로 예측 구간 추정</figcaption>
</figure>



### 4.1 Quantile Regression으로 문제 재정의

기존의 점 추정(point estimation) 문제를 quantile regression task로 재정의했습니다. 

이를 통해 단일 예측값이 아닌, 사이즈별로 데이터 분포를 고려한 예측 구간을 산출할 수 있게 되었습니다. 사용자는 이러한 구간 정보를 통해 결과를 더 직관적으로 이해하고 활용할 수 있게 되었습니다.

구체적으로 예측 구간(Prediction Interval)을 그려주기 위해 Quantile Regressor를 사용했습니다. 그 후에 Conformal prediction의 개념을 도입해 원하는 신뢰수준을 만족하는 예측구간을 추정할 수 있도록 했습니다.

개념에 대해서 제가 이해한 부분들을 정리한 내용입니다.
- [Quantile Regression이란?](/posts/Data%20Science/ML%20Engineering/quantile-regression-explained)
- [Conformal prediciton이란?](/posts/Data%20Science/ML%20Engineering/quantile_regression/conformal-prediction-explained.md)

### 4.2 새로운 평가지표 설계

문제를 재정의하면서 평가지표 역시 재설계했습니다.

단순 오차 기반(MAE)에서 벗어나, 예측 구간이 실제 데이터를 얼마나 포함하는지를 나타내는 **포함률(coverage)**과 **예측 구간의 길이(interval width)**를 새로운 핵심 지표로 정의했습니다.

포함률은 예측 구간이 실제 값을 얼마나 잘 포함하는지를 측정하여 모델의 신뢰도를 평가하고, 구간의 길이는 예측의 불확실성 정도를 나타내어 사용자에게 얼마나 유용한 정보를 제공하는지를 평가합니다. 이 두 지표를 함께 사용함으로써, 단순히 정확한 예측뿐만 아니라 사용자에게 실질적으로 유용한 예측을 제공할 수 있게 되었습니다.

이러한 평가지표는 실제 사용자 만족도와 정렬되어 있어, 비즈니스 목표를 달성하는 데 기여할 수 있었습니다.

### 4.3 성과 및 배운 점

이러한 접근을 통해 사용자의 요구사항을 만족시키고 신뢰도를 높일 수 있었습니다.

실제 사용자 만족도를 높일 수 있는, 비즈니스 목표와 정렬된 평가지표를 새롭게 정의했고, 이를 기반으로 모델을 재설계하여 사용자 경험을 강화했습니다. 그 결과, 실제 사용자로부터 만족도가 향상되었다는 긍정적인 피드백을 받을 수 있었습니다.

이 과정을 통해 사용자의 요구사항을 분석하여 이를 엔지니어링 문제로 재정의하는 경험을 했습니다. 단순히 기술적 성능 지표를 개선하는 것이 아니라, 사용자가 실제로 원하는 것이 무엇인지 이해하고 이를 수학적, 통계적 문제로 변환하는 과정에서 많은 것을 배울 수 있었습니다. 특히 사용자 만족도와 정렬된 평가지표를 설계함으로써 실제로 만족도를 높이는 경험을 할 수 있었습니다.



---

## 5. 예측구간 추정 모델 고도화하기 (진행 중)

### 배경

4번에서 quantile regression으로 문제를 재정의하고 예측 구간을 추정하는 모델을 개발했습니다. 

그러나 여러 분위수를 추정하는 과정에서 분위수끼리의 순서가 맞지 않는 quantile crossing problem이 발생했습니다. 예를 들어, 10% 분위수의 예측값이 90% 분위수의 예측값보다 큰 경우가 발생하는 것입니다. 이는 통계적으로 말이 되지 않으며, 사용자의 신뢰도를 하락시킬 수 있는 심각한 문제였기 때문에 반드시 해결해야 했습니다.

### 5.1 후처리를 통한 임시 해결

우선 빠르게 문제를 해결하기 위해 후처리 기능을 도입했습니다.

추정된 분위수들을 정렬하여 순서가 맞지 않는 부분을 강제로 수정하는 방식으로 quantile crossing 문제를 해결했습니다. 이를 통해 서비스에서 발생하는 문제를 즉시 해결할 수 있었습니다.

그러나 이는 임시적인 해결책일 뿐 근본적인 해결이 될 수 없었습니다. 후처리로 순서를 강제로 맞추면 모델이 학습한 패턴과 다른 결과를 출력하게 되어, 예측 품질이 저하될 수 있기 때문입니다.

### 5.2 제약 조건을 포함한 모델 개발

근본적인 해결을 위해 quantile 간의 단조증가 조건을 학습 과정에 포함시킬 수 있는 모델을 개발하고 있습니다.

이러한 모델은 학습 단계부터 분위수 간의 순서 제약을 만족하도록 설계되어, 후처리 없이도 항상 올바른 순서의 분위수를 출력할 수 있습니다. 구체적으로는 loss function에 단조증가 제약을 추가하거나, 모델 구조 자체가 단조성을 보장하도록 설계하는 방법들을 실험하고 있습니다.

현재 여러 접근 방법을 비교 실험 중이며, 성능과 안정성을 모두 만족하는 최적의 모델을 찾기 위해 노력하고 있습니다.

### 5.3 배운 점

이 과정을 통해 quantile regression의 이론적인 측면을 깊이 있게 이해할 수 있었습니다.

특히 학습 과정에서 quantile 간 단조증가 제약조건을 포함시킬 수 있는 다양한 모델 구조와 최적화 기법에 대해 공부하면서, 단순히 모델을 사용하는 것을 넘어서 내부 동작 원리와 수학적 기반을 이해하게 되었습니다.

또한 실무에서는 빠른 해결책(후처리)과 근본적인 해결책(모델 재설계)의 균형을 맞추는 것이 중요하다는 점을 배웠습니다. 사용자가 겪는 문제를 즉시 해결하면서도, 동시에 장기적으로 더 나은 솔루션을 개발해 나가는 접근이 필요하다는 것을 경험할 수 있었습니다.

