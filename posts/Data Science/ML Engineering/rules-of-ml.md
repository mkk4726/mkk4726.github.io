---
title: "ì¢‹ì€ ML ì„œë¹„ìŠ¤ë€? ì–´ë–»ê²Œ ì •ì˜í•  ìˆ˜ ìˆê³ , ì–´ë–»ê²Œ ê°œë°œí•  ìˆ˜ ìˆì„ì§€"
date: "2025-11-07"
excerpt: "Google - rules of mlì—ì„œ ì´ì•¼ê¸°í•˜ëŠ” ë‚´ìš©ë“¤ ì •ë¦¬"
category: "Data Science"
tags: ["ML Engineering"]
---

ML ì„œë¹„ìŠ¤ë¥¼ êµ¬ì¶•í•˜ë©´ì„œ ë†“ì¹˜ê³  ìˆë˜ ê°œë…ë“¤, ìƒê°ë“¤ì„ ì •ë¦¬í•´ë³´ì.

<a id="ì°¸ê³ ìë£Œ"></a>

ì°¸ê³ ìë£Œ
- 1: [êµ¬ê¸€ì—ì„œ ì œê³µí•˜ëŠ” í¬ìŠ¤íŠ¸ - rules of ml](https://developers.google.com/machine-learning/guides/rules-of-ml#terminology)
  - Google ì—”ì§€ë‹ˆì–´ Martin Zinkevichê°€ ì“´, "ë¨¸ì‹ ëŸ¬ë‹ì„ ì—”ì§€ë‹ˆì–´ë§ì ìœ¼ë¡œ ì„±ê³µì‹œí‚¤ê¸° ìœ„í•œ 43ê°€ì§€ ì‹¤ë¬´ ê·œì¹™"ì„ ë‹´ì€ ëª…ë¬¸ ê°€ì´ë“œ
- 2: [ë§¤ë²ˆ í° ì˜ê°ì„ ì–»ëŠ” ë§í¬ë“œì¸ ì´ì œí—Œë‹˜ì˜ ê¸€](https://www.linkedin.com/feed/update/urn:li:activity:7391194835900305408/)
  - íœ´ë¦¬ìŠ¤í‹±ì˜ ë¬¸ì œ, í•œê³„ì ì€ ë­ê°€ ìˆëŠ”ì§€. AIê°€ ì´ë¥¼ ëŒ€ì²´í•  ìˆ˜ ìˆëŠ” ì´ìœ ëŠ” ë¬´ì—‡ì¸ì§€ ì˜ ì„¤ëª…í•˜ê³  ìˆìŒ

---

# ë‚˜ì˜ ì»¤ë¦¬ì–´ì  ëª©í‘œ

ë‚´ê°€ ê°€ì§€ê³  ìˆëŠ” ì»¤ë¦¬ì–´ì—ì„œ ëª©í‘œëŠ”, ì¢‹ì€ ì„œë¹„ìŠ¤ë¥¼ ë§Œë“¤ê³  ì‹¶ë‹¤ëŠ” ê²ƒ.
ì‚¬ìš©ìê°€ ë§Œì¡±í•˜ë©° ìì£¼ ì‚¬ìš©í•˜ê³ , ì´ë¥¼ í†µí•´ ìˆ˜ìµì„ ë‚¼ ìˆ˜ ìˆëŠ” ê·¸ëŸ° ì„œë¹„ìŠ¤ë¥¼ ë§Œë“¤ê³  ì‹¶ë‹¤.
ì—¬ëŸ¬ ì„œë¹„ìŠ¤ê°€ ìˆê² ì§€ë§Œ ê·¸ ì¤‘ì—ì„œ MLì„ ì‚¬ìš©í•´ í¸ì˜ë¥¼ ì œê³µí•˜ëŠ”, ML ì„œë¹„ìŠ¤ë¥¼ ì˜ ë§Œë“œëŠ” ì‚¬ëŒì´ ë˜ê³  ì‹¶ë‹¤.

ê·¸ë ‡ë‹¤ë©´ ì¢‹ì€ ML ì„œë¹„ìŠ¤ë€, ML ì„œë¹„ìŠ¤ë¥¼ ì˜ ë§Œë“œëŠ” ê²ƒì´ë€ ë¬´ì—‡ì¸ì§€ ìƒê°í•´ë´ì•¼í•œë‹¤.
- ML ì„±ëŠ¥ì´ ê°€ì¥ ì¢‹ì€?
- ì‚¬ìš©í•˜ê¸° í¸í•œ?
- ê°œë°œ ë¹„ìš© ëŒ€ë¹„ ì„±ê³¼ê°€ ë†’ì€?

ì˜í™” ì¶”ì²œ ì„œë¹„ìŠ¤ë¥¼ ë§Œë“ ë‹¤ë©´, ì¢‹ì€ ì˜í™” ì¶”ì²œ ì„œë¹„ìŠ¤ë€ ë¬´ì—‡ì¸ì§€ë¶€í„° ìƒê°í•´ë´ì•¼í•œë‹¤.
- ê·¸ëƒ¥ ì¸ê¸°ë„ ê¸°ë°˜ ì¶”ì²œì„ í•˜ë©´ ì•ˆë˜ëŠ”ê±´ê°€?
  
ì´ëŸ° ê³ ë¯¼ë“¤ì— ëŒ€í•œ ë‹µì„ [ì°¸ê³ 1](#ì°¸ê³ ìë£Œ), rules of ml í¬ìŠ¤íŠ¸ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

---

# ê°œìš”

> Do machine learning like the great engineer you are, not like the great machine learning expert you aren't.

ì‹¤ì œë¡œ ë§ˆì£¼í•˜ëŠ” ëŒ€ë¶€ë¶„ì˜ ë¬¸ì œëŠ” ëª¨ë¸ì˜ ë¬¸ì œê°€ ì•„ë‹ˆë¼ ì—”ì§€ë‹ˆì–´ë§ì ì¸ ë¬¸ì œë‹¤.
ëª¨ë¸ì€ ì „ì²´ ì„œë¹„ìŠ¤ì˜ ì¼ë¶€ë¶„ì— í•´ë‹¹.

> So, the basic approach is:
> 1. Make sure your pipeline is solid end to end.
> 2. Start with a reasonable objective.
> 3. Add commonÂ­-sense features in a simple way.
> 4. Make sure that your pipeline stays solid.

ê°€ì¥ ê¸°ë³¸ì ì¸ ì ‘ê·¼ì€ ê²¬ê³ í•œ íŒŒì´í”„ë¼ì¸ì„ ë§Œë“¤ê³ , ê·¸ ì•ˆì—ì„œ í‰ê°€ì§€í‘œë¡¤ ì„¸ìš°ê³ , ë³´í¸ì ì¸ í”¼ì²˜ë¥¼ ì¶”ê°€í•˜ëŠ” ê²ƒ.
ì—¬ê¸°ì„œ ë” ì´ìƒ ê°œì„ í•  ìˆ˜ ìˆëŠ”ê²Œ ì—†ì„ ë–„, ì¡°ê¸ˆì”© ë³µì¡í•œ ë°©ë²•ë“¤ì„ ì¶”ê°€í•˜ê¸°.

í•™ìƒ ë•ŒëŠ” ëª¨ë¸ì ì¸ ì¸¡ë©´ì—ë§Œ ì§‘ì¤‘í•˜ê³  ë” ë†’ì€ ì„±ëŠ¥ì„ ë†’ì´ëŠ”ë° ì§‘ì¤‘í•˜ì§€ë§Œ, ì‚¬ì‹¤ ì„œë¹„ìŠ¤ë¥¼ ë§Œë“¤ë‹¤ë³´ë©´ ëŒ€ë¶€ë¶„ì€ ì—”ì§€ë‹ˆì–´ë§ ì˜ì—­ì´ë¼ëŠ” ê²ƒì„ ì•Œê²Œ ë˜ëŠ” ê²ƒ ê°™ë‹¤.
ëˆ„êµ°ê°€ëŠ” ë‹¹ì—°í•œ ì´ì•¼ê¸°ë¼ê³  ìƒê°í•  ìˆ˜ ìˆì§€ë§Œ, ê°€ì¥ í•µì‹¬ì ì¸ ë¶€ë¶„ì´ë¼ê³  ìƒê°í•˜ê³  í•œë²ˆ ë” ë§ˆìŒì— ìƒˆê¸°ê²Œ ëœë‹¤.

---

# Before Machine Learning

ì´ ë¶€ë¶„ì´ ê°€ì¥ ì¢‹ë‹¤.
ë‹¹ì—°í•œ ì´ì•¼ê¸°ì§€ë§Œ ë¨¸ì‹ ëŸ¬ë‹ì„ ê¼­ ì‚¬ìš©í•´ì•¼í•˜ëŠ” ê±´ ì•„ë‹ˆë‹¤.
íœ´ë¦¬ìŠ¤í‹±ë„ ì²˜ìŒì—” ì¢‹ì€ ì ‘ê·¼ ë°©ë²•ì´ë‹¤.

## Rule #1: Don't be afraid to launch a product without machine learning.

> Machine learning is cool, but it requires data. Theoretically, you can take data from a different problem and then tweak the model for a new product, but this will likely underperform basic heuristics. 
> If you think that machine learning will give you a 100% boost, then a heuristic will get you 50% of the way there.

ë‚´ê°€ ìš´ì˜í•˜ê³  ìˆëŠ” [ì˜í™” ì¶”ì²œ ì„œë¹„ìŠ¤](https://movie.mingyuprojects.dev) ë¥¼ ìƒê°í•´ë³´ë©´ ctr prediction ëª¨ë¸ì„ ë§Œë“¤ê³  ì‹¶ì–´ë„, ê´€ë ¨í•œ ë°ì´í„°ê°€ ì—†ë‹¤. ë”°ë¼ì„œ íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ ì¶”ì²œì„ í•˜ê³  ê·¸ ë‹¤ìŒì— ë¡œê·¸ ë°ì´í„°ë¥¼ í†µí•´ ì˜ˆì¸¡í•  í™•ë¥ ì´ ë†’ì€ ê±¸ ë³´ì—¬ì¤„ ìˆ˜ ìˆì§€ ì•Šì„ê¹Œ?

## Rule #2: First, design and implement metrics.

ì´ ë¶€ë¶„ì´ ê°€ì¥ í•µì‹¬.
ë˜ ë‚´ê°€ ê°€ì¥ í•´ë³´ê³  ì‹¶ì€ ê²½í—˜.
ì‚¬ìš©ì ë¡œê·¸ë¡œë¶€í„° ë©”íŠ¸ë¦­ì„ ì •ì˜í•˜ê³ , ì´ë¥¼ ê³ ë„í™” í•´ë‚˜ê°€ëŠ” ì‘ì—….

> Before formalizing what your machine learning system will do, track as much as possible in your current system. Do this for the following reasons:
> 1. It is easier to gain permission from the systemâ€™s users earlier on.
> 2. If you think that something might be a concern in the future, it is better to get historical data now.
> 3. If you design your system with metric instrumentation in mind, things will go better for you in the future. 
>    Specifically, you donâ€™t want to find yourself grepping for strings in logs to instrument your metrics!
> 4. You will notice what things change and what stays the same. 
>    For instance, suppose you want to directly optimize oneÂ­-day active users. 
>    However, during your early manipulations of the system, you may notice that dramatic alterations of the user experience donâ€™t noticeably change this metric.

> Google Plus team measures expands per read, reshares per read, plusÂ­ones per read, comments/read, comments per user, reshares per user, etc. which they use in computing the goodness of a post at serving time. 
> Also, note that an experiment framework, in which you can group users into buckets and aggregate statistics by experiment, is important. See Rule #12.

> By being more liberal about gathering metrics, you can gain a broader picture of your system. Notice a problem? Add a metric to track it! Excited about some quantitative change on the last release? Add a metric to track it!

## Rule #3: Choose machine learning over a complex heuristic.

ë‹¨ìˆœí•œ íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ ì œí’ˆ ì¶œì‹œê¹Œì§€ ê°€ëŠ¥, ê·¸ í›„ì— ë³µì¡í•œ íœ´ë¦¬ìŠ¤í‹±ì€ ìœ ì§€ë³´ìˆ˜ê°€ ì–´ë ¤ì›€.
( Hyperconnect ë§í¬ë“œì¸ì—ì„œ ì´ëŸ° ê¸€ì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆë‹¤ )

> As in most software engineering tasks, you will want to be constantly updating your approach, whether it is a heuristic or a machineÂ­-learned model, and you will find that the machineÂ­-learned model is easier to update and maintain (see Rule #16).

---

# ML Phase I â€” Your First Pipeline (+ Monitoring)

> â€œëª¨ë¸ë³´ë‹¤ ì¸í”„ë¼ Â· ë°ì´í„° ì‹ ë¢°ì„±ì„ ë¨¼ì € í™•ë³´í•˜ë¼.â€
> ì²« ëª¨ë¸ì€ ë‹¨ìˆœí•˜ê²Œ, íŒŒì´í”„ë¼ì¸ì€ ê²€ì¦ ê°€ëŠ¥í•˜ê²Œ ë§Œë“¤ê³ , ëª¨ë‹ˆí„°ë§ ìœ¼ë¡œ ì•ˆì •ì„±ì„ ìœ ì§€í•˜ë¼.

- ìš”ì•½í‘œ
| êµ¬ë¶„             | Rule | í•µì‹¬ ì œëª©                         | ìš”ì•½ í•µì‹¬ ë©”ì‹œì§€            |
| -------------- | ---- | ----------------------------- | -------------------- |
| **Phase I**    | #4   | Keep the first model simple   | ì²« ëª¨ë¸ì€ ë‹¨ìˆœí•˜ê²Œ, ì¸í”„ë¼ëŠ” í™•ì‹¤íˆ |
|                | #5   | Test infra independently      | ML ì—†ì´ë„ íŒŒì´í”„ë¼ì¸ ê²€ì¦ ê°€ëŠ¥í•˜ê²Œ |
|                | #6   | Beware dropped data           | ë³µì‚¬ íŒŒì´í”„ë¼ì¸ ë°ì´í„° ëˆ„ë½ ì£¼ì˜   |
|                | #7   | Turn heuristics into features | ê¸°ì¡´ ë£°ì„ feature ë¡œ í™œìš©   |
| **Monitoring** | #8   | Know freshness requirements   | ëª¨ë¸ ê°±ì‹  ì£¼ê¸°ë¥¼ ì •í™•íˆ íŒŒì•…     |
|                | #9   | Detect problems before export | ë°°í¬ ì „ sanity check í•„ìˆ˜ |
|                | #10  | Watch for silent failures     | ì„œì„œíˆ ë§ê°€ì§€ëŠ” ë°ì´í„° ê°ì‹œ      |
|                | #11  | Give feature owners & docs    | feature ì†Œìœ ìÂ·ë¬¸ì„œ ëª…ì‹œ    |


ì²«ë²ˆì§¸ë¡œ ML pipelineì„ ê°œë°œí•  ë•ŒëŠ” ì—­ì‹œ "íŒŒì´í”„ë¼ì¸ ì•ˆì •ì„±"ì„ ìš°ì„ ì‹œ í•´ì•¼ í•¨.
ëª¨ë¸ì€ ìº¡ìŠí™”í•´ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•˜ê³ , ëª¨ë¸ ì—†ì´ (ë”ë¯¸ ëª¨ë¸ë¡œ)ë„ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥í•´ì•¼ í•¨.

ë˜ ì˜ ëŒì•„ê°€ëŠ”ì§€ ì‚¬ì „ì— í™•ì¸ (test case, sanity check) í•´ì•¼í•˜ê³ , ëª¨ë‹ˆí„°ë§ì„ í†µí•´ í™•ì¸í•  ìˆ˜ ìˆì–´ì•¼ í•¨.

---

# âš™ï¸ ML Phase II â€” Feature Engineering

> â€œEnd-to-end íŒŒì´í”„ë¼ì¸ì´ ì•ˆì •ëë‹¤ë©´, ì´ì œ â€˜ì¢‹ì€ í”¼ì²˜ë¥¼ ì–¼ë§ˆë‚˜ ì˜ ë§Œë“¤ê³  ë‹¤ë£° ìˆ˜ ìˆëŠ”ê°€â€™ê°€ í•µì‹¬ì´ë‹¤.â€

> ëª¨ë¸ë³´ë‹¤ **ë°ì´í„° í‘œí˜„ë ¥(Features)** ì—ì„œ ëŒ€ë¶€ë¶„ì˜ ì„±ëŠ¥ì´ ë‚˜ì˜¨ë‹¤.


| Rule    | ì œëª©                                     | í•µì‹¬ ë©”ì‹œì§€           | ì£¼ìš” í‚¤ì›Œë“œ                           |
| ------- | -------------------------------------- | ---------------- | -------------------------------- |
| **#16** | Plan to launch and iterate             | ëª¨ë¸ì€ ê³„ì† ê°œì„ ë˜ëŠ” ì¡´ì¬   | Iteration, Launch cycle          |
| **#17** | Start with directly observed features  | ì§ì ‘ ê´€ì¸¡ ê°€ëŠ¥í•œ í”¼ì²˜ë¶€í„°   | Raw features, Avoid learned ones |
| **#18** | Explore generalizable content features | ë§¥ë½ ê°„ ì¼ë°˜í™” ê°€ëŠ¥í•œ í”¼ì²˜  | Cross-context, Content features  |
| **#19** | Use very specific features             | ë§ì€ ë‹¨ìˆœ í”¼ì²˜ë¥¼ í™œìš©     | Granular, Regularization         |
| **#20** | Combine & modify features meaningfully | ì‚¬ëŒì´ ì´í•´ ê°€ëŠ¥í•œ í”¼ì²˜ ì¡°í•© | Discretization, Cross            |
| **#21** | Feature count âˆ data size              | í”¼ì²˜ ìˆ˜ëŠ” ë°ì´í„° ì–‘ì— ë¹„ë¡€  | Data-volume scaling              |
| **#22** | Clean up unused features               | ì•ˆ ì“°ëŠ” í”¼ì²˜ëŠ” ê¸°ìˆ  ë¶€ì±„   | Feature store hygiene            |




## ğŸš€ Rule #16 â€“ Plan to launch and iterate

**â€œëª¨ë¸ì€ í•œ ë²ˆì´ ì•„ë‹ˆë¼ ê³„ì† ê°œì„ ë˜ëŠ” ì¡´ì¬ë‹¤.â€**

* **í•µì‹¬ ë©”ì‹œì§€:**
  í•œ ë²ˆì˜ ëª¨ë¸ë¡œ ëë‚˜ì§€ ì•ŠëŠ”ë‹¤.
  â†’ **â€œLaunch â†’ Measure â†’ Iterateâ€** ì‚¬ì´í´ì„ ì§€ì†ì ìœ¼ë¡œ ë°˜ë³µ.
* **ì‹¤í–‰ í¬ì¸íŠ¸:**

  * ëª¨ë¸ì€ ì£¼ê¸°ì ìœ¼ë¡œ ê°œì„ ë˜ì–´ì•¼ í•œë‹¤ (ë¶„ê¸°ë³„ ì—…ë°ì´íŠ¸ë„ OK).
  * í”¼ì²˜ ì¶”ê°€, ì •ê·œí™” ì¡°ì •, objective ë³€ê²½ ë“±ì€ ê¾¸ì¤€íˆ ë°˜ë³µ.
  * **ë³µì¡ë„ë¥¼ ëŠ˜ë¦´ ë•ŒëŠ”** â€œë‹¤ìŒ ëŸ°ì¹­ì„ ì–¼ë§ˆë‚˜ ì–´ë µê²Œ ë§Œë“¤ê¹Œ?â€ë¥¼ í•­ìƒ ê³ ë ¤.
* **ì‹¤ë¬´ íŒ:**
  ëª¨ë¸ì„ êµì²´í•˜ê¸° ì‰½ê²Œ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì„± (feature ì¶”ê°€/ì œê±° ìš©ì´ì„± í™•ë³´).


## ğŸ§  Rule #18 â€“ Explore with features of content that generalize across contexts

**â€œë§¥ë½ì„ ì´ˆì›”í•´ ì¼ë°˜í™” ê°€ëŠ¥í•œ ì½˜í…ì¸  í”¼ì²˜ë¥¼ ì°¾ì•„ë¼.â€**

* **í•µì‹¬ ë©”ì‹œì§€:**
  í”¼ì²˜ëŠ” **ë‹¤ë¥¸ í™˜ê²½ì—ì„œë„ ì˜ë¯¸ê°€ ìœ ì§€**ë˜ì–´ì•¼ í•œë‹¤.
* **ì˜ˆì‹œ:**

  * YouTube Watch NextëŠ” ê²€ìƒ‰ì—ì„œì˜ **co-watch(ê³µë™ì‹œì²­)** ë°ì´í„°ë¥¼ ì¬í™œìš©.
  * ê²Œì‹œê¸€ ì¶”ì²œ ëª¨ë¸ì€ ë‹¤ë¥¸ ì±„ë„ì—ì„œì˜ **ì¢‹ì•„ìš”, ëŒ“ê¸€, ê³µìœ ** í”¼ì²˜ë¥¼ í™œìš©.
* **ìš”ì :**
  í•œ ì‹œìŠ¤í…œì—ì„œ ìŒ“ì¸ í–‰ë™ ë°ì´í„°ëŠ” ë‹¤ë¥¸ ì‹œìŠ¤í…œì—ì„œë„ ìœ ìš©í•˜ë‹¤.
  â†’ â€œcross-context featuresâ€ëŠ” cold-start ë¬¸ì œ í•´ê²°ì—ë„ ë„ì›€.
* **ì‹¤ë¬´ íŒ:**
  personalizationë³´ë‹¤ **ì½˜í…ì¸  ìì²´ íŠ¹ì„±(content features)** ì„ ë¨¼ì € í™•ë³´í•˜ë¼.



---

# Human Analysis of the System

> **â€œëª¨ë¸ì´ ì˜ ëŒì•„ê°€ë„, ë§¹ì‹ í•˜ì§€ ë§ê³  ì¸ê°„ì˜ ëˆˆìœ¼ë¡œ ë¶„ì„í•˜ë¼.â€**
> ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ì˜ í•µì‹¬ì€ **ëª¨ë¸ í•´ì„ â†’ ì—ëŸ¬ ë¶„ì„ â†’ í”¼ì²˜ ì¶”ê°€**ì˜ ë°˜ë³µì´ë‹¤.

| Rule    | ì œëª©                                         | í•µì‹¬ ë©”ì‹œì§€                    | ì£¼ìš” í‚¤ì›Œë“œ                                  |
| ------- | ------------------------------------------ | ------------------------- | --------------------------------------- |
| **#23** | You are not a typical end user             | ë‚´ë¶€ ì‹œê°ì€ í¸í–¥ë¨, ì‹¤ì œ ì‚¬ìš©ì í…ŒìŠ¤íŠ¸ í•„ìš” | Usability, Persona, Crowdsourcing       |
| **#24** | Measure the delta between models           | ëª¨ë¸ ê°„ ë³€í™”ëŸ‰(Î”)ì„ ì •ëŸ‰ì ìœ¼ë¡œ ë¹„êµ     | Side-by-side test, Symmetric difference |
| **#25** | Utilitarian performance > predictive power | ì˜ˆì¸¡ ì •í™•ë„ë³´ë‹¤ ì‹¤ì œ íš¨ìš©ì´ ë” ì¤‘ìš”      | Utility, Decision impact                |
| **#26** | Find error patterns â†’ new features         | ì˜¤ë¥˜ íŒ¨í„´ì„ ë°œê²¬í•´ featureë¡œ ë³´ì™„    | Error analysis, Feature engineering     |
| **#27** | Quantify undesirable behavior              | ë¬¸ì œ í–‰ë™ì„ ìˆ˜ì¹˜í™”í•´ ê°œì„             | Metrics, Human labeling, Measurement    |

> **â€œëª¨ë¸ì˜ í•œê³„ëŠ” ë°ì´í„°ê°€ ì•„ë‹ˆë¼ â€˜ë¶„ì„ ë¶€ì¡±â€™ì—ì„œ ì˜¨ë‹¤.â€**
> ì¸ê°„ì´ ì§ì ‘ ëª¨ë¸ì˜ ì˜¤ë¥˜ íŒ¨í„´ì„ ë³´ê³ ,
> ë¬¸ì œë¥¼ ìˆ˜ì¹˜í™”í•˜ê³ , ìƒˆ í”¼ì²˜ë¥¼ ì„¤ê³„í•  ë•Œ
> ë¹„ë¡œì†Œ ML ì‹œìŠ¤í…œì€ ì§„ì§œë¡œ ì„±ì¥í•œë‹¤.

## ğŸ§  Rule #23 â€“ You are not a typical end user

**â€œë‹¹ì‹ ì€ ì¼ë°˜ ì‚¬ìš©ìê°€ ì•„ë‹ˆë‹¤.â€**

* **í•µì‹¬ ìš”ì§€:**
  ê°œë°œì ìì‹ ì´ ì§ì ‘ ì‹œìŠ¤í…œì„ í‰ê°€í•˜ë©´ **í¸í–¥(bias)** ì´ ìƒê¸´ë‹¤.
* **ì´ìœ :**

  1. **ì½”ë“œì— ë„ˆë¬´ ìµìˆ™í•´ì„œ** íŠ¹ì • ë¬¸ì œë¥¼ ëª» ë³¸ë‹¤.
  2. **ì‹œê°„ ê°€ì¹˜ê°€ ë†’ì•„** ëŒ€ê·œëª¨ í”¼ë“œë°± ìˆ˜ì§‘ì´ ë¹„íš¨ìœ¨ì ì´ë‹¤.
* **ëŒ€ì•ˆ:**

  * ë‚´ë¶€ í…ŒìŠ¤íŠ¸(fishfooding)ì™€ ì™¸ë¶€ ì‚¬ìš©ì í…ŒìŠ¤íŠ¸(crowdsourcing, A/B test)ë¥¼ ë³‘í–‰.
  * **â€œì§„ì§œ ì‚¬ìš©ìâ€ì˜ ë°˜ì‘ìœ¼ë¡œ ëª¨ë¸ í’ˆì§ˆì„ íŒë‹¨í•˜ë¼.**
* **ì‹¤ë¬´ íŒ:**

  * **User Persona(ê°€ìƒ ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤)** ì„¤ì •
  * **Usability Testing(ì‹¤ì‚¬ìš©ì í…ŒìŠ¤íŠ¸)** ë„ì…
  * íŒ€ ë‚´ êµ¬ì„±ì›ì´ ì‹¤ì œ ì‚¬ìš©ì ì¸µê³¼ ë‹¤ë¥´ë©´, ë”ë”ìš± ì™¸ë¶€ í‰ê°€ê°€ í•„ìš”.

## ğŸ§® Rule #24 â€“ Measure the delta between models

ê³ ë ¤í•˜ì§€ ëª»í–ˆë˜ ë¶€ë¶„ì¸ë°, deltaë¥¼ ê³„ì‚°í•´ë´ì•¼ í•˜ëŠ”êµ¬ë‚˜.

**â€œëª¨ë¸ ê°„ì˜ ì°¨ì´ë¥¼ ì •ëŸ‰ì ìœ¼ë¡œ ì¸¡ì •í•˜ë¼.â€**

* **í•µì‹¬ ìš”ì§€:**
  ìƒˆ ëª¨ë¸ì´ ì¢‹ë‹¤ê³  ëŠë¼ê¸° ì „ì—,
  ê¸°ì¡´ ëª¨ë¸ê³¼ **ê²°ê³¼ ì°¨ì´(Î”)** ë¥¼ ìˆ˜ì¹˜ë¡œ ë¹„êµí•˜ë¼.
* **ë°©ë²•:**

  * ê°™ì€ ì…ë ¥(ì˜ˆ: ì¿¼ë¦¬, ë¬¸ì„œ ì„¸íŠ¸)ì— ëŒ€í•´ ë‘ ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ë¹„êµ.
  * **Symmetric Difference** (ì–‘ìª½ì—ì„œ ë‹¬ë¼ì§„ í•­ëª© ë¹„ìœ¨)ë¥¼ ê³„ì‚°.
  * ì°¨ì´ê°€ ë„ˆë¬´ í¬ê±°ë‚˜ ë„ˆë¬´ ì‘ìœ¼ë©´ ì›ì¸ ë¶„ì„ í•„ìš”.
* **í™œìš©:**

  * ì°¨ì´ê°€ **ë„ˆë¬´ ì‘ìœ¼ë©´ â†’ ì˜í–¥ì´ ê±°ì˜ ì—†ìŒ.**
  * ì°¨ì´ê°€ **ë„ˆë¬´ í¬ë©´ â†’ ìœ„í—˜ë„ê°€ ë†’ìŒ.**
  * ì°¨ì´ í° ì¼€ì´ìŠ¤ë¥¼ ìƒ˜í”Œë§í•´ ì§ì ‘ ì ê²€ (Qualitative Review)
* **ìš”ì•½:**

  > â€œë³€í™”ê°€ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ê°€? ì¡´ì¬í•œë‹¤ë©´ ê·¸ ë³€í™”ëŠ” ì˜¬ë°”ë¥¸ ë°©í–¥ì¸ê°€?â€


## ğŸ“Š Rule #25 â€“ When choosing models, utilitarian performance trumps predictive power

**â€œì˜ˆì¸¡ ì •í™•ë„ë³´ë‹¤ ì‹¤ì œ ìœ ìš©ì„±ì„ ìš°ì„ í•˜ë¼.â€**

ë‚´ê°€ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ìƒê°í•˜ëŠ” ë¶€ë¶„!

* **í•µì‹¬ ìš”ì§€:**
  ëª¨ë¸ì˜ ëª©ì ì€ ì˜ˆì¸¡ì´ ì•„ë‹ˆë¼ **ì˜ì‚¬ê²°ì •(decision)** ì´ë‹¤.
  â†’ ì‹¤ì‚¬ìš©ì—ì„œì˜ íš¨ìš©(utility)ì´ ì •í™•ë„ë³´ë‹¤ ì¤‘ìš”í•˜ë‹¤.
* **ì˜ˆì‹œ:**

  * í´ë¦­ í™•ë¥  ì˜ˆì¸¡(CVR)ì´ ì •í™•í•´ë„,
    ì‹¤ì œ **ìˆœìœ„ í’ˆì§ˆ**ì´ ë‚˜ë¹ ì§€ë©´ ì˜ë¯¸ ì—†ë‹¤.
  * Spam filterì—ì„œ log lossê°€ ê°œì„ ë¼ë„,
    ì‹¤ì œ **ìŠ¤íŒ¸ í†µê³¼ìœ¨**ì´ ë†’ì•„ì§€ë©´ ì•ˆ ëœë‹¤.
* **í•µì‹¬ ë¬¸ì¥:**

  > â€œWhat matters is what you do with the prediction.â€
  > ì¦‰, ëª¨ë¸ì´ ë‚´ë†“ì€ ìˆ«ìë³´ë‹¤ ê·¸ ìˆ«ìë¥¼ **ì–´ë–»ê²Œ ì‚¬ìš©í• ì§€(policy layer)** ê°€ ë” ì¤‘ìš”í•˜ë‹¤.


## ğŸ” Rule #26 â€“ Look for patterns in the measured errors, and create new features

**â€œëª¨ë¸ì´ í‹€ë¦° íŒ¨í„´ì„ ì°¾ì•„ë‚´ê³ , ê·¸ê²ƒì„ í”¼ì²˜ë¡œ ë°”ê¿”ë¼.â€**

* **í•µì‹¬ ìš”ì§€:**
  ëª¨ë¸ì´ **ì–´ë””ì„œ, ì™œ í‹€ë¦¬ëŠ”ì§€(error pattern)** ë¥¼ ë¶„ì„í•˜ê³ ,
  ê·¸ ì›ì¸ì„ ë³´ì •í•  **ìƒˆë¡œìš´ feature** ë¥¼ ë§Œë“ ë‹¤.
* **ì˜ˆì‹œ:**

  * ëª¨ë¸ì´ â€œê¸´ ê²Œì‹œë¬¼â€ì„ ì¼ê´€ë˜ê²Œ ë‚®ê²Œ í‰ê°€í•œë‹¤ë©´,
    â†’ â€œê²Œì‹œë¬¼ ê¸¸ì´(post_length)â€ í”¼ì²˜ë¥¼ ì¶”ê°€í•˜ë¼.
  * ëª¨ë¸ì´ â€œíŠ¹ì • ì‹œê°„ëŒ€â€ì— ì„±ëŠ¥ì´ ë–¨ì–´ì§„ë‹¤ë©´,
    â†’ â€œtime_of_dayâ€ í”¼ì²˜ ì¶”ê°€.
* **ì¤‘ìš” í¬ì¸íŠ¸:**

  * ëª¨ë¸ì´ **ì‹¤ìˆ˜í•œ ì˜ˆì œ**ë§Œ ì§‘ì¤‘ ë¶„ì„í•˜ë¼.
    â†’ ëª¨ë¸ì´ ìŠ¤ìŠ¤ë¡œ ê³ ì¹˜ê³  ì‹¶ì–´í•˜ëŠ” ì§€ì ì„ ì•Œë ¤ì¤Œ.
  * ì˜ ë§ì¶˜ ì˜ˆì œëŠ” feature ì¶”ê°€í•´ë„ ì˜ë¯¸ ì—†ìŒ.
* **ì •ë¦¬:**

  > â€œError = feature engineeringì˜ ê¸°íšŒ.â€


## ğŸ§® Rule #27 â€“ Try to quantify observed undesirable behavior

**â€œë¬¸ì œë˜ëŠ” ëª¨ë¸ í–‰ë™ì„ ìˆ˜ì¹˜ë¡œ ì •ì˜í•˜ë¼.â€**

* **í•µì‹¬ ìš”ì§€:**
  ëª¨ë¸ì˜ ë‚˜ìœ í–‰ë™(undesirable behavior)ì„
  **ì •ëŸ‰í™”(quantify)** í•´ì•¼ ê°œì„ ì´ ê°€ëŠ¥í•˜ë‹¤.
* **ì˜ˆì‹œ:**

  * â€œê°€ì§œ ì•±(gag apps)â€ì´ ë„ˆë¬´ ë§ì´ ì¶”ì²œëœë‹¤ë©´,
    â†’ â€œê°€ì§œ ì•±â€ ë¼ë²¨ì„ ì¸ìœ„ì ìœ¼ë¡œ ë¶™ì´ê³  ê·¸ ìˆ˜ë¥¼ ì¶”ì .
  * â€œìŠ¤íŒ¸ ê²Œì‹œë¬¼â€ì´ ê³¼ë„í•˜ê²Œ ë…¸ì¶œëœë‹¤ë©´,
    â†’ human labelerë¡œ ìŠ¤íŒ¸ ë¹„ìœ¨ ì¸¡ì • â†’ feature or metric ì¶”ê°€.
* **í•µì‹¬ ì² í•™:**

  * â€œëª¨í˜¸í•œ ë¶ˆë§Œì„ ìˆ˜ì¹˜ë¡œ ë°”ê¿”ì•¼ ê°œì„ í•  ìˆ˜ ìˆë‹¤.â€
  * **Measure first, optimize second.**

---

# Training-Serving Skew

| Rule    | ì œëª©                               | í•µì‹¬ ë©”ì‹œì§€                | ì£¼ìš” í‚¤ì›Œë“œ                         |
| ------- | -------------------------------- | --------------------- | ------------------------------ |
| **#29** | Train like you serve             | ì„œë¹™ê³¼ í•™ìŠµ feature ì¼ì¹˜     | Logging, Serving-feature reuse |
| **#30** | Importance-weight sampled data   | ë°ì´í„°ëŠ” ë²„ë¦¬ì§€ ë§ê³  ê°€ì¤‘ì¹˜ ìƒ˜í”Œë§   | Sampling, Calibration          |
| **#31** | Beware of joined table drift     | ì¡°ì¸ í…Œì´ë¸”ì˜ ì‹œì  ë¶ˆì¼ì¹˜ ì£¼ì˜     | Snapshot, Feature drift        |
| **#32** | Reuse code between train & serve | í•™ìŠµÂ·ì„œë¹™ íŒŒì´í”„ë¼ì¸ ì½”ë“œ ê³µìœ      | Shared library                 |
| **#33** | Test on future data              | ë¯¸ë˜ ì‹œì  ë°ì´í„°ë¡œ í‰ê°€         | Temporal validation            |
| **#34** | Clean data > more data           | ê¹¨ë—í•œ ë°ì´í„° í™•ë³´ê°€ ë” ì¤‘ìš”      | Filtering bias                 |
| **#35** | Ranking skew                     | ë‹¨ê¸° â‰  ì¥ê¸° í–‰ë™, í”¼ë“œë°± ë£¨í”„ ê´€ë¦¬ | Regularization, Exploration    |
| **#36** | Positional feedback loops        | ë…¸ì¶œ ìœ„ì¹˜ í”¼ì²˜ë¡œ ì¸í•œ ë£¨í”„ ì£¼ì˜    | Position feature isolation     |
| **#37** | Measure training/serving skew    | ë¶ˆì¼ì¹˜ë¥¼ ì •ëŸ‰ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§       | Consistency check, Monitoring  |

> **â€œëª¨ë¸ì€ ë°ì´í„°ì˜ ê±°ìš¸ì´ë‹¤ â€” í›ˆë ¨ê³¼ ì„œë¹„ìŠ¤ê°€ ë‹¤ë¥´ë©´, ê±°ìš¸ì´ ì™œê³¡ëœë‹¤.â€**
>
> í•™ìŠµÂ·ì„œë¹™ í™˜ê²½ì˜ ë°ì´í„°, ì½”ë“œ, í…Œì´ë¸”, ì‹œì , ìœ„ì¹˜ íš¨ê³¼ë¥¼ ì¼ì¹˜ì‹œí‚¤ê³ 
> ì£¼ê¸°ì ìœ¼ë¡œ skewë¥¼ ëª¨ë‹ˆí„°ë§í•˜ëŠ” ê²ƒì´
> ëŒ€ê·œëª¨ ML ì‹œìŠ¤í…œ ì‹ ë¢°ì„±ì˜ í•µì‹¬ì´ë‹¤.

## ğŸ§© ê°œìš”: Training-Serving Skewë€?

> **Training-serving skew** =
> ëª¨ë¸ì´ í•™ìŠµí•  ë•Œ ë³¸ ë°ì´í„°(Training)ì™€
> ì‹¤ì œ ì„œë¹„ìŠ¤ ì‹œì (Serving)ì—ì„œ ë°›ëŠ” ë°ì´í„°ê°€ **ì„œë¡œ ë‹¬ë¼ì„œ ì„±ëŠ¥ì´ ë–¨ì–´ì§€ëŠ” í˜„ìƒ.**

### ğŸ’¥ ì˜ˆì‹œ

* í•™ìŠµ ì‹œì—ëŠ” ì •ê·œí™”ëœ featureë¥¼ ì‚¬ìš©í–ˆì§€ë§Œ,
  ì„œë¹™ ì‹œì—ëŠ” raw featureê°€ ë“¤ì–´ê° â†’ ì˜ˆì¸¡ê°’ ì—‰ë§
* Training ë•ŒëŠ” â€œì‚¬ìš©ì í´ë¦­ ë¡œê·¸â€ë¥¼ ì¼ëŠ”ë°,
  ì„œë¹™ ì‹œì—” â€œìƒˆ ìœ ì €â€ë¼ì„œ ê·¸ëŸ° feature ì—†ìŒ â†’ cold-start ë°œìƒ
* DB ì¡°ì¸ì´ í•™ìŠµ ë•Œì™€ ë‹¬ë¼ feature ê°’ì´ ë°”ë€œ â†’ feature drift ë°œìƒ

ì¦‰, ëª¨ë¸ì´ **í›ˆë ¨ ë•Œ ë³¸ ì„¸ìƒê³¼ ì‹¤ì œ ì„¸ìƒì´ ë‹¤ë¥´ë‹¤.**

## âš™ï¸ Rule #29 â€“ Train like you serve

**â€œì„œë¹™í•  ë•Œì²˜ëŸ¼ í•™ìŠµí•˜ë¼.â€**

* **í•µì‹¬ ìš”ì§€:**
  ëª¨ë¸ í•™ìŠµ ì‹œ ì‚¬ìš©ëœ feature êµ¬ì„±ì„
  ì‹¤ì œ ì„œë¹„ìŠ¤ ì‹œ ì‚¬ìš©í•˜ëŠ” featureì™€ **ì •í™•íˆ ì¼ì¹˜**ì‹œì¼œë¼.
* **ë°©ë²•:**

  * Serving ì‹œ ì‚¬ìš©ë˜ëŠ” feature setì„ ê·¸ëŒ€ë¡œ logë¡œ ì €ì¥í•˜ì—¬ í•™ìŠµì— ì¬ì‚¬ìš©.
  * ìµœì†Œí•œ ì¼ë¶€ ìƒ˜í”Œì´ë¼ë„ serving feature log â†’ training dataë¡œ ì—­ì „ì†¡(feedback loop).
* **ì‚¬ë¡€:**
  YouTube Home ëª¨ë¸ì´ serving-time feature loggingìœ¼ë¡œ ì „í™˜í•˜ë©´ì„œ
  í’ˆì§ˆ ìƒìŠ¹ + ì½”ë“œ ë³µì¡ë„ ê°ì†Œ.

## âš ï¸ Rule #30 â€“ Importance-weight sampled data, donâ€™t arbitrarily drop it

**â€œë°ì´í„°ê°€ ë§ë‹¤ê³  ì•„ë¬´ê±°ë‚˜ ë²„ë¦¬ì§€ ë§ê³ , ê°€ì¤‘ì¹˜ ìƒ˜í”Œë§ì„ ì¨ë¼.â€**

* **ë¬¸ì œ:**
  ë°ì´í„°ê°€ ë„ˆë¬´ ë§ì„ ë•Œ ì„ì˜ë¡œ ì¼ë¶€ë§Œ ì“°ë©´ ë¶„í¬ê°€ ì™œê³¡ë¨.
* **í•´ê²°:**

  * **Importance weighting**:
    ìƒ˜í”Œ í™•ë¥ ì´ ë‚®ì„ìˆ˜ë¡ ê°€ì¤‘ì¹˜ë¥¼ ë†’ì—¬ ë°˜ì˜.
    ì˜ˆ: 30%ë§Œ ìƒ˜í”Œë§í–ˆìœ¼ë©´ â†’ weight = 1 / 0.3 = 3.33
* **ê²°ê³¼:**
  â†’ ë°ì´í„° ë¶„í¬ ì™œê³¡ ì—†ì´ íš¨ìœ¨ì  í•™ìŠµ ê°€ëŠ¥.
  (ì •ê·œí™” í›„ì—ë„ calibration ìœ ì§€)

## ğŸ§  Rule #31 â€“ Beware of data changes in joined tables

**â€œTrainingê³¼ Serving ì‹œì ì— ì¡°ì¸ë˜ëŠ” í…Œì´ë¸” ë°ì´í„°ê°€ ë°”ë€” ìˆ˜ ìˆë‹¤.â€**

* **ë¬¸ì œ:**
  featureë¥¼ ì™¸ë¶€ í…Œì´ë¸”ì—ì„œ join í•  ë•Œ,
  ì‹œê°„ì°¨ë¡œ ì¸í•´ ë‚´ìš©ì´ ë³€ê²½ â†’ prediction ë¶ˆì¼ì¹˜.
* **ì˜ˆì‹œ:**
  doc_idì— ëŒ€í•œ â€œclick_countâ€ê°€ serving ì‹œì ì—ëŠ” ì—…ë°ì´íŠ¸ë¨.
* **í•´ê²°ì±…:**

  * Serving ì‹œì  featureë¥¼ logë¡œ ë‚¨ê²¨ í•™ìŠµì— ì¬ì‚¬ìš© (Rule #32 ì°¸ì¡°)
  * ì£¼ê¸°ì  snapshot(ì˜ˆ: ë§¤ì¼ í…Œì´ë¸” freeze)ìœ¼ë¡œ ì¼ê´€ì„± í™•ë³´.

## ğŸ” Rule #32 â€“ Reuse code between training and serving

**â€œí•™ìŠµ íŒŒì´í”„ë¼ì¸ê³¼ ì„œë¹™ íŒŒì´í”„ë¼ì¸ì€ ì½”ë“œê¹Œì§€ ê³µìœ í•˜ë¼.â€**

* **í•µì‹¬ ìš”ì§€:**
  Trainingìš© ë°ì´í„° ìƒì„± ë¡œì§ê³¼ Servingìš© feature ìƒì„± ë¡œì§ì´
  ë”°ë¡œ ì¡´ì¬í•˜ë©´ ë¶ˆì¼ì¹˜ê°€ ìƒê¸´ë‹¤.
* **í•´ê²°ì±…:**

  * ê°€ëŠ¥í•œ í•œ **ê³µí†µ ì½”ë“œ(shared library)** ë¥¼ ì‚¬ìš©.
  * Training / Serving í™˜ê²½ì˜ ì–¸ì–´ê°€ ë‹¤ë¥´ë©´ (ì˜ˆ: Python vs C++) â†’ ì¼ê´€ì„± ìœ ì§€ ì–´ë ¤ì›€.
* **ê²°ë¡ :**
  â€œí•™ìŠµÂ·ì„œë¹™ ì½”ë“œì˜ ì¬ì‚¬ìš©ë¥ ì´ ë†’ì„ìˆ˜ë¡ skewëŠ” ì¤„ì–´ë“ ë‹¤.â€

## ğŸ“† Rule #33 â€“ Test on future data

**â€œí›ˆë ¨ ë°ì´í„°ë³´ë‹¤ ì´í›„ ì‹œì  ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸í•˜ë¼.â€**

* **í•µì‹¬ ìš”ì§€:**
  Training ì‹œì  ì´í›„ ë°ì´í„°(next-day or next-week data)ë¡œ ê²€ì¦í•´ì•¼
  ì‹¤ì œ ìš´ì˜ ì„±ëŠ¥ì„ ì˜ˆì¸¡í•  ìˆ˜ ìˆë‹¤.
* **ì‹¤ë¬´ íŒ:**

  * 1/5ì¼ ë°ì´í„°ë¡œ í•™ìŠµí–ˆë‹¤ë©´ â†’ 1/6ì¼ ì´í›„ ë°ì´í„°ë¡œ ê²€ì¦.
  * Test ì„±ëŠ¥ì´ í•™ìŠµë³´ë‹¤ ì•½ê°„ ë‚®ì€ ê±´ ì •ìƒ.
  * ê¸‰ê²©í•œ í•˜ë½ì€ ì‹œê³„ì—´ì  driftë‚˜ feature degradation ì‹ í˜¸.

## ğŸ§¹ Rule #34 â€“ Clean data matters more than more data

**â€œë°ì´í„°ê°€ ê¹¨ë—í•´ì•¼ ëª¨ë¸ì´ ì‚°ë‹¤.â€ (íŠ¹íˆ filtering task)**

* **ë¬¸ì œ:**
  spam filtering ê°™ì€ ì´ì§„ ë¶„ë¥˜ì—ì„œ negative ë°ì´í„°ë¥¼ ì„ì˜ë¡œ ë²„ë¦¬ë©´ bias ë°œìƒ.
* **í•´ê²°:**

  * Serving ì¤‘ ì¼ë¶€ traffic(ì˜ˆ: 1%)ì„ â€œheld-outâ€ìœ¼ë¡œ ìœ ì§€,
    ëª¨ë“  ê²°ê³¼ë¥¼ ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤€ ë’¤ label ìˆ˜ì§‘ â†’ í¸í–¥ ì—†ëŠ” ë°ì´í„° í™•ë³´.
* **í•µì‹¬:**
  ì•½ê°„ì˜ ë‹¨ê¸° ì„±ëŠ¥ ì†í•´(ë…¸ì´ì¦ˆ í¬í•¨)ë¥¼ ê°ìˆ˜í•˜ê³ ë„
  ì¥ê¸°ì ìœ¼ë¡œëŠ” ë” ê¹¨ë—í•œ ë°ì´í„°ë¡œ í•™ìŠµí•´ì•¼ í•œë‹¤.

## âš–ï¸ Rule #35 â€“ Ranking skew: identical short-term â‰  identical long-term

**â€œë­í‚¹ ì•Œê³ ë¦¬ì¦˜ì€ ë°”ê¾¸ë©´, ë°ì´í„° ë¶„í¬ë„ ë°”ë€ë‹¤.â€**

* **í•µì‹¬ ìš”ì§€:**
  ìƒˆ ranking ëª¨ë¸ì„ ì ìš©í•˜ë©´ â€œì‚¬ìš©ì ë°˜ì‘ ë°ì´í„°â€ ìì²´ê°€ ë‹¬ë¼ì§.
  â†’ **Feedback loop** ë°œìƒ
* **ì˜ˆì‹œ:**
  ì¸ê¸° ì•±ë§Œ ë…¸ì¶œ â†’ ê³„ì† ì¸ê¸° ì•± ë°ì´í„°ë§Œ ìŒ“ì„ â†’ long-tail ì½˜í…ì¸ ëŠ” ì‚¬ë¼ì§
* **í•´ê²°ì±…:**

  * Regularizationìœ¼ë¡œ ì¸ê¸° feature ì˜í–¥ ì™„í™”
  * ë¬¸ì„œ ì „ìš© feature(document-only) í”¼í•˜ê¸°
  * ì¼ë¶€ randomness (exploration) ìœ ì§€

## ğŸ“ Rule #36 â€“ Avoid feedback loops with positional features

**â€œìœ„ì¹˜(position) í”¼ì²˜ë¡œ ì¸í•œ í”¼ë“œë°± ë£¨í”„ë¥¼ ì¡°ì‹¬í•˜ë¼.â€**

* **ë¬¸ì œ:**
  ìƒìœ„ ë…¸ì¶œ(position 1)ì— ìˆëŠ” ì½˜í…ì¸ ëŠ” ë” ë§ì´ í´ë¦­ë¨.
  â†’ ëª¨ë¸ì´ â€œ1ìœ„ì˜€ë˜ í•­ëª© = ì¸ê¸° ìˆë‹¤â€ë¡œ í•™ìŠµ â†’ ë£¨í”„ ë°œìƒ.
* **í•´ê²°ì±…:**

  * í•™ìŠµ ì‹œ positional featureë¥¼ ì‚¬ìš©í•˜ë˜,
    ì„œë¹™ ì‹œì—” default position ê°’ ì‚¬ìš©.
  * Position featureëŠ” ë‹¤ë¥¸ featureì™€ crossí•˜ì§€ ë§ ê²ƒ.
* **í•µì‹¬:**
  ìœ„ì¹˜ ì˜í–¥ì€ ë¶„ë¦¬í•´ì„œ ëª¨ë¸ë§í•´ì•¼ í•œë‹¤.

## ğŸ“ Rule #37 â€“ Measure training/serving skew

**â€œí›ˆë ¨-ì„œë¹™ ë¶ˆì¼ì¹˜ë¥¼ ì •ëŸ‰ì ìœ¼ë¡œ ì¸¡ì •í•˜ë¼.â€**

* **í•µì‹¬ ìš”ì§€:**
  skewëŠ” ë°˜ë“œì‹œ ìƒê¸´ë‹¤. ë¬¸ì œëŠ” **ì–¼ë§ˆë‚˜, ì™œ ìƒê¸°ëŠ”ì§€ ëª¨ë‹ˆí„°ë§í•˜ëŠëƒ**ì´ë‹¤.
* **ì¸¡ì • í•­ëª©:**

  1. Train vs Holdout ë°ì´í„° ì„±ëŠ¥ ì°¨ì´
  2. Holdout vs Next-day ë°ì´í„° ì„±ëŠ¥ ì°¨ì´
  3. Next-day vs Live (Serving) ì˜ˆì¸¡ ì°¨ì´
* **í•µì‹¬ ë¬¸ì¥:**

  > â€œIf a model gives a different score on the same example in training and serving, itâ€™s an engineering bug.â€

ì¦‰, ê°™ì€ ì…ë ¥ì— ëŒ€í•´ ì ìˆ˜ê°€ ë‹¤ë¥´ë©´ ML ë¬¸ì œê°€ ì•„ë‹ˆë¼ **ì‹œìŠ¤í…œ ë²„ê·¸**ë‹¤.


---

