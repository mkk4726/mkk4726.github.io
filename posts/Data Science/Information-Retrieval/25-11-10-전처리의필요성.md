---
title: "BM25 검색엔진에서 전처리의 필요성"
date: "2025-11-10"
excerpt: "형태소 분석, 스테밍, 레마타이제이션, 동의어 처리가 한국어 검색 품질을 결정하는 원리와 실전 구현 전략"
category: "Information Retrieval"
tags: ["IR", "BM25", "형태소분석", "전처리", "한국어NLP"]
---

BM25 같은 전통적 랭킹 모델에서는 전처리의 품질이 곧 검색 품질이다. 특히 한국어는 교착어 특성상 형태소 분석, 스테밍, 레마타이제이션, 동의어 처리가 필수적이다. 이 글에서는 각 전처리 단계가 BM25 점수 계산과 검색 품질에 어떤 영향을 미치는지, 그리고 실전에서 어떻게 구현하는지를 정리한다.

## BM25는 "단어 기반 확률 모델"이다

BM25는 단어(term) 단위로 동작한다.

$$
BM25(q,d) = \sum_{t \in q} IDF(t) \cdot \frac{f(t,d)(k_1+1)}{f(t,d)+k_1(1-b+b|d|/avgdl)}
$$

즉, 문서(d)와 쿼리(q)를 단어 단위로 분해(tokenize)해야 하고, "단어"가 같다고 인식돼야 매칭이 이루어진다. 전처리가 잘못되면 BM25가 아무리 좋아도 쿼리-문서 매칭이 깨진다.

## 한국어의 어려움

영어나 독일어와 달리 한국어는 교착어(agglutinative language)로, 어근 + 조사/어미가 결합되어 한 단어가 다양한 형태로 변형된다.

예시:

```
가다 → 가고, 갔다, 가면, 가니까, 가려고, 갔었다, 가는구나 ...
```

이 모든 게 "같은 의미(lemma)"임에도 BM25는 기본적으로 "가고", "갔다"를 다른 단어로 처리한다. 형태소 분석이 없으면 검색 Recall이 폭락한다.

## 전처리가 BM25에 미치는 영향

| 단계 | 역할 | BM25에 미치는 영향 |
|------|------|-------------------|
| **토크나이징(Tokenizing)** | 문장 → 단어(형태소) 분할 | 단어 경계 인식이 정확해야 term-frequency, IDF가 정확함 |
| **스테밍 / 레마타이즈** | "갔다", "가서" → "가다" | 변형된 단어를 하나로 통합 → term-frequency 증가 → Recall↑ |
| **동의어 사전 관리** | "핸드폰 = 휴대폰" | 의미상 동일어를 통합 → 매칭 확률↑ |
| **오타 교정** | "삼성ㄹ전자 → 삼성전자" | 노이즈 제거로 올바른 term 매칭 유지 |

각 항목이 BM25 계산식에 직접적으로 개입하진 않지만, "f(t, d)" (문서 내 단어 빈도)와 "IDF(t)" (단어 희귀도)를 올바르게 계산하기 위한 기초 통계의 정확도를 결정한다.

## 1. 토크나이징 (Tokenization)

### 문제 상황

```
입력 문장: "삼성전자가 갤럭시폰을 출시했다."
```

| 잘못된 토크나이징 | 올바른 형태소 분석 |
|------------------|-------------------|
| [삼성전자, 가, 갤럭시, 폰, 을, 출시, 했다] | [삼성전자, 갤럭시폰, 출시하다] |

첫 번째처럼 쪼개지면 "갤럭시폰" 검색 시 매칭 안 된다. BM25는 "갤럭시폰"이라는 term 자체를 인덱스에 못 만들기 때문에 "갤럭시" + "폰"으로만 검색된다.

### 영향

- 잘못된 토큰 → 인덱스 term 수 증가, 중복 term 발생 → IDF 왜곡
- 실제 의미 단위(명사, 복합명사)를 인식 못 하면 쿼리 매칭 실패
- Precision↓, Recall↓

### 해결

한국어 전용 형태소 분석기 (예: Mecab, Khaiii, Komoran 등) 사용.

## 2. 스테밍과 레마타이제이션

### 개념 비교

| 구분 | 영어 | 한국어 대응 개념 | 예시 |
|------|------|----------------|------|
| **Stemming** | 단순 접사 제거 ("studies → studi") | **어미, 조사, 접사 제거** ("갔다 → 가") | 어간 추출 |
| **Lemmatization** | 품사 기반 원형 복원 ("better → good") | **형태소 분석 후 표제어 복원** ("먹었다 → 먹다") | 표제어 복원 |

한국어는 단어의 굴절(활용)이 많기 때문에 형태소 분석(morphological analysis) 단계에서 이미 "스테밍 + 레마타이즈"가 같이 수행되는 셈이다.

### 한국어 스테밍(어간 추출) 예시

| 원문 | 형태소 분석 | 스테밍 결과 (어간) |
|------|------------|-------------------|
| 먹었다 | 먹 + 었 + 다 | **먹** |
| 갔었다 | 가 + 았 + 었 + 다 | **가** |
| 뛰어간다 | 뛰 + 어 + 가 + ㄴ + 다 | **뛰**, **가** |
| 예뻐요 | 예쁘 + 어 + 요 | **예쁘** |

### 한국어 레마타이제이션(표제어 복원) 예시

| 원문 | 형태소 분석 결과 | 표제어 (lemma) |
|------|----------------|----------------|
| 먹었다 | 먹 + 었 + 다 | **먹다** |
| 갔었다 | 가 + 았 + 었 + 다 | **가다** |
| 뛰어간다 | 뛰 + 어 + 가 + ㄴ + 다 | **가다**, **뛰다** |
| 예뻐요 | 예쁘 + 어 + 요 | **예쁘다** |

### 검색에서의 효과

```
쿼리: "서울로 가는 버스"
문서: "서울에 갔다"
```

형태소 분석 없이 인덱싱하면 "가다" vs "갔다" 매칭 안 됨. 형태소 분석으로 "가다"로 정규화하면 동일 term으로 처리되어 BM25 점수 계산된다.

**효과:**
- f(t,d) 값이 더 커짐 (동일 의미 단어 통합) → Recall ↑
- IDF(t) 계산도 안정화 → Rare term 처리가 정확

### 실전 코드 예시 (KoNLPy)

```python
from konlpy.tag import Okt

okt = Okt()
text = "그는 학교에 갔다가 친구를 만났어요."

print(okt.morphs(text))        # 형태소 단위로 분리
print(okt.pos(text))           # 품사 태깅
print(okt.normalize(text))     # 정규화
```

출력 예시:

```python
['그', '는', '학교', '에', '가', '았', '다가', '친구', '를', '만나', '았', '어요', '.']

[('그', 'Noun'), ('는', 'Josa'), ('학교', 'Noun'), ('에', 'Josa'),
 ('가', 'Verb'), ('았', 'Eomi'), ('다가', 'Eomi'),
 ('친구', 'Noun'), ('를', 'Josa'),
 ('만나', 'Verb'), ('았', 'Eomi'), ('어요', 'Eomi'), ('.', 'Punctuation')]
```

### 한국어 분석기별 특징

| 분석기 | 특징 | 레마타이즈 지원 |
|--------|------|----------------|
| **Okt** | SNS / 구어체에 강함 | 부분적 (표제어 복원 X) |
| **Mecab** | 빠르고 정확, 형태소 구분 세밀 | ✅ 완전 지원 |
| **Khaiii** | Kakao 개발, 문맥 기반 | ✅ 완전 지원 |
| **Komoran** | 품사 태깅 다양 | 부분 지원 |

## 3. 동의어 처리 (Synonym Handling)

### 왜 필요한가?

예를 들어 이런 상황을 생각해보자.

| 쿼리 | 문서 | 기본 BM25 결과 | 문제 |
|------|------|----------------|------|
| "핸드폰 케이스" | "휴대폰 케이스 출시" | ❌ 불일치 | 단어가 다름 |
| "US dollar" | "미국 달러 강세" | ❌ 불일치 | 언어가 다름 |
| "전기차" | "EV 배터리 성능 개선" | ❌ 불일치 | 약어 불일치 |

BM25는 정확히 같은 토큰만 매칭한다. "핸드폰" ≠ "휴대폰", "전기차" ≠ "EV"로 인식하기 때문에 동의어 사전(synonym dictionary)을 적용해야 한다.

### 동의어 처리 방식

#### (1) 인덱싱 시 확장 (Index-time Synonym Expansion)

문서를 색인할 때 동의어를 같은 토큰 세트로 확장해서 인덱스에 저장한다.

```
문서 내용: "휴대폰 케이스"
동의어 사전: 휴대폰, 핸드폰, 스마트폰

→ 인덱싱 시: ["휴대폰", "핸드폰", "스마트폰", "케이스"]
```

**장점:**
- 쿼리 처리 시 별도 확장 불필요 (빠름)
- Recall(검색 누락) 개선

**단점:**
- 인덱스 크기 커짐
- 수정/삭제 시 사전 전체 재색인 필요

#### (2) 쿼리 시 확장 (Query-time Synonym Expansion)

사용자 쿼리 입력 시점에만 동의어를 확장한다.

```
쿼리: "핸드폰 케이스"
→ 동의어 확장: ("핸드폰" OR "휴대폰" OR "스마트폰") AND "케이스"
```

**장점:**
- 인덱스 크기 작음
- 동의어 사전 업데이트 용이 (재색인 불필요)

**단점:**
- 쿼리 처리 비용 증가
- 긴 쿼리일 경우 성능 저하 가능

### Elasticsearch 구현 예시

#### 사전 예시 (synonyms.txt)

```text
휴대폰, 핸드폰, 스마트폰
미국, 美, USA
전기차, EV
```

#### 분석기(analyzer) 정의

```json
{
  "settings": {
    "analysis": {
      "filter": {
        "korean_synonym_filter": {
          "type": "synonym_graph",
          "synonyms_path": "analysis/synonyms.txt"
        }
      },
      "analyzer": {
        "korean_custom": {
          "tokenizer": "seunjeon_tokenizer",
          "filter": [
            "lowercase",
            "korean_synonym_filter"
          ]
        }
      }
    }
  }
}
```

### 동의어 사전 관리 전략

| 방법 | 설명 | 장점 | 단점 |
|------|------|------|------|
| **수동 관리** | 사람이 직접 정의 (휴대폰, 핸드폰) | 정확 | 업데이트 번거로움 |
| **통계적 추출** | word2vec, FastText, embedding 유사도 기반 | 자동 확장 가능 | 노이즈 많음 |
| **도메인 특화 사전** | 쇼핑, 뉴스, 의료, 법률 등 | 높은 정확도 | 범용성 낮음 |
| **하이브리드** | 수동 + 임베딩 추천 결합 | 자동화 + 검증 | 구축 비용 큼 |

### BM25 점수에 미치는 영향

| 항목 | 변화 |
|------|------|
| **f(t,d)** | 여러 단어가 하나로 묶이므로 term 빈도 증가 → 점수 상승 |
| **IDF(t)** | 동의어 전체 문서 빈도로 계산 → 희귀 단어 안정화 |
| **쿼리 매칭 수** | "핸드폰", "휴대폰", "스마트폰" 전부 매칭 가능 → Recall↑ |
| **결과 정렬 품질** | 유사 의미 문서들이 한 클러스터에 모여 Precision↑ |

### 최신 동향: 임베딩 기반 동의어 자동 확장

```python
from gensim.models import Word2Vec

model = Word2Vec.load("ko_embedding.model")
model.wv.most_similar("핸드폰", topn=5)
# [('휴대폰', 0.91), ('스마트폰', 0.89), ('모바일', 0.85), ...]
```

이런 자동 동의어 후보를 수동 사전에 추가하거나 semantic search (dense retrieval)로 전환하는 추세다.

## 4. 오타 교정 (Spell Correction)

### 문제 상황

```
쿼리: "갤럭시ㄹ폰"  → 교정 → "갤럭시폰"
```

BM25는 토큰 단위 정확 일치를 요구하므로 오타가 있으면 f(t,d) = 0 → 완전 불일치. 교정기를 통해 "갤럭시폰"으로 수정하면 term 일치 복구.

### 오타 교정의 원리

오타 교정은 **편집 거리(Edit Distance)** 기반 알고리즘과 **통계적 방법**을 결합해서 작동한다.

#### 1. 편집 거리 계산 (Levenshtein Distance)

한 문자열을 다른 문자열로 바꾸는 데 필요한 최소 편집 횟수를 계산한다.

| 연산 | 예시 | 편집 거리 |
|------|------|----------|
| **삭제** | "갤럭시ㄹ폰" → "갤럭시폰" | 1 |
| **삽입** | "갤럭폰" → "갤럭시폰" | 1 |
| **치환** | "갤력시폰" → "갤럭시폰" | 1 |
| **복합** | "갤럭시ㄹ폰ㄴ" → "갤럭시폰" | 2 |

검색엔진은 보통 편집 거리 1~2 이내의 단어만 교정 대상으로 고려한다. 거리가 멀수록 계산 비용이 기하급수적으로 증가하기 때문이다.

#### 2. 오타 교정 프로세스

```
입력 쿼리: "갤럭시ㄹ폰"

Step 1: 후보 생성
  → 편집 거리 1~2 이내의 모든 변형 생성
  → ["갤럭시폰", "갤럭시본", "갤럭시론", "갤력시폰", ...]

Step 2: 사전 필터링
  → 인덱스에 실제 존재하는 term만 선택
  → 역색인(inverted index) 조회
  → ["갤럭시폰"] (인덱스에 존재)

Step 3: 확률 기반 선택
  → 문서 빈도(DF) 또는 언어 모델 확률 사용
  → "갤럭시폰" (DF=1000) vs "갤럭시본" (DF=5)
  → 최종 선택: "갤럭시폰"
```

#### 3. 한국어 오타의 특수성

한국어는 자판 배열과 자모 분리 입력 특성 때문에 영어와 다른 오타 패턴이 발생한다.

| 오타 유형 | 예시 | 원인 | 교정 방법 |
|----------|------|------|----------|
| **자음 중복** | "삼성ㄹ전자" | 쌍자음 입력 실수 | 불필요한 자음 제거 |
| **모음 누락** | "갤럭ㅅ폰" | 모음 입력 누락 | 인접 키 기반 복원 |
| **받침 오류** | "갤럭시폰ㄴ" | 받침 중복 입력 | 마지막 자음 제거 |
| **자모 분리** | "ㄱㅐㄹㄹㅓㄱㅅㅣ" | 조합 실패 | 자모 결합 규칙 적용 |

한국어 오타 교정기는 두벌식/세벌식 자판 배열을 고려해서 인접 키 오타 확률을 계산한다.

#### 4. 통계 기반 교정: 쿼리 로그 분석

실시간 검색 로그를 분석해서 오타 패턴을 학습한다.

```python
# 쿼리 세션 로그 예시
사용자 A: "갤럭시ㄹ폰" (결과 없음) → "갤럭시폰" (클릭)
사용자 B: "갤럭시ㄹ폰" (결과 없음) → "갤럭시폰" (클릭)
사용자 C: "갤럭시ㄹ폰" (결과 없음) → "갤럭시폰" (클릭)

→ 패턴 학습: "갤럭시ㄹ폰" → "갤럭시폰" (신뢰도 95%)
```

이런 패턴이 반복되면 자동으로 교정 사전에 추가된다.

#### 5. Elasticsearch Fuzzy Query 구현

```json
{
  "query": {
    "fuzzy": {
      "product_name": {
        "value": "갤럭시ㄹ폰",
        "fuzziness": "AUTO",
        "prefix_length": 0,
        "max_expansions": 50
      }
    }
  }
}
```

| 파라미터 | 의미 | 설정 예시 |
|---------|------|----------|
| **fuzziness** | 허용 편집 거리 | AUTO (길이 기반 자동 조정) |
| **prefix_length** | 앞부분 일치 필수 문자 수 | 0 (전체 fuzzy 매칭) |
| **max_expansions** | 최대 후보 term 수 | 50 (성능 제어) |

#### 6. N-gram 기반 부분 매칭

오타가 있어도 부분 문자열로 검색되도록 n-gram 인덱싱을 병행한다.

```
"갤럭시폰" → 3-gram 인덱싱
["갤럭시", "럭시폰"]

쿼리: "갤럭시ㄹ폰" → 3-gram
["갤럭시", "럭시ㄹ", "시ㄹ폰"]

→ "갤럭시" 부분 일치 → 후보로 제시
```

이 방식은 편집 거리 계산 없이도 빠르게 유사 단어를 찾을 수 있다.

### BM25에 미치는 영향

| 항목 | 오타 있을 때 | 교정 후 |
|------|------------|---------|
| **f(t,d)** | 0 (매칭 실패) | 정상 빈도 계산 |
| **IDF(t)** | 계산 불가 | 정상 IDF 적용 |
| **BM25 점수** | 0 | 정상 점수 |
| **Recall** | ❌ 검색 실패 | ✅ 정상 검색 |

오타 교정은 BM25 계산 이전 단계에서 쿼리를 정규화해서 올바른 term으로 매칭될 수 있게 만드는 전처리다.

### 효과

- Recall ↑ (오타로 인한 검색 실패 방지)
- 사용자 쿼리 로그 품질 개선 → IDF 계산도 안정화됨
- 검색 만족도 향상 (사용자가 재검색할 필요 없음)

## 전처리 품질이 검색 결과에 미치는 실제 비교

| 케이스 | 전처리 수준 | 검색 결과 품질 |
|--------|------------|----------------|
| ❌ 단순 띄어쓰기 기반 | "서울", "가", "는", "버스" | "서울 가는 버스"와 "서울에 갔다" 매칭 불가 |
| ✅ 품사 기반 분석 | "서울", "가다", "버스" | "서울에 갔다" 문서도 검색 가능 |
| ✅ + 동의어 확장 | "서울", "버스", "고속버스" | 쿼리 "서울 고속버스"도 매칭됨 |

Recall(검색 누락률)이 크게 달라진다.

## 실제 검색엔진 구조 (Elasticsearch Korean Analyzer)

```json
"analyzer": {
  "korean_custom": {
    "type": "custom",
    "tokenizer": "seunjeon_tokenizer",
    "filter": [
      "lowercase",
      "synonym_graph",    // 동의어 처리
      "korean_stop",      // 불용어 제거
      "korean_stemmer"    // 스테밍, 레마타이즈
    ]
  }
}
```

이런 형태로 BM25 기반 인덱스에 들어가기 전에 모든 단어가 정규화되고, 동일 의미를 갖는 term들이 통합된다.

## 결론

| 단계 | 역할 | 검색 품질 영향 |
|------|------|----------------|
| **토크나이징** | 단어 경계 인식 | 인덱스 품질 결정 (Recall/Precision) |
| **스테밍/레마타이즈** | 단어 원형 복원 | 문법 변형 단어 통합 → Recall↑ |
| **동의어 사전** | 의미 확장 | 쿼리-문서 간 의미 일치율 향상 |
| **오타 교정** | 노이즈 제거 | 쿼리 매칭률 향상 |

**핵심 요약:** BM25는 단어 기반 모델이라, 전처리 품질이 곧 검색 품질이다. 한국어에서는 토크나이징·레마타이즈·동의어 관리·오타 교정이 "단어 일치 정확도"를 높여서 BM25의 근본 성능을 좌우한다. 형태소 분석의 품질 = 인덱스의 품질 = 검색의 품질이라는 등식이 성립한다.

