---
title: "AI Chatbot Project"
date: ""
excerpt: "고객상담용 챗봇 개발"
category: "Career"
tags: ["RAG"]
---

- 기간 : 2024.11 ~ 2025.02 (4개월)
- 역할 : 문제정의, RAG pipeline 구현 및 배포, 모니터링 시스템 구축
- 결과 (성과) : 일평균 100~200건정도의 상담을 자동화해 상담사의 상담 효율성 향상

---

# 프로젝트 개요

## 1. 프로젝트 배경 및 목표

반복되는 고객상담업무는 상담사가 필요한 상담업무를 하지 못하게 만드는 요인이었습니다. 이를 해결하기 위해 FAQ 데이터셋을 기반으로 RAG pipeline을 구축해 고객 질문에 자동으로 답변하는 챗봇을 개발했습니다. 답변 후 만족/불만족 피드백을 수집하고, 이를 분석해 지속적으로 만족도를 개선하는 방식으로 프로젝트를 진행했습니다.

## 2. 주요 성과

- **상담 자동화** : 일평균 100~200건의 반복 상담을 자동화해 상담사의 업무 효율성 향상
- **사용자 만족도 개선** : 불만족 원인 분석 후 질문 분류 모델 도입으로 불만족도 80% 이상 감소
- **검색 성능 개선** : 대화 맥락 반영, 질문 분리, 키워드 추출을 통해 검색 정확도 90% 이상 달성
- **모니터링 자동화** : LLM 기반 자동 평가 시스템 구축으로 모니터링 시간 83% 단축 (30분 → 5분)

## 3. 핵심 학습 내용

- **RAG pipeline 구축 경험** : 질문 재정의, 문서 검색, 답변 생성까지 전체 파이프라인 설계 및 최적화 경험
- **사용자 피드백 기반 개선** : 실제 서비스 운영을 통해 사용자 불만족 요인을 파악하고, 이를 해결하며 만족도를 높이는 과정 경험
- **LLM 기반 자동화** : 반복적이고 시간이 많이 드는 모니터링 업무를 LLM을 활용해 자동화하고 운영 비용을 절감하는 방법 학습

## 4. 기술 스택

**AI/ML**
- LLM: OpenAI GPT 시리즈 (질문 분류, 재정의, 쪼개기, 키워드 추출, 답변 생성)
- Embedding Model: 테스트셋 기반 비교 평가 후 선정
- Vector DB: Qdrant (시멘틱 서치 및 하이브리드 검색)

**Backend**
- API Framework: FastAPI (RAG pipeline API 구현)
- Session Management: Redis (대화 기록 관리)
- Deployment: Docker, Amazon EC2

**Monitoring**
- Workflow: Apache Airflow (배치 작업 스케줄링)
- Storage: Google Spreadsheet (로그 수집)
- Alerting: Slack (모니터링 알림)
- Evaluation: RAGAS 기반 커스텀 평가 지표

자세한 문제 해결과정은 아래에 정리했습니다.

---

# 문제 해결 과정

RAG 파이프라인은 다음과 같이 구성되어있습니다.

<figure>
<img src="./images/chatbot_pipeline1.png" alt="RAG pipeline" width="50%" />
</figure>
<figure>
<img src="./images/chatbot_pipeline2.png" alt="RAG pipeline" width="100%" />
<figcaption>그림1. RAG pipeline</figcaption>
</figure>

각각의 구성 요소들을 어떻게 구성했으며, 어떻게 최적화했는지 설명드리겠습니다.

---

## 1. 질문 분류를 통한 사용자 만족도 개선

### 배경

서비스를 운영하면서 만족도를 높여나가는 방향으로 프로젝트를 진행했습니다. 만족도는 대답 후에 "만족", "불만족" 버튼을 통해 수집했습니다. 

실제 서비스를 배포해 사용해본 결과, 사용자 피드백을 통해 불만족이 발생하는 지점을 확인할 수 있었습니다. 분석 결과, 불만족은 답변의 정확도 부족에서 비롯된 것이 아니라, 답변할 수 없는 질문에 대해 엉뚱한 대답을 하거나, 사용자가 비정상적인 질문을 이어갈 때 주로 발생한다는 점을 발견했습니다.

사용자들이 가장 불만족스러워했던 부분은 LLM이 명확히 답변할 수 없는 질문에 대해 모호한 답변을 생성하는 것이었습니다. 특히, 답변할 수 없는 내용임에도 불구하고 계속해서 재질문만 하며 대화를 이어가는 불필요한 상황이 빈번하게 발생했습니다. 주민번호와 전화번호를 입력하며 예약에 대한 문의를 하는 것과 같은 상황입니다.

### 과정

사용자 불만족의 주요 원인이 답변 불가능한 질문에서 비롯된다는 점을 해결하기 위해, RAG 파이프라인에 질문 분류 단계를 추가했습니다. 이 과정을 통해 LLM이 답변을 생성해야 하는 질문과 그렇지 않은 질문을 구분하여 흐름을 분리했습니다.

예를 들어 "상담사 연결해줘"와 같은 질문은 모델이 불필요한 답변을 생성하지 않고, 대신 관련 버튼을 제공하도록 설계하여 사용자 경험을 개선했습니다. 또한 고객사에서 원하는 메뉴얼이 있었지만, 이를 LLM에게 명령하기에는 쉽지 않았기 때문에, 질문 분류를 통해 특정 유형의 질문에 대해서는 정해진 흐름을 따르도록 구현했습니다.

파이프라인의 맨 앞단에 분류 모델을 배치해, 질문의 종류를 분류하여 적절한 대응을 할 수 있도록 했습니다. 분류 모델은 LLM에 분류 프롬프트를 적용해 구현했습니다.

### 성과

문제의 원인 분석을 통해, 질문 분류 단계를 추가해 불필요하거나 부적절한 답변을 줄여 사용자 경험을 개선할 수 있었고, 실제로 불만족도를 80% 이상 감소시킬 수 있었습니다.

### 배운점

실제 서비스를 운영해보니 생각지 못한 부분에서 불만족 피드백을 받을 수 있었습니다. 이를 해결하기 위해 문제를 정의하고, 이를 해결하면서 실제 사용자의 만족도를 개선하는 경험을 할 수 있었습니다.

---

## 2. 대화 맥락을 고려한 질문 재정의

### 배경

대화의 흐름을 고려해 답변을 생성해야 했습니다. 사용자는 종종 이전 대화 내용을 참조하는 간략한 질문을 던지는데, 이를 맥락 없이 그대로 문서 검색에 사용하면 정확한 답변을 제공할 수 없었습니다. 이때 맥락을 고려해 문서를 검색하는 부분이 중요했습니다.

예를 들어 다음과 같은 대화 상황에서:

Q: 라식 가격은 얼마야?
A: 라식 가격은 ~~
이후에 
Q: 라섹은?

사용자가 "라섹은?"이라고 묻는다면 이는 단독으로는 불완전한 질문이지만, 대화 맥락상 "라섹의 가격은 얼마야?"를 의미합니다. 따라서 이전 대화 기록을 참조해 질문을 재정의하는 과정이 필요했습니다.

### 과정

Redis를 활용해 짧은 기간의 대화기록을 세션별로 관리했습니다. 사용자의 새로운 질문이 들어오면, 해당 세션의 최근 대화 기록을 불러와 LLM에 전달하고, 대화 맥락을 고려해 완전한 형태의 질문으로 재정의하도록 프롬프트를 설계했습니다.

이를 통해 불완전한 질문이나 대명사가 포함된 질문도 맥락에 맞는 완전한 질문으로 변환해 문서 검색의 정확도를 높일 수 있었습니다. Redis를 선택한 이유는 빠른 읽기/쓰기 속도와 세션 관리에 적합한 TTL(Time To Live) 기능 때문이었습니다.

### 성과

질문 재정의를 도입한 후 대화 흐름이 자연스러워졌고, 이전 대화를 참조하는 간략한 질문에도 정확한 답변을 제공할 수 있게 되었습니다. 특히 3턴 이상 이어지는 대화에서 검색 정확도가 크게 향상되었습니다.

---

## 3. 질문 쪼개기 + 키워드 추출

### 배경

사용자는 종종 하나의 질문에 여러 의도를 담아 질문합니다. "라식과 라섹의 가격 알려줘"라는 질문을 답변하기 위해서는 "라식의 가격"과 "라섹의 가격"이라는 2개의 질문으로 쪼개서, 각각에 대한 문서를 검색할 필요가 있습니다. 하나의 질문으로 검색하면 두 가지 정보를 모두 포함한 문서가 없을 경우 검색 실패가 발생하기 때문입니다.

또한 시멘틱 서치의 한계와 사용하는 embedding model이 원장 이름과 같은 도메인 특화 단어를 모르기 때문에 발생하는 한계점이 존재했습니다. 사전 학습된 embedding model은 일반적인 언어 패턴은 잘 이해하지만, 특정 병원의 의사 이름이나 도메인 특화 용어는 제대로 인식하지 못하는 경우가 많았습니다.

### 과정

LLM을 활용해 질문을 여러 개의 독립적인 하위 질문으로 분해하도록 프롬프트를 설계했습니다. 예를 들어 "라식과 라섹의 가격 및 회복기간 알려줘"는 "라식의 가격", "라섹의 가격", "라식의 회복기간", "라섹의 회복기간" 총 4개의 질문으로 쪼개져 각각에 대해 문서를 검색하도록 구현했습니다.

동시에 질문에서 핵심 키워드를 추출하는 과정도 추가했습니다. "김민규 원장님에 대한 정보 알려줘"와 같은 질문에서는 임베딩 벡터만으로는 적절한 문서를 찾기 어려웠지만, "김민규"라는 키워드를 추출해 문서의 메타데이터나 본문에서 해당 키워드를 포함한 문서를 필터링하게 되면 관련 정보를 정확히 찾을 수 있었습니다.

이는 시멘틱 서치와 키워드 기반 검색을 결합한 하이브리드 검색 방식으로, 의미적 유사도와 정확한 키워드 매칭의 장점을 모두 활용할 수 있었습니다. 특히 FAQ 데이터셋의 경우 자주 묻는 질문이 키워드 중심으로 구성되어 있어 이 방식의 효과가 컸습니다.

### 성과

질문 쪼개기를 통해 복합 질문에 대한 답변 완성도가 높아졌고, 키워드 추출을 통해 도메인 특화 질문에 대한 검색 실패율을 크게 줄일 수 있었습니다. 특히 인명이나 고유명사가 포함된 질문의 검색 정확도가 개선되었습니다.

---

## 4. 문서 검색 모델 선정

### 배경

질문 재정의, 질문 쪼개기, 키워드 추출 등 다양한 전처리 과정을 거치더라도 결국 문서 검색 성능을 좌우하는 핵심은 시멘틱 서치에 사용될 임베딩 벡터의 품질입니다. 적절한 embedding model을 선택하지 않으면 아무리 파이프라인을 잘 구성해도 검색 정확도가 떨어질 수밖에 없었습니다.

시중에는 다양한 embedding model이 존재하지만, 각 모델마다 성능과 특성이 다르기 때문에 현재 도메인과 데이터셋에 가장 적합한 모델을 선택하는 것이 중요했습니다. 특히 한국어 FAQ 데이터셋이라는 특수한 환경을 고려해야 했습니다.

### 과정

먼저 객관적인 모델 선정을 위해 평가용 데이터셋을 구축했습니다. FAQ 데이터를 바탕으로 LLM을 활용해 각 답변에 대해 사용자가 실제로 물을 법한 다양한 형태의 질문을 생성하도록 했습니다. 이렇게 구성한 테스트셋을 통해 여러 embedding model을 비교 평가하고, 검색 정확도가 가장 높은 모델을 선택했습니다.

VectorDB는 Qdrant로 선택했습니다. Qdrant는 고성능 벡터 검색을 제공하며, 필터링 기능이 우수해 키워드 기반 필터링과 시멘틱 서치를 동시에 수행하기에 적합했습니다. 

운영 측면에서는 사용자가 FAQ 문서를 수정하거나 추가했을 때 시스템에 바로 반영되도록 자동화 파이프라인을 구축했습니다. 이를 통해 문서 업데이트마다 수동으로 벡터를 재생성하는 유지보수 비용을 최소화했습니다. 또한 참조 문서 버전별로 명확히 구분되도록 Qdrant의 멀티테넌시 기능을 활용해 버전 관리 체계를 구축했습니다. 이를 통해 여러 버전의 문서를 동시에 관리하면서도 각 버전의 독립성을 보장할 수 있었습니다.

### 성과

구축한 평가용 데이터셋과 개선된 파이프라인을 통해 검색 정확도 90% 이상을 달성했습니다. 단순히 수치상의 향상뿐 아니라, 도메인 특화 용어에 대한 검색 누락 문제를 해결하고, 복합 질문을 분리·처리함으로써 실제 사용자 질의에 대한 응답 품질을 크게 개선할 수 있었습니다.

### 배운점

검색 성능 개선은 단순히 모델의 성능 문제가 아니라, 사용자의 복잡한 질의를 올바르게 정의하고 구조화하는 과정이 핵심임을 배울 수 있었습니다.

---

## 5. 답변 생성

### 배경

검색된 문서를 바탕으로 최종 답변을 생성하는 단계에서는 정확성과 사용자 경험이라는 두 가지 목표를 동시에 달성해야 했습니다. RAG 시스템의 가장 큰 문제점 중 하나는 LLM이 자체 학습 데이터를 기반으로 답변을 생성해 실제 참조 문서와 다른 내용을 말하는 환각(hallucination) 현상입니다. 고객 상담이라는 도메인 특성상 정확하지 않은 정보는 신뢰도 문제로 이어질 수 있었습니다.

동시에 단순히 문서를 그대로 복사해 전달하는 것이 아니라, 사용자가 이해하기 쉽고 친근하게 느낄 수 있는 자연스러운 답변을 생성해야 했습니다.

### 과정

프롬프트 엔지니어링을 통해 LLM의 역할과 제약사항을 명확히 정의했습니다. 첫째, 참조 문서의 내용만을 바탕으로 답변하도록 제한했습니다. 문서에 없는 내용은 절대 생성하지 않고, 정보가 불충분하면 솔직하게 "관련 정보를 찾을 수 없습니다"라고 응답하도록 했습니다.

둘째, 사용자가 친근하고 이해하기 쉽다고 느끼는 톤으로 답변을 생성하도록 설계했습니다. 딱딱한 공식 문서 스타일이 아닌, 상담사가 친절하게 설명해주는 듯한 톤을 유지하도록 프롬프트에 명시했습니다. 전문 용어가 필요한 경우 간단한 부연 설명을 덧붙이도록 했습니다.

셋째, 여러 문서에서 검색된 정보를 통합해 일관성 있는 하나의 답변으로 재구성하도록 했습니다. 단순 나열이 아닌, 자연스러운 흐름으로 정보를 전달하도록 구현했습니다.

### 성과

프롬프트 설계를 통해 참조 문서 기반 답변 생성률을 높이고, 동시에 사용자 만족도도 향상시킬 수 있었습니다. 정확성과 사용자 경험이라는 두 마리 토끼를 모두 잡을 수 있었습니다.

---

## 6. 모니터링 자동화를 통한 운영비용 감소

### 배경

에러를 발생하지 않고 조용한 실패(silent failure)를 발생하는 서비스의 특성상 대화 기록을 모니터링 해야 했습니다. 하지만 평균 150건 정도의 대화 기록을 모니터링하는 것은 꽤나 큰 시간적인 비용이 발생했습니다.

사용자 채팅 로그를 자동으로 모니터링해, silent failure를 감지하고 유지보수 비용을 최소화하기 위해 모니터링 기능을 구현할 필요가 있었습니다.

### 과정

모니터링을 자동화하기 위해 새로운 평가지표를 설계하고 이를 시스템에 적용했습니다. 구체적으로, 모델의 답변이 검색된 문서에 얼마나 근거하고 있는지를 평가하도록 했으며, 이 계산은 LLM을 통해 자동으로 수행했습니다.

오픈소스인 RAGAS 프레임워크의 프롬프트를 뜯어보면서 구현했고, 답변이 검색된 문서에 기반한 것인지에 대한 점수를 냈습니다. 이를 통해 LLM이 문서 기반으로 답변을 생성하는 정도를 손쉽게 모니터링할 수 있었습니다.

Airflow를 통해 로그가 쌓이는 스프레드 시트에서 점수를 냈고, 결과는 요약된 형태로 일별 혹은 주별 점수와 점수가 낮은 대화를 Slack을 통해 확인했습니다. 이를 통해 문제가 의심되는 사례만 선별적으로 확인할 수 있도록 했습니다. 이 과정을 통해 사람이 직접 모든 대화 기록을 검수하던 비효율을 제거하고, 모니터링에 소요되는 시간적 비용을 크게 절감할 수 있었습니다.

### 성과

모니터링 프로세스를 자동화하여 작업 시간을 약 30분에서 5분으로 단축, 전체 모니터링 비용을 83% 절감했습니다. 이를 통해 시간적인 비용을 크게 줄이며 안정적인 서비스 모니터링 체계를 구축할 수 있었습니다.

### 배운점

지표를 정의하고 LLM을 통해 반복적이고 시간이 많이 드는 업무를 자동화·대체하는 경험을 할 수 있었습니다.