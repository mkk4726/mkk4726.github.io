---
title: "(Seoul) Research Engineer Â· AutoML "
date: "2025-07-10"
excerpt: "ë£¨ë‹› ì±„ìš©ê³µê³  ë¶„ì„ê³¼ ì¤€ë¹„ê³¼ì •"
category: "Career"
tags: ["ë£¨ë‹› ì±„ìš©ê³µê³ "]
---

# ì±„ìš©ê³µê³ 

<details>
<summary>ğŸ“‹ <strong>ì±„ìš©ê³µê³  ìƒì„¸ì •ë³´</strong></summary>

[ë§í¬](https://www.linkedin.com/jobs/search/?currentJobId=4261590818&keywords=Lunit%20Cancer%20Screening&origin=JOB_COLLECTION_PAGE_KEYWORD_AUTOCOMPLETE&refresh=true)

- Lunit, a portmanteau of â€˜Learning unit,' is a medical AI software company devoted to providing AI-powered total cancer care. Our AI solutions help discover cancer and predict cancer treatment outcomes, achieving timely and individually tailored cancer treatment.

ğŸ—¨ï¸ About The Team

- AutoML team at Lunit automates AI product development processes to streamline time-consuming tasks and advance cutting-edge AutoML research. By combining engineering expertise with state-of-the-art deep learning techniques, our team plays an important role in accelerating product development for cancer detection and treatment. Join us in our mission to Conquer Cancer Through AI where your contributions will directly influence AI innovations that improve patient outcomes worldwide
- In short, we're a team that maximizes AI tech to *create AI models* with extreme efficiency


ğŸ—¨ï¸ About The Position

- As a research engineer, you will work closely with the team to develop and optimize platforms for automating medical AI model research workflows
- Your responsibilities will involve implementing an automated product development framework for the medical domain, covering data ingestion, model training, packaging and inference
- You will collaborate with both research and engineering teams to bring cutting-edge AI research into real-world applications
- This position is ideal for someone with a strong research engineering background and deep understanding of the AI model development process


ğŸš© Roles & Responsibilities

- Develop and implement tailored AutoML platforms to automate medical AI model research workflows
- Integrate AutoML pipelines into AI agent which includes data ingestion, model training, hyperparameter optimization and inference
- Enhance the maintainability, reliability, and efficiency of both new and existing frameworks
- Build robust AI infrastructure using Kubernetes, Docker, and cloud computing services (GCP, AWS, Azure)
Keep up with the latest advancements in AI agents, LLMs, and AutoML research to drive innovation


ğŸš© Tools Used

- Development Related: Django, Django REST Framework, React, Next.js, MySQL, PostgreSQL, Redis, Celery, Nginx, Go
- ML framework: PyTorch, Optuna
- Infrastructure: Google Cloud Platform, Kubernetes, Git, Docker, Helm, ArgoCD, Terraform
- General: Slack, Confluence, Jira


Requirements


ğŸ¯Qualifications

- 3+ years of experience in research engineering in the AI industry
- Master's, or Ph.D. in Computer Science or a related field
- Proficiency in Python, unit/integration testing, documentation, Git, collaborative code development, and Docker
- Solid knowledge of software design and system architecture, with a strong understanding of RESTful API design
- Hands-on experience with developing and operating scalable AI platforms and infrastructure, including DevOps
- Effective communication skills: Ability to clearly and efficiently convey information, thoughts, and ideas to other developers
- Proven ability to take ownership and drive projects from concept to deployment
- Highly responsible and detail-oriented, with a strong motivation to build high-quality, reliable solutions in line with current best practices


ğŸ… Preferred Experiences

- Familiarity with web development, including both backend and frontend
- Deep insight into automating and orchestrating ML workflows
- Experience in designing or developing automated AI platforms
- Experience in designing or developing AI agents or LLM-based automation (e.g., fine-tuning, prompt engineering)
- Knowledge of cloud computing services (GCP, AWS, or Azure)
- Publications in AI or computer vision conferences, or active participation in the research community
- Ability to collaborate effectively as a team player in a cross-functional research-engineering environment
- Proactive in sharing knowledge, initiating collaborations, and promoting a positive research environment
- Passion for high-quality programming and software engineering to produce and maintain reliable code for the training and evaluation of models


ğŸ“ How To Apply

- CV (resume, free format)


ğŸƒâ€â™€ï¸ Hiring Process

- Document Screening â†’ Technical Interview(Teams) â†’ Assignment â†’ PT Interview â†’ Culture-fit Interview â†’ Onboarding
- After the final interview, we may proceed with reference checks if needed. 

ğŸ¤ Work Conditions and Environment

- Work type: Full Time
- Work location : Lunit HQ (5F, 374, Gangnam-daero, Gangnam-gu, Seoul)
- Salary: After Negotiation


ğŸ¸ ETC

- If you misrepresent your experience or education or provide false or fraudulent information in or with your application, it may be grounds for cancellation of the employment
- Lunit is committed in providing the preferential processing to those eligible for employment protection (national merits and people with disabilities) relevant to related laws and regulations


Benefits

ğŸŒ» Benefits & Perks

- The office is at a very convenient location, just a minute away from Gangnam Station Exit 3
- Meal Allowance is provided (up to 12,000 KRW per meal) when working at the office
- Up to 300,000 KRW is covered upon joining to decorate your personal workspace
- Latest computer models, such as Macs and 4K monitors are provided and can be renewed every three years
- Seminar registration fees and book purchases are covered
- Regular in-house AI and medical seminars are held
- Korean lessons are provided for Lunitians who do not speak Korean as their first language
- In-house English lessons (aka Luniversal) is provided for English development
- Access to high-quality AI learning resources & deep learning DevOps system
- Up to 1.2 million KRW worth of benefits points can be claimed annually
- Holiday Allowances are provided in the form of gifts or vouchers for Korean National holidays, Seollal and Chuseok
- Congratulatory and Condolence allowances, along with paid time off are provided
- Annual medical checkups and employee accident insurance are provided
- Expenses for monthly employees gatherings are partially covered

</details>


# ì¤€ë¹„í•´ì•¼í•˜ëŠ” ê²ƒë“¤

ì¼ë‹¨ ë‚´ ë¶„ì•¼ì™€ ê²¹ì¹˜ëŠ” ì˜ë£Œìª½ ì±„ìš©ê³µê³ ê³ , ì—¬ê¸°ì„œ í–ˆë˜ MLê°œë°œë“¤ì— ëŒ€í•œ ê²½í—˜ì„ ì‚´ë¦´ ìˆ˜ ìˆê² ë‹¤.
ì´ê²ƒë„ ì´ë²ˆì£¼ ì£¼ë§ì— ì´ê±°ì— ë§ê²Œ ì´ë ¥ì„œ ì“°ê¸°.


# ì—¬ê¸°ì— ë„ˆê°€ ìƒê°í•˜ëŠ” ì¤€ë¹„í•˜ë©´ ì¢‹ì€ ê²ƒë“¤ ì¶”ê°€í•´ì¤˜

## ğŸ¯ í•µì‹¬ ì¤€ë¹„ì‚¬í•­

### 1. AutoML ì „ë¬¸ì„± ê°•í™”
- **Optuna ì‹¤ìŠµ**: í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” í”„ë ˆì„ì›Œí¬ ê²½í—˜ ìŒ“ê¸°
- **AutoML íŒŒì´í”„ë¼ì¸**: MLflow, DVC ë“±ì„ í™œìš©í•œ ML ì›Œí¬í”Œë¡œìš° ìë™í™” ê²½í—˜
- **Neural Architecture Search (NAS)** ê´€ë ¨ ë…¼ë¬¸ ë° êµ¬í˜„ ê²½í—˜
- **Meta-learning** ê¸°ì´ˆ ê°œë… í•™ìŠµ

### 2. ì˜ë£Œ AI ë„ë©”ì¸ ì§€ì‹
- **ì˜ë£Œ ì˜ìƒ ë¶„ì„**: DICOM í¬ë§·, ì˜ë£Œ ì˜ìƒ ì „ì²˜ë¦¬ ê¸°ë²• í•™ìŠµ
- **Cancer detection papers**: ë£¨ë‹›ì˜ ì£¼ìš” ë…¼ë¬¸ë“¤ ì½ì–´ë³´ê¸° (arXiv, ì˜ë£Œ AI ì»¨í¼ëŸ°ìŠ¤)
- **FDA ìŠ¹ì¸ AI ì˜ë£Œê¸°ê¸°**: ê·œì œ ìš”êµ¬ì‚¬í•­ ë° í’ˆì§ˆ ê´€ë¦¬ ê¸°ì¤€ ì´í•´
- **Medical imaging datasets**: ChestX-ray, MIMIC ë“± ê³µê°œ ë°ì´í„°ì…‹ ê²½í—˜

### 3. ì¸í”„ë¼/DevOps ìŠ¤í‚¬ ì—…ê·¸ë ˆì´ë“œ
- **Kubernetes ì‹¤ìŠµ**: ë¡œì»¬ í´ëŸ¬ìŠ¤í„° êµ¬ì¶• ë° ML ì›Œí¬ë¡œë“œ ë°°í¬
- **Docker ê³ ê¸‰ í™œìš©**: Multi-stage builds, ìµœì í™” ê¸°ë²•
- **Cloud ML ì„œë¹„ìŠ¤**: GCP AI Platform, Vertex AI ì‹¤ìŠµ
- **CI/CD for ML**: GitHub Actionsë¡œ ëª¨ë¸ í•™ìŠµ/ë°°í¬ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•

### 4. ì›¹ ê°œë°œ ìŠ¤í‚¬ (Preferred ìš”êµ¬ì‚¬í•­)
- **Django REST Framework**: API ê°œë°œ ì‹¤ìŠµ
- **React/Next.js ê¸°ì´ˆ**: ê°„ë‹¨í•œ ML ëª¨ë¸ ë°ëª¨ í˜ì´ì§€ êµ¬ì¶•
- **ë°ì´í„°ë² ì´ìŠ¤**: PostgreSQL, Redis í™œìš© ê²½í—˜

### 5. í¬íŠ¸í´ë¦¬ì˜¤ í”„ë¡œì íŠ¸ ì œì•ˆ
- **ì˜ë£Œ ì˜ìƒ AutoML í”Œë«í¼**: ê°„ë‹¨í•œ AutoML ì‹œìŠ¤í…œ êµ¬ì¶•
- **MLOps íŒŒì´í”„ë¼ì¸**: ëª¨ë¸ í•™ìŠµë¶€í„° ë°°í¬ê¹Œì§€ ìë™í™”
- **API ì„œë²„**: ML ëª¨ë¸ ì„œë¹™ REST API ê°œë°œ
- **Kubernetes ë°°í¬**: ìœ„ í”„ë¡œì íŠ¸ë“¤ì„ K8së¡œ ë°°í¬

### 6. ì´ë ¥ì„œ ì‘ì„± í¬ì¸íŠ¸
- **ì •ëŸ‰ì  ì„±ê³¼**: ëª¨ë¸ ì„±ëŠ¥ ê°œì„ , ì²˜ë¦¬ ì‹œê°„ ë‹¨ì¶•, ì¸í”„ë¼ ë¹„ìš© ì ˆê° ë“± ìˆ˜ì¹˜ë¡œ í‘œí˜„
- **ì˜ë£Œ AI ê´€ë ¨ ê²½í—˜**: ì§ì ‘ì ì´ì§€ ì•Šë”ë¼ë„ í—¬ìŠ¤ì¼€ì–´ ë°ì´í„° ë‹¤ë£¬ ê²½í—˜ ê°•ì¡°
- **AutoML/MLOps í‚¤ì›Œë“œ**: íŒŒì´í”„ë¼ì¸ ìë™í™”, ëª¨ë¸ ìµœì í™” ê²½í—˜ ë¶€ê°
- **í˜‘ì—… ê²½í—˜**: ì—°êµ¬íŒ€ê³¼ ê°œë°œíŒ€ ê°„ ë¸Œë¦¿ì§€ ì—­í•  ê²½í—˜

### 7. ë©´ì ‘ ì¤€ë¹„
- **ê¸°ìˆ  ë©´ì ‘**: AutoML ê°œë…, PyTorch ì‹¬í™”, ì‹œìŠ¤í…œ ì„¤ê³„ ë¬¸ì œ
- **ê³¼ì œ**: ê°„ë‹¨í•œ AutoML íŒŒì´í”„ë¼ì¸ êµ¬í˜„ ë˜ëŠ” ì˜ë£Œ ì˜ìƒ ë¶„ì„ íƒœìŠ¤í¬ ì˜ˆìƒ
- **PT ë©´ì ‘**: ë³¸ì¸ì˜ í”„ë¡œì íŠ¸ë¥¼ AutoML ê´€ì ì—ì„œ ì„¤ëª…í•  ìˆ˜ ìˆë„ë¡ ì¤€ë¹„
- **ì»¬ì²˜í•**: ì˜ë£Œ AIë¡œ í™˜ìì—ê²Œ ë„ì›€ì´ ë˜ê³  ì‹¶ë‹¤ëŠ” ë™ê¸°, ì—°êµ¬ì™€ ê°œë°œ ì‚¬ì´ì˜ ê· í˜•ê°

### 8. ì¶”ê°€ í•™ìŠµ ìë£Œ
- **ë…¼ë¬¸**: "Efficient Neural Architecture Search via Parameter Sharing" (ENAS)
- **ì±…**: "Hands-On Machine Learning" (AutoML ì±•í„°)
- **ê°•ì˜**: CS330 (Stanford Meta-Learning), MLOps ê´€ë ¨ ì˜¨ë¼ì¸ ê°•ì˜
- **ë¸”ë¡œê·¸**: Google AI Blogì˜ AutoML ê´€ë ¨ í¬ìŠ¤íŠ¸ë“¤

### 9. ë„¤íŠ¸ì›Œí‚¹
- **ì˜ë£Œ AI ì»¤ë®¤ë‹ˆí‹°**: í•œêµ­ ì˜ë£Œ AI í•™íšŒ, ê´€ë ¨ ë°‹ì—… ì°¸ì—¬
- **ë£¨ë‹› ì§ì›**: LinkedInìœ¼ë¡œ í˜„ì§ìì™€ ì»¤í”¼ì±— ìš”ì²­
- **ì»¨í¼ëŸ°ìŠ¤**: MICCAI, SPIE Medical Imaging ë“± ì˜ë£Œ AI ì»¨í¼ëŸ°ìŠ¤ ë…¼ë¬¸ ì½ê¸°

### ğŸ“… ì£¼ì°¨ë³„ ì¤€ë¹„ ê³„íš (4ì£¼ ê°€ì •)
- **1ì£¼ì°¨**: AutoML ê¸°ì´ˆ í•™ìŠµ + Optuna ì‹¤ìŠµ
- **2ì£¼ì°¨**: ì˜ë£Œ AI ë…¼ë¬¸ ë¦¬ë·° + Docker/K8s ì‹¤ìŠµ  
- **3ì£¼ì°¨**: í¬íŠ¸í´ë¦¬ì˜¤ í”„ë¡œì íŠ¸ êµ¬í˜„
- **4ì£¼ì°¨**: ì´ë ¥ì„œ ì™„ì„± + ë©´ì ‘ ì¤€ë¹„


# ë‚˜ì˜ ê´€ë ¨ ì§ë¬´ê²½í—˜ê³¼ í•„ì‚´ê¸° ì¤€ë¹„í•˜ê¸°

