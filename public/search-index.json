[
  {
    "id": "Self_Development/Singing/장효진강의/6강_하복부만 조이는 감각을 통해 횡경막 컨트롤하기",
    "title": "6강 하복부만 조이는 감각을 통해 횡경막 컨트롤하기",
    "date": "2025-08-10",
    "excerpt": "하복부만 조이는 감각을 통해 횡경막 컨트롤하기. 관련 연습법 정리",
    "category": "Singing",
    "tags": [
      "Singing Practice",
      "장효진 강의",
      "연습방법"
    ],
    "content": "유료 인강 링크 가슴은 서브. 가슴은 최대한 안쓰는게 좋음. 갈비뼈 아래 부분만 조이는 느낌 아래 위쪽으로 > 처음으로 분리하는 연습!"
  },
  {
    "id": "Self_Development/English Study/SPEAK/소문및가십/08-10-듣기로는다시만나고싶어한대",
    "title": "듣기로는 다시 만나고 싶어 한대",
    "date": "2025-08-10",
    "excerpt": "소문 및 가십 파트",
    "category": "English Study",
    "tags": [
      "SPEAK",
      "소문 및 가십"
    ],
    "content": "From what I've heard, he wants to get back together. I knew it 오늘 배운 것들 내가 들은 바로는 내가 아는 바로는 내가 이해하는 범위 > From what I've haard From what I've heard, Steve wants to get back together. (다시 만나고 싶더라) From what I've heard, Andrew is seeing someone else. (다른사람을 만나고 있다) > From what I know : (틀릴 수도 있는데) 내가 아는 바로는 know 자체가 상태를 나타내기 때문에 현재형으로 쓸 수 있음 From what I know, Sean is from New York. From what I know, Sue used to work at Google. From what I know, Alex is from Hawai. > As far as I understand: 내가 이해하는 범위 내에서 As far as I understand, Julie doesn't want to get back together. have a huge crash on someone 간단한 작문 (배운 표현들 사용해서) I had a blind date yesterday. (I went on a blind date yesterday.) I heared that from matchmaker, from what she know, my blind date has really good personality. So I expected that our date would be fun. After date, I have a good emotion to her. As far as I unserstand, she is so 무해하다 and cute. I wanna know more about her. --- 수정된 버전 I went on a blind date yesterday. I heard that from the matchmaker. According to what she knows, my blind date has a really good personality. So I expected that our date would be fun. After the date, I have good feelings toward her. As far as I understand, she is so harmless and cute. I want to know more about her. --- 피드백 및 수정사항 문법적 오류 수정: \"heared\" → \"heard\" (hear의 과거형) \"matchmaker\" → \"the matchmaker\" (관사 필요) \"she know\" → \"she knows\" (3인칭 단수 현재형) \"my blind date has really good personality\" → \"my blind date has a really good personality\" (관사 필요) \"After date\" → \"After the date\" (관사 필요) \"I have a good emotion to her\" → \"I have good feelings toward her\" (더 자연스러운 표현) \"I wanna know\" → \"I want to know\" (공식적인 작문에서는 완전한 형태 사용) 더 자연스러운 표현: \"According to what she knows\" - \"from what she know\"보다 더 자연스러움 \"good feelings toward her\" - \"good emotion to her\"보다 더 자연스러운 표현 \"harmless\" - \"무해하다\"의 적절한 영어 번역"
  },
  {
    "id": "Data Science/what-is-information-entropy",
    "title": "Information Entropy란?",
    "date": "2025-08-10",
    "excerpt": "Information Entropy 개념정리",
    "category": "Data Science",
    "tags": [
      "statistics"
    ],
    "content": "참고자료 1: 공돌이의 수학정리노트 2: 위키피디아 Information content 정보란? > In information theory, the information content, self-information, surprisal, or Shannon information is a basic quantity derived from the probability of a particular event occurring from a random variable. > It can be thought of as an alternative way of expressing probability, much like odds or log-odds, but which has particular mathematical advantages in the setting of information theory. surprisal, information content 이런 단어들은 확률을 변형해서 표현하는 것들. 놀라움 정도를 양적으로 표현한 것 같다. > The Shannon information can be interpreted as quantifying the level of \"surprise\" of a particular outcome. > As it is such a basic quantity, it also appears in several other settings, such as the length of a message needed to transmit the event given an optimal source coding of the random variable. $$I(x) = -log_b(P(X))$$ $b$: $2, e, 10$ 왜 log를 붙여서 정의했을까? 확률값에 반비례 해야 하기 때문에 두 사건의 정보량을 합치면 각 사건의 정보량을 합친 것과 같아야 하기 때문에 엔트로피 (entropy) : 평균 정보량 $$H(X) = E[I(X)] = - \\sum_{i=1}^n P(x_i) log_b (P(x_i))$$"
  },
  {
    "id": "Data Science/what-is-data-drift",
    "title": "Data Drift란?",
    "date": "2025-08-10",
    "excerpt": "Data Drift의 개념과 활용되는 사례에 대한 정리",
    "category": "Data Science",
    "tags": [
      "data-drift",
      "machine-learning",
      "statistics",
      "data-engineering"
    ],
    "content": "참고한 글 1: 링크드인 - Machine Learning Community (Moderated) --- How to choose Data Drift metrics in ML Production (참조 1)? Jensen–Shannon(JS) Distance 장점: symmetric적이고 값이 0~1로 bounded라 해석이 쉽고 threshold 설정이 안정적. noise·경미한 변동에 robust. 단점: computational cost가 상대적으로 큼(특히 high-dimensional). 언제 쓰나: 해석 용이성과 stable monitoring이 중요할 때. Kullback–Leibler(KL) Divergence 장점: distribution의 subtle differences까지 sensitive하게 감지(early warning에 유리). 단점: outlier·작은 probability mass에 sensitive해 spike/false alarm 가능, support set mismatch 시 발산. 언제 쓰나: early detection이 최우선이거나 높은 sensitivity가 필요한 시스템. Wasserstein Distance 장점: 큰 distribution 변화도 smoothly tracking, reference·current distribution이 겹치지 않아도 동작. 단점: computational cost 큼(large-scale/real-time, high-dimensional에서 특히 부담). 언제 쓰나: large/structural changes의 stable tracking이 필요할 때. 한 줄 가이드 interpretability·threshold stability: JS early detection of subtle changes: KL smooth and robust tracking: Wasserstein <figure> <img src=\"/post/DataScience/DataDrift_plot_1.gif\" alt=\"Data Drift Plot\" /> <figcaption>그림 1. Data Drift Plot</figcaption> </figure> --- 지표별 파이썬 구현 예시 (JS/KL/Wasserstein) 연속형 feature의 distribution을 동일한 구간으로 discretize한 뒤, KL/JS를 계산하고 Wasserstein distance를 직접 계산하는 간단한 예시입니다. ``python import numpy as np from scipy.stats import entropy, wasserstein_distance def _normalize_hist(values: np.ndarray, bins: np.ndarray, epsilon: float = 1e-8) -> np.ndarray: counts, _ = np.histogram(values, bins=bins) probs = counts.astype(float) probs = probs / max(probs.sum(), 1.0) probs = np.clip(probs, epsilon, None) probs = probs / probs.sum() return probs def kl_divergence_from_samples(reference: np.ndarray, current: np.ndarray, num_bins: int = 30, base: int = 2) -> float: \"\"\"KL(P Q): 기준(reference)=P, 현재(current)=Q\"\"\" bins = np.histogram_bin_edges(reference, bins=num_bins) p = _normalize_hist(reference, bins) q = _normalize_hist(current, bins) return float(entropy(p, qk=q, base=base)) def js_distance_from_samples(reference: np.ndarray, current: np.ndarray, num_bins: int = 30, base: int = 2) -> float: \"\"\"JS distance: sqrt(JS divergence), 0~1 범위(base=2)\"\"\" bins = np.histogram_bin_edges(reference, bins=num_bins) p = _normalize_hist(reference, bins) q = _normalize_hist(current, bins) m = 0.5 (p + q) js_div = 0.5 entropy(p, qk=m, base=base) + 0.5 * entropy(q, qk=m, base=base) return float(np.sqrt(js_div)) def wasserstein_from_samples(reference: np.ndarray, current: np.ndarray) -> float: return float(wasserstein_distance(reference, current)) 예시 데이터 ref = np.random.normal(0.0, 1.0, size=10_000) cur = np.random.normal(0.3, 1.2, size=2_000) metrics = { \"KL(P Q)\": kl_divergence_from_samples(ref, cur), \"JS distance\": js_distance_from_samples(ref, cur), \"Wasserstein\": wasserstein_from_samples(ref, cur), } print(metrics) ` 참고: 범주형 feature는 각 category의 relative frequency를 probability로 normalize하여 KL/JS를 계산하면 됩니다(동일한 category 순서와 smoothing 필요). 데이터 드리프트 지표 비교표 Metric 값 범위 symmetry distribution overlap 필요 sensitivity(subtle changes) 장점 단점 computational cost 권장 사용 --- --- --- --- --- --- --- --- --- JS distance 0~1 symmetric 불필요 중간 interpretability·threshold 설정 용이, noise robust high-dimensional에서 computational cost 증가 중 stable monitoring/threshold 운영 KL divergence 0~∞ asymmetric 부분 overlap 권장 높음 subtle changes early detection outlier/sparse probability에 sensitive, false alarm 가능 중 early warning이 중요한 시스템 Wasserstein ≥0 symmetric 불필요 중간 large/structural changes도 smoothly tracking, interpretation 직관적 large-scale/real-time·high-dimensional에서 cost 큼 높음 robust change tracking, overlap 적은 distribution --- 지표 상세 설명 Kullback–Leibler(KL) Divergence relative entropy, I-divergence. > A simple interpretation of the KL divergence of P from Q is the expected excess surprisal from using Q as a model instead of P when the actual distribution is P. P대신 Q를 썼을 때 정보량의 변화정도가 KL divergence. $$ D_{KL}(P Q) = \\sum_{x \\in X} p(x) \\log \\frac{p(x)}{q(x)} = H(P, Q) - H(P) \\tag{3} $$ distance의 속성을 만족하지 못해서 distance라고 표현할 수는 없다. squared distances의 속성은 만족한다고 한다. 직관: 진짜가 P인데 Q로 coding하려고 할 때 “추가로 내야 하는 information cost”. directionality이 중요해 KL(P Q)와 KL(Q P)는 다른 값을 준다. 수식 $$ KL(P\\,\\ \\,Q) = \\sum\\limits_{x} p(x)\\,\\log\\frac{p(x)}{q(x)}\\quad(\\text{연속형은 적분}) $$ 특징: asymmetric, lower bound 0·upper bound 없음. Q(x)=0이면서 P(x)>0이면 발산(infinity). sparse probability·outlier에 매우 sensitive. 계산법: histogram/KDE로 p,q 추정 후 epsilon smoothing(예: 1e-6). 운영에서는 KL(P\\ \\ Q), KL(Q\\ \\ P) 둘 다 보거나 symmetricization(KL sym) 혹은 JS로 대체. threshold 힌트: spike가 잦으므로 moving average·quantile 기반 경보, permutation(label shuffle) null로 p-value 추정 권장. 사용처: early 미세 변화 탐지, sensitive도 최우선 경보 시스템, 리스크가 큰 영역의 세밀 monitoring. 흔한 함정: sample 적을 때 unstable, bin 선택/bandwidth sensitive, log 수치unstable → smoothing/clipping·normalization 필요. --- Jensen–Shannon(JS) Divergence information radius(IRAD) or total divergence > It is based on the Kullback-Leibler divergence, with some notable (and useful) differences, including that it is symmetric and it always has a finite value. square root of Jensen-Shannon divergence == Jensen-Shannon distance 직관: 두 distribution의 “중간 distribution” M과의 information difference를 평균해 측정하고, square root을 취해 실제 distance로 만든 값. symmetric이고 0~1 범위라 threshold을 정하기 쉽다. 수식 $$ JS(P, Q) = \\tfrac{1}{2}\\,KL(P\\,\\ \\,M) + \\tfrac{1}{2}\\,KL(Q\\,\\ \\,M)\\\\ M = \\tfrac{1}{2}(P + Q)\\\\ JS\\_\\text{dist}(P, Q) = \\sqrt{JS(P, Q)}\\quad(\\text{log base}=2\\Rightarrow 0\\le JS\\_\\text{dist}\\le 1) $$ 특징: symmetric, bounded(0~1), support set mismatch에도 finite. rare event에 over-sensitive하지 않아 운영 monitoring에 안정적. 계산법: 연속형은 공통 bin 또는 KDE로 확률추정 후 계산, 범주형은 범주 집합을 합집합으로 정렬해 smoothing(e.g., 1e-6) 후 계산. 표본 적으면 분산↑ → 윈도우 크기 확대. threshold 힌트: 기준 기간에서 distribution를 부트스트랩해 경험적 distribution를 만든 뒤 상위 quantile로 경보선 설정(조직별 캘리브레이션 권장). 사용처: 해석 용이·안정적 스케일이 필요한 대시보드, 다수 피처의 일관된 threshold 운영. 흔한 함정: bin 개수/경계, KDE bandwidth에 sensitive. 범주 희박도 높을 때 값이 과소평가될 수 있음 → smoothing/병합 고려. --- Wasserstein Distance (Earth Mover's Distance, 1-Wasserstein) 직관: 한 distribution의 질량을 다른 distribution로 옮길 때 필요한 “최소 작업량”. 값의 단위가 원 변수와 같아 해석이 직관적이다. 수식(1차원) $$ W\\_1(P, Q) = \\int\\limits_{0}^{1} \\big F\\_P^{-1}(u) - F\\_Q^{-1}(u)\\big \\,du $$ 특징: symmetric, distribution 겹침이 없어도 정의 가능, support set 경계에 강함. 위치·스케일 이동을 부드럽게 반영. 계산법: 1D는 scipy.stats.wasserstein_distance`로 정렬 기반 O(n log n). 다변량은 표준화 후 Sinkhorn(엔트로피 normalization) 등으로 근사(POT 등 라이브러리). threshold 힌트: 원 단위 그대로 해석하거나 IQR/표준편차로 normalization해 무단위 distance로 비교. KPI와 직접 연결해 threshold 세팅 용이. 사용처: 큰/구조적 이동 추적, 기준·현재 distribution가 거의 겹치지 않는 상황, 비즈니스 단위 해석이 중요한 경우. 흔한 함정: 고차원 계산량 부담·메모리 사용 증가, 피처 스케일 mismatch 시 왜곡 → 표준화 필수. 다변량 OT는 구현·튜닝 난이도 높음. 직관적 이해 🚚 \"흙을 옮기는 비용\" 개념 한 분포의 \"질량\"을 다른 분포로 옮기는 최소 작업량을 의미합니다 마치 건설 현장에서 흙을 한 곳에서 다른 곳으로 옮기는 것과 비슷합니다 각 위치에서 필요한 흙의 양과 옮겨야 할 거리를 고려하여 총 작업량을 계산합니다 간단한 예시 분포 P: [0, 0, 1, 0, 0] (중앙에만 질량) 분포 Q: [0, 0, 0, 1, 0] (오른쪽으로 한 칸 이동) Wasserstein Distance = 1 (한 칸 옮기면 됨) KL divergence = ∞ (겹치는 부분이 없음) 데이터 드리프트에서의 활용 데이터 드리프트를 감지할 때: 시간에 따른 분포 변화를 정량적으로 측정 모델 성능 저하의 원인 분석 데이터 품질 모니터링에 활용 이 방법은 특히 연속형 변수나 순서가 있는 범주형 변수에서 분포 변화를 측정할 때 매우 유용합니다. ---"
  },
  {
    "id": "Data Science/what-is-KL-divergence",
    "title": "KL Divergence란?",
    "date": "2025-08-10",
    "excerpt": "KL Divergence 개념정리",
    "category": "Data Science",
    "tags": [
      "statistics"
    ],
    "content": "참고자료 1: 공돌이의 수학정리노트 entropy entropy 개념 정리 $$ H(x) = - \\sum_{i=1}^n p(x_i)log(p(x_i)) \\tag{1} $$ cross entropy 예측과 달라서 생기는 깜놀도 (즉 정보량) $$ H(p, q) = - \\sum_{i=1}^n p(x_i)log(q(x_i)) \\tag{2} $$ KL divergence > A simple interpretation of the KL divergence of P from Q is the expected excess surprisal from using Q as a model instead of P when the actual distribution is P. $$ D_{KL}(p q) = \\sum_{x \\in X} p(x) \\log \\frac{p(x)}{q(x)} \\tag{3} $$ $$ = \\sum_{x \\in X} p(x) \\log p(x) - \\sum_{x \\in X} p(x) \\log q(x) \\tag{4} $$ $$ D_{KL}(p q) = H(p, q) - H(p) \\tag{5} $$"
  },
  {
    "id": "Self_Development/English Study/SPEAK/소문및가십/08-09-결국-둘이-잘될줄-알았어",
    "title": "08-09 결국 둘이 잘될줄 알았어",
    "date": "2025-08-09",
    "excerpt": "소문및가십 08-09 결국 둘이 잘될줄 알았어",
    "category": "English Study",
    "tags": [
      "SPEAK",
      "소문및가십"
    ],
    "content": "I knew they would end up together. 배운 것들 No wonder : 놀랍지 않아. No wonder he didn't call. No wonder he's great with kids. I knew it : 그럴 줄 알았어. I knew they would end up together. I knew they would break up. would have naver p.p : 절대 ~하지 못했을거야. I would have naver guessed it. I would have naver thought it."
  },
  {
    "id": "Self_Development/Singing/장효진강의/5강_마지막까지 뱉는 방법을 통한 복부가 조이는 감각 익히기",
    "title": "5강 마지막까지 뱉는 방법을 통한 복부가 조이는 감각 익히기",
    "date": "2025-08-07",
    "excerpt": "마지막까지 뱉는 방법을 통해 복부가 조이는 감각 익히기. 관련 연습법 정리",
    "category": "Singing",
    "tags": [
      "Singing Practice",
      "장효진 강의",
      "연습방법"
    ],
    "content": "유료 인강 링크 4강 헀던 상황에서 조금만 틈을 벌리기 휘파람 모양 만들기 마지막까지 뱉기!! 주먹으로 막기 피지컬 훈련!! 많이 연습하면 연습할수록 빨리 늠. 다음 수업을 듣더라도 계속 해주기. 가수들은 노래를 잘하니까 기본만 더 많이 함. 더 빡세게."
  },
  {
    "id": "Self_Development/Singing/장효진강의/4강_입을 막아서 뱉을 때 쓰는 압력 느끼기",
    "title": "4강 입을 막아서 뱉을 때 쓰는 압력 느끼기",
    "date": "2025-08-07",
    "excerpt": "입을 막아서 뱉을 때 쓰는 압력 느끼기. 관련 연습법 정리",
    "category": "Singing",
    "tags": [
      "Singing Practice",
      "장효진 강의",
      "연습방법"
    ],
    "content": "유료 인강 링크 3강 훈련. 아침 점심 저녁 기준으로 15번은 할 수 있을 때 넘어오기. 입을 막고 압력을 느껴보는 훈련 나갈 길이 없기 때문에 압축에 가까움. 압축을 느껴보는 훈련. 강하게 뱉어보기 뱉다가 막아보기 저항이 생김. 이 느낌. 힘을 꾹 주고 있는 느낌. 막은 걸 뚫고 나가겠다는 힘을 주기 배가 안으로 밀려 올라가는 느낌. 손으로. 최대한 많이. 압력 = 저항법"
  },
  {
    "id": "Data Science/confidence_interval_for_ML",
    "title": "ML의 신뢰구간을 구하는 방법",
    "date": "2025-08-06",
    "excerpt": "ML의 신뢰구간은 어떻게 구할까?",
    "category": "Data Science",
    "tags": [
      "machine-learning",
      "confidence-interval"
    ],
    "content": "참고자료 1: Confidence Intervals for Machine Learning 2: Don’t Forget Confidence Intervals for Your ML Product 3: Creating Confidence Intervals for Machine Learning Classifiers 4: Confidence vs Prediction Intervals: Understanding the Difference --- 신뢰구간의 정의 > A confidence interval provides a range of values within which a population parameter is likely to fall, with a certain level of confidence. 신뢰구간은 모집단의 모수(parameter)가 특정 범위 내에 있을 가능성을 나타내는 통계적 구간 --- metric에 대한 신뢰구간 (참고1) 보통 ML의 신뢰구간은 metric에 대한 신뢰구간을 의미하는 것 같다. <figure> <img src=\"/post/DataScience/CI_for_ML/CI_example1.png\" alt=\"confidence_interval_for_ML\" style=\"width: 50%;\" /> <figcaption>그림1. confidence_interval_for_ML (참고1)</figcaption> </figure> > For example, a 95% confidence interval of [85%, 90%] for model accuracy means that if we repeated the process multiple times, about 95% of the intervals would contain the true accuracy. This helps in assess model reliability and make informed decisions. 정확도와 같은 평가지표를 신뢰구간으로 제시하면 데이터가 바뀌었을 때에 대한 고려도 할 수 있고, 이러한 이유 떄문에 선택에 더 도움이 됨. --- 신뢰구간의 중요성 (참고1) 신뢰구간은 머신러닝의 다양한 영역에서 가치 있는 정보를 제공합니다: 모델 성능 평가 정확도나 F1-score와 같은 단일 지표에만 의존하는 대신, 신뢰구간은 서로 다른 샘플에서의 성능 변화를 이해하는 데 도움을 줍니다. 예시: 모델의 정확도가 85%이고 95% 신뢰구간이 [82%, 88%]라면, 새로운 데이터에서 테스트할 때 모델의 정확도가 이 범위 내에서 변동할 수 있음을 의미합니다. 회귀 계수 해석 선형 회귀 모델에서 신뢰구간은 추정된 계수의 신뢰성을 평가하는 데 도움을 줍니다. 예시: 특정 특성의 계수가 2.5이고 95% 신뢰구간이 [1.8, 3.2]라면, 해당 특성이 양의 효과를 가진다고 합리적으로 확신할 수 있습니다. 예측의 불확실성 신뢰구간은 모델 예측에 대한 불확실성 측정을 제공하며, 특히 확률적 모델에서 유용합니다. 예시: 주택 가격을 [200K, 250K] 범위로 95% 신뢰수준에서 예측한다면, 실제 가격이 이 범위 내에 있을 가능성이 높음을 의미합니다. A/B 테스트 및 가설 검정 두 모델이나 특성을 비교할 때, 신뢰구간은 차이가 통계적으로 유의한지 판단하는 데 도움을 줍니다. 예시: 모델 A의 정확도가 90% [88%, 92%]이고 모델 B가 87% [85%, 89%]라면, 모델 A가 우수하다는 증거가 있습니다. --- 신뢰구간을 구하는 법 (참고2) > So how can we create and add confidence intervals to our models? As the name implies, to build confidence intervals (or any other measure of confidence) you first need to define what your metric represents and what confidence means to you and your user. > There are many ways to derive a measure of confidence but all depend on some sort of knowledge which you can use to validate and test your predictions. --- 신뢰구간을 구하는 법 (참고3) > Confidence intervals are no silver bullet, but at the very least, they can offer an additional glimpse into the uncertainty of the reported accuracy and performance of a model. 여러 글에서 신뢰구간을 제시하는게 소통을 하는데 도움을 준다고 이야기하네. 공감이 된다. 어떤 추정값을 이야기할 때 불확실성에 대한 이야기는 꼭 포함이 되어야 한다고 생각한다. <figure> <img src=\"/post/DataScience/CI_for_ML/with_CI_without_CI.png\" alt=\"confidence_interval_for_ML\" style=\"width: 80%;\" /> <figcaption>그림2. with_CI_without_CI</figcaption> </figure> 확실히 포함된게 더 보기 좋음 이 블로그에서 CI를 구하는 다양한 방법들을 소개하고 있다. 기본적인 컨셉만 이해하고, 정리하다가 너무 많아서 패스. Confidence Intervals in a Nutshell > A confidence interval is a method that computes an upper and a lower bound around an estimated value. The actual parameter value is either insider or outside these bounds. 추정값에 대한 불확실성을 정량화한게 신뢰구간이라고 생각해볼 수 있겠다. <figure> <img src=\"/post/DataScience/CI_for_ML/95_percent_CI.png\" alt=\"confidence_interval_for_ML\" style=\"width: 80%;\" /> <figcaption>그림3. 95% 신뢰구간의 의미</figcaption> </figure> 95% 신뢰구간의 의미는? > “95% 신뢰구간”이란, 동일한 방법으로 표본을 여러 번 뽑아서 신뢰구간을 계속 계산한다면, 그중 약 95%의 신뢰구간이 모집단의 참값을 포함하게 된다는 의미 오해와 정확한 해석 > 많은 사람들이 “이 신뢰구간 안에 진짜 평균이 95% 확률로 들어 있다”라고 생각하지만, 엄밀하게는 틀린 해석이야. 참값은 이미 고정된 값이니까, 확률로 해석하지 않아. 올바른 해석은 “이 방식으로 구한 신뢰구간이 모집단의 평균을 95% 수준으로 포함한다”는 것. 원하는 건 모델의 성능에 대한 값들. 신뢰구간은 위에서 언급한 것처럼 모델이 추정값에 대한 얼만큼의 불확실성을 가지고 있는지를 의미. A Note About Statistical Significance 통계적 유의성이란? > 통계적 유의성은 관찰된 결과가 단순한 우연이나 확률적 변동이 아닌, 실제로 의미 있는 차이나 관계가 있다고 판단할 수 있는 정도를 나타냅니다. <figure> <img src=\"/post/DataScience/CI_for_ML/ci-overlap.png\" alt=\"confidence_interval_for_ML\" style=\"width: 80%;\" /> <figcaption>그림4. 신뢰구간의 중복을 통한 판단</figcaption> </figure> group1과 group2가 다른지를 신뢰구간을 통해 확인해볼 수 있다. 당연하게도 완전히 겹치지 않으면 확실히 다른 것이라고 판단할 수 있다. 겹친다면 겹친 분포를 그리고 여기서 mu = 0이 신뢰구간에 포함되는지를 통해 확인할 수 있다. Method 1 : Normal Approximation Interval Based on a Test Set > In our case, the sample mean $\\bar x$ is test set accuracy $\\text{ACC}_{test}$, a proportion of success (in the context of a Binomial proportion confidence interval). Binomial proportion confidence interval? > 성공/실패와 같은 이항 분포를 따르는 비율(proportion)에 대한 신뢰구간 ML에서의 적용: 분류 모델의 정확도(accuracy)는 이항 분포를 따름 각 예측이 맞음(성공) 또는 틀림(실패)의 두 가지 결과만 가짐 전체 예측 중 맞은 비율이 정확도 예시: 테스트셋에서 100개 샘플 중 85개를 맞췄다면 정확도 = 85/100 = 0.85 (85%) 이 85%라는 비율에 대한 신뢰구간을 구하는 것이 이항 비율 신뢰구간 계산 방법: 정규근사법 (Normal Approximation) Wilson 방법 Clopper-Pearson 방법 수식 정의 standard error : $\\sqrt{\\frac{1}{n} \\text{ACC}_{test} (1 - \\text{ACC}_{test})}$ > You can find a description of this method in section 1.7 Confidence Intervals via Normal Approximation of my “Model Evaluation, Model Selection, and Algorithm Selection in Machine Learning”. <figure> <img src=\"/post/DataScience/CI_for_ML/normal-approx.png\" alt=\"confidence_interval_for_ML\" style=\"width: 80%;\" /> <figcaption>그림5. 정확도에 대한 신뢰구간 표시</figcaption> </figure> Method 2: Bootstrapping Training Set - Setup Step > If we only have one estimate, like the accuracy from a single test set, we need to make assumptions about the distribution of this accuracy value. > For example, we may assume that the accuracy values (that we would compute from different samples) are normally distributed. 부트스트랩 기반으로 신뢰구간을 구한다는건 정규분포를 가정하는건가? > No! 부트스트랩은 정규분포 가정 없이도 신뢰구간을 구할 수 있는 강력한 비모수적 방법입니다. 이것이 바로 부트스트랩의 가장 큰 장점 중 하나입니다. Confidence vs Prediction Intervals: Understanding the Difference (참고4) > The root cause of this uncertainty is the sampling process. > It is unrealistic to consider the entire population when conducting a statistical analysis. 좋은 문장이다. > The true value of the population parameter is usually not exactly equal to the value estimated from the sample - this difference is the standard error. > To account for this error, it is conventional to estimate an expected value and then specify a range that is expected to contain the actual value. 추정값은 실제값과 차이가 있을 것이고, 이를 범위로 표시한다. What is a Prediction Interval? > A prediction interval is the range that is expected - with some level of confidence, to contain the true value of an individual data point, based on a prediction made using regression analysis. 내가 원하는 개념이 prediction interval이구나. 개별 추정값에 대한 오차 범위. > However, you must account for the increased variability of individual data points because you are predicting an individual value (and not an average). > Thus, the prediction interval is larger than the confidence interval."
  },
  {
    "id": "Data Science/Data Engineering/sharding_vs_partitioning",
    "title": "sharding vs partitioning",
    "date": "2025-08-05",
    "excerpt": "DB관리할 때 sharding과 partitioning의 차이에 대한 개념 정리",
    "category": "Data Science",
    "tags": [
      "DataBase"
    ],
    "content": "참고한 글 링크드인 게시물 - Ashish Pratap Singh <figure> <img src=\"/post/DataScience/sharding_vs_partitioning.gif\" alt=\"Sharding vs Partitioning 차이점\" /> <figcaption>Sharding vs Partitioning</figcaption> </figure> 구분 Partitioning Sharding ------ ------------- ---------- 범위 단일 서버 내 여러 서버 간 목적 성능 최적화 수평적 확장 복잡도 상대적으로 단순 복잡한 분산 시스템 사용 시기 단일 머신 내 최적화 단일 머신 한계 초과 시 Partitioning이란? > 하나의 큰 테이블을 더 작은 청크(파티션)로 나누는 것 목적: 성능 향상과 유지보수 단순화 특징: 논리적으로는 하나의 테이블: 개발자가 쿼리할 때는 마치 하나의 테이블처럼 사용 (파티션을 신경 쓸 필요 없음) 물리적으로는 여러 파일로 분산: 실제로는 각 파티션이 별도의 파일/세그먼트로 저장됨 쿼리 성능 향상 (특정 파티션만 스캔) 데이터 관리 용이성 (오래된 파티션 삭제 등) ``sql -- 파티셔닝된 테이블을 조회할 때 SELECT FROM logs WHERE log_date >= '2024-01-01'; -- 개발자는 마치 하나의 테이블을 조회하는 것처럼 사용 -- 하지만 DB 엔진은 내부적으로 2024년 파티션만 스캔함 ` 파티셔닝은 대부분의 현대적인 DBMS에서 지원하는 기능 지원하는 DBMS MySQL: Range, List, Hash, Key 파티셔닝 지원 PostgreSQL: Range, List, Hash 파티셔닝 지원 Oracle: Range, List, Hash, Composite 파티셔닝 지원 SQL Server: Range, List, Hash 파티셔닝 지원 BigQuery: Date, Integer Range 파티셔닝 지원 Snowflake: 다양한 파티셔닝 전략 지원 지원하지 않는 DBMS SQLite: 기본적으로 파티셔닝 미지원 일부 NoSQL DB: 파티셔닝 대신 샤딩 개념 사용 MySQL 파티셔닝 예시 `sql -- 월별 Range 파티셔닝 CREATE TABLE logs ( id INT, log_date DATE, message TEXT ) PARTITION BY RANGE (YEAR(log_date) 100 + MONTH(log_date)) ( PARTITION p202401 VALUES LESS THAN (202402), PARTITION p202402 VALUES LESS THAN (202403), PARTITION p202403 VALUES LESS THAN (202404), PARTITION p_future VALUES LESS THAN MAXVALUE ); ` Sharding이란? > 데이터를 여러 데이터베이스 서버에 분산 배치 목적: 수평적 확장(horizontal scaling)을 통한 대용량 처리 특징: 각 서버(샤드)가 전체 데이터셋의 일부를 보유 단일 머신의 한계를 넘어서는 확장성 제공 복잡한 분산 시스템 관리 필요 예시 `sql -- 샤딩된 환경에서 사용자 조회 -- 사용자 ID를 4로 나눈 나머지로 샤드 결정 shard_number = user_id % 4 -- 사용자 ID가 123인 경우: 123 % 4 = 3 → shard_3에서 조회 SELECT * FROM users WHERE user_id = 123; -- 실제로는 shard_3 서버에서 실행됨 ` 수평적 확장(Horizontal Scaling)이란? > 수평적 확장은 \"더 많은 서버를 추가\"하는 방식으로 시스템을 확장하는 것을 의미 수직적 확장 vs 수평적 확장 구분 수직적 확장 (Vertical Scaling) 수평적 확장 (Horizontal Scaling) ------ ------------------------------- ---------------------------------- 방식 기존 서버의 성능을 향상 새로운 서버를 추가 예시 CPU 4코어 → 16코어, RAM 8GB → 64GB 서버 1대 → 서버 10대 장점 구현이 단순 무제한 확장 가능 단점 물리적 한계 존재, 비용 증가 복잡한 분산 시스템 관리 필요 샤딩에서의 수평적 확장 ` 초기 상태: 서버 1대 (모든 데이터 보유) ├── 사용자 1~1000 ├── 사용자 1001~2000 └── 사용자 2001~3000 샤딩 후: 서버 3대 (데이터 분산) ├── 서버1: 사용자 1~1000 ├── 서버2: 사용자 1001~2000 └── 서버3: 사용자 2001~3000 더 많은 사용자가 늘어나면: ├── 서버1: 사용자 1~1000 ├── 서버2: 사용자 1001~2000 ├── 서버3: 사용자 2001~3000 ├── 서버4: 사용자 3001~4000 ← 새로 추가 └── 서버5: 사용자 4001~5000 ← 새로 추가 `` RDBMS MySQL: ProxySQL, MySQL Router 등 미들웨어 필요 PostgreSQL: 기본 버전은 샤딩 미지원 Oracle: RAC는 있지만 샤딩과는 다름 SQL Server: 기본 버전은 샤딩 미지원 샤딩 구현 방법 샤딩은 DBMS에서 직접 지원하는 경우가 적어서, 다양한 방법으로 구현해야 합니다. 3.1 DBMS별 샤딩 지원 현황 내장 샤딩 지원 DBMS MongoDB: 자동 샤딩 지원 (shard key 기반) Cassandra: 파티션 키 기반 샤딩 Redis Cluster: 해시 슬롯 기반 샤딩 Elasticsearch: 인덱스 기반 샤딩 샤딩 미지원 DBMS (수동 구현 필요) MySQL: ProxySQL, MySQL Router 등 미들웨어 필요 PostgreSQL: 기본 버전은 샤딩 미지원 (Citus 확장으로 가능) Oracle: RAC는 있지만 샤딩과는 다름 SQL Server: 기본 버전은 샤딩 미지원 3.2 샤딩 구현 방식 애플리케이션 레벨 샤딩 개념: 개발자가 직접 애플리케이션 코드에서 샤딩 로직을 구현 방식: 사용자 ID나 다른 키를 기반으로 어떤 샤드에 접근할지 결정 장점: 완전한 제어 가능, 세밀한 튜닝 가능 단점: 개발 복잡도 증가, 유지보수 부담 미들웨어를 통한 샤딩 개념: 데이터베이스와 애플리케이션 사이에 중간 계층을 두어 샤딩 처리 방식: 쿼리를 받아서 적절한 샤드로 라우팅 장점: 애플리케이션 코드 변경 최소화, 전문적인 샤딩 관리 단점: 추가적인 인프라 복잡도, 성능 오버헤드 클라우드 서비스 활용 개념: 클라우드 제공업체가 관리하는 샤딩 서비스 사용 방식: 설정만으로 자동 샤딩 구성 장점: 관리 부담 최소화, 자동 확장 단점: 벤더 종속성, 비용 증가 3.3 샤딩 전략 Hash 기반 샤딩 개념: 데이터의 해시값을 기반으로 샤드 결정 특징: 데이터가 균등하게 분산됨 예시: 사용자 ID를 해시해서 샤드 번호 결정 Range 기반 샤딩 개념: 데이터의 범위를 기반으로 샤드 결정 특징: 범위 쿼리 성능이 좋음 예시: 날짜별, ID 범위별로 샤드 할당 Directory 기반 샤딩 개념: 매핑 테이블을 사용해서 샤드 결정 특징: 유연한 샤드 할당 가능 예시: 특정 사용자를 특정 샤드에 고정 배치 3.4 샤딩 시 고려사항 장점 무제한 수평적 확장 가능 각 샤드별 독립적인 성능 최적화 장애 격리 (한 샤드 장애가 전체에 영향 없음) 단점 복잡한 분산 시스템 관리 크로스 샤드 쿼리의 성능 이슈 데이터 일관성 보장의 어려움 트랜잭션 관리의 복잡성"
  },
  {
    "id": "Data Science/Data Engineering/datapipeline_linkedin_shared",
    "title": "링크드인에서 공유된 Data Pipeline 구조 정리",
    "date": "2025-08-05",
    "excerpt": "링크드인에서 공유된 Data Pipeline 참고해서 그림 그려보고, 이해하는 과정",
    "category": "Data Science",
    "tags": [
      "Data Pipeline"
    ],
    "content": "참고한 글 링크드인 - Aurimas Griclunas <figure> <img src=\"/post/DataScience/Datapipeline_linkedin.gif\" alt=\"Data Pipeline LinkedIn\" /> <figcaption>Data Pipeline LinkedIn</figcaption> </figure> 원본 글 정리 ML 시스템의 Data Pipeline 구조 ML 시스템에서 Data Quality와 Integrity를 보장하는 것은 매우 중요합니다. 특히 ML Training 및 Inference Pipeline의 upstream에서 이를 확보해야 하며, downstream 시스템에서 이를 시도하면 대규모 작업 시 불가피한 실패를 야기할 수 있습니다. Data Lake 또는 LakeHouse layer에서 수행해야 할 작업이 많습니다. 아래는 production-grade end-to-end data flow의 예시 아키텍처입니다. Data Flow 단계별 설명 Schema 관리 Schema changes는 version control에서 구현 승인 후 Applications, Databases, 중앙 Data Contract Registry에 푸시 Applications는 생성된 Data를 Kafka Topics로 전송 Data 수집 2단계: Application Services에서 직접 발생하는 Events IoT Fleets 및 Website Activity Tracking 포함 2.1단계: CDC streams을 위한 Raw Data Topics Data 검증 및 처리 3단계: Flink Application(s)이 Raw Data streams을 소비하고 Contract Registry의 schemas에 대해 검증 4단계: contract를 충족하지 않는 Data는 Dead Letter Topic으로 전송 5단계: contract를 충족하는 Data는 Validated Data Topic으로 전송 6단계: Validated Data Topic의 Data는 추가 Validation을 위해 object storage로 전송 Data Warehouse 및 변환 7단계: Object Storage의 Data는 schedule에 따라 Data Contracts의 추가 SLAs에 대해 검증되고, analytical purposes를 위해 transformed 및 modeled되어 Data Warehouse로 전송 Feature Store 및 ML Pipeline 8단계: Modeled 및 Curated data는 추가 Feature Engineering을 위해 Feature Store System으로 전송 8.1단계: Real Time Features는 Validated Data Topic(5단계)에서 직접 Feature Store로 ingested SLA checks가 어려워 Data Quality 보장이 복잡함 9단계: High Quality Data는 ML Training Pipelines에서 사용 10단계: 동일한 Data는 Inference에서 Feature Serving에 사용 주의사항 ML Systems는 Data Drift와 Concept Drift와 같은 다른 Data 관련 문제로 고통받습니다. 이는 silent failures이며 monitoring할 수 있지만 Data Contract에 포함할 수 없습니다. --- 이 구조는 LLM 기반 시스템에서도 사용할 수 있습니다. CDC streams? > CDC(Change Data Capture) Stream은 데이터베이스의 변경사항(INSERT, UPDATE, DELETE)을 실시간으로 감지하고 스트리밍하는 기술입니다. 데이터 동기화에 사용되는 개념? 실시간 데이터 동기화 아키텍처: Kafka & CDC 기반 설계 경험 Kafka? > Apache Kafka는 고성능 분산 스트리밍 플랫폼입니다. 실시간 데이터 파이프라인과 스트리밍 애플리케이션을 구축하기 위한 오픈소스 플랫폼입니다. 핵심 개념: Producer: 데이터를 Kafka로 전송하는 애플리케이션 Consumer: Kafka에서 데이터를 읽어가는 애플리케이션 Topic: 데이터가 저장되는 카테고리 (메시지 큐와 유사) Broker: Kafka 서버 (클러스터로 구성) Partition: Topic을 여러 개로 나눈 단위 (병렬 처리)"
  },
  {
    "id": "Self_Development/English Study/SPEAK/소문및가십/08-04-너한테_작업_걸었다니_말도안돼",
    "title": "너한테 작업 걸었다니 말도 안돼",
    "date": "2025-08-04",
    "excerpt": "믿을 수 없다는 듯 다시 묻는 표현들. 그럴리 없다는 이야기",
    "category": "English Study",
    "tags": [
      "영어공부꾸준히!",
      "SPEAK"
    ],
    "content": "배운 것들 정리 Are you telling me that John got plastic surgery? There's no way : 그럴리가 없어 There's no way that Mark is cheating on his girlfriend. hit on makes fun of someone : ~~를 비웃다."
  },
  {
    "id": "Self_Development/Career/how-to-get-job",
    "title": "이직하는 방법 정리",
    "date": "2025-08-04",
    "excerpt": "이직하는 법 찾아보면서 하나씩 정리한 것들",
    "category": "Career",
    "tags": [
      "이직성공하자!"
    ],
    "content": "잡플래닛 이직 자료"
  },
  {
    "id": "Self_Development/Career/Job Transition/25-08-04-하이퍼커넥트",
    "title": "하이퍼커넥트 ML Engineer",
    "date": "2025-08-04",
    "excerpt": "하이퍼커넥트 ML Engineer 적어보기",
    "category": "Career",
    "tags": [
      "하이퍼커넥트 채용공고"
    ],
    "content": "하이퍼커넥트 ML Engineer 채용공고 채용공고 링크: LinkedIn Job Posting 회사 정보 Legal Entity 회사명: Hyperconnect 브랜드: Match Group AI Match Group AI 소개 Match Group AI는 중앙 AI 조직으로서, AI 기술을 활용하여 Tinder와 Hinge를 비롯한 Match Group의 다양한 제품군에 기여하고 있습니다. 기존의 기술로는 접근하기 어렵지만 AI 기술을 통해 풀 수 있는 문제들을 찾아내고 사용자 경험을 혁신합니다. 주요 역할: 사용자들이 자신을 더 잘 표현할 수 있도록 돕는 도구 개발 의미 있는 만남을 발견하는 과정에서 더 만족스러운 경험을 제공하는 기능 개발 ML Team 소개 ML Team은 Match Group의 다양한 서비스에 AI 기술을 적용하는 ML Engineer로 구성된 팀입니다. 이들은 최신 AI 기술을 연구하고 적용하는 과학자이자, 실제 서비스 환경에 맞게 모델 및 시스템을 설계하고 최적화하여 실질적인 임팩트를 만들어내는 엔지니어이기도 합니다. 업무 프로세스 문제 발굴 및 정의: 실제 서비스 현장에서 발생하는 문제를 발굴하고 정의 모델 개발: 문제 해결에 가장 적합한 SotA(State-of-the-Art) 모델을 개발하거나 재현 배포: 완성된 모델을 모바일과 서버 환경에 안정적이고 효율적으로 배포 모니터링 및 개선: 지속적인 모니터링과 개선을 통해 서비스의 AI Flywheel 구축 협업 백엔드/프론트엔드/DevOps 엔지니어, 데이터 분석가, PM 등 다양한 전문 조직과 긴밀히 협업하며 실제 사용자에게 임팩트를 주는 AI 경험을 만들어갑니다. 참고 자료 How AI Lab Works - Head of AI - Shurain 인터뷰 AI in Social Discovery(Blending Research and Production) 연구 성과 업무 성과 중 일부는 논문 또는 오픈소스 코드로 외부에 공개하기도 합니다. 지금까지 약 20여 건의 대외적 연구 성과를 거둘 수 있었습니다. 주요 연구 성과 2024년 CUPID: 1:1 소셜 디스커버리 플랫폼을 위한 실시간 세션 기반 상호 추천 시스템 (ICDM Workshop 발표) 2023년 TiDAL: 효율적인 학습 과정의 모델 행동에 기반한 액티브 러닝 기법 (ICCV 2023 게재) 모더레이션 환경에서 여러 분류 기준을 동시에 만족하기 위한 문턱값을 잡는 연구 (WSDM 2023 게재) 2022년 대화 생성에서의 의미적 다양성을 높이는 연구 (EMNLP 2022 게재) 레이블 노이즈가 심한 환경에서 효과적으로 학습하는 방법 (ECCV 2022 게재) 타깃 캐릭터의 몇가지 발화만을 이용하여 타깃 캐릭터를 모방하는 챗봇연구 (NAACL 2022 게재) 대화 생성 모델에서 예시를 활용하여 성능을 높이는 연구 (ACL 2022 Workshop 발표) 모바일 환경에서 오디오 분류를 위한 distillation 기술 연구 (ICASSP 게재) 인프라 및 환경 딥러닝 클러스터 총 160대 A100 GPU 40대 H100 GPU 데이터 파이프라인 데이터 수집, 전처리를 포함한 자체적인 데이터 파이프라인 클라우드 서비스를 활용하여 구축 및 운영 협업 환경 다양한 software engineer(백엔드/프론트엔드/DevOps/MLSE)와 함께 작업 담당 업무 Match Group AI의 ML Engineer는 Tinder, Hinge 등 매치그룹의 글로벌 팀들과 협업하며, 생성형 AI, 온디바이스 AI, 추천 시스템 등 다양한 AI 기술을 활용해 데이팅 도메인 사용자 경험을 혁신하는 다양한 프로젝트를 수행합니다. 주요 역할 아이디어 구상부터 프로토타이핑, 실제 사용자에게 도달하기까지 전 과정을 주도적으로 이끌기 필요시 직무 역할과 도메인, 기술 스택의 경계를 넘나들며 문제 해결 다루는 문제 영역 다음과 같은 문제들 중 일부에 대한 경험이 있거나, 아직 경험해보지 않은 문제라도 빠르게 학습하고 주도적으로 대응할 수 있는 분을 찾고 있습니다: Multi-modal 데이터 활용 제품에서 발생하는 multi-modal data를 효과적으로 활용 극도로 불균형하거나 노이즈가 많은 데이터 처리 서로 다른 도메인에서 수집된 데이터 간 차이를 극복할 수 있는 domain adaptation 기법 Meta Learning 모델 요구사항이 자주 변경되거나 초기 데이터가 충분하지 않은 상황에도 유연하게 대응할 수 있는 meta learning 접근법 모바일 최적화 모바일 환경에서 짧은 응답 시간(latency)을 유지하면서도 높은 성능을 달성할 수 있도록, 모델을 경량화하고 최적화하는 방법 대규모 모델 활용 대규모 언어 모델(large language models)이나 멀티모달 모델(multimodal models)을 활용해 새로운 기능을 개발 특정 기능을 위해 효과적으로 모델 성능을 끌어올리는 방법 서비스 운영 대규모 모델을 실제 서비스 환경에서 안정적으로 운영하기 위한 모델링, 최적화 및 경량화 기법 편향 해결 서비스, 시스템, 모델에 의해 발생하는 다양한 데이터 편향을 해결하기 위한 방법 Requirements 필수 요구사항 AI/ML에 대한 기본 지식과 적어도 한 개 이상의 특정 도메인에 대한 깊이 있는 지식을 갖추고, 관련 프로젝트 경험이 있으신 분 Exploratory Data Analysis(EDA)를 통해, 데이터의 통계적 특성과 패턴을 발견하고 이를 ML 모델에 반영하실 수 있는 분 공개된 벤치마크 데이터 셋을 이용해 모델의 테스트 성능을 올리기 위해 여러 가지 모델링을 해본 경험이 있으신 분 구현체가 공개되지 않은 논문을 읽고, 빠르고 정확하게 구현할 수 있는 구현 역량을 갖추신 분 Tensorflow, PyTorch, JAX 등 오픈소스 프레임워크 및 전반적인 파이썬 개발에 능숙하신 분 ML 모델 학습 및 서비스 배포에 필요한 엔지니어링 역량을 갖추신 분 AI 기술의 서비스화에 관심이 많으신 분 학위/국적 무관, 영어로 기초적인 의사소통이 가능하고, 한국어로 원활한 의사소통이 가능한 분 Preferred Qualifications 우대사항 AI/ML 도메인 전반에 대한 이해를 갖추신 분 ML 관련 탑티어 학회 및 저널(NeurIPS, ICLR, ICML, CVPR, ICCV/ECCV, KDD, …) 게재 실적 혹은 AI 관련 대회 수상 실적이 있으신 분 ML 관련 오픈 소스 개발에 참여해 본 경험이 있으신 분 ML 워크플로우의 자동화 경험이 있으신 분(예: AutoML, hyperparameter optimization, 데이터 및 학습 파이프라인 구성 등) 클라이언트(Android, iOS), 백엔드를 포함해 AI/ML 분야 외 프로젝트 개발 경험이 있으신 분 실제 서비스에 AI 기술을 통합하고 주요 지표를 유의미하게 향상시켜 본 경험이 있으신 분 A/B 테스트 실험 기획 및 타겟 KPI 지표를 정의하고, SQL기반 데이터 분석을 진행한 경험이 있으신 분 영어로 비즈니스 의사소통이 가능하신 분 Hiring Process 채용 정보 고용 형태: 정규직 지원 서류: 자유 양식의 상세 경력기반 영문이력서(PDF) 채용 절차 서류전형 코딩테스트, 과제전형 1차 면접 Recruiter Call 2차 면접 최종합격 필요 시 전형이 변경 진행될 수 있습니다. 서류 전형의 경우 합격자에 한하여 개별 안내드릴 예정입니다. 특별 안내사항 이 포지션은 전문연구요원 현역 편입/전직, 전문연구요원 보충역 편입/전직 채용이 가능합니다. 병역특례요원의 경우, 병역특례 관련법에 따라 복무관리를 진행합니다. 주의사항 제출해 주신 내용 중 허위 사실이 있거나 관련법 상 근로제공에 결격사유가 있는 경우 채용이 취소될 수 있으며, 필요시 사전에 안내된 채용 절차 외에도 추가 전형 및 서류 확인이 진행될 수 있습니다. 국가보훈대상자는 관계 법령에 따라 우대하오니, 해당되시는 분께서는 지원 시 고지해주시고 채용 시 증빙서류를 제출해주시기 바랍니다. 하이퍼커넥트가 채용하는 포지션에 지원하는 경우, 개인정보 처리에 관하여서는 본 개인정보처리방침이 적용됩니다: https://career.hyperconnect.com/privacy"
  },
  {
    "id": "Self_Development/Career/Job Transition/25-08-04-토스ML엔지니어-간편지원",
    "title": "Toss - ML Engineer 간편지원",
    "date": "2025-08-04",
    "excerpt": "Toss ML Engineer 간편지원 적어보기",
    "category": "Career",
    "tags": [
      "토스 채용공고"
    ],
    "content": "https://toss.im/builder/to/59b74ab2bee94d93b41025c8bd7afb49?utm_source=linkedin&utm_medium=display&utm_campaign=2507_ML 🤖 ML 엔지니어의 다음 커리어, 부담 없이 시작하세요 ML 엔지니어로 3년 이상의 경력을 가지고 있다면, 이력서 없이 가볍게 지원해 보세요. 본 간편지원 이벤트는 지원 이력에 남지 않아요. 3개의 질문을 통해 여러분의 경험과 잘 맞는 포지션을 찾아드릴게요. 기술적인 고민을 즐기고, 문제를 풀어온 경험이 있다면 충분해요. 📆 지원 마감 ~8/6(수) 오후 12시까지 결과는 마감일 이후 순차적으로 안내해 드려요. 🗺️ 진행 절차 간편 지원 → 합격할 경우 채용팀의 포지션 제안 → 직무 인터뷰 경력과 방향에 맞는 포지션을 함께 검토해 드려요. 🔎 토스의 ML 포지션이 궁금하다면, 다음 링크를 통해 자세히 살펴보실 수 있어요. JD 바로 가기 *문의: 토스 채용팀 (recruit@toss.im) Q1. 토스에 지원하는 이유를 알려주세요. Q2. 본인이 가장 깊이 관여했던 프로젝트는 무엇인가요? 해당 프로젝트에서 다뤘던 문제와 도메인을 간단히 소개해주세요. Q3. 해당 프로젝트에서 본인이 정의한 문제와 선택한 접근 방식에 대해 구체적으로 설명해주세요. 프로젝트 결과가 조직이나 서비스에 어떤 영향을 주었나요? 가능하다면 정량적 성과(AUC, CVR, latency 등)로 작성해주세요. (e.g. 어떤 데이터를 어떻게 활용했는지, 어떤 모델이나 기법을 적용했는지 등) 한 번 제출한 내용은 수정할 수 없으니, 제출 전 마지막으로 확인해 주세요."
  },
  {
    "id": "Self_Development/Career/Job Transition/25-08-04-지마켓-데이터과학자",
    "title": "Gmarket 데이터 사이언티스트 (Data Scientist)",
    "date": "2025-08-04",
    "excerpt": "Gmarket 데이터 사이언티스트 (Data Scientist) 적어보기",
    "category": "Career",
    "tags": [
      "지마켓 채용공고"
    ],
    "content": "팀 소개 Foundation AI팀은 지마켓의 핵심 자산인 데이터를 기반으로, e-commerce 비즈니스의 다양한 문제를 AI 기술로 해결하는 모델 및 시스템을 개발합니다. 범용 모델이 아닌, 실제 커머스 데이터 기반의 자체 학습 Foundation 모델을 구축하고 있으며, 이를 다양한 비즈니스 과제에 적용하고 있습니다. 특히, 고객 행동 이력 데이터를 활용한 개인화 타겟팅 및 CRM 쿠폰 최적화 모델링을 통해 고객 경험을 향상시키고, 데이터 기반의 마케팅 전략 고도화에 기여하고 있습니다. 주요 업무 ■ CRM 쿠폰 타겟팅 최적화를 위한 개인화 모델 개발 고객 상황과 문맥 기반의 관심 상품 예측 및 세분화(Contextual Segmentation) 쿠폰/마케팅 캠페인 효율 분석 및 CRM 성과 최적화를 위한 분석 모델 설계 ■ 이커머스 도메인 내 데이터 융합 분석 및 AI 모델링 다양한 서비스에서 발생하는 대규모 데이터를 통합·분석하여 핵심 인사이트 도출 비즈니스 성과 개선을 위한 AI/ML 기반 모델 개발 및 운영 자격 요건 데이터 사이언티스트 또는 유사 직무 경력 3년 이상 9년 이하 PyTorch, TensorFlow 등 주요 ML 프레임워크 사용 경험이 있는 분 Python 등 데이터 분석 및 ML 모델링 관련 언어에 능숙하신 분 NoSQL / SQL 기반 데이터 처리 및 분석 역량 보유한 분 머신러닝/딥러닝 적용을 위한 기본적인 통계 및 알고리즘을 이해하는 분 (우대) E-commerce 또는 유사 플랫폼 도메인에서 데이터 분석 및 ML 모델링 실무 경험이 있는 분 (우대) Spark, Hive 등 분산 컴퓨팅 환경에서의 대용량 데이터 처리 경험이 있는 분 (우대) 데이터 분석 관련 분야 석사 학위 이상을 소지하신 분 공통 요건 해외여행 결격 사유가 없는 분 남성의 경우, 병역필 또는 면제자 국가보훈 대상자와 장애인은 관련 법에 따라 우대합니다 국가유공자 가산점 부여받기 위해 \"취업 지원 대상자 증명서\" 회사에 제출 필요 지원 방법 및 전형 절차 모집기간: 2025년 08월 4일 23시 59분 까지 지마켓 채용홈페이지 (https://careers.gmarket.com) 통해 지원 전형 절차: 서류전형 > 1차 면접(코딩테스트 포함) > 2차 면접 > 최종 합격 면접전형의 세부절차 및 진행방식은 상황에 따라 변동될 수 있습니다. 자세한 내용은 합격 시 개별 안내 예정입니다. 본 채용은 수시 모집으로 적합한 분이 있으실 경우 조기 마감될 수 있습니다. 최종 제출 후에는 지원서 수정이 불가하오니 이 점 유의하여 주시기 바랍니다. 기타사항 기본정보(성명, 전화번호, 이메일, 이력서, 유관 경력 기간)는 필수 제출 필요, 이외 정보는 선택하시어 작성 부탁드립니다. 시스템상 반복되는 오류가 있으실 경우, 크롬으로 접속 부탁드립니다. 지원서 내용이 사실과 다르거나, 허위 서류를 제출하신 경우 채용이 취소될 수 있습니다. 기타 문의 사항은 FAQ 참조 또는 지원 후 안내해 드리는 메일, 카카오톡 내 '문의하기' 이용 부탁드립니다."
  },
  {
    "id": "Data Science/what-is-meta-learning",
    "title": "meta-learning이란?",
    "date": "2025-08-04",
    "excerpt": "meta-learning의 개념과 활용되는 사례에 대한 정리",
    "category": "Data Science",
    "tags": [
      "meta-learning",
      "machine-learning",
      "statistics"
    ],
    "content": "참고자료 Bot Penguin - Meta Learning 논문세미나 007 - Meta-Learning의 개념 및 연구 분야 (김도형 연구원) meta-learning이란? 개념적 정의 --- “배우는 방법을 배우는 것” (learning to learn) > meta-learning (메타 러닝)은 기계학습에서 점점 더 중요한 개념이 되고 있으며, 특히 few-shot learning, online adaptation, 개인화 모델링 등에서 매우 강력한 도구입니다. > Meta-learning, also known as \"learning how to learn,\" is a cutting-edge approach in machine learning that focuses on algorithms that learn from their experiences and adapt to new data more effectively 개념만으로는 크게 와닿진 않네. <figure> <img src=\"/post/DataScience/meta_learning_concept_1.webp\" alt=\"Meta-learning 개념도\" /> <figcaption>그림 1. Meta-learning의 기본 개념</figcaption> </figure> > Meta-learning enhances traditional machine learning methods by adding a meta-layer to optimize learning algorithms. 과거의 학습 경험 (데이터나 파라미터)를 바탕으로 새로운 문제에 대해서 빠르게 학습해나가는 방법 <figure> <img src=\"/post/DataScience/A-taxonomy-of-meta-learning-Meta-learning-strategies-are-divided-into-two-main.png\" alt=\"Meta-learning strategies\" /> <figcaption>그림 2. Meta-learning strategies</figcaption> </figure> 기본 아이디어 : 일반적인 머신러닝에서는 하나의 작업(task)에 대해 모델을 학습합니다. 하지만 메타 러닝은 여러 개의 작업들을 보고, 새로운 작업에 빠르게 적응할 수 있는 학습 전략을 학습하는 것이 목표입니다. 일반 머신러닝: 학습: 하나의 데이터셋에서 파라미터를 최적화 테스트: 같은 도메인의 unseen 데이터에 적용 메타 러닝: 학습: 여러 task를 보면서, 모델이 \"어떻게 빠르게 적응할 수 있을지\"를 학습 테스트: 새로운 task에 소수의 샘플(few-shot)만으로 빠르게 적응 Meta-Classifiers and Regressors > Meta-classifiers play a central role in ensemble machine learning techniques. They act as a higher-level classifier that takes the predictions of multiple base-level classifiers to generate a final prediction. 여러 값을 하나로 합치는 역할을 하는 모델. stacking 방법에서 맨 마지막에 쓰이는 모델, 모델의 예측값을 바탕으로 예측값을 생성하는 모델. random-forest도 어떻게 보면 meta-classifier구나. decision-tree 예측값을 voting해서 결과내는 방식이니까."
  },
  {
    "id": "Data Science/github-notebook-preview",
    "title": "GitHub에서 Jupyter Notebook 리뷰하기 - ReviewNB",
    "date": "2025-08-04",
    "excerpt": "GitHub에서 Jupyter Notebook 코드 리뷰를 쉽게 할 수 있는 ReviewNB 도구 소개",
    "category": "Data Science",
    "tags": [
      "github",
      "jupyter-notebook",
      "code-review",
      "tools"
    ],
    "content": "GitHub에서 Jupyter Notebook 리뷰하기 문제 상황 주피터 노트북을 GitHub에서 관리할 때 겪는 어려움: 기존 방식의 한계 JSON diff: 노트북 파일이 JSON 형태로 표시되어 가독성 떨어짐 리뷰 어려움: 실제 코드와 결과를 확인하기 어려움 검증 복잡: 로컬 환경이나 Colab에 포팅해서 validation 필요 실제 문제점 ``json { \"cells\": [ { \"cell_type\": \"code\", \"execution_count\": 1, \"metadata\": {}, \"outputs\": [], \"source\": [ \"import pandas as pd\\n\", \"df = pd.read_csv('data.csv')\" ] } ] } ` 이런 식으로 JSON이 보이면 실제 코드를 이해하기 어려움! 해결책: ReviewNB What is ReviewNB? > \"Say Goodbye to messy JSON diffs!\" ReviewNB는 GitHub에서 Jupyter Notebook 코드 리뷰를 실제 노트북이 렌더링된 상태에서 직관적으로 할 수 있도록 도와주는 도구입니다. 주요 특징 직관적인 리뷰 ✅ 실제 노트북 형태로 렌더링 ✅ 코드와 결과를 함께 확인 ✅ 셀 단위로 리뷰 가능 무료 사용 ✅ Public 저장소: 무제한 무료 사용 ✅ Private 저장소: 제한적 무료 사용 편리한 기능 ✅ Side-by-side diff 확인 ✅ 과거 PR 검토 가능 ✅ 실시간 코멘트 작성 설치 및 사용법 설치 과정 ReviewNB 웹사이트 방문: https://www.reviewnb.com/ \"Install GitHub App\" 버튼 클릭 GitHub 마켓플레이스에서 Free 버전 설치 저장소 권한 설정 사용 방법 PR 리뷰하기 ` GitHub PR 페이지 방문 ReviewNB 탭 확인 노트북 파일 선택 렌더링된 상태에서 리뷰 ` 코멘트 작성 셀 단위로 코멘트 추가 가능 코드 라인별 코멘트 작성 마크다운 지원 실제 사용 예시 Before (기존 방식) ` JSON diff만 보임 실제 코드 내용 파악 어려움 결과 확인 불가능 ` After (ReviewNB 사용) ` 실제 노트북 형태로 표시 코드와 결과를 함께 확인 직관적인 리뷰 가능 `` 장점과 활용 사례 장점 가독성 향상: JSON 대신 실제 노트북 형태 효율성 증대: 별도 환경 구축 불필요 협업 개선: 팀 리뷰 프로세스 간소화 품질 향상: 더 정확한 코드 검토 활용 사례 데이터 사이언스 프로젝트 머신러닝 모델 코드 리뷰 데이터 전처리 과정 검토 시각화 결과 확인 교육 및 튜토리얼 노트북 튜토리얼 리뷰 교육 자료 품질 관리 학습 자료 검증 연구 프로젝트 연구 노트북 공유 실험 결과 검토 재현성 확인 대안 도구들 nbviewer GitHub 노트북 렌더링 단순 뷰어 기능 Binder 인터랙티브 노트북 실행 환경 설정 복잡 Google Colab 클라우드 기반 실행 GitHub 연동 제한 결론 ReviewNB는 GitHub에서 Jupyter Notebook을 관리하는 팀에게 필수적인 도구입니다. 핵심 가치 간편함: 설치 후 즉시 사용 효율성: JSON diff 문제 해결 무료: Public 저장소 무제한 사용 직관성: 실제 노트북 형태로 리뷰 추천 대상 데이터 사이언스 팀 머신러닝 프로젝트 관리자 교육 기관 연구 프로젝트 팀 링크: https://www.reviewnb.com/ --- 이 도구를 사용하면 GitHub에서 Jupyter Notebook 리뷰가 훨씬 효율적이고 직관적이 됩니다!"
  },
  {
    "id": "Data Science/Causal Inference/residualization-fwl-theorem-test",
    "title": "FWL에 기반한 잔차화 방법론 구현 노트북",
    "date": "2025-07-10T00:00:00.000Z",
    "excerpt": "잔차화를 하기 위해 nusiance function을 만들고 결과를 분석하는 노트북",
    "category": "Causal Inference",
    "tags": [
      "residualization",
      "FWL"
    ],
    "content": "--- title: \"FWL에 기반한 잔차화 방법론 구현 노트북\" date: 2025-07-10 category: \"Causal Inference\" tags: [\"residualization\", \"FWL\"] excerpt: \"잔차화를 하기 위해 nusiance function을 만들고 결과를 분석하는 노트북\" --- # Load Data # from src.dataloader.vault.main import VaultDatasetLoader from src.dataloader.vault.utils import split_df_od_os from src.utils.db import SOFTCRM_DBINFO, get_conn import warnings import pandas as pd import numpy as np warnings.filterwarnings(\"ignore\") # pandas display 옵션 설정 - 모든 열 보이기 pd.set_option('display.max_columns', None) pd.set_option('display.width', None) pd.set_option('display.max_colwidth', None) loader = VaultDatasetLoader() feature_df, y_df = loader.run(start_date=\"2022-01-01\", end_date=\"2024-12-31\", piol_data_path=\"./data/PIOL렌즈주문서.xlsx\", refresh=False, db=\"crm_emr\") # y_df의 oper_date와 feature_df의 date를 기준으로 병합 merged_df = pd.merge(y_df, feature_df, left_on=['cust_num', 'oper_date'], right_on=['cust_num', 'date'], how='left') merged_df = split_df_od_os(merged_df) query = \"\"\"SELECT CUST_NUM, BIRTH_DAY FROM VIEW_CUSTOM_JUMIN\"\"\" with get_conn(SOFTCRM_DBINFO) as conn, conn.cursor() as cursor: cursor.execute(query) result = cursor.fetchall() age_df = pd.DataFrame([list(res) for res in result], columns=[\"cust_num\", \"birthday\"]) age_df = age_df.applymap(lambda x: np.nan if isinstance(x, str) and x.strip() == \"\" else x) age_df[\"birthday\"] = pd.to_datetime(age_df[\"birthday\"], errors=\"coerce\", format=\"%Y-%m-%d\") age_df = age_df.dropna().reset_index(drop=True) age_df[\"cust_num\"] = age_df[\"cust_num\"].apply(lambda x: x.strip()) cust_age_dict = dict(zip(age_df[\"cust_num\"], age_df[\"birthday\"])) merged_df['birthday'] = merged_df['cust_num'].map(cust_age_dict) merged_df['age'] = merged_df.apply(lambda row: pd.to_datetime(row['oper_date']).year - row['birthday'].year if pd.notnull(row['birthday']) else np.nan, axis=1) # merged_df.to_csv(\"./merged_df_2022_01_01_2024_12_31_with_age.csv\", index=False) # Modules from src.preprocessing.constants import ALL_RANGES_NO_SIDE import pandas as pd import numpy as np def load_data() -> tuple[pd.DataFrame, list, list, list]: \"\"\" 데이터를 로드하고 전처리하여 분석에 필요한 형태로 반환합니다. Returns: tuple[pd.DataFrame, list, list, list]: df_clean (pd.DataFrame): 전처리된 데이터프레임 features (list): 특성 변수명 리스트 [\"Cas_ata\", \"Cas_acd_endo\", \"Cas_clr\", \"age\"] treatment (list): 처치 변수명 리스트 [\"size\"] y (list): 결과 변수명 리스트 [\"meas_vault\"] Note: NaN 값이 있는 행은 제거됩니다 size가 [12.1, 12.6, 13.2]가 아닌 경우는 제거됩니다 \"\"\" df = pd.read_csv(\"./data/merged_df_2022_01_01_2024_12_31_with_age.csv\") df.head() features = [\"Cas_ata\", \"Cas_acd_endo\", \"Cas_clr\", \"age\"] treatment = [\"size\"] y = [\"meas_vault\"] # df 중 features, treatment, y 컬럼만 남기고 칼럼 제거, 이 칼럼들에 대한 값이 NaN인 것도 제거 selected_columns = features + treatment + y df_clean = df[selected_columns].copy() # df['size']가 [12.1, 12.6, 13.2] 이 아닌 경우 제거 df_clean = df_clean[df_clean[\"size\"].isin([12.1, 12.6, 13.2])].reset_index(drop=True) # 이상치 제거 로직 # 모든 컬럼에 대해 범위 적용 for column, range_obj in ALL_RANGES_NO_SIDE.items(): if column in df_clean.columns: # 컬럼 값이 범위를 벗어나면 np.nan으로 변경 df_clean[column] = df_clean[column].where((df_clean[column] >= range_obj.min) & (df_clean[column] <= range_obj.max), np.nan) # Cas_cct로 vault 범위 만들고, 넘어가면 없애주기 max_vault = ALL_RANGES_NO_SIDE[\"Cas_cct\"].max 1.5 df_clean = df_clean[df_clean[\"meas_vault\"] <= max_vault].reset_index(drop=True) # NaN 값이 있는 행 제거 df_clean = df_clean.dropna() # 나이가 60이상 제거 df_clean = df_clean[df_clean[\"age\"] < 60].reset_index(drop=True) df_clean[y] = df_clean[y].abs() return df_clean, features, treatment, y # 잔차화 진행하기 > R-learner는 FWL theorem에 이론적 배경을 두고 있습니다. FWL 정리는 다중 회귀분석에서 특정 변수의 계수를 구하는 두 가지 방법이 동일한 결과를 준다는 것을 보여줍니다: 직접 회귀: 모든 변수를 포함한 전체 회귀모형 잔차화 후 회귀: 관심 변수와 종속변수를 다른 변수들에 대해 각각 회귀하여 잔차를 구한 후, 이 잔차들 간의 회귀 수학적 표현: 모형: Y = Xβ + Zγ + ε에서 β를 구하고 싶다면: 방법 1: 전체 회귀 `` β̂ = (X'M_Z X)^(-1) X'M_Z Y ` 방법 2: 잔차화 ` X̃ = M_Z X (X를 Z에 회귀한 잔차) Ỹ = M_Z Y (Y를 Z에 회귀한 잔차) β̂ = (X̃'X̃)^(-1) X̃'Ỹ ` 여기서 M_Z = I - Z(Z'Z)^(-1)Z'는 Z에 수직인 투영행렬입니다. 잔차화가 가능해지는 이유: 직교성: 잔차화는 다른 변수들의 영향을 제거하여 순수한 효과만 분리 차원 축소: 복잡한 다변량 문제를 단순한 이변량 문제로 변환 해석 용이성: 다른 변수들을 통제한 후의 순수한 관계 파악 > R-learner는 다음과 같은 두 단계로 구현됩니다: Propensity Score: Treatment를 Features로 예측 Outcome Function: Outcome을 Features로 예측 Step 1: Propensity Score (Treatment 잔차화): `python X → T 회귀 (Treatment를 Features로 예측) model = LogisticRegression() model.fit(X_train, y_train) propensity_scores = model.predict_proba(X_val) ` Step 2: Outcome Function (Y 잔차화): `python X → Y 회귀 (Outcome을 Features로 예측) Y_residual = Y - E[Y X] T_residual = T - E[T X] (propensity score 활용) ` 왜 잔차화가 \"가능\"해지는가? : A. 조건부 독립성 확보 ` E[T_residual X] = 0 E[Y_residual X] = 0 ` X의 영향을 제거함으로써 순수한 T→Y 효과만 분리 B. 편향 제거 (Bias Elimination) Selection bias: 관측되지 않은 교란변수의 영향 Confounding: X가 T와 Y 모두에 영향을 주는 문제 C. 과적합 방지 `python Cross-fitting 사용 kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED) ` Out-of-sample 예측으로 과적합 방지 실제 인과효과 추정 최종적으로는 다음과 같은 회귀를 수행: ` Y_residual = τ × T_residual + noise ` 여기서 τ`가 순수한 treatment effect입니다. 결론: FWL 정리에서 잔차화가 가능해지는 이유는: 수학적: 직교 투영의 성질로 인한 계수 불변성 통계적: 교란변수 통제를 통한 편향 제거 실용적: 복잡한 다변량 문제를 단순한 이변량 문제로 변환 > R-learner 구현은 이 이론적 기반을 인과추론에 실제 적용한 사례로, 특히 이질적 처치효과(Heterogeneous Treatment Effects) 추정에 활용되고 있습니다. # 1. propensity score function > P(T X) X일 때 T일 확률을 구해서, 이를 통해 잔차화 진행 propensity score를 통제하는 것과 T를 통제하는 것은 같은 의미이기 때문에 df, features, treatment, y = load_data() df[treatment] = df[treatment].astype(\"category\") (treatment,) = treatment print(treatment) df.head() 중요한점! > 과적합을 피하기 위해 cross-fitting (또는 sample splitting)을 사용해서 out-of-sample 예측값을 활용 import numpy as np import pandas as pd from sklearn.model_selection import StratifiedKFold from sklearn.linear_model import LogisticRegression from sklearn.metrics import accuracy_score, roc_auc_score from sklearn.preprocessing import StandardScaler RANDOM_SEED = 42 np.random.seed(RANDOM_SEED) 카테고리형 treatment를 숫자로 변환 X_features = df[features] y_treatment_cat = df[treatment].cat.codes # 카테고리를 숫자로 변환 print(f\"Treatment 카테고리: {df[treatment].cat.categories}\") print(f\"Treatment 분포:\\n{df[treatment].value_counts()}\") print(f\"숫자 변환된 분포:\\n{pd.Series(y_treatment_cat).value_counts()}\") 각 클래스별 propensity score 저장용 배열 class_categories = df[treatment].cat.categories n_classes = len(class_categories) propensity_scores_all = np.zeros((len(df), n_classes)) StratifiedKFold로 카테고리 비율 맞춤 kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED) fold_performances = [] for fold, (train_idx, val_idx) in enumerate(kf.split(X_features, y_treatment_cat)): print(f\"\\n=== Fold {fold + 1} ===\") X_train, X_val = X_features.iloc[train_idx], X_features.iloc[val_idx] y_train, y_val = y_treatment_cat[train_idx], y_treatment_cat[val_idx] # 각 fold의 treatment 분포 확인 print(f\"Train 분포: {pd.Series(y_train).value_counts().to_dict()}\") print(f\"Val 분포: {pd.Series(y_val).value_counts().to_dict()}\") # 데이터 스케일링 (수렴 성능 향상) scaler = StandardScaler() X_train_scaled = scaler.fit_transform(X_train) X_val_scaled = scaler.transform(X_val) # 모델 훈련 (수렴 문제 해결을 위한 설정) model = LogisticRegression( random_state=42, max_iter=1000, # 반복 횟수 증가 (기본값: 100) solver=\"liblinear\", # 다중 클래스 분류에 적합한 솔버 ) model.fit(X_train_scaled, y_train) # 훈련 성능 확인 train_pred = model.predict(X_train_scaled) train_accuracy = accuracy_score(y_train, train_pred) # 검증 데이터에 대한 모든 클래스별 propensity score 계산 val_propensity = model.predict_proba(X_val_scaled) propensity_scores_all[val_idx] = val_propensity # 모든 클래스 확률 저장 # 검증 성능 확인 val_pred = model.predict(X_val_scaled) val_accuracy = accuracy_score(y_val, val_pred) fold_performances.append( {\"fold\": fold + 1, \"train_accuracy\": train_accuracy, \"val_accuracy\": val_accuracy, \"train_size\": len(X_train), \"val_size\": len(X_val)} ) print(f\"훈련 정확도: {train_accuracy:.3f}\") print(f\"검증 정확도: {val_accuracy:.3f}\") 원본 df에 각 클래스별 propensity_score 컬럼 추가 for i, category in enumerate(class_categories): df[f\"propensity_score_{category}\"] = propensity_scores_all[:, i] print(f\"\\n=== 전체 결과 ===\") performance_df = pd.DataFrame(fold_performances) print(f\"평균 훈련 정확도: {performance_df['train_accuracy'].mean():.3f} ± {performance_df['train_accuracy'].std():.3f}\") print(f\"평균 검증 정확도: {performance_df['val_accuracy'].mean():.3f} ± {performance_df['val_accuracy'].std():.3f}\") print(f\"\\n처음 10개 샘플:\") propensity_cols = [f\"propensity_score_{cat}\" for cat in class_categories] print(df[[\"meas_vault\", treatment] + propensity_cols].head(10)) print(f\"\\n생성된 propensity score 컬럼들:\") for col in propensity_cols: print(f\"{col}: 평균 {df[col].mean():.3f}\") df # 2. Outcome function >m(Y X) 이를 통해 Y에서 X의 영향을 제거한 잔차를 구할 수 있음. df, features, treatment, y = load_data() df[treatment] = df[treatment].astype(\"category\") (treatment,) = treatment print(treatment) df.head() 중요한점! > 과적합을 피하기 위해 cross-fitting (또는 sample splitting)을 사용해서 out-of-sample 예측값을 활용 import numpy as np import pandas as pd import lightgbm as lgb from sklearn.model_selection import KFold from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error import matplotlib.pyplot as plt 한글 폰트 설정 (맥 환경) import matplotlib.font_manager as fm plt.rcParams[\"font.family\"] = \"AppleGothic\" # 맥용 한글 폰트 plt.rcParams[\"axes.unicode_minus\"] = False # 마이너스 기호 깨짐 방지 RANDOM_SEED = 42 np.random.seed(RANDOM_SEED) Outcome function (features로 y 예측) print(\"=== Outcome Function 학습 (features → y) ===\") X_features = df[features] y_outcome = df[y[0]] # y는 리스트이므로 첫 번째 요소 추출 print(f\"Features: {features}\") print(f\"Target: {y[0]}\") print(f\"데이터 크기: X={X_features.shape}, y={y_outcome.shape}\") print(f\"Target 통계:\") print(f\" 평균: {y_outcome.mean():.2f}\") print(f\" 표준편차: {y_outcome.std():.2f}\") print(f\" 범위: [{y_outcome.min():.2f}, {y_outcome.max():.2f}]\") Out-of-sample 예측값 저장용 배열 outcome_predictions = np.zeros(len(df)) KFold로 분할 (회귀 문제이므로 StratifiedKFold 대신 KFold 사용) kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED) fold_performances = [] LightGBM 파라미터 설정 (과적합 방지에 중점) lgb_params = { \"objective\": \"regression\", \"metric\": \"rmse\", \"boosting_type\": \"gbdt\", \"num_leaves\": 15, # 작게 설정하여 과적합 방지 \"learning_rate\": 0.1, \"feature_fraction\": 0.8, \"bagging_fraction\": 0.8, \"bagging_freq\": 5, \"lambda_l1\": 0.1, # L1 정규화 \"lambda_l2\": 0.1, # L2 정규화 \"min_data_in_leaf\": 20, \"min_split_gain\": 0.1, \"max_depth\": 6, \"verbose\": -1, \"random_state\": RANDOM_SEED, } for fold, (train_idx, val_idx) in enumerate(kf.split(X_features, y_outcome)): print(f\"\\n=== Fold {fold + 1} ===\") X_train, X_val = X_features.iloc[train_idx], X_features.iloc[val_idx] y_train, y_val = y_outcome.iloc[train_idx], y_outcome.iloc[val_idx] print(f\"Train 크기: {len(X_train)}, Val 크기: {len(X_val)}\") print(f\"Train target 평균: {y_train.mean():.2f}, Val target 평균: {y_val.mean():.2f}\") # LightGBM 데이터셋 생성 train_data = lgb.Dataset(X_train, label=y_train) val_data = lgb.Dataset(X_val, label=y_val, reference=train_data) # 모델 훈련 model = lgb.train( lgb_params, train_data, valid_sets=[train_data, val_data], valid_names=[\"train\", \"eval\"], num_boost_round=500, callbacks=[ lgb.early_stopping(stopping_rounds=50), lgb.log_evaluation(period=0), # 로그 출력 비활성화 ], ) # 예측 train_pred = model.predict(X_train, num_iteration=model.best_iteration) val_pred = model.predict(X_val, num_iteration=model.best_iteration) # Out-of-sample 예측값 저장 outcome_predictions[val_idx] = val_pred # 성능 계산 train_rmse = np.sqrt(mean_squared_error(y_train, train_pred)) val_rmse = np.sqrt(mean_squared_error(y_val, val_pred)) train_r2 = r2_score(y_train, train_pred) val_r2 = r2_score(y_val, val_pred) train_mae = mean_absolute_error(y_train, train_pred) val_mae = mean_absolute_error(y_val, val_pred) fold_performances.append( { \"fold\": fold + 1, \"train_rmse\": train_rmse, \"val_rmse\": val_rmse, \"train_r2\": train_r2, \"val_r2\": val_r2, \"train_mae\": train_mae, \"val_mae\": val_mae, \"best_iteration\": model.best_iteration, \"train_size\": len(X_train), \"val_size\": len(X_val), } ) print(f\"훈련 RMSE: {train_rmse:.3f}, 검증 RMSE: {val_rmse:.3f}\") print(f\"훈련 R²: {train_r2:.3f}, 검증 R²: {val_r2:.3f}\") print(f\"훈련 MAE: {train_mae:.3f}, 검증 MAE: {val_mae:.3f}\") print(f\"최적 반복횟수: {model.best_iteration}\") 원본 df에 outcome 예측값 추가 df[\"outcome_prediction\"] = outcome_predictions print(f\"\\n=== 전체 Outcome Function 결과 ===\") performance_df = pd.DataFrame(fold_performances) print(f\"평균 훈련 RMSE: {performance_df['train_rmse'].mean():.3f} ± {performance_df['train_rmse'].std():.3f}\") print(f\"평균 검증 RMSE: {performance_df['val_rmse'].mean():.3f} ± {performance_df['val_rmse'].std():.3f}\") print(f\"평균 훈련 R²: {performance_df['train_r2'].mean():.3f} ± {performance_df['train_r2'].std():.3f}\") print(f\"평균 검증 R²: {performance_df['val_r2'].mean():.3f} ± {performance_df['val_r2'].std():.3f}\") print(f\"평균 훈련 MAE: {performance_df['train_mae'].mean():.3f} ± {performance_df['train_mae'].std():.3f}\") print(f\"평균 검증 MAE: {performance_df['val_mae'].mean():.3f} ± {performance_df['val_mae'].std():.3f}\") 과적합 체크 overfitting_score = performance_df[\"train_r2\"].mean() - performance_df[\"val_r2\"].mean() print(f\"\\n과적합 지표 (Train R² - Val R²): {overfitting_score:.3f}\") if overfitting_score > 0.1: print(\"⚠️ 심각한 과적합이 감지되었습니다. 정규화를 강화하세요.\") elif overfitting_score > 0.05: print(\"⚠️ 약간의 과적합이 있습니다.\") else: print(\"✅ 과적합이 잘 제어되고 있습니다.\") print(f\"\\n처음 10개 샘플의 실제값 vs 예측값:\") comparison_df = df[[y[0], \"outcome_prediction\"]].head(10) comparison_df[\"residual\"] = comparison_df[y[0]] - comparison_df[\"outcome_prediction\"] print(comparison_df) print(f\"\\nOutcome 예측값 통계:\") print(f\" 평균: {df['outcome_prediction'].mean():.2f}\") print(f\" 표준편차: {df['outcome_prediction'].std():.2f}\") print(f\" 범위: [{df['outcome_prediction'].min():.2f}, {df['outcome_prediction'].max():.2f}]\") 잔차 계산 (R-learner의 다음 단계를 위해) df[\"outcome_residual\"] = df[y[0]] - df[\"outcome_prediction\"] print(f\"\\nOutcome 잔차 통계:\") print(f\" 평균: {df['outcome_residual'].mean():.2f} (0에 가까워야 함)\") print(f\" 표준편차: {df['outcome_residual'].std():.2f}\") 시각화 plt.figure(figsize=(12, 4)) 실제값 vs 예측값 plt.subplot(1, 3, 1) plt.scatter(df[y[0]], df[\"outcome_prediction\"], alpha=0.6, s=10) plt.plot([df[y[0]].min(), df[y[0]].max()], [df[y[0]].min(), df[y[0]].max()], \"r--\", lw=2) plt.xlabel(\"실제값\") plt.ylabel(\"예측값\") plt.title(\"실제값 vs 예측값\") 잔차 분포 plt.subplot(1, 3, 2) plt.hist(df[\"outcome_residual\"], bins=30, alpha=0.7, edgecolor=\"black\") plt.xlabel(\"잔차\") plt.ylabel(\"빈도\") plt.title(\"잔차 분포\") plt.axvline(0, color=\"red\", linestyle=\"--\", alpha=0.7) Fold별 성능 plt.subplot(1, 3, 3) plt.plot(performance_df[\"fold\"], performance_df[\"train_r2\"], \"o-\", label=\"Train R²\", alpha=0.7) plt.plot(performance_df[\"fold\"], performance_df[\"val_r2\"], \"s-\", label=\"Val R²\", alpha=0.7) plt.xlabel(\"Fold\") plt.ylabel(\"R² Score\") plt.title(\"Fold별 성능\") plt.legend() plt.grid(True, alpha=0.3) plt.tight_layout() plt.show() 성능 요약 테이블 print(f\"\\n=== Fold별 성능 요약 ===\") print(performance_df[[\"fold\", \"train_rmse\", \"val_rmse\", \"train_r2\", \"val_r2\", \"best_iteration\"]].round(3)) df.iloc[[4799, 4800]] import matplotlib.pyplot as plt import numpy as np 한글 폰트 설정 plt.rcParams[\"font.family\"] = \"AppleGothic\" plt.rcParams[\"axes.unicode_minus\"] = False Size별 잔차 분포 시각화 fig, axes = plt.subplots(2, 3, figsize=(18, 10)) Size별 히스토그램 (겹치게) plt.subplot(2, 3, 1) for size in sorted(df[\"size\"].unique()): residuals = df[df[\"size\"] == size][\"outcome_residual\"] plt.hist(residuals, bins=30, alpha=0.7, label=f\"Size {size}\", density=True) plt.axvline(0, color=\"red\", linestyle=\"--\", alpha=0.7) plt.xlabel(\"Outcome 잔차\") plt.ylabel(\"밀도\") plt.title(\"Size별 잔차 분포 (히스토그램)\") plt.legend() plt.grid(True, alpha=0.3) Size별 박스플롯 plt.subplot(2, 3, 2) size_groups = [df[df[\"size\"] == size][\"outcome_residual\"] for size in sorted(df[\"size\"].unique())] size_labels = [f\"Size {size}\" for size in sorted(df[\"size\"].unique())] plt.boxplot(size_groups, labels=size_labels) plt.axhline(0, color=\"red\", linestyle=\"--\", alpha=0.7) plt.ylabel(\"Outcome 잔차\") plt.title(\"Size별 잔차 분포 (박스플롯)\") plt.grid(True, alpha=0.3) 바이올린 플롯 plt.subplot(2, 3, 3) parts = plt.violinplot(size_groups, positions=range(1, len(size_groups) + 1)) plt.axhline(0, color=\"red\", linestyle=\"--\", alpha=0.7) plt.xticks(range(1, len(size_labels) + 1), size_labels) plt.ylabel(\"Outcome 잔차\") plt.title(\"Size별 잔차 분포 (바이올린 플롯)\") plt.grid(True, alpha=0.3) 4-6. Size별 개별 히스토그램 for i, size in enumerate(sorted(df[\"size\"].unique())): plt.subplot(2, 3, 4 + i) residuals = df[df[\"size\"] == size][\"outcome_residual\"] plt.hist(residuals, bins=30, alpha=0.7, edgecolor=\"black\") plt.axvline(0, color=\"red\", linestyle=\"--\", alpha=0.7) plt.axvline(residuals.mean(), color=\"blue\", linestyle=\"-\", alpha=0.7, label=f\"평균: {residuals.mean():.1f}\") plt.xlabel(\"Outcome 잔차\") plt.ylabel(\"빈도\") plt.title(f\"Size {size} 잔차 분포 (n={len(residuals)})\") plt.legend() plt.grid(True, alpha=0.3) plt.tight_layout() plt.show() Size별 통계 요약 print(\"=== Size별 잔차 통계 ===\") for size in sorted(df[\"size\"].unique()): residuals = df[df[\"size\"] == size][\"outcome_residual\"] print(f\"\\nSize {size} (n={len(residuals)}):\") print(f\" 평균: {residuals.mean():8.2f}\") print(f\" 표준편차: {residuals.std():8.2f}\") print(f\" 중앙값: {residuals.median():8.2f}\") print(f\" 범위: [{residuals.min():6.1f}, {residuals.max():6.1f}]\") 전체 잔차 통계 print(f\"\\n전체 (n={len(df)}):\") print(f\" 평균: {df['outcome_residual'].mean():8.2f}\") print(f\" 표준편차: {df['outcome_residual'].std():8.2f}\") ANOVA 검정 (size별 잔차 평균 차이 검정) from scipy.stats import f_oneway size_12_1 = df[df[\"size\"] == 12.1][\"outcome_residual\"] size_12_6 = df[df[\"size\"] == 12.6][\"outcome_residual\"] size_13_2 = df[df[\"size\"] == 13.2][\"outcome_residual\"] f_stat, p_value = f_oneway(size_12_1, size_12_6, size_13_2) print(f\"\\n=== ANOVA 검정 (size별 잔차 평균 차이) ===\") print(f\"F-통계량: {f_stat:.4f}\") print(f\"p-value: {p_value:.6f}\") if p_value < 0.05: print(\"❌ Size별로 잔차 평균에 유의한 차이가 있음 (문제)\") else: print(\"✅ Size별 잔차 평균에 유의한 차이 없음 (좋음)\") > 잔차화가 잘 됐는지는 어떻게 판단할 수 있는거지? 주요 평가 기준: 조건부 독립성 (가장 중요) E[잔차 X] ≈ 0 R² < 0.01 이면 우수 R² > 0.05 이면 문제 편향 제거 잔차 평균 ≈ 0 체계적인 과대/과소예측 없음 정규성 잔차가 정규분포 형태 왜도, 첨도가 0에 가까움 잔차 간 독립성 Treatment 잔차와 Outcome 잔차 간 낮은 상관관계 상관계수 < 0.1 이면 이상적 import numpy as np import pandas as pd import matplotlib.pyplot as plt import matplotlib.font_manager as fm from sklearn.linear_model import LinearRegression from sklearn.metrics import r2_score from scipy import stats 한글 폰트 설정 plt.rcParams[\"font.family\"] = \"AppleGothic\" plt.rcParams[\"axes.unicode_minus\"] = False def check_conditional_independence_comprehensive(df): \"\"\" Outcome 잔차의 조건부 독립성을 종합적으로 확인 \"\"\" features = [\"Cas_ata\", \"Cas_acd_endo\", \"Cas_clr\", \"age\"] residual_col = \"outcome_residual\" print(\"=\" 60) print(\"조건부 독립성 검사: E[outcome_residual X] = 0\") print(\"=\" 60) X = df[features] residuals = df[residual_col] # ===== 1. 전체 R² 확인 ===== print(\"\\n1. 전체 조건부 독립성 검사\") print(\"-\" 40) model = LinearRegression() model.fit(X, residuals) predictions = model.predict(X) r2_total = r2_score(residuals, predictions) print(f\"Features로 잔차 예측 R²: {r2_total:.6f}\") # R² 평가 if r2_total < 0.001: print(\"🎉 우수: 매우 강한 조건부 독립성\") grade = \"A+\" elif r2_total < 0.01: print(\"✅ 우수: 강한 조건부 독립성\") grade = \"A\" elif r2_total < 0.05: print(\"⚠️ 양호: 약간의 의존성 존재\") grade = \"B\" elif r2_total < 0.1: print(\"⚠️ 보통: 중간 정도의 의존성\") grade = \"C\" else: print(\"❌ 문제: 강한 의존성 - 모델 개선 필요\") grade = \"D\" # ===== 2. 각 feature별 상관관계 ===== print(f\"\\n2. 각 Feature별 상관관계\") print(\"-\" 40) correlations = {} for feature in features: corr = np.corrcoef(df[feature], residuals)[0, 1] correlations[feature] = corr if abs(corr) < 0.05: status = \"✅ 매우 낮음\" elif abs(corr) < 0.1: status = \"⚠️ 낮음\" elif abs(corr) < 0.2: status = \"⚠️ 중간\" else: status = \"❌ 높음\" print(f\"{feature:15}: {corr:8.4f} {status}\") # ===== 3. 잔차의 기본 통계 ===== print(f\"\\n3. 잔차 기본 통계\") print(\"-\" 40) mean_residual = residuals.mean() std_residual = residuals.std() skew_residual = stats.skew(residuals) kurt_residual = stats.kurtosis(residuals) print(f\"평균: {mean_residual:8.4f} (0에 가까워야 함)\") print(f\"표준편차: {std_residual:8.4f}\") print(f\"왜도: {skew_residual:8.4f} (0에 가까워야 함)\") print(f\"첨도: {kurt_residual:8.4f} (0에 가까워야 함)\") # ===== 4. 통계적 검정 ===== print(f\"\\n4. 통계적 검정\") print(\"-\" 40) # F-test for overall significance n = len(residuals) k = len(features) f_stat = (r2_total / k) / ((1 - r2_total) / (n - k - 1)) f_p_value = 1 - stats.f.cdf(f_stat, k, n - k - 1) print(f\"F-검정 (전체 모델 유의성):\") print(f\" F-통계량: {f_stat:.4f}\") print(f\" p-value: {f_p_value:.6f}\") if f_p_value > 0.05: print(\" ✅ 잔차와 features 간 유의한 관계 없음 (좋음)\") else: print(\" ❌ 잔차와 features 간 유의한 관계 존재 (문제)\") # Shapiro-Wilk test for normality (샘플이 너무 크면 생략) if len(residuals) <= 5000: shapiro_stat, shapiro_p = stats.shapiro(residuals) print(f\"\\nShapiro-Wilk 정규성 검정:\") print(f\" 통계량: {shapiro_stat:.4f}\") print(f\" p-value: {shapiro_p:.6f}\") if shapiro_p > 0.05: print(\" ✅ 잔차가 정규분포를 따름\") else: print(\" ⚠️ 잔차가 정규분포를 벗어남\") # ===== 5. 시각화 ===== print(f\"\\n5. 시각적 진단\") print(\"-\" 40) fig, axes = plt.subplots(2, 3, figsize=(18, 12)) fig.suptitle(\"조건부 독립성 진단\", fontsize=16) # 5-1. 각 feature vs 잔차 for i, feature in enumerate(features): row = i // 2 col = i % 2 axes[row, col].scatter(df[feature], residuals, alpha=0.6, s=10) axes[row, col].axhline(0, color=\"red\", linestyle=\"--\", alpha=0.7) # 추세선 z = np.polyfit(df[feature], residuals, 1) p = np.poly1d(z) x_line = np.linspace(df[feature].min(), df[feature].max(), 100) axes[row, col].plot(x_line, p(x_line), \"r-\", alpha=0.8, linewidth=2) axes[row, col].set_xlabel(feature) axes[row, col].set_ylabel(\"Outcome 잔차\") axes[row, col].set_title(f\"{feature} vs 잔차 (상관계수: {correlations[feature]:.3f})\") axes[row, col].grid(True, alpha=0.3) # 5-2. 예측값 vs 잔차 axes[1, 0].scatter(df[\"outcome_prediction\"], residuals, alpha=0.6, s=10) axes[1, 0].axhline(0, color=\"red\", linestyle=\"--\", alpha=0.7) z = np.polyfit(df[\"outcome_prediction\"], residuals, 1) p = np.poly1d(z) x_line = np.linspace(df[\"outcome_prediction\"].min(), df[\"outcome_prediction\"].max(), 100) axes[1, 0].plot(x_line, p(x_line), \"r-\", alpha=0.8, linewidth=2) axes[1, 0].set_xlabel(\"예측값\") axes[1, 0].set_ylabel(\"잔차\") axes[1, 0].set_title(\"예측값 vs 잔차 (등분산성 검사)\") axes[1, 0].grid(True, alpha=0.3) # 5-3. 잔차 분포 axes[1, 1].hist(residuals, bins=50, density=True, alpha=0.7, edgecolor=\"black\") # 정규분포 곡선 오버레이 mu, sigma = residuals.mean(), residuals.std() x_norm = np.linspace(residuals.min(), residuals.max(), 100) axes[1, 1].plot(x_norm, stats.norm.pdf(x_norm, mu, sigma), \"r-\", lw=2, label=\"정규분포\") axes[1, 1].axvline(0, color=\"red\", linestyle=\"--\", alpha=0.7) axes[1, 1].set_xlabel(\"잔차\") axes[1, 1].set_ylabel(\"밀도\") axes[1, 1].set_title(\"잔차 분포\") axes[1, 1].legend() axes[1, 1].grid(True, alpha=0.3) plt.tight_layout() plt.show() # ===== 6. Q-Q Plot ===== plt.figure(figsize=(8, 6)) stats.probplot(residuals, dist=\"norm\", plot=plt) plt.title(\"Q-Q Plot: 잔차 정규성 검정\") plt.grid(True, alpha=0.3) plt.show() # ===== 7. 종합 평가 ===== print(f\"\\n\" + \"=\" 60) print(\"종합 평가\") print(\"=\" 60) issues = [] if r2_total > 0.05: issues.append(\"조건부 독립성 위반\") if abs(mean_residual) > 0.1: issues.append(\"편향 존재\") if any(abs(corr) > 0.2 for corr in correlations.values()): issues.append(\"강한 feature 의존성\") if f_p_value < 0.05: issues.append(\"통계적으로 유의한 의존성\") print(f\"조건부 독립성 등급: {grade}\") print(f\"전체 R²: {r2_total:.6f}\") print(f\"발견된 문제: {len(issues)}개\") if issues: print(\"\\n문제점:\") for issue in issues: print(f\" ❌ {issue}\") print(f\"\\n개선 방안:\") print(f\" 🔧 모델 복잡도 증가 (더 많은 features, interaction terms)\") print(f\" 🔧 비선형 변환 적용\") print(f\" 🔧 정규화 파라미터 조정\") print(f\" 🔧 다른 알고리즘 시도 (XGBoost, Neural Network)\") else: print(\"\\n🎉 조건부 독립성이 잘 만족됩니다!\") print(\"✅ R-learner의 다음 단계로 진행 가능\") return { \"r2_total\": r2_total, \"correlations\": correlations, \"mean_residual\": mean_residual, \"f_p_value\": f_p_value, \"grade\": grade, \"issues\": issues, } 실행 results = check_conditional_independence_comprehensive(df) # 3. CATE 추정 모델 > CATE(X, T) class MultiTreatmentRLearner: def __init__(self, model_y, model_t, model_final): self.model_y = model_y # Y 모델 self.model_t = model_t # Treatment propensity 모델 self.model_final = model_final # Final stage 모델 def fit(self, Y, T, X, W=None): # Step 1: Estimate E[Y X,W] if W is not None: XW = np.concatenate([X, W], axis=1) else: XW = X self.model_y.fit(XW, Y) Y_pred = self.model_y.predict(XW) Y_res = Y - Y_pred # Y residuals # Step 2: Multi-treatment propensity estimation # One-hot encode treatments T_onehot = pd.get_dummies(T, drop_first=True) T_pred = np.zeros_like(T_onehot) for k, col in enumerate(T_onehot.columns): # Each treatment vs rest self.model_t.fit(XW, T_onehot[col]) T_pred[:, k] = self.model_t.predict_proba(XW)[:, 1] T_res = T_onehot - T_pred # Treatment residuals # Step 3: Final stage - regress Y_res on T_res X # Create interaction terms features = [] for k in range(T_res.shape[1]): # θ_k(X) = X α_k (linear case) interaction = T_res[:, k : k + 1] X features.append(interaction) final_features = np.concatenate(features, axis=1) self.model_final.fit(final_features, Y_res) def predict(self, X, T0, T1): # Predict treatment effects between T0 and T1 # θ(X) (T1 - T0) pass from econml.dml import DML from econml.metalearners import XLearner, TLearner EconML의 meta-learners는 multi-treatment 지원 xl = XLearner(models=RandomForestRegressor()) xl.fit(Y, T, X=X) # T can be multi-valued from causalml.inference.meta import XLearner Multi-treatment support"
  },
  {
    "id": "Data Science/Causal Inference/Industry Application/lenze-size-recommendation-problem-definition",
    "title": "렌즈 사이즈 추천 문제에서 문제 정의에 대한 고민",
    "date": "2025-08-04",
    "excerpt": "렌즈 사이즈 추천에서 인과추론을 도입할 때 문제 정의를 어떻게 할 것인가",
    "category": "Causal Inference",
    "tags": [
      "problem definition"
    ],
    "content": "렌즈 삽입술에서 Y는 vault로 정의가 됨 (지금 풀려고 하는 문제에서는). vault는 렌즈 삽입술 후에 측정되는 값으로, 렌즈 후면과 수정체 전면까지의 거리를 의미함. 여기서 고민사항은 $T=0$인 것을 어떻게 정의해야하는지. $T=0$ 인 상황은 무엇일까? --- 수술 받기 전 상태 수술(처치) 받기 전 상태라고 정의하게 되면 vault값이 존재하지 않는다. 왜냐하면 vault의 정의 자체가 렌즈 후면과 수정체 전면까지의 거리라서. 존재하지 않는 값이지만 계산을 위해 0으로 정의해놔도 괜찮을까? $\\text{vault} = Y(T=0, X=x) = 0$ 가장 작은 크기의 렌즈를 받은 상태 현재 삽입하는 렌즈 크기에는 [12.1, 12.6, 13.2]가 있다. 이때 가장 작은 렌즈를 삽입한 상태를 $T=0$ 처치를 받은 상태로 정의해도 될까? $Y(T=0, X=x) = Y(T=12.1, X=x)$ 인과추론에서 T=0 의 정의가 뭐지? > 처치(treatment)가 적용되기 전의 시점, 즉 control 상태. T=0: 처치가 시작되기 직전의 시점 (baseline), 대조군에 해당하는 값 T=1: 처치가 적용된 후의 시점 (post-treatment) 예를 들어: 의약품 효과 연구: 약을 먹기 전(T=0)과 약을 먹은 후(T=1)의 건강 상태 비교 교육 프로그램 평가: 프로그램 참여 전(T=0)과 참여 후(T=1)의 성적 비교 마케팅 캠페인: 캠페인 시작 전(T=0)과 시작 후(T=1)의 매출 비교 대조군(control group)과 처치군(treatment group)의 개념처럼 어떤 처치의 효과를 추정하려고 할 때 비교대상이 되는 값. 이 개념에 따르면 2번 정의는 말이 안된다. 하지만 이렇게 정의해보는 건 어떨까? > 처치효과는 가장 작은 렌즈 대비 렌즈의 크기가 결과에 미치는 효과 혹은 영향도 처치를 받기 전에 Y값이 없는 경우는 어떻게 하지? (정의가 안될 떄) AI랑 ideation 해보면서 나온 것들 정리. 대안적 결과 변수 정의: vault 대신 다른 결과 변수 사용: 수술 전후 모두 측정 가능한 변수 예: 시력 개선도, 안압 변화, 환자 만족도 등 vault의 변화율: 수술 전후 vault 변화량을 결과 변수로 사용 T=12.1mm 렌즈를 기준(control)으로 정의 — 상대 비교: 완전 무처치는 존재하지 않음 -> 최소 크기 렌즈를 기준점으로 설정: $T=12.1$을 기준으로 $CATE(T=t, X=x) = E[Y T=t, X=x] - E[Y T=12.1, X=x]$ 이는 \"최소 크기 대비 다른 크기의 효과\"를 측정 렌즈 크기 자체가 treatment level인 multi-valued treatment setting $T \\in {12.1, 12.6, 13.2}$ 기준점: $T_0 = 12.1$ 이전 렌즈 대비 개선도: 환자가 이전에 사용하던 렌즈 대비 개선 효과 장점: 인과추론의 틀에서 정의 가능한 treatment comparison 단점: 절대값이 아닌 상대값만 추정 가능하며, baseline vault가 \"충분히 작은가?\"에 대한 해석적 고민 필요 Vault를 0으로 정의 — \"절대 효과로 바꾸기\": vault = 0 가정: 수술 전 vault를 0으로 가정 $CATE(T=t, X=x) = E[Y T=t, X=x] - 0 = E[Y T=t, X=x]$ 이는 \"절대적 vault 효과\"를 측정 CATE가 아닌 ATE와 유사한 구조로 해석됨 특정 렌즈를 넣었을 때 vault값이 얼마나 나오는지를 절대적 관점에서 해석 🧠 결론 및 제안 임상 현실 + 인과추론 이론을 동시에 고려할 때, 가장 자연스러운 정의는: $T=12.1$mm 렌즈를 기준으로 상대적 효과(CATE)를 정의하고, 절대효과(=vault 값 자체)는 최적화 목적의 타겟으로 사용 인과추론: $CATE(T=t, X=x) = E[Y T=t, X=x] - E[Y T=12.1, X=x]$ 추천 목적: $\\arg\\max_t E[Y T=t, X=x]$ 측정하지 않은 값에 대한 예측값은 어떻게 평가할 것인가 --- <figure> <img src=\"/post/Causal_Inference/렌즈추천_평가고민.jpeg\" alt=\"how-to-evalutate-counterfactual\" /> <figcaption>그림1. 측정하지 않은 값에 대한 예측값은 어떻게 평가할 것인가</figcaption> </figure> 내가 생각하는 문제는 결국 그림1과 같은 상황이다. 3가지의 렌즈 크기 중 고객은 하나에 대해서 수술을 받게 되는데, 그러면 나머지 2개에 대한 결과값이 없는 상황에서, 예측모델의 성능은 어떻게 판단할 수 있을까? 여기서 사용되는 개념이 양수성 (positivity). 이는 $ 0 < P(T=t X=x) < 1$ 을 만족하는 것을 의미함. 즉 어떤 고객이 각 처치를 받을 확률이 0보다 크다는 것. 따라서 A는 12.1을 받았지만, A랑 비슷한 다른 고객은 12.6을 받았기 때문에 성능을 확인해볼 수 있다는 것. 처치 간의 분포가 겹쳐있으면 반사실에 대해서도 어느정도 추정이 가능하다. > 이는 \"비슷한 고객들이 다양한 처치를 받았는가?\"라는 질문과 직결됨. $P(T=t X=x)$로 모델의 신뢰도를 정의하는 법 직관적으로 생각해보면 P(T=12.1 X)가 낮다면 해당 고객 같은 경우에는 12.1을 받을 확률이 낮으니까, 12.1에 대한 예측값의 신뢰도가 낮을 것이다. 이를 수학적으로 정의할 수 있을까?"
  },
  {
    "id": "Data Science/Causal Inference/Industry Application/how-to-define-confidence-score",
    "title": "렌즈 사이즈 추천 문제에서 모델의 신뢰도를 어떻게 정의할 것인가",
    "date": "2025-08-04",
    "excerpt": "렌즈 사이즈 추천에서 모델의 신뢰도를 어떻게 정의할 것인가",
    "category": "Causal Inference",
    "tags": [
      "confidence score"
    ],
    "content": ""
  },
  {
    "id": "Self_Development/English Study/SPEAK/소문및가십/08-03-못믿겠지만탐쿠르즈봤어",
    "title": "못 믿겠지만 탐크루즈 봤어",
    "date": "2025-08-03",
    "excerpt": "믿지 못할만한 소문이나 소식을 전할 때 쓰는 표현들",
    "category": "English Study",
    "tags": [
      "영어공부꾸준히!",
      "SPEAK"
    ],
    "content": "배운 것들 Believe it or not, I bumped into a Tom Cruise. Believe it or not : 너가 믿기 힘들겠지만, 믿든 말든. Believe it or not, Joe and Mary are getting married. Believe it or not, Joe and Mary are engaged. engaged : 약혼하다 divorce : 이혼하다 This may be a surprise : 놀랄만한 일일수도 있는데, 예상치 못했겠지만 This may be a surprise, but Joe is getting divorced. This may be a surprise, but Lenny passed bar exam. bar exam : 변호사 시험 You may not know this : 모를수도 있는데 You may not know this, but Drake is Canadian. 간단한 작문 Believe it or not, I will have love metting(?소개팅, 영어로 뭐지). Someone who is joined in same project suggest it to me. I like her style, maybe she has lovely smile I guess in the picture. You may not know this, my 이상형 is someone who has lovely smile and isn't short (more than 165cm). 피드백이랑 더 자연스러운 작문 Believe it or not, I'm going on a blind date this weekend! Someone from the same project suggested it to me. I really like her style, and from her picture, I can see she has a lovely smile. You might not know this about me, but my ideal type is someone with a beautiful smile and who isn't too short (preferably over 165cm). I'm actually quite nervous about it. I haven't been on a blind date in ages, and I'm not sure what to expect. But I'm trying to stay positive and just be myself. The person who set us up said we have similar interests and personalities, so hopefully we'll hit it off. I'm planning to meet her at a nice café downtown - nothing too fancy, just somewhere comfortable where we can talk and get to know each other. Wish me luck! I'll let you know how it goes. 피드백 원본 작문의 문제점들: 문법 오류들: \"I will have love metting\" → \"I'm going on a blind date\" \"Someone who is joined\" → \"Someone who joined\" \"suggest it to me\" → \"suggested it to me\" 어휘 선택: \"love meeting\" → \"blind date\" (소개팅의 정확한 표현) \"이상형\" → \"ideal type\" 또는 \"type\" 자연스러운 표현: \"I guess in the picture\" → \"from her picture, I can see\" \"isn't short\" → \"isn't too short\" 개선된 점들: 더 자연스러운 문장 구조 감정과 상황 설명 추가 (긴장감, 계획 등) 대화체 톤 유지 (친근하고 자연스러운 느낌) 구체적인 세부사항 (카페에서 만나기, 비슷한 관심사 등) 학습 포인트: 소개팅 = blind date \"hit it off\" = 잘 맞다, 사이가 좋다 \"in ages\" = 오랫동안 \"set us up\" = 소개해주다"
  },
  {
    "id": "Data Science/Codility Study/코딩테스트합격자되기/그래프/합격자가되는모의테스트",
    "title": "합격자가 되는 모의 테스트 - 그래프",
    "date": "2025-08-03",
    "excerpt": "그래프 탐색 파이썬 구현",
    "category": "Codility Study",
    "tags": [
      "코딩 테스트 합격자 되기",
      "Codility Study",
      "그래프",
      "알고리즘"
    ],
    "content": "--- title: \"합격자가 되는 모의 테스트 - 그래프\" date: \"2025-08-03\" category: \"Codility Study\" tags: [\"코딩 테스트 합격자 되기\", \"Codility Study\", \"그래프\", \"알고리즘\"] excerpt: \"그래프 탐색 파이썬 구현\" --- # 문제 42: 게임 맵 최단 거리 https://school.programmers.co.kr/learn/courses/30/lessons/1844 5x5 크기의 게임맵에서 (1, 1) -> (5, 5)까지 가는 최단거리를 구하는 문제 제약조건 maps는 n x m 크기의 게임 맵의 상태가 들어 있는 2차원 배열. 1 <= n, m <= 100 n과 m은 같거나 다를 수 있음 maps는 0과 1로 구성됨 0 : 벽 1 : 벽이 없는 자리 def solution(maps: list) -> int: # 관련 값들 정의 start_x, start_y = 0, 0 end_x, end_y = len(maps[0]) - 1, len(maps[1]) -1 distance_list = [] def bfs(x, y, distance): print(x, y, distance) if x == end_x and y == end_y: distance_list.append(distance) return if 0 < x + 1 < end_x and 0 < y < end_y and maps[x + 1][y] == 1: maps[x + 1][y] = 0 bfs(x + 1, y, distance + 1) elif 0 < x - 1 < end_x and 0 < y < end_y and maps[x -1][y] == 1: maps[x - 1][y] = 0 bfs(x - 1, y, distance + 1) elif 0 < x < end_x and 0 < y - 1 < end_y and maps[x][y - 1] == 1: maps[x][y - 1] = 0 bfs(x, y - 1, distance + 1) elif 0 < x < end_x and 0 < y + 1 < end_y and maps[x][y + 1] == 1: maps[x][y + 1] = 0 bfs(x, y + 1, distance + 1) bfs(start_x, start_y, 0) return distance_list solution_1 = solution(maps=[[1,0,1,1,1],[1,0,1,0,1],[1,0,1,1,1],[1,1,1,0,1],[0,0,0,0,1]]) print(solution_1) assert solution_1 == 11 solution_2 = solution(maps=[[1,0,1,1,1],[1,0,1,0,1],[1,0,1,1,1],[1,1,1,0,0],[0,0,0,0,1]]) print(solution_2) assert solution_2 == -1 from collections import deque def solution(maps: list) -> int: # 1. 이동할 수 있는 방향 정의 move = [[-1, 0], [0, -1], [0, 1], [1, 0]] # 2. 맵의 크기 저장 n = len(maps) m = len(maps[0]) # 3. 거리를 저장하는 배열 초기화 dist = [[-1] * m for _ in range(n)] # 4. bfs def bfs(start): q = deque([start]) dist[start[0]][start[1]] = 1 while q: here = q.popleft() for direct in move: row, column = here[0] + direct[0], here[1] + direct[1] if row < 0 or row >= n or column < 0 or column >= m: continue if maps[row][column] == 0: continue if dist[row][column] == -1: q.append([row, column]) dist[row][column] = dist[here[0]][here[1]] + 1 return dist bfs([0, 0]) return dist[n - 1][m - 1] solution_1 = solution(maps=[[1,0,1,1,1],[1,0,1,0,1],[1,0,1,1,1],[1,1,1,0,1],[0,0,0,0,1]]) print(solution_1) assert solution_1 == 11 solution_2 = solution(maps=[[1,0,1,1,1],[1,0,1,0,1],[1,0,1,1,1],[1,1,1,0,0],[0,0,0,0,1]]) print(solution_2) assert solution_2 == -1"
  },
  {
    "id": "Data Science/Codility Study/코딩테스트합격자되기/그래프/몸풀기문제",
    "title": "뭄풀기 문제 - 그래프",
    "date": "2025-08-03",
    "excerpt": "그래프 탐색 파이썬 구현",
    "category": "Codility Study",
    "tags": [
      "코딩 테스트 합격자 되기",
      "Codility Study",
      "그래프",
      "알고리즘"
    ],
    "content": "--- title: \"뭄풀기 문제 - 그래프\" date: \"2025-08-03\" category: \"Codility Study\" tags: [\"코딩 테스트 합격자 되기\", \"Codility Study\", \"그래프\", \"알고리즘\"] excerpt: \"그래프 탐색 파이썬 구현\" --- # 문제 38 : 깊이 우선 탐색 순회 입출력의 예 graph : 인접리스트 / start / return : 리스트 def solution(graph: list[list[str]], start: str) -> list[str]: def dfs(node): # 방문했던 거면 pass if visited[node]: return # 방문처리 visited[node] = True visited_list.append(node) if node in graph_list: for adj_nodes in graph_list[node]: dfs(adj_nodes) graph_list = {} node_set = set() for start_node, end_node in graph: if start_node in graph_list: graph_list[start_node].append(end_node) else: graph_list[start_node] = [end_node] node_set.add(start_node) node_set.add(end_node) visited = {key: False for key in node_set} # 노드가 숫자인 경우에는 [False] len(node) 이런식으로 가능 visited_list = [] dfs(start) return visited_list # 답안지 풀이 from collections import defaultdict adj_list = defaultdict(list) visited = set() result = [] def dfs(node): visited.add(node) result.append(node) for adj_node in adj_list.get(node, []): if adj_node not in visited: dfs(adj_node) def solution(graph, start): for u, v in graph: adj_list[u].append(v) dfs(start) return result solution_1 = solution(graph=[['A', 'B'], ['B', 'C'], ['C', 'D'], ['D', 'E']], start='A') print(solution_1) assert solution_1 == [\"A\", \"B\", \"C\", \"D\", \"E\"] solution_2 = solution(graph=[['A', 'B'], ['A', 'C'], ['B', 'D'], ['B', 'E'], ['C', 'F'], ['E', 'F']], start='A') print(solution_2) assert solution_2 == [\"A\", \"B\", \"D\", \"E\", \"F\", \"C\"] 시간복잡도 계산하기 : 노드 개수 N, 간선 개수 E라고 하면, 인접리스트 생성 : O(E) 탐색시 모든 노드 방문 : O(N) 따라서 O(N+E) # 문제 39: 너비 우선 탐색 순회 from queue import deque from collections import defaultdict def solution(graph: list, start:int) -> list: adj_list = defaultdict(list) visited = set() for start_node, end_node in graph: adj_list[start_node].append(end_node) visited_list = [] # 헷갈릴 수 있는 포인트가, bfs는 바로 방문할거니까 넣으면서 방문했다는 표시 해주기 queue = deque() queue.append(start) visited.add(start) visited_list.append(start) while queue: next_node = queue.popleft() for adj_node in adj_list[next_node]: if adj_node not in visited: queue.append(adj_node) visited.add(adj_node) visited_list.append(adj_node) return visited_list solution_1 = solution(graph=[(1, 2), (1, 3), (2, 4), (2, 5), (3, 6), (3, 7), (4, 8), (5, 8), (6, 9), (7, 9)], start=1) print(solution_1) assert solution_1 == [1, 2, 3, 4, 5, 6, 7, 8, 9] solution_2 = solution(graph=[(0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 0)], start=1) print(solution_2) assert solution_2 == [1, 2, 3, 4, 5, 0] 시간복잡도 : adj_list 생성할 때 : O(E) 탐색할 때 : O(N) # 문제 40: 다익스트라 알고리즘 시작노드에서 각 노드까지 최단거리 구하는 알고리즘 from collections import defaultdict def solution(start:int, numNodes:int, edges:list) -> list: adj_list = defaultdict(list) check_nodes = set() for start_node, end_node, weight in edges: adj_list[start_node].append((end_node, weight)) # 1. 최단거리 결과를 담을 자료구조 INF = 1e20 result = [INF] len(adj_list) result[start] = 0 check_nodes.add(0) for end_node, weight in adj_list[start]: if result[end_node] > weight: result[end_node] = weight # 2. 가장 작은 노드부터 greedy하게 갱신하기 # 가장 작은 거리인 노드를 찾는것도 짜줘야하는건가? min_node = None for i, tmp in arange(result): if i not in check_nodes # 우선 순위 큐 (heap) 자료구조로 최단 거리를 관리 import heapq from collections import defaultdict, deque from turtle import distance INF = 1e10 def solution(start:int, numNodes:int, edges:list) -> list: # 1. 그래프 초기화 graph = defaultdict(list) for start_node, end_node, weight in edges: graph[start_node].append((end_node, weight)) # 2. 최단경로 길이 및 방문 기록 초기화 distances = [INF] numNodes visited = [False] numNodes distances[start] = 0 # 3. 우선순위 큐 priority_queue = [(0, start)] # (거리, 노드) while priority_queue: # 4. 현재 노드 찾기 current_distance, current_node = heapq.heappop(priority_queue) # 5. 이미 방문한 노드는 무시 if visited[current_node]: continue # 6. 현재 노드 방문 처리 visited[current_node] = True # 7. 인접 노드에 대한 거리 업데이트 for adj_node, weight in graph[current_node]: new_distance = distances[current_node] + weight if new_distance < distances[adj_node]: distances[adj_node] = new_distance heapq.heappush(priority_queue, (new_distance, adj_node)) return distances solution_1 = solution(start=0, numNodes=3, edges=[[0, 1, 9], [0, 2, 3], [1, 0, 5], [2, 1, 1]]) print(solution_1) assert solution_1 == [0, 4, 3] solution_2 = solution(start=0, numNodes=4, edges=[[0, 1, 1], [1, 2, 5], [2, 3, 1]]) print(solution_2) assert solution_2 == [0, 1, 6, 7] 시간복잡도 : 인접 리스트 생성 : O(E) 최소 비용 찾는 부분 : O(VlogV) 최종 : O(E + VlogV) # 벨만-포드 알고리즘 음의 가중치가 있을 때 최소거리 구하는 방법 from collections import defaultdict import dis INF = 1e15 def solution(num_vertices:int, edges:list, source: int) -> list int: # 1. adj list adj_list = defaultdict(list) for start_node, end_node, weight in edges: adj_list[start_node].append((end_node, weight)) # 2. distasnce 초기화 distance = [INF] num_vertices distance[source] = 0 # 3. 정점의 개수 -1만큼 최소 비용을 갱신 for _ in range(num_vertices - 1): for u in range(num_vertices): for v, weight in adj_list[u]: if distance[u] + weight < distance[v]: distance[v] = distance[u] + weight # 4. 음의 순환이 있는지 확인 for u in range(num_vertices): for v, weight in adj_list[u]: if distance[u] + weight < distance[v]: return [-1] return distance solution_1 = solution(num_vertices=5, edges=[[0, 1, 4], [0, 2, 3], [0, 4, -6], [1, 3, 5], [2, 1, 2], [3, 0, 7], [3, 2, 4], [4, 2, 2]], source=0) print(solution_1) assert solution_1 == [0, -2, -4, 3, -6] solution_2 = solution(num_vertices=4, edges=[[0, 1, 5], [0, 2, -1], [1, 2, 2], [2, 3, -2], [3, 0, 2], [3, 1, 6]], source=0) print(solution_2) assert solution_2 == [-1] # 음의 순환이 있을 때 시간복잡도 = O(N E)"
  },
  {
    "id": "Data Science/Codility Study/자료구조/heapq",
    "title": "heapq 개념정리",
    "date": "2025-08-03",
    "excerpt": "heapq에 대한 설명과 어떻게 사용되는지 정리",
    "category": "Codility Study",
    "tags": [
      "코딩 테스트 합격자 되기",
      "Codility Study",
      "자료구조"
    ],
    "content": "heapq와 우선순위 큐 (Priority Queue) <figure> <img src=\"/post/CodilityStudy/heapq.png\" alt=\"heapq 개념도\" /> <figcaption>heapq 그림</figcaption> </figure> heapq란? Python의 내장 모듈로, 최소 힙(Min Heap)을 구현하는 모듈입니다. ``python import heapq 빈 힙 생성 heap = [] 요소 추가 heapq.heappush(heap, 5) heapq.heappush(heap, 2) heapq.heappush(heap, 8) heapq.heappush(heap, 1) print(heap) # [1, 2, 8, 5] - 최솟값이 루트에 위치 ` 기본 메서드들 요소 추가 `python heapq.heappush(heap, item) # 힙에 요소 추가 ` 최솟값 제거 및 반환 `python min_value = heapq.heappop(heap) # 최솟값 제거하고 반환 ` 리스트를 힙으로 변환 `python numbers = [5, 2, 8, 1, 9] heapq.heapify(numbers) # 리스트를 힙으로 변환 print(numbers) # [1, 2, 8, 5, 9] ` 최솟값 확인 (제거하지 않음) `python min_value = heap[0] # 힙의 루트 노드 확인 ` 우선순위 큐 구현 기본 우선순위 큐 `python import heapq class PriorityQueue: def __init__(self): self.heap = [] def push(self, item): heapq.heappush(self.heap, item) def pop(self): return heapq.heappop(self.heap) def peek(self): return self.heap[0] if self.heap else None def is_empty(self): return len(self.heap) == 0 사용 예시 pq = PriorityQueue() pq.push(5) pq.push(2) pq.push(8) pq.push(1) print(pq.pop()) # 1 (가장 작은 값) print(pq.pop()) # 2 ` 튜플을 이용한 우선순위 큐 `python (우선순위, 데이터) 형태로 저장 pq = [] heapq.heappush(pq, (3, \"task3\")) heapq.heappush(pq, (1, \"task1\")) heapq.heappush(pq, (2, \"task2\")) print(heapq.heappop(pq)) # (1, \"task1\") - 우선순위가 가장 높은 것 ` 최대 힙 구현 방법 1: 음수 변환 `python 최대 힙을 원할 때는 음수로 변환 numbers = [5, 2, 8, 1, 9] max_heap = [-x for x in numbers] heapq.heapify(max_heap) 최댓값 추출 max_value = -heapq.heappop(max_heap) print(max_value) # 9 ` 방법 2: 튜플 사용 `python (-우선순위, 데이터) 형태 max_heap = [] heapq.heappush(max_heap, (-5, \"task5\")) heapq.heappush(max_heap, (-2, \"task2\")) heapq.heappush(max_heap, (-8, \"task8\")) priority, task = heapq.heappop(max_heap) print(f\"우선순위: {-priority}, 작업: {task}\") # 우선순위: 8, 작업: task8 ` heapq를 사용하는 알고리즘들 5.1 다익스트라 알고리즘 (Dijkstra's Algorithm) 목적: 가중 그래프에서 최단 경로 찾기 `python import heapq def dijkstra(graph, start): distances = {node: float('inf') for node in graph} distances[start] = 0 pq = [(0, start)] while pq: current_dist, current_node = heapq.heappop(pq) if current_dist > distances[current_node]: continue for neighbor, weight in graph[current_node].items(): distance = current_dist + weight if distance < distances[neighbor]: distances[neighbor] = distance heapq.heappush(pq, (distance, neighbor)) return distances ` 5.2 프림 알고리즘 (Prim's Algorithm) 목적: 최소 신장 트리(MST) 찾기 `python def prim(graph, start): mst = [] visited = set() pq = [(0, start, None)] # (가중치, 노드, 부모) while pq: weight, node, parent = heapq.heappop(pq) if node in visited: continue visited.add(node) if parent is not None: mst.append((parent, node, weight)) for neighbor, edge_weight in graph[node].items(): if neighbor not in visited: heapq.heappush(pq, (edge_weight, neighbor, node)) return mst ` 5.3 A* 알고리즘 목적: 휴리스틱을 사용한 최단 경로 찾기 `python def a_star(graph, start, goal, heuristic): pq = [(0, start, [start])] # (f_score, node, path) g_score = {start: 0} f_score = {start: heuristic(start, goal)} while pq: current_f, current, path = heapq.heappop(pq) if current == goal: return path for neighbor, weight in graph[current].items(): tentative_g = g_score[current] + weight if neighbor not in g_score or tentative_g < g_score[neighbor]: g_score[neighbor] = tentative_g f_score[neighbor] = tentative_g + heuristic(neighbor, goal) heapq.heappush(pq, (f_score[neighbor], neighbor, path + [neighbor])) return None ` 5.4 허프만 코딩 (Huffman Coding) 목적: 데이터 압축을 위한 가변 길이 인코딩 `python from collections import Counter def huffman_coding(text): # 빈도수 계산 freq = Counter(text) # 힙에 모든 문자 추가 heap = [[freq[char], char] for char in freq] heapq.heapify(heap) # 허프만 트리 구성 while len(heap) > 1: left = heapq.heappop(heap) right = heapq.heappop(heap) # 새로운 노드 생성 new_node = [left[0] + right[0], left, right] heapq.heappush(heap, new_node) return heap[0] # 루트 노드 ` 5.5 Top K 문제 목적: 배열에서 상위 K개의 요소 찾기 `python def find_top_k(nums, k): # 최소 힙을 사용해서 상위 K개 유지 heap = [] for num in nums: heapq.heappush(heap, num) if len(heap) > k: heapq.heappop(heap) # 가장 작은 값 제거 return sorted(heap, reverse=True) # 내림차순 정렬 사용 예시 nums = [3, 2, 1, 5, 6, 4] print(find_top_k(nums, 2)) # [6, 5] - 상위 2개 ` 5.6 중간값 찾기 (Median) 목적: 스트리밍 데이터에서 중간값 유지 `python class MedianFinder: def __init__(self): self.max_heap = [] # 왼쪽 절반 (최대 힙) self.min_heap = [] # 오른쪽 절반 (최소 힙) def addNum(self, num): # 최대 힙에 추가 heapq.heappush(self.max_heap, -num) # 균형 맞추기 if self.max_heap and self.min_heap and -self.max_heap[0] > self.min_heap[0]: val = -heapq.heappop(self.max_heap) heapq.heappush(self.min_heap, val) # 크기 균형 맞추기 if len(self.max_heap) > len(self.min_heap) + 1: val = -heapq.heappop(self.max_heap) heapq.heappush(self.min_heap, val) elif len(self.min_heap) > len(self.max_heap): val = heapq.heappop(self.min_heap) heapq.heappush(self.max_heap, -val) def findMedian(self): if len(self.max_heap) > len(self.min_heap): return -self.max_heap[0] return (-self.max_heap[0] + self.min_heap[0]) / 2 ` 5.7 병합 K개 정렬된 리스트 목적: K개의 정렬된 리스트를 하나로 병합 `python def merge_k_sorted_lists(lists): pq = [] result = [] # 각 리스트의 첫 번째 요소를 힙에 추가 for i, lst in enumerate(lists): if lst: heapq.heappush(pq, (lst[0], i, 0)) while pq: val, list_idx, element_idx = heapq.heappop(pq) result.append(val) # 다음 요소가 있으면 힙에 추가 if element_idx + 1 < len(lists[list_idx]): heapq.heappush(pq, (lists[list_idx][element_idx + 1], list_idx, element_idx + 1)) return result ` 시간복잡도 삽입: O(log n) 삭제: O(log n) 최솟값 확인: O(1) 힙 생성: O(n) 코딩테스트 팁 자주 사용되는 패턴 `python 최소값/최대값 유지 min_heap = [] max_heap = [] 우선순위와 함께 데이터 저장 pq = [(priority, data)] 여러 정보를 튜플로 저장 pq = [(cost, node, path)] 음수 변환으로 최대 힙 구현 max_heap = [-x for x in numbers] ` 주의사항 튜플 비교: 첫 번째 요소부터 순서대로 비교 같은 우선순위: 두 번째 요소로 구분 최대 힙: 음수 변환 또는 (-priority, data) 형태 중복 방문: 방문 체크 필수 (다익스트라 등) 핵심 포인트: heapq`는 최소 힙을 구현 우선순위 큐의 기본 구현체 그래프 알고리즘에서 필수적 실시간 데이터 처리에 유용 메모리 효율적인 자료구조"
  },
  {
    "id": "Self_Development/Singing/장효진강의/3강_깊게 마시고 뱉기를 통한 호흡 익히기",
    "title": "3강 깊게 마시고 뱉기를 통한 호흡 익히기",
    "date": "2025-08-02",
    "excerpt": "깊게 마시고 뱉는 법을 통해 내복근 느낌 잡는 법. 관련 연습법 정리",
    "category": "Singing",
    "tags": [
      "Singing Practice",
      "장효진 강의",
      "연습방법"
    ],
    "content": "점진적 과부하 공기를 다 뺐다고 느낄 때, 그 떄 떠 뺼떄 내복근이 더 많이 쓰임 똑같은 힘으로 끝까지 뱉는 느낌 허리펴고. 같은 힘으로. > 마지막에 마지막에 마지막까지 뱉어주기"
  },
  {
    "id": "Self_Development/Singing/장효진강의/2강_내복근_컨트롤",
    "title": "2강 내복근 컨트롤",
    "date": "2025-08-02",
    "excerpt": "2강 내복근 컨트롤 , 에 대한 내용정리",
    "category": "Singing",
    "tags": [
      "Singing Practice",
      "장효진 강의"
    ],
    "content": "유로인강 유튭 링크 호흡을 내뱉는 법. 패시브가 되어야 함. 횡경막의 역할. 나온 배를 다시 배만 정위치로 돌려놓는 느낌. \"배만 움직이는 느낌\" \"피지컬의 중요성\" 가슴도 안써야됨. 배로만 컨트롤하는 느낌."
  },
  {
    "id": "Self_Development/Singing/장효진강의/1강_개념정리 및 본질",
    "title": "1강 개념정리 및 본질",
    "date": "2025-08-02",
    "excerpt": "1강 개념정리 및 본질 , 에 대한 내용정리",
    "category": "Singing",
    "tags": [
      "Singing Practice",
      "장효진 강의"
    ],
    "content": "전체적인 목차에 대한 설명 호흡에 대한 자세한 설명 발성의 시작. 소리를 만드는 법 성대 컨트롤과 관련된 내용들 정~~말 많은 내용이 있구나. 꾸준히 하나씩 들어보자고. > 시키는대로만 하세요. 묻지도 따지지도 말고 영상에서 하라는대로."
  },
  {
    "id": "Data Science/Codility Study/코딩테스트합격자되기/그래프/그래프_최단경로_구하기",
    "title": "그래프 최단 경로 구하기",
    "date": "2025-08-02",
    "excerpt": "그래프 최단 경로 구하기",
    "category": "Codility Study",
    "tags": [
      "코딩 테스트 합격자 되기",
      "Codility Study",
      "그래프",
      "알고리즘"
    ],
    "content": "> 최단 경로 (shortest path)는 그래프의 종류에 따라 그 진의가 다르게 해석될 수도 있는 주제입니다. 가중치의 여부. 알고리즘 목적 장단점 및 특징 시간 복잡도 --------- ------ ---------------- ------------- 다익스트라 알고리즘 출발 노드로부터 도착 노드들까지의 최단 경로 찾기 음의 가중치를 가지는 그래프에서 최단 경로를 구할 수 없음 (그리디 방식) O(V^2), 우선순위 큐로 개선하면 O(E logV) 벨만-포드 알고리즘 출발 노드로부터 도착 노드들까지의 최단 경로 찾기 음의 가중치를 가지는 그래프에서 최단 경로를 구할 수 있고, 음의 순환도 감지할 수 있음 O(VE) 다익스트라(dijkstra) 알고리즘 --- 모든 가중치가 양수일 때. > 다익스트라 알고리즘의 목적은 그래프 내에서 특정 노드를 기준으로 각 노드까지 최단 경로 또는 최단 경로의 길이를 찾는 것에 있습니다. > 다익스트라 알고리즘의 핵심은 현재까지 발견한 가장 적은 비용으로 갈 수 있는 노드를 경유해서, 각 노드까지 최단 경로를 갱신하는 작업을 반복하는 것입니다. 시작 노드에서 각 노드까지 거리를 초기화 현재 가장 적은 비용으로 갈 수 있는 노드 선택 (각 노드는 한 번씩만 선택) 2에서 선택한 노드의 주변 노드 거리를 갱신 알고리즘 동작 순서 시작 노드를 설정하고 시작 노드로부터 특정 노드까지의 최소 비용을 저장할 공간과 직전 노드를 저장할 공간을 마련합니다. 1-1. 최소 비용을 저장할 공간은 모두 매우 큰 값으로 초기화합니다. 1-2. 시작 노드의 최소비용은 0, 직전 노드는 자신으로 합니다. 현재까지 구한 각 노드까지 최소 비용을 기준으로 지금까지 선택하지 않은 노드 중 최소 비용이 가장 적은 노드를 선택합니다. 2-1. 해당 노드를 거쳐서 각 노드까지 가는 최소 비용과 현재까지 구한 최소 비용을 비교하여 작은 값을 각 노드의 최소 비용으로 갱신합니다. 2-2. 이때 직전 노드도 같이 갱신합니다. 노드 개수에서 1을 뺀 만큼 반복합니다. 벨만-포드(bellman-ford) 알고리즘 --- > 벨만-포드 알고리즘은 매 단계마다 모든 간선의 가중치를 다시 확인하여 최소 비용을 갱신하므로 음의 가중치를 가지는 그래프에서도 최단 경로를 구할 수 있습니다. 알고리즘 동작순서 시작노드를 설정한 다음 시작 노드의 최소 비용은 0, 나머지 노드는 INF로 초기화. 노드 개수 -1 만큼 다음 연산은 반복 2-1. 시작 노드에서 갈 수 있는 각 노드에 대하여 전체 노드 각각을 거쳐갈 때 현재까지 구한 최소 비용보다 더 적은 최소 비용이 있는지 확인하여 갱신. 과정2를 마지막으로 한번 더 수행하여 갱신되는 최소 비용이 있는지 확인. 있다면 음의 순환이 있음을 의미. 왜 정점개수 -1만큼 반복하는가? 매 연산마다 최단경로가 1개씩 확정되므로! 벨만-포드 알고리즘에서 정점 개수 - 1번만큼 반복하는 이유는 최단 경로의 특성 때문입니다. 핵심 원리 최단 경로는 최대 V-1개의 간선으로 구성됩니다 n개의 정점이 있을 때, 최단 경로는 최대 n-1개의 간선을 가질 수 있습니다 만약 n개 이상의 간선이 있다면, 그 경로에는 반드시 순환(cycle)이 포함되어 있습니다 예시로 이해하기 `` 정점: A, B, C, D (4개) 가능한 최단 경로: A → B → C → D (3개 간선, 최대) A → B → D (2개 간선) A → D (1개 간선) ` 왜 V-1번이면 충분한가? 1번째 반복: 출발점에서 1개 간선으로 도달 가능한 모든 정점의 최단 거리 확정 2번째 반복: 출발점에서 2개 간선으로 도달 가능한 모든 정점의 최단 거리 확정 ... (V-1)번째 반복: 출발점에서 (V-1)개 간선으로 도달 가능한 모든 정점의 최단 거리 확정 이후 더 반복해도 새로운 최단 경로를 찾을 수 없습니다. 왜 한번 더 연산을 반복하는가? 음의 순환을 찾기 위해! 벨만-포드 알고리즘의 마지막 단계에서 한 번 더 반복하는 이유는 음의 순환(negative cycle)을 감지하기 위해서입니다. 음의 순환이란? ` A → B → C → A (순환) 가중치: 2 → 3 → (-6) → 2 ` 이 경우 A에서 시작해서 A로 돌아올 때마다 비용이 -1씩 감소합니다. 즉, 무한히 작아질 수 있습니다. 감지 방법 V-1번 반복: 정상적인 최단 경로 계산 V번째 반복: 한 번 더 반복하여 거리 값이 갱신되는지 확인 만약 거리 값이 갱신된다면 → 음의 순환이 존재 만약 거리 값이 갱신되지 않는다면 → 음의 순환이 없음 예시 ` 정점: A, B, C 간선: A→B(2), B→C(3), C→A(-6) V-1번 반복 후: dist[A] = 0, dist[B] = 2, dist[C] = 5 V번째 반복 시: dist[A] = 5 + (-6) = -1 (갱신됨!) → 음의 순환 존재! `` 왜 V번째에서 감지되는가? V-1번 반복으로 모든 정상적인 최단 경로를 찾았습니다 V번째 반복에서 거리 값이 갱신된다면, 그것은 V개 이상의 간선을 사용하는 경로입니다 V개 이상의 간선을 사용하는 경로는 반드시 순환을 포함합니다 그 순환이 음의 가중치를 가진다면, 거리 값이 계속 감소하게 됩니다"
  },
  {
    "id": "Self_Development/English Study/SPEAK/지나간달/08-01-최악의대비_리뷰",
    "title": "최악의 대비 리뷰 데이",
    "date": "2025-08-01",
    "excerpt": "최악의 대비 관련 표현들 리뷰 데이",
    "category": "English Study",
    "tags": [
      "영어공부꾸준히!",
      "SPEAK"
    ],
    "content": "리뷰하는 것들 What if I mess up? What if I fail the exam? What if it rains? What if the flight is delayed? What if I miss thre connecting flight? What if I miss my flight? What if I miss my train? What if you were in Seoul? What if you were in New York? What would you do if you were in Newyork? If it hadn't been for your help, I wouldn't have made it. Would you have moved to New York? Let me know if you're interested. I don't mind if we go clubbing. Even if it's inconvenient, I'll still wear a mask. No matter what happens, I'll always be there for you."
  },
  {
    "id": "Data Science/Codility Study/현대오토에버코테",
    "title": "현대오토에버 코테 준비하기",
    "date": "2025-08-01",
    "excerpt": "현대오토에버 코테 준비하기",
    "category": "Codility Study",
    "tags": [
      "코테 준비"
    ],
    "content": "시험 기출 문제 유형 참고한 블로그 2025년 기출 문제 유형 백엔드 총 2문제 DFS 문제 그래프가 나뉘어져 있는 경우와 사이클인 경우를 고려해야 하는 문제. DP 유형의 문제 늘보코치의 IT 취업 코테 + 서류로 보통 1차 평가 예정 알고리즘 위주인데 시간복잡도를 줄여주는 알고리즘 선호 투포인터 (백준 1253번) 완전탐색으로 풀면 시간 초과 이분탐색 (백준 6236번) DP 기본문제 (백준 12865번), 메모이제이션 (백준 9184번) 우선순위 큐 (백준 1766번) 누적합 (백준 2143번)"
  },
  {
    "id": "Data Science/Codility Study/코딩테스트합격자되기/그래프/그래프_탐색_노트북",
    "title": "그래프 탐색 파이썬 구현",
    "date": "2025-08-01",
    "excerpt": "그래프 탐색 파이썬 구현",
    "category": "Codility Study",
    "tags": [
      "코딩 테스트 합격자 되기",
      "Codility Study",
      "그래프",
      "알고리즘"
    ],
    "content": "--- title: \"그래프 탐색 파이썬 구현\" date: \"2025-08-01\" category: \"Codility Study\" tags: [\"코딩 테스트 합격자 되기\", \"Codility Study\", \"그래프\", \"알고리즘\"] excerpt: \"그래프 탐색 파이썬 구현\" --- # DFS 구현 !DFS 그래프 그림 # 인접 리스트로 표시된 그래프 graph = { 1: [4, 5], 2: [3], 3: [], 4: [2, 3], 5: [4] } 방문 여부 visited = [False] (len(graph) + 1) def dfs(current_node): visited[current_node] = True print(current_node) for neighbor in graph[current_node]: if not visited[neighbor]: dfs(neighbor) dfs(1) # BFS 구현 from collections import deque 인접 리스트로 표시된 그래프 graph = { 1: [4, 5], 2: [3], 3: [], 4: [2, 3], 5: [4] } def bfs(start_node): # 방문 여부 visited = [False] (len(graph) + 1) queue = deque([start_node]) visited[start_node] = True while queue: node = queue.popleft() print(node) for adj_node in graph[node]: if not visited[adj_node]: queue.append(adj_node) visited[adj_node] = True bfs(1)"
  },
  {
    "id": "Data Science/Codility Study/코딩테스트합격자되기/그래프/그래프_탐색",
    "title": "그래프 탐색 개념 정리",
    "date": "2025-08-01",
    "excerpt": "그래프 탐색 개념 정리",
    "category": "Codility Study",
    "tags": [
      "코딩 테스트 합격자 되기",
      "Codility Study",
      "그래프",
      "알고리즘"
    ],
    "content": "구현 노트북 그래프 탐색 파이썬 구현 DFS / BFS 더 이상 탐색할 노드가 없을 때까지 일단 가봅니다. 그러다가 더 이상 탐색할 노드가 없으면 최근에 방문했던 노드로 되돌아간 다음 가지 않은 노드를 방문합니다. 현재 위치에서 가장 가까운 노드부터 모두 방문하고 다음 노드로 넘어갑니다. 그 노드에서 또 다시 가장 가까운 노드부터 모두 방문합니다. 최단경로찾기 일때는 보통 BFS, 나머지는 DFS인 경우가 많다. > DFS와 BFS가 방문처리 시점이 다른 이유 : > DFS는 stack에서 pop을 할 때 방문처리를 하지만, BFS는 queue에 push할 때 방문처리를 함. > 왜냐하면 DFS는 나중에 확인할 노드이고, BFS는 바로 확인할 노드이기 때문에. DFS(Deep-First Search) : 깊이 우선 탐색 > 최대 깊이 노드까지 방문한 다음에는 이전에 방문한 노드를 거슬러 올라가며 해당 노드와 연결된 노드 중 방문하지 않은 노드로 다시 최대 깊이까지 차례대로 방문합니다. stack 자료구조 활용 <figure> <img src=\"/post/CodilityStudy/stack.png\" alt=\"stack\" style=\"width: 100%; height: auto; display: block; margin: 0 auto;\" /> <figcaption style=\"text-align: center;\">그림1. stack 자료구조 : FILO(First In Last Out) 구조</figcaption> </figure> sudo code : 스택이 비었는지 확인. 스택이 비었다면 -> 모든 노드 방문 완료 -> 종료 스택에서 노드를 팝. 팝한 노드는 최근에 스택에 푸쉬한 노드 팝한 노드의 방문 여부 확인 아직 방문 안했으면 -> 노드를 방문처리 방문한 노드와 인접한 모든 노드를 확인 아직 방문하지 않은 노드를 스택에 푸쉬. 고려사항 : 탐색할 노드가 없을 때까지 간선을 타고 내려갈 수 있어야 함 가장 최근에 방문한 노드를 알아야 함 이미 방문한 노드인지 확인할 수 있어야 함 > 가장 깊은 노드까지 방문한 후에 더 이상 방문할 노드가 없으면 최근 방문한 노드로 돌아온 다음, 해당 노드에서 방문할 노드가 있는지 확인한다. back tracking : 탐색하고 있는 방향의 역방향으로 되돌아가는 동작 스택은 최근에 푸쉬한 노드를 팝 연산으로 확인할 수 있으므로 특정 노드를 방문하기 전에 최근 방문노드를 팝 연산으로 쉽게 확인할 수 있음. 스택을 활용한 구현 / 재귀를 활용한 구현 스택을 활용한 깊이 우선 탐색 : <figure> <img src=\"/post/CodilityStudy/DFS_그려보기.png\" alt=\"DFS\" style=\"width: 50%; height: auto; display: block; margin: 0 auto;\" /> <figcaption style=\"text-align: center;\">그림2. DFS stack 구현</figcaption> </figure> 재귀 함수를 활용한 깊이 우선 탐색 : > 재귀 함수를 호출할 때마다 호출한 함수는 시스템 스택이라는 곳에 쌓이므로 깊이 우선 탐색에 활용할 수 있는 것입니다. <figure> <img src=\"/post/CodilityStudy/DFS_재귀.png\" alt=\"DFS\" style=\"width: 50%; height: auto; display: block; margin: 0 auto;\" /> <figcaption style=\"text-align: center;\">그림3. DFS 재귀 구현</figcaption> </figure> stack으로 구현하는 것과 논리는 같음. 스택에 쌓아주는 대신 이웃노드에 대한 재귀함수를 실행시켜주는 방식. BFS(Breadth-First Search) : 너비 우선 탐색 Queue 자료구조 활용 <figure> <img src=\"/post/CodilityStudy/queue.webp\" alt=\"queue\" style=\"width: 50%; height: auto; display: block; margin: 0 auto;\" /> <figcaption style=\"text-align: center;\">그림4. queue 자료구조 : FIFO(First In First Out) 구조</figcaption> </figure> <figure> <img src=\"/post/CodilityStudy/BFS_큐.png\" alt=\"BFS\" style=\"width: 50%; height: auto; display: block; margin: 0 auto;\" /> <figcaption style=\"text-align: center;\">그림5. BFS 큐 구현</figcaption> </figure>"
  },
  {
    "id": "Data Science/Codility Study/코딩테스트합격자되기/그래프/그래프_개념정리",
    "title": "그래프 개념정리",
    "date": "2025-08-01",
    "excerpt": "그래프 개념정리",
    "category": "Codility Study",
    "tags": [
      "코딩 테스트 합격자 되기",
      "Codility Study",
      "자료구조",
      "그래프"
    ],
    "content": "그래프란? 정의 : > 그래프는 노드 (vertex)와 간선 (edge)을 이용한 비선형 데이터 구조 데이터의 관계를 표현하는데 사용 그래프의 특징과 종류 : 방향성 존재 여부 방향 그래프 (directed graph) : 간선에 방향성이 있는 그래프 무방향 그래프 (undirected graph) : 간선에 방향성이 없는 그래프 간선의 가중치 존재 여부 가중치 그래프 (weighted graph) : 간선에 가중치가 있는 그래프 무가중치 그래프 (unweighted graph) : 간선에 가중치가 없는 그래프 순환 여부 순환 그래프 (cyclic graph) : 간선을 따라 이동하면 출발점으로 돌아오는 경로가 존재하는 그래프 비순환 그래프 (acyclic graph) : 간선을 따라 이동하면 출발점으로 돌아오는 경로가 존재하지 않는 그래프 그래프 구현 : 그래프의 표현 방법 인접 행렬 (adjacency matrix) : 2차원 배열로 그래프의 연결 관계를 표현 인접 리스트 (adjacency list) : 연결 리스트로 그래프의 연결 관계를 표현 > 입력값이 적거나 특정 정점 사이의 간선 여부를 빠르게 판단해야 할 때는 인접 행렬을, 그렇지 않으면 인접 리스트를 사용하면 좋습니다. 인접행렬 노드 간의 관계를 행렬로 표현하는 것 인접 리스트 [정점(v), 가중치(w), 다음 노드(next)] 로 구성된 리스트로 그래프를 표현. 노드에 대한 배열이 있고, 노드별로 인접 리스트를 가진다. 장단점 메모리 사용 시간복잡도 기타 --- --- --- --- 인접 행렬 $O(N^2)$ $O(1)$ 구현이 상대적으로 쉬움 인접 리스트 $O(N+E)$ $O(N)$ 인접 행렬 인접 리스트의 장점 : 정보를 확인할 떄 시간 복잡도가 O(1)로 좋음 인접 행렬의 단점 : 인접 행렬로 희소 그래프를 표현하는 경우 -> 굉장히 비효율적. 메모리 낭비. 노드들의 값의 차이가 매우 큰 그래프를 표현하는 경우 -> 가장 큰 값을 기준으로 인접 행렬의 크기를 잡아야 하니까. 인접 리스트 (인접 행렬과 반대) 인접 리스트의 장점 : 메모리 사용량이 적음 노드들의 값의 차이가 매우 큰 그래프를 표현하는 경우 메모리 낭비가 적음 인접 리스트의 단점 : 정보를 확인할 떄 시간 복잡도가 O(n)으로 비효율적."
  },
  {
    "id": "Self_Development/English Study/SPEAK/지나간달/07-31-좀불편해도마스크쓸거야",
    "title": "좀 불편해도 마스크 쓸 거야",
    "date": "2025-07-31",
    "excerpt": "좀 불편해도 마스크 쓸 거야",
    "category": "English Study",
    "tags": [
      "영어공부꾸준히!",
      "SPEAK"
    ],
    "content": "배운 것들 What if I catch the flu? Even if it's inconvinient, I will still wear a mask. Even if you mess up, we'll still believe in you. No matter what happens, I'll always believe in you. be there for you. 겁나 로맨틱하게 느껴지. Failures are okay as long as youy learn from then. 간단한 작문 Even if I'm tired, I'll practice English. No matter what happens, I'll always be there for you."
  },
  {
    "id": "Self_Development/English Study/SPEAK/지나간달/07-30-고깃집에가도난상관없어",
    "title": "고깃집에 가도 난상관없어",
    "date": "2025-07-30",
    "excerpt": "고깃집에 가도 난상관없어",
    "category": "English Study",
    "tags": [
      "영어공부꾸준히!",
      "SPEAK"
    ],
    "content": "배운 것들 Sharing is caring. 관심 있으면 알려줘 그렇게 해도 상관없어 Let me know. 알려줘. 연락해. Let me know if you're interested. 관심 있으면 알려줘. change your mind. hange out : 같이 시간을 보내다. I don't mind if we go clubbing. 간단한 작문 I totally agree about the sentence \"Sharing is caring.\" I'm willing to share my insights or knowledge with my pioneers and friends. Today I learned the phares that is used in the conversation. Let me know if you wonder my codes. Then I will explain it. And my food type (식성) is so normal. I like almost foods. So I always say to my friends that I don't mind if we have chinese foods. 피드백 문법 오류 \"pioneers\" → \"peers\" (동료를 의미할 때) \"phares\" → \"phrases\" (철자 오류) \"that is\" → \"that are\" (phrases는 복수) \"wonder my codes\" → \"wonder about my code\" (code는 보통 단수형 사용) \"almost foods\" → \"almost all foods\" (거의 모든 음식) \"chinese foods\" → \"Chinese food\" (음식은 보통 단수형) 표현 개선 \"I totally agree about\" → \"I totally agree with\" \"I'm willing to share\" → 더 자연스러운 표현으로 개선 \"Let me know if you wonder\" → 더 자연스러운 표현으로 개선 개선된 버전 I totally agree with the saying \"Sharing is caring.\" I'm always happy to share my insights and knowledge with my peers and friends. Today I learned some useful phrases that are commonly used in conversations. If you're curious about my code, feel free to ask. I'd be happy to explain it to you. As for my food preferences, I'm quite flexible. I enjoy almost all types of food. That's why I always tell my friends that I don't mind going to Chinese restaurants."
  },
  {
    "id": "Self_Development/Career/site-recommendation",
    "title": "취업 준비 사이트 추천",
    "date": "2025-07-30",
    "excerpt": "취업 준비 사이트 추천",
    "category": "Career",
    "tags": [
      "취업"
    ],
    "content": "취업 준비 사이트 추천 zighang offercent bzpp 링크드인 채용공고나 채용하는 피드 참고하기"
  },
  {
    "id": "Self_Development/English Study/SPEAK/지나간달/07-29-너아니었으면",
    "title": "너 아니었으면",
    "date": "2025-07-29",
    "excerpt": "너 아니었으면, 너라면 어떻게 했겠어?",
    "category": "English Study",
    "tags": [
      "영어공부꾸준히!",
      "SPEAK"
    ],
    "content": "배운거 정리 match maker 문법. 현재와 다른 어떤 상황을 가정할 때는 과거완료를 사용. If it hadnt been for you, I wouldn't have made it. would've -> /wʊdəv/ (woul-duv) wouldn't -> /wʊdnt/ (woul-dnt) wou-ov 발음 기호를 추가했습니다! 📝 발음 가이드 would've: /wʊdəv/ (woul-duv) wʊ = \"woul\" (wool과 비슷) dəv = \"duv\" (duh + v 소리) wouldn't: /wʊdnt/ (woul-dnt) wʊ = \"woul\" (wool과 비슷) dnt` = \"dnt\" (d + n + t를 빠르게 연결) 실제로는 \"would have\"와 \"would not\"이 축약되어 더 짧고 빠르게 발음되는 형태입니다. Would you have moved to New York?"
  },
  {
    "id": "Self_Development/Career/how-to-write-resume",
    "title": "이력서, 경력기술서 작성 방법 정리",
    "date": "2025-07-29",
    "excerpt": "이력서, 경력기술서 적는 방법 정리",
    "category": "Career",
    "tags": [
      "이력서"
    ],
    "content": "참고링크: 유튜브 이형 - 경력기술서 작성법 총정리 이직이 처음이라면 이것부터 보세요 이직바이블 137p ~ 187p 경력기술서 작성방법 : 최근경력 - 지원직무에 맞게 먼저 제출 직무와 무관한 경험에 대해서는 과감하게 삭제 연차별 1칸씩은 필수 가급적 10개 미만 경력기술서의 내용 : 구분 작성 방법 --- --- 기간 프로젝트 중심으로 설명 성과 (1줄 이내) How + Result -> KPI 역할 (5줄 이내) 1. 문제 해결 관점: 핵심 문제 해결 과정에서의 역할<br>2. 생산성 향상 관점: 업무 효율성 개선에서의 역할<br>3. 의사소통 관점: 팀 협업 및 커뮤니케이션에서의 역할 기술 1. 도구/툴: 사용한 기술 스택<br>2. 프로세스 이해: 업무 프로세스에 대한 이해도 물경력 진단 리스트: 숫자로 설명할 수 있는 성과가 없다. 내 직무 KPI가 무엇인지 모른다 진행한 프로젝트/업무의 Before/After가 명확하지 않다. 성과를 달성하기 위해 구체적으로 어떤 역할을 수행했는지 설명할 수 없다. 연속 근무 기간이 1년 미만이다. 최근 3년 내 2곳 이상으로 이직했다. 동기나 동일 연차에 비해 승진이 늦다. 경력 기술서 작성 프로세스 : 경력 기술서를 위한 소재 준비하기 : 경험 리스트업 경험 리스트업 템플릿을 활용하여 주요 활동 정리하기 KPI 매칭하기 경력 기술서 작성하기 프로젝트명 기간 성과 역할 기술 > 간혹 경력 기술서를 구체적이고 길게 서술하는 경우가 있는데, 경력 기술서의 목적 자체가 핵심을 간결하게 보기 위함이기 때문에 > 우리는 면접관이 궁금해야할 내용만 작성하자. 예시 직무 : MD 프로젝트명/업무명 : 명절 시즌 라이브 판매 방송으로 매출 154% 견인 기간 : 2010년 9월 ~ 2020년 10월 (2개월) 성과 : 5000명의 관심고객 CRM 분석을 통한 명절 판매 방송으로 라이브 매출 1억 달성 역할 : 경쟁사 100개 상품조살르 바탕으로 3만원 대 세트 상품을 제안해 객단가 50% 증가 5000명 관심고객 대상으로 CRM 마케팅 진행으로 유입 300% 증가 100개 벤더사 분석을 통해 벤더사 선정으로 기획 단가 30% 절감 기술 : Jira, Data Studio, Slack 라이브 커머스 프로세스에 대한 이해 직무: 품질관리 프로젝트명/업무명 : 대만 공장 생산 가동 기간 : 2019.10 ~ 2020.10 (1년) 성과 : 신규 품질관리 시스템 구축을 통해 대만 공장 생산 제품 불량률 80% 감소 역할 : 불량품 100% 전수검사를 통해 완제품 결함 비용 30% 감소 반복되는 접착 결함 이슈 프로세스 개선을 통한 검사 시간 10% 감소 유효기간 만료된 완제품을 결함 테스트용으로 사용하여 악성 재고 70% 처리 불량품 데이터 100개 분석을 통해 생산 메뉴얼 개발 및 교육 불량 발생 원인 파악을 통해 신규 장비 구매로 생산비 3% 절감 기술 : QMS, ISO 9001 대만 법률에 대한 이해 직무: 재무회계 프로젝트명/업무명 : 분기 재무 실사 기획 및 분석 보고 기간 : 2022년 8월 ~ 2022년 10월 (3개월) 성과: 분기별 재고조사 총 10회 실시를 통해 재무 데이터 일치율 10%p 상승 역할 현장 재고조사를 통해 자료 오차율 0% 달성 실사 내역 분석을 통해 세무 증빙 업무 프로세스 변경 및 메뉴얼 교육 잘못 기재된 계정 70% 수정 재고관리 프로세스 개선을 통해 재고 관리 비용 10% 절감 기술 : ERP 자산 유형별 재무관리 법률에 대한 이해 경력 기술서 탬플릿 사용 가이드 기간 : 되게 중요한 부분. 꼭 번거롭지 않게 몇개월 한건지를 적어주자. 기간 : 2022.08 ~ 2022.10 (3개월) 성과 : > 경력기술서는 나의 소속과 직무를 적는 칸이 아니다. > 면접관은 근거를 토대로 지원자들의 합불을 가른다. > 그 근거로 결정적인 요소가 바로 성과이다. > 앞에서 아마추어와 프로페셔널의 차이를 노력을 강조하는가 결과를 강조하는가라고 설명했다. > 경력기술서의 성과를 작성하는게 바로 결과를 강조하는 행위이다. > 성과를 보고 지원자를 뽑고 싶은지를 결정한다고 해도 과언이 아니다. 성과는 간결하게 작성할수록 좋다. 반드시 한 줄로. How + Result. 아쉬운 예시 신규브랜드 런칭 100만원 달성 좋은 예시 브랜드 콜라보레이션을 통한 신재품 출시로 객단가 1.5배 상승 및 매출 300% 상승 수요 에측 오류 발견 및 로직 변경 통한 판매 순위 100위권 내 forecast accuracy 5% 상승 가장 중요한 부분. > 지원자들이 자주 하는 실수는 너무 많은 내용을 담으려는 것이다. > 성과는 자세함보다 핵심을 잘 표현했는가가 중요하다. 역할 : 어떻게 성과를 달성했는지를 나타내는 부분. > 역할이라고 적었지만 사실은 전략이라고 표현하는 것이 더 적합하다. 문제를 해결한 액션 생산성을 높인 액션 의사소통을 잘한 액션 > 역할을 훨씬 엣지있게 작성하는 방법이 있다. > 각 액션들에 수치화를 가미하는 것이다. 아쉬운 예시 역할 : 제품 콘셉트와 스토리보드 도출, 시장분석 -> 당연히 해야하는 일들을 적고 있음 성과 : 신제품 출시를 통해 고객만족도 100% 상승 역할 : 해외 플랫폼 시장 마케팅 방안 조사 경쟁사 콘텐츠를 벤치마킹해 제품 랜딩 페이지 리뉴얼 및 광고 소재 기획 마케팅 성과 분석 -> 신제품 출시라는 액션이 모호하기 때문에, 역할이 성과와 연결되어 보이지 않는다. 각 역할도 수치화가 되지 않아서 당연한 업무 활동으로 해석된다. 역할에 기술된 내용이 성과에 어떤 영향을 주었는지 수치로 설명해보자. 좋은 예시 역할 : 기존 프로세스 분석을 통한 생산관리 프로세스 로직을 설게하여 불량품 검증 자동화 기능 개발 불량품 검증 자동화 시스템 개발을 통해 불량품 검사 시간 300% 단축 제품별, 고객사별 100가지 불량품 케이스 분석을 통해 테스트 데이터를 만들어 불량품 검사 비용 30% 절감 -> 문제를 해결한 핵심 액션과 생산성을 높인 액션을 숫자를 근거로 정확하게 나타냈다. 역할 : 신규 유입자 30%가 랜딩 페이지 체류시간이 10초 이내인 점을 분석 홈페이지 유입자 5000명 데이터 분석으로 랜딩 페이지 개선안 도출 A/B 테스트로 개선안 디자인 검증을 통해 클릭률 높은 문구, 버튼 위치 파악 변경된 랜딩 페이지로 연계 매출 100% 증가 -> 히트맵 분서기라는 분명한 액션이 있고 역항에 기술된 내용이 연결된다. 역할에 기술된 내용이 성과에 어떤 영향을 주었는지 숫자로 잘 표현되어 있다. > 역할을 적을 때 가장 피해야 할 일은, 당연히 해야 하는 일들을 나열하는 것이다. > 목표와 상관없이 반복하는 일들은 적을 필요가 없다. 기술 : > 내가 지원하는 회사의 정보를 파악하여 그에 맞게 작성하는 것 필수적인 건 아님 경력기술서 체크리스트 기관, 성과, 역할, 획득 기술을 작성하였는가? 성과를 서술형이 아닌 개조식으로 작성하였는가? 핵심적인 내용 외에 다른 내용이 많지는 않은가? 해석이 필요 없는 객관적이고 직관적인 숫자 혹은 결과물로 작성하였는가? 성과를 달성하기 위한 나의 역할을 3-5가지로 기재했는가? 지원하는 직무, 산업, 회사와 일치도가 떨어지는 경력 내용을 제거하였는가? 경력 기술서에 기술한 경력수가 총 경력기간 / 2 보다 많은가?"
  },
  {
    "id": "Self_Development/Career/Resumes/25-07-29-hyundai-autoever-ml-engineer-resume",
    "title": "[탈락!] Hyundai Autoever - ML Engineer Resume",
    "date": "2025-07-29",
    "excerpt": "현대자동차 이력서",
    "category": "Career",
    "tags": [
      "현대자동차 채용공고",
      "이력서"
    ],
    "content": "채용공고와 분석내용 필요한 경험만 살려서 짧고 굵게 쓰기. 2장정도 분량 필살기? 유사경험 🔍 이런 분과 함께 하고 싶어요 -> 검색 / 챗봇 관련 데이터 구축 및 서비스 개발 경험 프로젝트명: 챗봇 시스템 개발 및 서비스 운영 기간: 2024.11 ~ 2025.02 (4개월) 성과: RAG 파이프라인 구현 및 최적화로 기존 상담 중 65% 대체 및 사용자 만족도 90% 이상 달성 역할: 쿼리 분해 및 재작성, 하이브리드 검색 기반 RAG 파이프라인 구축으로 검색 정확도 90% 이상 달성 질문 분류 모델 도입으로 불완전 응답률을 낮춰 사용자 불만 70% 감소 프롬프트 엔지니어링(Instruct, Role, Context 기반) 최적화로 상담 톤의 자연스러운 응답 생성 및 답변 정확도 90% 이상 달성 Qdrant 벡터 데이터베이스 구축 및 운영, 메타데이터 기반 필터링 시스템 구현으로 검색 성능 40% 향상 LLM 기반 대화 품질 자동 평가 시스템 구축으로 모니터링 비용 80% 감소 카카오톡 채널 연동을 통한 실제 병원 상담 서비스 운영으로 기존 상담 중 65% 챗봇 대체 기술: Python, FastAPI, Transformers, Qdrant, Docker, AWS RAG 시스템 아키텍처, 벡터 데이터베이스 구축 및 운영, 챗봇 서비스 품질 관리 프로세스에 대한 이해 --- 데이터 품질 검증 프로세스 경험자 프로젝트명: OCR 파이프라인 시스템 구축 및 데이터 품질 검증 프로세스 개발 기간: 2024.08 ~ 2024.10 (3개월) 성과: OCR 파이프라인 최적화로 정확도 99% 달성 및 에러율 1% 미만 운영, 자동화된 데이터 검증 시스템 구축으로 모니터링 자동화 역할: 이미지 위치 고정 특성을 활용한 전처리 및 text recognition 특화 모델 도입, 후처리 로직 구현으로 OCR 정확도 99% 달성 이미지 송수신부터 OCR 처리, DB 적재까지 각 단계별 에러 처리 시스템 구축 및 객체 지향 설계를 통해 에러율 1% 미만 달성 및 유지보수 효율 10배 증가 모델 정확도 및 데이터 품질 모니터링 자동화를 위해 통계적 분포 모니터링 시스템 구축으로 품질 검증 프로세스 개발 고객번호 등 일관성 검증 로직 개발 및 데이터 무결성 검증 프로세스 구축 자동 모니터링 시스템 개발로 각 객체별 실시간 품질 모니터링 자동화 기술: Python, Transformers, OpenCV, gRPC, FastAPI, Triton Server, Docker OCR 데이터 품질 검증 프로세스, 실시간 모니터링 시스템 운영, 단계별 에러 처리 및 객체 지향 설계를 통한 시스템 아키텍처에 대한 이해 --- 딥러닝 모델링 경험자 프로젝트명: 당뇨병성 망막병증 병변 탐지 모델링 및 서비스 개발 기간: 2024.04 ~ 2024.07 (4개월) 성과: Contrastive Learning 및 Multi-Task Learning 적용으로 기존 모델 대비 일반화 성능 10% 이상 향상 및 Dice Score 0.8 달성 역할: U-Net 기반 segmentation 모델 설계 및 최적화를 통해 기존 대비 성능 10-15% 향상 CLAHE 전처리 기법 적용으로 데이터 특징 명확화을 통해 민감도 10% 향상 Contrastive Learning과 Multi-Task Learning을 활용해 제한된 데이터(1,500개) 환경에서 모델 일반화 성능 10%이상 개선 Triton Server를 통한 고성능 모델 서빙 시스템 구축으로 추론 속도 20% 향상 기술: U-Net, OpenCV, CLAHE, PyTorch, Contrastive Learning, Multi-Task Learning, Triton Server, TensorRT, gRPC 제한된 데이터 환경에서의 일반화 성능 향상 방법론 및 모델 서빙 시스템에 대한 이해 --- 사전질문 (선택) 이력서 내용 외에 추가적으로 설명하거나 어필하고자 하는 내용이 있으시면 자유롭게 작성 부탁드립니다. (최대 1,000자) 안녕하세요! 저는 데이터과학자로서 일하면서 챗봇 개발부터 수술 경과 예측 모델 개발까지 다양한 데이터를 다루며 다양한 서비스를 개발하고 운영하는 경험을 하면서 즐겁게 일을 하고 있습니다. 서비스를 개발하고 모델을 만들면서 가장 많이 시간을 쓰는 부분은 역시 데이터를 수집하고 정제하는 과정인 것 같습니다. 특히 데이터 품질을 관리하는 일은 가장 많은 노력을 쏟는 일입니다. 이상치는 어떻게 정의할 것이며 어떻게 처리할 것인지와 데이터 안에 존재하는 노이즈는 어떻게 관리해야하는지 등등 많은 고민과 시행착오 끝에 하나씩 해결해 나가는 과정을 경험했습니다. 그리고 제가 구축한 OCR 파이프라인을 통해서 수집한 데이터와 그 외에 수집되는 데이터들을 데이터 웨어하우스에 적재하고 이를 정제해 데이터 마트와 피처 스토어를 개발하는 경험을 하며 데이터를 효율적으로 다루기 위한 시스템을 설계하는 법을 배울 수 있었습니다. 새로운 기술이나 개념을 배워 서비스에 적용하며 문제를 해결하는 일은 꽤나 설레는 일이라고 생각합니다. segmentation 모델을 개발하면서 데이터 부족 문제를 해결하기 위해 contrast learning과 multi-task learning에 대한 개념을 공부하고 논문들을 참고해 모델을 개발하고 최적화하는 경험을 했습니다. 그리고 최적의 렌즈 사이즈를 추천해주는 서비스를 개발하면서 예측 모델의 선택 문제에 가지는 한계점을 극복하기 위해 인과추론에 대해 공부했고, 이를 서비스에 적용한 경험을 했습니다. 그 외에도 다른 프로젝트에서도 프로젝트를 진행하면서 막히는 문제를 해결해나가는 경험은 꽤나 즐겁고 재미있었습니다. 이처럼 저는 길지 않은 기간이지만 다양한 프로젝트를 경험하며 많은 문제를 마주했고 새로운 기술을 이해하고 활용하면서 이를 해결하는 경험을 하고 있습니다. 후기 떨리는 구만... 일단 기대는 0... 떨어지면 떨어지는거지 뭐 ㅎ.ㅎ 결과 -> 탈락 1차에서 계속 떨어지는구만.. 왜 떨어지는걸까? [Tech] Machine Learning Engineer - AI 데이터 사이언티스트 서류전형 결과를 안내드립니다. 안녕하십니까, 현대오토에버입니다. 당사 채용에 관심을 가지고 귀한 시간을 내주셔서 감사드립니다. 김민규님께서는 아쉽게도 이번 전형에 불합격하셨습니다. 다음번에 더 좋은 인연으로 만나뵙길 희망하며, 앞으로 하시는 일 모두 건승하시길 바랍니다. 감사합니다."
  },
  {
    "id": "Self_Development/Career/Job Transition/25-07-29-hyundai-autoever-ml-engineer",
    "title": "Hyundai Autoever - ML Engineer",
    "date": "2025-07-29",
    "excerpt": "현대자동차 채용공고 분석과 준비과정",
    "category": "Career",
    "tags": [
      "현대자동차 채용공고"
    ],
    "content": "채용공고 <details> <summary>📋 <strong>채용공고 상세정보</strong></summary> 링크 [Tech] Machine Learning Engineer - AI 데이터 사이언티스트 📃 누구나 마음 속에 이력서 한 장은 있으니까, ⚡ 1분 컷 지원으로 현대오토에버로의 여정을 시작하세요. (이력서 자율양식) ✅ AI ​데이터 ​사이언티스트 🚀 합류하실 ​팀을 ​소개해요 인공지능기술실은 ​AI 신기술을 바탕으로 ​전사 ​AI 주제를 리드하며 ​공통 ​활용 ​기술에 대해 다룹니다. ​연구개발을 통해 ​'살아있는 ​AI' 기술을 ​만들어 사내 ​주요 ​서비스 및 제품이 ​더욱 경쟁력 ​있도록 만들어 갑니다. 음성/언어, 비전/인지 등 폭넓은 AI 주제 전반을 다루고 있으며, 개발 결과는 우리 회사 및 그룹의 중요 서비스에 적용되고 있습니다. AI 신기술에 대한 이해와 AI 모델 연구개발 역량을 바탕으로 미래 모빌리티 및 유관 분야의 주인공이 될 개발자/연구자 분들을 모십니다. 💻 합류하시면 함께 할 업무예요 AI 대화형 서비스를 위한 데이터 분석 및 설계 프롬프트 엔지니어링 / 데이터 증강 AI 대화형 서비스 데이터 관련 운영 및 품질 관리 🔍 이런 분과 함께 하고 싶어요 검색 / 챗봇 관련 데이터 구축 및 서비스 개발 경험 NLP 관련 Task 데이터 구축 및 설계 경험 Python 개발 경력 1년 이상 혹은 그에 준하는 실력 🔍 이런 분이라면 더욱 좋아요 전산언어학/자연어처리 전공 석사 이상 LLM 기반 프롬프트 엔지니어링 경험자 LLM / GPT 기반 데이터 증강 경험자 딥러닝 모델링 경험자 데이터 품질 검증 프로세스 경험자 ⌛ 이렇게 합류해요 서류 접수 → 서류 검토 → 직무역량테스트(코딩 또는 과제테스트) 및 인성검사 → 1차면접 → 2차면접 → 처우협의 및 채용검진 → 최종 합격🎉 📍 만나게 될 근무지는 여기예요 서울 강남 📣 동료의 한 마디 인공지능기술실의 기둥 L책임입니다. 우리 팀은 자율성이 특징이에요. 서비스에서부터 제조/생산까지, 기술이 적용되는 분야가 다양하고 또 팔로업 해야 하는 주제가 광범위하다 보니 자율성을 기반으로 성장을 지원하고 있어요. 전반적인 분야를 잘 아는 멘토들이 있어 많은 도움을 받고 있고, 또 각 분야별 주제에 따라 활발한 자율적 학습 그룹 구성을 통해 업무 외에 역량적 성장을 꾸준히 하고 있답니다 :) 연구개발 결과는 그룹 서비스나 제품에 반영되기도 하고, 관련 학회나 행사 등에 초대를 받아 발표하기도 해요. 사무실은 삼성역 인근에 있고, 롯데타워가 조망되는 뷰도 환경적 장점이랍니다! 함께 신기술을 공부하고 구체적 결과가 있는 실질적 기술 응용 경험을 통해 커리어적으로 성장하고 싶은 분들을 기다리고 있어요! (팀 리더) 인공지능기술실은 신기술에 대한 이해와 활용을 통해 문제를 해결하는 열정을 가진 사람들로 구성되어 있습니다. AI를 위한 인프라, 데이터, 분석 모델링 및 알고리즘, 기술 기반 공통 서비스 개발까지 다양한 분야를 다루며, 이런 노력을 바탕으로 그동안 의미 있고 결과들을 만들어내고 있습니다. 주로 주요 각 분야 AI 프레임워크를 이용해 개발을 하며 Python 등의 언어를 주로 사용합니다. 우리 팀은 멀티모달 기반의 궁극적 AI 개발을 지향하고, 이를 통해 회사의 성장과 각 구성원의 커리어 성장을 함께 이룰 수 있습니다. 관심을 가지고 성공의 여정을 함께해 주세요! Join Us! 📌 참고해 주세요 채용 시 마감되는 상시 채용 공고로 운영되며, 채용 절차와 일정은 변동될 수 있어요. 사회적 배려 대상자(보훈 취업지원대상자, 장애인)는 관계 법령과 내규에 따라 우대해요. 모집 분야 및 담당 업무에 따라 영어 구술평가, 레퍼런스 체크, 또는 기타 전형이 실시될 수 있어요. 지원자의 경험과 역량을 고려하여 다른 포지션이 더 적합하다고 판단되는 경우 지원 분야가 변경될 수 있어요. 배치 부서 및 근무지는 회사 사정에 따라 변경될 수 있어요. 아래의 경우, 합격이 취소되거나 전형 진행에서 불이익을 받으실 수 있어요. 지원서가 사실과 다르거나 증빙이 불가할 경우 해외여행 결격 사유가 있는 경우 (남성의 경우, 회사가 지정한 입사일까지 병역 필 또는 면제 필요) 최종 합격 후 회사가 지정하는 입사일에 입사 불가한 경우 </details> 이력서 전략 필요경험 검색 / 챗봇 관련 데이터 구축 및 서비스 개발 경험 -> 챗봇 개발하고 서비스 운영해본 경험이 있음 선호 경험 딥러닝 모델링 경험자 데이터 품질 검증 프로세스 경험자 NLP task는 아니지만 segmentation 모델 개발 경험이랑 --- 🎯 필요 경험 (Must Have) 검색 / 챗봇 관련 데이터 구축 및 서비스 개발 경험 ✅ Chatbot 프로젝트: RAG 기반 지능형 챗봇 시스템 개발 및 서비스 운영 ✅ 실제 서비스: 카카오톡 채널을 통한 병원 상담 자동화 서비스 🌟 선호 경험 (Nice to Have) 딥러닝 모델링 경험자 ✅ Computer Vision: OCR Pipeline에서 TrOCR 모델 활용 ✅ NLP: Chatbot에서 BGE-m3 임베딩 모델, GPT 기반 답변 생성 ✅ 모델 서빙: Triton Server, BentoML을 통한 프로덕션 배포 데이터 품질 검증 프로세스 경험자 ✅ 자동화된 품질 평가: LLM 기반 대화 품질 자동 평가 시스템 ✅ 실시간 모니터링: Slack 기반 에러 알림 및 작업 요약 ✅ 품질 지표 정의: 답변 출처 적합성, 질문-문서 연관성 평가 ✅ 임계치 기반 관리: 품질 점수 임계치 이하 시 자동 알림 ✅ 데이터 검증 로직: OCR 결과 정제, 수기 입력 데이터 완전성 검증 📋 포트폴리오 매칭도 요구사항 프로젝트 경험 수준 --------- --------- ---------- 챗봇 서비스 개발 Chatbot ⭐⭐⭐⭐⭐ 데이터 품질 검증 Chatbot + OCR ⭐⭐⭐⭐⭐ 딥러닝 모델링 OCR + Chatbot ⭐⭐⭐⭐ Python 개발 모든 프로젝트 ⭐⭐⭐⭐⭐ 🎯 강조 포인트 AI 대화형 서비스: 실제 병원 상담 챗봇 서비스 운영 경험 데이터 품질 관리: 자동화된 모니터링 시스템으로 품질 관리 프로세스 구축 프로덕션 배포: Docker, AWS, 온프레미스 환경에서 실제 서비스 운영 성과 지표: 사용자 만족도 90%+, 답변 정확도 95%+ 달성"
  },
  {
    "id": "Self_Development/English Study/SPEAK/지나간달/07-28-나망치면어떡하지",
    "title": "나망치면 어떡하지?",
    "date": "2025-07-28",
    "excerpt": "나망치면 어떡하지?",
    "category": "English Study",
    "tags": [
      "영어공부꾸준히!",
      "SPEAK"
    ],
    "content": "--- 배운거 ~하면 어쩌지? ~면 어떻게 할거야. What if I mess up? What if the flight is delayed? What if + 과거형 -> 현재와 일치하고 있지 않은 상황을 가정 What if you were in Seoul? What if he weren't married? (현재와 다른 가정을 할 때는 무조건 were을 씀) What would you do if you were in Seoul? anxious 간단한 작문 I think that what if questions are good to check value-thinking (가치관). What if I got a lot of money? Will I work continue? It then, it means I love my job. What would I do If I were fluent in English? This imaginations make me more 명확하게. --- 수정된 버전 I think that \"what if\" questions are good for checking values and priorities. What if I got a lot of money? Would I continue working? If so, it means I love my job. What would I do if I were fluent in English? These imaginations help me think more clearly. --- 피드백 문법 수정사항: \"what if questions\" → \"what if\" questions (따옴표 추가) \"check value-thinking\" → \"check values and priorities\" (더 자연스러운 표현) \"Will I work continue?\" → \"Would I continue working?\" (조건문에서는 would 사용) \"It then\" → \"If so\" (더 자연스러운 표현) \"What would I don\" → \"What would I do\" (오타 수정) \"This imaginations\" → \"These imaginations\" (복수형에 맞는 지시사) \"make me more 명확하게\" → \"help me think more clearly\" (영어로 완전히 표현) 표현 개선사항: \"value-thinking\" 대신 \"values and priorities\" 사용 \"It then\" 대신 \"If so\" 사용하여 더 자연스럽게 연결 마지막 문장을 더 구체적이고 명확하게 표현 전체적인 피드백: 조건문을 사용한 가치관 탐구라는 좋은 아이디어입니다! 문법적으로 몇 가지 수정이 필요했지만, 핵심 메시지는 잘 전달되고 있습니다. 특히 \"What if\" 질문을 통해 자신의 진짜 가치관을 파악하는 방법은 매우 효과적인 학습법입니다."
  },
  {
    "id": "Data Science/Engineering/회사에서하는고민_효율적인ML구조",
    "title": "효율적인 ML 구조 설계는 어떻게 하는걸까?",
    "date": "2025-07-28",
    "excerpt": "효율적인 ML 구조 설계에 대한 고민",
    "category": "Engineering",
    "tags": [
      "MLOps",
      "System Design"
    ],
    "content": "사수가 없는 회사에서 일을 하다보니 실제로 서비스를 운영하면서 맞닥뜨리는 문제들을 어떻게 해결하는게 좋은지에 대한 고민이 늘 생긴다. 이를 해결하기 위해 Designing Machine Learning Systems 책을 읽고 공부하면서 적용해보려고 한다. 읽을 책들 Designing Machine Learning Systems Machine Learning System Design Interview AI Engineering Designing Data-Intensive Applications 회사의 use case별로 ML을 어떻게 배포하고 있는지. 아키텍처 어떻게 설계할지. 고민했던 부분 포트폴리오로도 녹여내자."
  },
  {
    "id": "Data Science/Engineering/Designing Machine Learning Systems/ch3_데이터엔지니어링기초",
    "title": "데이터 엔지니어링 기초",
    "date": "2025-07-28",
    "excerpt": "데이터 엔지니어링 기초",
    "category": "Engineering",
    "tags": [
      "MLOps",
      "System Design",
      "Designing Machine Learning Systems"
    ],
    "content": "> 프로덕션용 ML 시스템을 구축하려면 증가하는 데이터를 수집, 처리, 저장, 검색 및 처리하는 방벙ㅂ을 숙지해야 합니다. > 시스템 관점의 데이터 엔지니어링을 더 자세히 알고 싶다면 마틴 클레프만의 \"데이터 중심 애플리케이션 설계\"를 읽어보기 바랍니다. 데이터 중심 애플리케이션 설계 데이터 소스 --- > ML 시스템은 다양한 소스에서 온 데이터로 작동합니다. > 데이터마다 특성, 목적, 처리 방법이 다르며 데이터 소스를 파악하면 데이터를 보다 효율적으로 사용하는데 도움이 됩니다. user input data system-generated data 데이터 포맷 --- JSON CSV (행 우선) Parquet (열 우선) 행 우선인 데이터에 행으로 접근하면 빠르고, 열 우선 데이터에 열로 접근하면 빠르다. 데이터 모델 --- 데이터가 어떻게 표현되는지 관계형 모델 : > 관계형 모델에서는 데이터는 관계 (relation)로 구성되며 각 관계는 튜플의 집합입니다. > 관계는 순서가 없습니다. 관계에서 행의 순서나 열의 순서를 섞더라도 여전히 동일한 관계입니다. 정규화하는 편이 좋다. 정규화를 통해 데이터 중복을 줄이고 데이터 무결성을 향상 다만, 데이터가 분산되어 관리되고 조인 비용 등이 증가. > 관계형 데이터 모델을 기반으로 구축된 데이터베이스를 관계형 데이터베이스라고 합니다. 쿼리 언어. SQL. > 주목해야 할 점은 SQL이 선언적 언어라는 사실입니다. > 명령형 언어인 파이썬과 대비되죠. 선언적 언어 (Declarative Language) -> 무엇을 원하는지를 표현하는 언어 (시스템이 자동으로 최적화 수행) 명령형 언어 (Imperative Language) -> 어떻게 원하는 것을 달성할지를 표현하는 언어 선언적 데이터 시스템에서 선언적 ML 시스템으로 : > 선언적 데이터 시스템이 성공한 데서 영감을 받은 많은 사람들은 선언적 ML을 기대해왔습니다. > 선언적 ML 시스템을 사용하면 사용자는 피처의 스키마와 작업만 선언하면 됩니다. > 그러면 시스템은 주어진 피처로 해당 작업을 수행하는데 가장 적합한 모델을 찾아냅ㄴ디ㅏ. ALudwig, AutoML. 모델 개발 부분은 많이 추상화되는 중. 그렇게 어려운 작업이 아니다. NoSQL : 스미카 관리에 대한 불만. > 비관계형 모델의 주요 유형 두 가지는 문서 모델과 그래프 모델입니다. 문서 모델 그래프 모델 > 데이터 모델에 따라 수행하기 쉬운 쿼리가 있고 어려운 쿼리가 있습니다. > 따라서 애플리케이션에 적합한 데이터 모델을 선택하는 것이 바람직하죠. 정형 데이터 vs 비정형 데이터 정형 데이터는 스키마를 따른다. > 정형 데이터를 저장하는 저장소를 데이터 웨어하우스라고 하며 비정형 데이터를 저장하는 저장소를 데이터 레이크라고 합니다. > 데이터 레이크는 읿나적으로 처리 전 원시 데이터를 저장하는데 사용하며 데이터 웨어하우스는 사용 가능한 형식으로 처리된 데이터를 저장하는데 사용됩니다. 데이터 스토리지 엔진 및 처리 --- 트랜잭션 처리와 분석 처리 : transaction : 온갖 종류의 작업 생성될 때 삽입되고 변경될 때 업데이트 되면 필요하지 않으면 삭제됨. OLTP (Online Transaction Processing) > 트랜잭션 데이터베이스는 온라인 트랜잭션을 처리하고 낮은 레이턴시와 고가용성 요구 사항을 충족하도록 설계됐습니다. ACID (Atomicity, Consistency, Isolation, Durability) Atomicity(원자성) : > 트랜잭션의 모든 단계가 하나의 그룹으로서 성공적으로 완료되도록 보장합니다. Consistency(일관성) : > 들어오는 모든 트랜잭션이 미리 정의된 규칙을 따라야 함을 보장합니다. Isolation(격리성) : > 두 트랜잭션이 마치 격리된 것처럼 동시에 발생하도록 보장합니다. Durability(지속성) : > 트랜잭션이 커밋된 후에는 시스템 장애가 발생하더라도 커밋된 상태를 유지하도록 보장합니다. 트랜잭션 데이터베이스는 행 우선일 때가 많음 -> 분석에 적절하지 않을 수 있음 OLAP (Online Analytical Processing) 분석에 더 적절한 database. 열 조회에 최적화 됨. 요즘은 구분해서 이야기안함. 둘 다 지원하는 경우가 많아서. ETL: Extract, Transform, Load : > ETL은 데이터를 범용 처리 및 원하는 모양과 포맷으로 집계함을 의미 <figure> <img src=\"/post/DesigningMachineLaerningSystem/ETL.webp\" alt=\"ETL Process\" /> <figcaption> 출처: <a href=\"https://www.getdbt.com/blog/etl-vs-elt\" target=\"_blank\" rel=\"noopener noreferrer\">https://www.getdbt.com/blog/etl-vs-elt</a> </figcaption> </figure> ELT: Extract, Load, Transform > 데이터를 먼저 스토리지에 적재한 뒤 나중에 처리하는 프로세스 <figure> <img src=\"/post/DesigningMachineLaerningSystem/ELT.webp\" alt=\"ELT Process\" /> <figcaption> 출처: <a href=\"https://www.getdbt.com/blog/etl-vs-elt\" target=\"_blank\" rel=\"noopener noreferrer\">https://www.getdbt.com/blog/etl-vs-elt</a> </figcaption> </figure> 데이터플로 모드 --- > 데이터가 한 프로세스에서 다른 프로세스로 전다로딜 때 데이터가 한 프로세스에서 다른 프로세스로 흐른다고 합니다. > 즉, 데이터 플로가 생깁니다. 데이터베이스를 통한 데이터 전달 서비스를 통한 데이터 전달 (REST, RPC API에서 제공하는 요청) 실시간 전송을 통한 데이터 전달 (아파치 카프카, 아마존 키네시스)"
  },
  {
    "id": "Data Science/Engineering/Designing Machine Learning Systems/ch2_머신러닝시스템설계소개",
    "title": "머신러닝 시스템 설계 소개",
    "date": "2025-07-28",
    "excerpt": "머신러닝 시스템 설계 소개",
    "category": "Engineering",
    "tags": [
      "MLOps",
      "System Design",
      "Designing Machine Learning Systems"
    ],
    "content": "ML 시스템 설계는 어떻게 하는걸까? MLOps에 시스템으로 접근 > 시스템을 비즈니스용으로 개발한다면 비즈니스 목적에 따라 업무를 추진해야 하며, 비즈니스 목적은 다시 ML 목적으로 바꿔서 ML 모델 개발의 이정표로 삼아야 합니다. 가장 중요하게 생각하는 부분. 비즈니스 목적을 이해하기 이에 맞게 ML 목적을 세우는 과정. 신뢰성, 확장성, 유지보수성, 적응성 비즈니스와 머신러닝의 목적 --- > 사실 기업들은 대부분 이런 화려한 ML 지표에 크게 관심이 없습니다. > 비즈니스 지표에 영향을 주지 않는 한 모델 정확도를 94%에서 94.2%로 높이는 일 따위에 신경쓰지 않죠. > 비즈니스 조직 내에서 ML 프로젝트가 성공하려면 ML 시슴템 성과를 전체적인 비즈니스 성과와 연결해야 합니다. > 신규 ML 시스템은 광고 수익, 월간 활성 사용자 수 등 어떤 비즈니스 성과 지표에 영향을 미칠까요? > 많은 회사에서 비즈니스 지표를 ML 지표에 연결하기 위해 자체 지표를 만듭니다. 넷플릭스 - 추천시스템. 채택률 (take-rate) 영상 재생 횟수 / 사용자가 본 추천 썸내일 개수 추천시스템의 채택률을 다른 비즈니스 지표, 예컨대 총 스트리밍 시간이나 구독 취소율의 맥락에서도 고려. 실제 비즈니스에 어떤 영향을 미치는지 확인하기 위한 시도들. -> 넷플릭스는 새로운 평가지표를 계산 직접적으로 파악하는건 꽤나 어렵고 많은 실험이 필요함 대안으로 A/B test를 진행해 어떻게 연관되는지는 모르지만, 비즈니스 목표 관점에서만 분석해볼 수도 있음 > 많은 기업에서 'AI 기반'이라는 문구가 고객 유치에 도움이 되기 때문에 ML을 사용한다고 이야기합니다. > AI가 실제로 유용한지는 상관없이 말이죠. ML이 마법같은 변화를 가져올 수는 있지만, 하루아침에 되는건 절대 아니다. 비즈니스 관점으로 ML이 가져올 수익에 대해서 현실적으로 생각해야 함. > ML 관련한 투자 수익은 도입 이후 성숙 단계에 다다라서야 눈에 띄기 시작합니다. > ML을 도입한 기간이 길수록 파이프라인이 효율적으로 실행되고 개발 주기가 빨라지며 엔지니어링 시간과 클라우드 비용이 줄어들어 수익이 높아지게 됩니다. 머신러닝 시스템 요구 사항 --- ML 시스템이 갖춰야 하는 요구사항 신뢰성 : > ML 시스템은 '시스템 동작의 올바름'을 판단하기 쉽지 않습니다. 실제 상황에서는 정답이 없는데, 틀렸다는 사실을 어떻게 파악할 수 있을까? 확장성 : > ML 시스템은 다양한 방식으로 확장 가능합니다. > 시스템 복잡도가 증가하든, 트래픽 양이 증가하든, ML 모델 개수가 증가하든 상관없이 규모 증가를 처리할 합리적인 방법이 필요합니다. resource scaling. artfiact managment. 유지보수성 : > 워크로드를 구조화하고 인프라를 설정하는 일이 중요합니다. 적응성 : > 시스템은 변화하는 데이터 분포와 비즈니스 요구 사항에 적응할 수 있어야 합니다. > 그러려면 성능 향상에 영향을 주는 요소를 찾아낼 수 있어야 하며 서비스 중단 없이 업데이트가 가능해야 합니다. > ML 시스템은 반은 코드이고 반은 데이터입니다. > 데이터는 빠르게 변화하므로 ML 시스템 또한 자체적으로 빠르게 진화할 수 있어야 하죠. 반복 프로세스 --- > ML 시스템 개발은 반복적이며 대부분 끝이 없는 프로세스입니다. > 시스템을 프로덕션 환경에 배포하면 지속적으로 모니터링하고 업데이트해야 합니다. 프로젝트 범위 산정 범위를 산정하고 목표, 목적과 제약사항을 설정하는 일 데이터 엔지니어링 ML 모델 개발 배포 > ML 시스템 개발은 글쓰기와 같습니다. 시스템은 결코 완벽히 완성되지 않습니다. > 하지만 어느 시점에는 시스템을 외부에 내보여야 합니다. 모니터링과 연속 학습 > 모델을 프로덕션 환경에 배포한 뒤에는 지속적으로 성능 저하를 모니터링하고 변화하는 환경과 요구 사항에 적응하도록 유지 관리해야 합니다. 비즈니스 분석 > 모델 성능을 비즈니스 목표 관점에서 분석해 비즈니스 인사이트를 추출합니다. 머신러닝 문제 구조화하기 --- > 고객 지원 속도가 느리다는 점은 문제지만 ML로 바로 풀 수 있는 문제는 아닙니다. > ML 문제는 입력과 출력, 학습 프로세스를 이끌어나가는 목적 함수로 정의됩니다. 분류 vs 회귀 이진분류 vs 다중클래스 분류 다중 클래스 vs 다중 레이블 분류 문제를 구조화하는 다양한 방법 : 문제: 사용자가 다음으로 열어볼 앱 예측하기 구조화 방법: 분류 -> 앱이 추가될 때마다 재학습을 해야하는 이슈 문제: 사용자가 다음으로 열어볼 앱 예측하기 구조화 방법: 회귀 입력으로 앱관련 피처를 넣어주고 열어볼 확률을 예측하는 문제로 정의하면, 다시 학습해야하는 소요가 줄어듬 지성 (mind) vs 데이터 (data) --- > 데이터보다 지성이 위위라고 생각하는 진영에는 튜링상 수상자인 주데아 펄 박사가 있습니다. > 펄은 인과 관계 추론과 베이즈 네트워크에 대한 연구로 잘 알려졌으며 그의 저서 인과성에 대해에 실린 서문 제목이 '데이터보다 우위인 지성'입니다."
  },
  {
    "id": "Data Science/Engineering/Designing Machine Learning Systems/ch1_머신러닝시스템개요",
    "title": "머신러닝 시스템 개요",
    "date": "2025-07-28",
    "excerpt": "머신러닝 시스템 개요",
    "category": "Engineering",
    "tags": [
      "MLOps",
      "System Design",
      "Designing Machine Learning Systems"
    ],
    "content": "> '머신러닝 시스템'이라고 하면 많은 사람이 로지스틱 회귀나 다양한 유형의 신경망 등 ML 알고리즘만 떠올립니다. > 그러나 프로덕션 환경에서 알고리즘은 ML 시스템의 일부일 뿐입니다. > 시스템은 ML 프로젝트의 출발점이 된 비즈니스 요구 사항, 사용자와 개발자가 시스템과 상호 작용하는 인터페이스, 데이터 스택, 모델을 개발 및 모니터링하고 업데이트하기 위한 로직은 물론 해당 로직을 전달할 수 있는 인프라를 포함합니다. ML을 사용해야하는 경우 (use case)는 언제인가? 사용하기 위해 필요한 것들은? 연구와 프로덕션 상황에서 머신러닝을 개발하는게 어떤 차이가 있는지에 대한 내용들. 연구는 연구 목표를 달성하기 위해 성능을 높이는 데에 목표가 있지만, 서비스를 운영할 때는 이해관계를 만족하고 비즈니스 목표에 맞는 모델을 개발하는 것이 목표. > ML 시스템은 다양한 요소로 구성된 복잡한 시스템입니다. > 프로덕션에서 ML 시스템을 작업하는 데이터 과학자와 ML 엔지니어는 ML 알고리즘에만 집중하는 걸로는 절대 충분치 않다는 사실을 깨달을 겁니다. > 알고리즘 외에 시스템의 다른 측면, 예컨대 데이터 스택, 배포, 모니터링, 유지 관리, 인프라에 관해 아는 것이 중요합니다. 내가 서비스를 구성한 후 이를 설명할 때도 내가 디자인한 시스템에 대해서, 이런 부분을 고려해 설명할 필요가 있겠다. 연구용 머신러닝 vs 프로덕션용 머신러닝 연구용 ML 프로덕션용 ML --- --- --- 요구사항 벤치마크 데이터셋에서 최적의 모델 성능 달성하기 이해관계자마다 다름 계산 우선순위 빠른 훈련, 높은 스루풋 빠른 추론, 낮은 레이턴세 데이터 정적임 끊임없이 변동함 공정성 중요하지 않은 경우가 많음 반드시 고려해야 함 해석 가능성 중요하지 않은 경우가 많음 반드시 고려해야 함 다양한 이해관계자와 요구사항 : > ML 시스템을 프로덕션에 적용하는 과정에는 많은 이해관계자가 얽혀 있으며 각각 요구 사항이 다릅니다. > 요구 사항들은 서로 충돌할 때도 많으므로 모든 요구 사항을 충족하는 ML 모델을 설계, 개발, 선택하기는 어려울 수 있습니다. 사용자 목표를 이해하고 목표가 여러개라면 쪼개서 각각의 모델을 만들 필요가 있다. 사용자 목표를 만족하지만 모델의 목표가 다를 수도 있고. > ML 프로젝트를 개발할 때 ML 엔지니어는 모든 이해관계자의 요구 사항을 파악하고 각각이 얼마나 엄격한지 이해해야 합니다. > 프로덕션용 ML은 연구용 ML과 요구사항이 다릅니다. 계산 우선순위 : > ML 시스템을 배포한 경험이 없는 분들은 시스템을 설계할 때 종종 모델 개발에만 너무 집중하고 배포와 유지 관리를 소홀히 하는 실수를 합니다. 연구에서는 학습단계가 병목이지만 배포 단계에서는 추론이 병목이다. > 한가지 결론은 연구에서는 높은 스루풋 (throughput)을 우선시 하는 반면에 프로덕션에서는 낮은 레이턴시를 우선시한다는 점입니다. > 레이턴시는 쿼리를 수신하고 결과를 반환하는데 걸리는 시간을 의미하며 스루풋은 특정 기간 내에 처리된 쿼리 수를 의미합니다. 스루풋(Throughput): 특정 시간 내에 처리할 수 있는 작업의 총량 레이턴시(Latency): 하나의 요청을 처리하는데 걸리는 시간 > 실험 단계에서 대량의 실험이 필요함. ``markdown 연구 시나리오: 하이퍼파라미터 튜닝: 1000개 조합 시도 모델 아키텍처 실험: 50가지 구조 테스트 데이터 증강 실험: 10가지 방법 비교 목표: 가능한 많은 실험을 빠르게 완료 → 스루풋이 중요 (시간당 처리할 수 있는 실험 수) ` > 프로덕션에서는 사용자 경험을 개선하고 비즈니스 임팩트를 줘야함. `markdown 실시간 서비스 시나리오: 추천 시스템: 사용자가 페이지 로드 후 100ms 내에 추천 제공 챗봇: 사용자 메시지에 2초 내에 응답 자율주행: 센서 데이터를 50ms 내에 처리 목표: 개별 요청을 빠르게 처리 → 레이턴시가 중요 (응답 시간) 예시: 이커머스 추천 시스템 레이턴시 100ms → 전환율 5% 레이턴시 500ms → 전환율 3% (40% 감소) 레이턴시 1초 → 전환율 1% (80% 감소) 결과: 1초 지연 = 매출 80% 감소 `` > 레이턴시는 개별 수치가 아닌 분포임을 기억합시다. 데이터 : > 프로덕션 단계의 데이터는 훨씬 더 복잡합니다. 잡음이 많고 비정형일 수 있으며 끊임없이 변화하죠. > 게다가 데이터가 편향됐을 수 있는데 어떻게 편향됐는지 모를 가능성이 큽니다. 진짜 raw data부터 다뤄본 경험이 꽤 많은데, 다 진짜 너무 더러웠다 ㅎ.ㅎ.. 공정성 : > 여러분 혹은 주변에 있는 누군가는 자신도 모르는 사이에 편향된 수학 알고리즘의 희생자일 수 있습니다. 해석 가능성 : > 산업계 대부분의 ML 유스 케이스에서 해석 가능성은 선택이 아닌 필수입니다. 머신러닝 시스템 vs 전통적인 소프트웨어 > 기존 SWE에서는 코드 테스트 및 버전 관리에만 집중하면 되지만 ML을 사용하면 데이터 또한 테스트하고 버전을 지정해야 합니다. > 프로덕션 환경에서 이러한 모델을 모니터링하고 디버깅하는 일 또한 사소하지 않습니다. > ML 모델이 복잡해지고 작업에 대한 가시성이 떨어짐에 따라 무엇이 잘못됐는지 파악하거나 문제가 발생했을 떄 신속하게 경고를 받기가 어렵습니다."
  },
  {
    "id": "Self_Development/English Study/SPEAK/지나간달/07-27-선태의상황에서_ReviewDay",
    "title": "선택의 상황에서 쓰는 표현들 Review Day",
    "date": "2025-07-27",
    "excerpt": "선택의 상황에서",
    "category": "English Study",
    "tags": [
      "영어공부꾸준히!",
      "SPEAK"
    ],
    "content": "배운 것들 One one hand One the other hand On one hand the note has really big screen. On the other the iPhone has a really good camera. On one hand, I havent had chinees food in a while. On the other hand, I'm craving fried chicken. Whether we eat Chinese food or fried chicken, we should order dilivery. The best thing about iPhone is its design. When it comes to online shopping, Amazon might be the best option. Although its a bit pricey, the bar has amazing view at night. Even though i`m not a big fan of animated films, I love Frozen. The dress is too expensive. It's pretty though. It's not about design. It's about performance. In which case, I'll probably go with the new Galaxy."
  },
  {
    "id": "Self_Development/Guitar/Practice Log/20250726_좋은밤좋은꿈",
    "title": "좋은밤 좋은꿈 인트로 연습",
    "date": "2025-07-26",
    "excerpt": "좋은밤 좋은꿈 인트로 부분 핑거스타일 아르페지오 연습",
    "category": "Practice Log",
    "tags": [
      "기타연습",
      "Guitar Practice",
      "Arpeggio"
    ],
    "content": "@audio좋은밤 좋은꿈 인트로 연습 뭔가 맛이 없다 ㅋㅋ F랑 Fm가 완벽하게 안누림 특히 3번줄이."
  },
  {
    "id": "Self_Development/Guitar/Practice Log/20250726_고백_스트로크",
    "title": "델리스파이스 고백 스트로크 연습",
    "date": "2025-07-26",
    "excerpt": "기타연습일지",
    "category": "Practice Log",
    "tags": [
      "기타연습",
      "Guitar Practice",
      "Strokes"
    ],
    "content": "@audio델리스파이스 고백 스트로크 연습 C#7이 잘 안잡힘. 특히 G#m -> C#7이 잘 안됨. 기타 톤은 낫배드한 듯? AC clean + front pickup + 싱싱싱"
  },
  {
    "id": "Self_Development/Guitar/Practice Log/20250726_love",
    "title": "웨이브 투어스 사랑으로 인트로 커버",
    "date": "2025-07-26",
    "excerpt": "기타연습일지",
    "category": "Practice Log",
    "tags": [
      "기타연습",
      "Guitar Practice"
    ],
    "content": "@audio웨이브 투어스 사랑으로 인트로 커버 확실히 녹음해서 들어보니까 끊기는 부분이 많이 들림. 박자 나가는 것도 보이고."
  },
  {
    "id": "Data Science/compare-vDB-libraries",
    "title": "VectorDB에 사용되는 라이브러리들 비교",
    "date": "2025-07-25",
    "excerpt": "챗봇 구현하면서 RAG 부분에 사용할 벡터화된 문서들을 관리할 DB들을 비교",
    "category": "Data Science",
    "tags": [
      "vector-database",
      "chatbot",
      "RAG"
    ],
    "content": "Qdrant vs ChromaDB vs FAISS vs Milvus DB 주요 특징 장점 단점 ------------ ---------------------------------------- -------------------------------------------------------------- -------------------------------------------------------------- Qdrant Rust 기반, 하이브리드 인덱스, API 다양 빠른 쿼리, 확장성, 메타데이터 필터링, 클라우드 지원 클러스터 관리 필요, 일부 고급 기능은 미흡 ChromaDB Python 기반, 내장형, LangChain 연동 쉬운 설치, 빠른 프로토타이핑, 파이썬 친화적, 실시간 검색 대규모 데이터/분산 미지원, 메모리 누수 이슈, 문서화 부족 FAISS Facebook 개발, 라이브러리, GPU 지원 매우 빠른 검색, 다양한 인덱스, 대규모 벡터 처리, 오픈소스 DB 아님(저장/운영 직접 구현 필요), 확장성/운영 자동화 미흡 Milvus 분산형, 클라우드/온프레미스, MLOps 연동 대규모 분산처리, 다양한 인덱스, RBAC 등 엔터프라이즈 기능 복잡한 배포(쿠버네티스 등), 리소스 요구 높음, 러닝커브 있음 --- Qdrant 특징: Rust로 개발된 오픈소스 벡터 DB. 하이브리드 인덱스(벡터+속성), 다양한 거리 측도(유클리드, 코사인 등), REST/gRPC API, 클라우드 및 온프레미스 지원. 장점: 빠른 쿼리 성능(HNSW, PQ 등 고급 인덱스) 메타데이터 기반 필터링(속성+벡터 동시 검색) 클러스터 확장성, 하이브리드 클라우드 지원 문서화 및 커뮤니티 활발 단점: 클러스터 관리/운영 복잡성 일부 고급 기능(예: 자동 클러스터링, 쿼리 리밸런싱 등) 미흡 추천 사용처: RAG, 추천시스템, 대규모 검색, 속성+벡터 동시 필터링이 필요한 서비스 ChromaDB 특징: Python 기반 내장형 벡터 DB. LangChain 등 LLM/RAG 파이프라인에 최적화. 내장 임베딩 모델, SQLite/ClickHouse 스토리지 지원. 장점: 설치/사용이 매우 간단, 빠른 프로토타이핑 파이썬 친화적(ML/AI 워크플로우와 연동 용이) 실시간 검색, 동적 메타데이터 필터링 LangChain, OpenAI API 등과 연동 쉬움 단점: 대규모 데이터/분산 미지원(싱글노드 한계) 메모리 누수 및 서비스 크래시 이슈(2024년 기준) 문서화/엔터프라이즈 기능 부족 추천 사용처: 소규모 RAG, LLM 실험, 빠른 프로토타입, 파이썬 기반 프로젝트 FAISS 특징: Facebook AI가 개발한 벡터 검색 라이브러리. 다양한 인덱스(HNSW, IVF, PQ 등), GPU 지원, 대규모 벡터 처리에 최적화. 장점: 매우 빠른 검색 속도(특히 GPU 활용 시) 다양한 인덱스/거리 측도 지원 대규모 벡터 데이터 처리에 강점 오픈소스, 커뮤니티 활발 단점: DB가 아니라 라이브러리(저장/운영 직접 구현 필요) 분산/확장성, 운영 자동화 미흡 메타데이터 필터링 등 DB적 기능 부족 추천 사용처: 대규모 벡터 검색 엔진 직접 구축, ML/AI 실험, GPU 기반 대용량 검색 Milvus 특징: 분산형 오픈소스 벡터 DB. 클라우드/온프레미스, 다양한 인덱스(HNSW, IVF 등), RBAC, MLOps 연동, 대규모 데이터 처리에 최적화. 장점: 대규모 분산처리(수억~수십억 벡터) 다양한 인덱스, GPU 가속 지원 엔터프라이즈 기능(RBAC, 감사로그, GDPR 등) MLOps, Grafana/Prometheus 등과 연동 단점: 복잡한 배포(쿠버네티스 등 인프라 필요) 높은 리소스 요구, 러닝커브 있음 소규모/단일 노드에는 과한 선택일 수 있음 추천 사용처: 대규모 RAG, 엔터프라이즈 검색, 보안/감사/확장성 중요한 서비스 --- 여러 회사/문서 그룹 구분 관리: 컬렉션/네임스페이스/파티션 비교 DB 데이터 분리 지원 분리 방식(컬렉션/네임스페이스 등) 멀티테넌시/권한관리 추천도(회사별 구분) ------------ ------------------ ------------------------------- -------------------- -------------------- Qdrant O 컬렉션(collection) O ★★★★☆ ChromaDB O 컬렉션(collection) X ★★☆☆☆ FAISS X(직접구현) 없음(코드로 인덱스 분리) X ★☆☆☆☆ Milvus O 컬렉션/파티션/네임스페이스 O ★★★★★ --- 실무/운영 관점에서의 추천 Qdrant: 컬렉션 단위로 회사A, 회사B 등 완전히 분리된 데이터 관리 가능. API/권한관리도 우수. 운영/확장성 모두 강점. Milvus: 컬렉션, 파티션, 네임스페이스 등 다양한 분리 방식 제공. 대규모 멀티테넌시, RBAC 등 엔터프라이즈 환경에 최적. ChromaDB: 컬렉션으로 구분은 가능하나, 싱글노드/내장형이라 대규모 운영에는 한계. 실험/소규모에 적합. FAISS: DB가 아니라 라이브러리라 데이터 분리/권한관리 직접 구현 필요. 운영/확장성 목적에는 비추천. 결론: 회사별, 프로젝트별 등 여러 그룹의 문서를 하나의 벡터 DB에서 안전하게 구분/운영하려면 Qdrant 또는 Milvus가 가장 적합합니다. (컬렉션/네임스페이스/권한관리 등 지원) ChromaDB는 소규모/실험에, FAISS는 직접 구현이 필요하므로 대규모 운영에는 부적합합니다. 멀티테넌시란? 멀티테넌시(Multi-tenancy)는 하나의 데이터베이스(혹은 시스템) 안에서 여러 사용자 그룹(회사, 조직, 프로젝트 등)이 서로의 데이터에 영향을 주지 않고 안전하게 분리된 공간에서 데이터를 관리할 수 있는 구조를 의미합니다. 테넌트(tenant): 하나의 고객, 회사, 조직, 프로젝트 등 독립적으로 데이터를 관리해야 하는 단위 멀티테넌시: 여러 테넌트(회사A, 회사B, …)가 한 DB 인스턴스를 공유하지만, 각 테넌트의 데이터는 완전히 분리되어 있고, 서로의 데이터에 접근하거나 영향을 줄 수 없음 벡터 DB에서의 멀티테넌시 예시 회사A와 회사B가 같은 Qdrant/Milvus 서버를 사용하지만, 회사A는 자신의 컬렉션/네임스페이스/파티션에만 접근 가능 회사B도 마찬가지로 자신의 데이터만 접근 가능 서로의 데이터는 절대 보거나 수정할 수 없음 권한 관리(RBAC), API 인증 등으로 보안도 보장 왜 중요할까? 운영비 절감: 회사마다 DB를 따로 띄우지 않아도 됨 보안/격리: 데이터가 섞이지 않고, 실수로도 접근 불가 확장성: 테넌트가 늘어나도 하나의 시스템에서 관리 가능 정리: 멀티테넌시는 “여러 회사/조직이 하나의 DB를 쓰더라도, 각자의 데이터가 완전히 분리·격리되어 안전하게 관리되는 구조”를 의미합니다. (SaaS 서비스에서 매우 중요한 개념!) 무료 서비스/오픈소스 여부 DB 오픈소스 자체 서버 무료 공식 클라우드 무료 플랜 비고 ------------ ---------- --------------- ------------------------ --------------------------- Qdrant O O O (Qdrant Cloud Free) 오픈소스, 클라우드 무료 티어(제한 있음) ChromaDB O O X 오픈소스, 자체 서버만 지원 FAISS O O X 오픈소스 라이브러리, 클라우드 없음 Milvus O O O (Zilliz Cloud Free) 오픈소스, Zilliz Cloud 무료 티어(제한 있음) --- 상세 설명 Qdrant 오픈소스(무료)로 직접 서버 운영 가능 공식 Qdrant Cloud에서 무료 플랜(제한적 용량/쿼리) 제공 ChromaDB 오픈소스(무료)로 직접 서버 운영만 가능 공식 클라우드 서비스/무료 플랜 없음 FAISS 오픈소스(무료) 라이브러리 클라우드 서비스 없음(직접 서버/코드로만 사용) Milvus 오픈소스(무료)로 직접 서버 운영 가능 공식 Zilliz Cloud에서 무료 플랜(제한적 용량/쿼리) 제공 --- 정리: 4개 모두 오픈소스라 직접 서버를 띄우면 무료로 사용 가능 Qdrant, Milvus는 공식 클라우드에서 무료 플랜도 제공 ChromaDB, FAISS는 클라우드 서비스가 없고, 직접 설치/운영만 가능 --- Qdrant vs ChromaDB 컬렉션의 차이 항목 Qdrant 컬렉션 ChromaDB 컬렉션 --------------------- ------------------------------------- ---------------------------------- 분리 수준 완전 분리(물리적/논리적) 논리적 분리(내장 DB 내 테이블) 확장성 분산/클러스터 지원, 대규모 운영 가능 싱글노드, 대규모 운영 한계 보안/권한관리 컬렉션 단위 권한/RBAC 지원 컬렉션 단위 권한관리 미흡 운영 신뢰성 장애 격리, 데이터 손상 최소화 전체 DB 장애 시 모든 컬렉션 영향 API/관리도구 REST/gRPC 등 공식 API, 관리도구 풍부 파이썬 API 위주, 관리도구 제한적 백업/복구 컬렉션 단위 백업/복구 지원 전체 DB 단위 백업/복구 멀티테넌시 엔터프라이즈급 멀티테넌시 구현 용이 실험/소규모 멀티테넌시에 적합 상세 설명 Qdrant 컬렉션이 완전히 분리된 데이터베이스처럼 동작합니다. 각 컬렉션은 별도의 인덱스, 설정, 권한, 백업/복구가 가능합니다. 대규모 서비스, 멀티테넌시, 보안이 중요한 환경에 적합합니다. 장애가 나도 한 컬렉션만 영향받고, 나머지는 정상 동작합니다. ChromaDB 컬렉션은 논리적 분리(테이블 수준)로, 하나의 내장 DB 파일에 여러 컬렉션이 들어갑니다. 싱글노드 기반이라 대규모 운영, 장애 격리, 권한 분리에는 한계가 있습니다. 실험, 소규모 서비스, 빠른 프로토타입에는 충분히 유용합니다. Qdrant vs Milvus 비교 항목 Qdrant Milvus --------------------- ---------------------------------------------- --------------------------------------------- 개발 언어/엔진 Rust 기반, 경량/고성능 C++/Go 기반, 대규모 분산 아키텍처 아키텍처 싱글노드/클러스터 모두 지원, 경량화 분산형(클러스터 전용), 대규모 확장성 설치/운영 설치/운영 간단, 로컬/클라우드 모두 용이 쿠버네티스 등 인프라 필요, 복잡한 배포 확장성 중~대규모까지 무난, 클러스터 지원 초대규모(수억~수십억 벡터) 분산처리 최적화 API/언어 지원 REST/gRPC, Python 등 다양한 언어 지원 REST/gRPC, Python/Java/Go 등 다양한 언어 지원 인덱스/검색 HNSW, PQ 등 고성능 인덱스, 하이브리드 검색 HNSW, IVF, DiskANN 등 다양한 인덱스 메타데이터/필터 벡터+속성 동시 필터링(하이브리드 검색 강점) 벡터+속성 동시 필터링, 복잡한 쿼리 지원 권한/보안 컬렉션 단위 권한, RBAC(클라우드) RBAC, 감사로그, GDPR 등 엔터프라이즈 기능 멀티테넌시 컬렉션 단위 완전 분리, 멀티테넌시 용이 네임스페이스/컬렉션/파티션 등 분리, 엔터프라이즈급 클라우드 서비스 Qdrant Cloud(무료/유료 플랜) Zilliz Cloud(무료/유료 플랜) 커뮤니티/문서 활발, 문서/가이드 풍부 활발, 엔터프라이즈 문서/사례 풍부 추천 사용처 RAG, 추천시스템, 중~대규모 서비스, 빠른 구축 초대규모 검색, 엔터프라이즈, 보안/감사 필수 환경 실무적 선택 포인트 Qdrant 설치/운영이 쉽고, 중~대규모 서비스에 적합 빠른 프로토타이핑, RAG, 추천시스템, 속성+벡터 동시 필터링이 중요한 서비스 클라우드/온프레미스 모두 유연하게 사용 가능 대규모 분산이 꼭 필요하지 않다면 Qdrant가 더 간편 Milvus 초대규모(수억~수십억 벡터) 데이터, 분산처리, 엔터프라이즈급 보안/감사/권한이 필요한 환경 쿠버네티스 등 인프라 구축이 가능하고, 복잡한 운영을 감수할 수 있을 때 MLOps, 대규모 AI/검색 플랫폼, 보안/감사/규제 준수가 중요한 기업 환경 결론: 빠른 구축, 중~대규모, 운영 편의성 → Qdrant 추천 초대규모, 엔터프라이즈, 보안/감사/분산 필수 → Milvus 추천 둘 다 무료/클라우드 플랜이 있으니, 실제 PoC(파일럿)로 테스트해보고 결정하는 것도 좋습니다. 샘플 코드들 compare-vDB-libraries"
  },
  {
    "id": "Data Science/Data Engineering/vDB_code_notebook",
    "title": "vDB관련 샘플 코드들",
    "date": "2025-07-25",
    "excerpt": "vDB관련 샘플 코드들",
    "category": "Data Science",
    "tags": [
      "VectorDB",
      "Qdrant",
      "ChromaDB",
      "FAISS",
      "Milvus"
    ],
    "content": "--- title: \"vDB관련 샘플 코드들\" date: \"2025-07-25\" category: \"Data Science\" tags: [\"VectorDB\", \"Qdrant\", \"ChromaDB\", \"FAISS\", \"Milvus\"] excerpt: \"vDB관련 샘플 코드들\" --- # Qdrant 파이썬 클라이언트 설치 필요 pip install qdrant-client from qdrant_client import QdrantClient from qdrant_client.models import VectorParams, Distance, PointStruct import numpy as np Qdrant 서버에 연결 (로컬 서버 예시) client = QdrantClient(host=\"localhost\", port=6333) 컬렉션 생성 (벡터 차원 1536, cosine 거리) client.recreate_collection( collection_name=\"my_collection\", vectors_config=VectorParams(size=1536, distance=Distance.COSINE), ) 벡터 데이터 삽입 vectors = np.random.rand(3, 1536).tolist() # 3개 벡터, 1536차원 payloads = [ {\"doc_id\": \"A1\", \"text\": \"문서1\"}, {\"doc_id\": \"A2\", \"text\": \"문서2\"}, {\"doc_id\": \"A3\", \"text\": \"문서3\"}, ] points = [ PointStruct(id=i, vector=vectors[i], payload=payloads[i]) for i in range(3) ] client.upsert(collection_name=\"my_collection\", points=points) 유사도 검색 (임의 쿼리 벡터) query_vector = np.random.rand(1536).tolist() results = client.search( collection_name=\"my_collection\", query_vector=query_vector, limit=2, ) for hit in results: print(f\"ID: {hit.id}, Score: {hit.score}, Payload: {hit.payload}\") from qdrant_client import QdrantClient from qdrant_client.models import VectorParams, Distance, PointStruct import numpy as np client = QdrantClient(host=\"localhost\", port=6333) 회사A 컬렉션 생성 client.recreate_collection( collection_name=\"companyA_docs\", vectors_config=VectorParams(size=1536, distance=Distance.COSINE), ) 회사B 컬렉션 생성 client.recreate_collection( collection_name=\"companyB_docs\", vectors_config=VectorParams(size=1536, distance=Distance.COSINE), ) 회사A 데이터 삽입 vectors_a = np.random.rand(2, 1536).tolist() payloads_a = [{\"doc_id\": \"A1\"}, {\"doc_id\": \"A2\"}] points_a = [PointStruct(id=i, vector=vectors_a[i], payload=payloads_a[i]) for i in range(2)] client.upsert(collection_name=\"companyA_docs\", points=points_a) 회사B 데이터 삽입 vectors_b = np.random.rand(2, 1536).tolist() payloads_b = [{\"doc_id\": \"B1\"}, {\"doc_id\": \"B2\"}] points_b = [PointStruct(id=i, vector=vectors_b[i], payload=payloads_b[i]) for i in range(2)] client.upsert(collection_name=\"companyB_docs\", points=points_b) 회사A 데이터만 검색 query_vector = np.random.rand(1536).tolist() results = client.search( collection_name=\"companyA_docs\", query_vector=query_vector, limit=1, ) for hit in results: print(f\"회사A 결과: {hit.payload}\") 회사B 데이터만 검색 results = client.search( collection_name=\"companyB_docs\", query_vector=query_vector, limit=1, ) for hit in results: print(f\"회사B 결과: {hit.payload}\") # Multi tenancy 를 잘 구현하는 법 # 1. 컬렉션 네이밍 컨벤션 from qdrant_client import QdrantClient from qdrant_client.models import VectorParams, Distance, PointStruct import numpy as np client = QdrantClient(host=\"localhost\", port=6333) 테넌트별 컬렉션 네이밍 패턴 def get_collection_name(tenant_id: str, data_type: str = \"docs\") -> str: \"\"\"테넌트별 컬렉션 이름 생성\"\"\" return f\"{tenant_id}_{data_type}\" 예시: 회사별 컬렉션 생성 tenants = [\"company_a\", \"company_b\", \"company_c\"] data_types = [\"docs\", \"images\", \"products\"] for tenant in tenants: for data_type in data_types: collection_name = get_collection_name(tenant, data_type) client.recreate_collection( collection_name=collection_name, vectors_config=VectorParams(size=1536, distance=Distance.COSINE), ) print(f\"Created collection: {collection_name}\") # 2. 멀티 테넌시 매니저 클래스 class QdrantMultiTenantManager: def __init__(self, client: QdrantClient): self.client = client self.tenant_configs = { \"company_a\": { \"collections\": [\"docs\", \"images\"], \"vector_size\": 1536, \"distance\": Distance.COSINE }, \"company_b\": { \"collections\": [\"docs\", \"products\"], \"vector_size\": 1536, \"distance\": Distance.COSINE } } def get_collection_name(self, tenant_id: str, collection_type: str) -> str: \"\"\"테넌트별 컬렉션 이름 생성\"\"\" return f\"{tenant_id}_{collection_type}\" def ensure_collection_exists(self, tenant_id: str, collection_type: str): \"\"\"컬렉션이 없으면 생성\"\"\" if tenant_id not in self.tenant_configs: raise ValueError(f\"Unknown tenant: {tenant_id}\") collection_name = self.get_collection_name(tenant_id, collection_type) config = self.tenant_configs[tenant_id] # 컬렉션 존재 여부 확인 collections = self.client.get_collections() collection_names = [c.name for c in collections.collections] if collection_name not in collection_names: self.client.create_collection( collection_name=collection_name, vectors_config=VectorParams( size=config[\"vector_size\"], distance=config[\"distance\"] ), ) print(f\"Created collection: {collection_name}\") def upsert_for_tenant(self, tenant_id: str, collection_type: str, vectors, payloads, ids): \"\"\"테넌트별 데이터 삽입\"\"\" self.ensure_collection_exists(tenant_id, collection_type) collection_name = self.get_collection_name(tenant_id, collection_type) points = [ PointStruct(id=id_, vector=vector, payload=payload) for id_, vector, payload in zip(ids, vectors, payloads) ] return self.client.upsert( collection_name=collection_name, points=points ) def search_for_tenant(self, tenant_id: str, collection_type: str, query_vector, limit=10, kwargs): \"\"\"테넌트별 검색\"\"\" collection_name = self.get_collection_name(tenant_id, collection_type) return self.client.search( collection_name=collection_name, query_vector=query_vector, limit=limit, kwargs ) def get_tenant_collections(self, tenant_id: str): \"\"\"테넌트의 모든 컬렉션 조회\"\"\" collections = self.client.get_collections() tenant_prefix = f\"{tenant_id}_\" return [ c.name for c in collections.collections if c.name.startswith(tenant_prefix) ] def delete_tenant_data(self, tenant_id: str): \"\"\"테넌트의 모든 데이터 삭제\"\"\" collections = self.get_tenant_collections(tenant_id) for collection_name in collections: self.client.delete_collection(collection_name) print(f\"Deleted collection: {collection_name}\") # 3. 실제 사용 예시 매니저 초기화 manager = QdrantMultiTenantManager(client) 회사A에 문서 데이터 삽입 vectors_a = np.random.rand(3, 1536).tolist() payloads_a = [ {\"doc_id\": \"A1\", \"title\": \"회사A 문서1\", \"tenant\": \"company_a\"}, {\"doc_id\": \"A2\", \"title\": \"회사A 문서2\", \"tenant\": \"company_a\"}, {\"doc_id\": \"A3\", \"title\": \"회사A 문서3\", \"tenant\": \"company_a\"} ] ids_a = [\"A1\", \"A2\", \"A3\"] manager.upsert_for_tenant(\"company_a\", \"docs\", vectors_a, payloads_a, ids_a) 회사B에 제품 데이터 삽입 vectors_b = np.random.rand(2, 1536).tolist() payloads_b = [ {\"product_id\": \"B1\", \"name\": \"회사B 제품1\", \"tenant\": \"company_b\"}, {\"product_id\": \"B2\", \"name\": \"회사B 제품2\", \"tenant\": \"company_b\"} ] ids_b = [\"B1\", \"B2\"] manager.upsert_for_tenant(\"company_b\", \"products\", vectors_b, payloads_b, ids_b) 테넌트별 검색 query_vector = np.random.rand(1536).tolist() 회사A 문서 검색 results_a = manager.search_for_tenant(\"company_a\", \"docs\", query_vector) print(\"회사A 검색 결과:\", [hit.payload for hit in results_a]) 회사B 제품 검색 results_b = manager.search_for_tenant(\"company_b\", \"products\", query_vector) print(\"회사B 검색 결과:\", [hit.payload for hit in results_b]) # 백업 복구 import json import os class TenantBackup: def __init__(self, manager: QdrantMultiTenantManager): self.manager = manager def backup_tenant(self, tenant_id: str, backup_path: str): \"\"\"테넌트별 백업\"\"\" collections = self.manager.get_tenant_collections(tenant_id) for collection_name in collections: # 컬렉션 데이터 내보내기 points = self.manager.client.scroll( collection_name=collection_name, limit=10000 # 적절한 배치 크기 )[0] # 백업 파일에 저장 backup_file = f\"{backup_path}/{collection_name}_backup.json\" with open(backup_file, 'w') as f: json.dump(points, f, indent=2) print(f\"Backed up {collection_name} to {backup_file}\") def restore_tenant(self, tenant_id: str, backup_path: str): \"\"\"테넌트별 복구\"\"\" collections = self.manager.get_tenant_collections(tenant_id) for collection_name in collections: backup_file = f\"{backup_path}/{collection_name}_backup.json\" if os.path.exists(backup_file): with open(backup_file, 'r') as f: points_data = json.load(f) # 데이터 복구 self.manager.client.upsert( collection_name=collection_name, points=points_data ) print(f\"Restored {collection_name} from {backup_file}\")"
  },
  {
    "id": "Self_Development/English Study/SPEAK/지나간달/07-24-물건에대한분석",
    "title": "물건에 대한 분석",
    "date": "2025-07-24",
    "excerpt": "물건에 대한 분석",
    "category": "English Study",
    "tags": [
      "영어공부꾸준히!",
      "SPEAK"
    ],
    "content": "배운 것들 It's not about performance. It's about design. It's not about customizabiltiy. It's about compatibility. In which case, I'll probably go with the new Galaxy. go with : 선택하다"
  },
  {
    "id": "Data Science/Causal Inference/how-can-evaluate-casual-models",
    "title": "how to evaluate CATE estimation model",
    "date": "2025-07-24",
    "excerpt": "CATE estimation model 평가 방법에 대해 정리",
    "category": "Causal Inference",
    "tags": [
      "인과추론",
      "metrics"
    ],
    "content": "참고한 자료 Causal Inference for The Brave and True > When Prediction Fails chapter, they generate data on both $Y_{0i}$ and $Y_{1i}$ so that they can check if their model is correctly capturing the treatment effect $Y_{1i} - Y_{0i}$. > That’s fine for academic purposes, but in the real world, we don’t have that luxury. CATE estimation model은 어떻게 평가할 수 있을까요? 학문적으로는 임의로 데이터를 생성해서 실제로 이를 잘 추정하는지 확인해볼 수 있을 것 같습니다. > The quality of your model will have to be grounded on something more concrete than a beautiful theory. > Unfortunately, it isn’t obvious at all how we achieve anything like a train-test paradigm in the case of causal inference. > That’s because causal inference is interested in estimating an unobservable quantity, $\\frac{\\delta y}{\\delta t}$ 하지만 실제 데이터에서는 CATE를 직접 확인할 수 없으니, 다른 방법을 써야합니다. 회사에 인과추론을 적용하면서 가장 많이 고민헀던 부분이기도 합니다. 내가 만든 모델의 성능을 어떻게 설명하고 설득할 수 있을까요? 머신러닝은 train-test paradigm을 통해 성능을 평가할 수 있고, 이는 꽤나 직관적으로 모델의 성능을 증명해주고 있습니다. CATE estimation model에도 이러한 방법이 존재할까요? > Is not a definitive one, but it works in practice and it has that concreteness, which I hope will approach causal inference from a train-test paradigm similar to the one we have with machine learning. > The trick is to use aggregate measurements of sensitivity. > Even if you can’t estimate sensitivity individually, you can do it for a group and that is what we will leverage here. 개개인의 CATE는 알 수 없지만 그룹의 ATE는 알 수 있으니 이를 활용해서 CATE를 평가해볼 수 있습니다. Sensitivity by Model Band --- > A good causal model should help us find which customers will respond better and worse to a proposed treatment. > They should be able to separate units into how elastic or sensitive they are to the treatment. CATE estimation의 목적은 처치에 대한 민감도를 개인별로 추정하여, 개인화된 처치를 하는데에 있습니다. 따라서 개인별로 민감도를 명확하게 구분하는 것이 중요합니다. > If that is the goal, it would be very useful if we could somehow order units from more sensitive to less sensitive. CATE estimation을 통해 개인별 민감도를 계산하고 이를 활용해 정렬을 할 수 있습니다. 정렬을 얼마나 잘하는지를 통해 모델의 성능을 평가해볼 수 있지 않을까요? > Sadly, we can’t evaluate that ordering on a unit level. > But, what if we don’t need to? > What if, instead, we evaluate groups defined by the ordering? > If our treatment is randomly distributed (and here is where randomness enters), estimating sensitivity for a group of units is easy. > All we need is to compare the outcome between the treated and untreated. <figure style=\"text-align: center;\"> <img src=\"/post/Causal_Inference/cate_metric_using_ate.png\" alt=\"cate_metric_using_ate\" /> <figcaption> 그림1. CATE 평가 방법에 대한 직관적 설명 (low: 비처치대상, high: 처치대상-가격을 높였을 때)</figcaption> </figure> 그림1이 의미하는 것은 추정된 cate로 정렬했을 때, 정렬된 것들을 기준으로 그룹을 나눠 ATE를 구하면 그 차이가 분명할 것이라는 것입니다. 맨 오른쪽에 있는, 랜덤하게 cate를 배정한 경우 ATE가 완전하게 같은 것을 확인할 수 있습니다. 반대로 model-2의 경우 ATE가 분명하게 차이가 나는 것을 확인할 수 있습니다. > Just by looking at these plots, you can get a feeling of which model is better. > The more ordered the sensitivities look like and the more different they are between bands, the better. > Here, model 2 is probably better than model 1, which is probably better than the random model. Cumulative Gain Curve 계속해서 가져가고 있는 컨셉은, CATE estimation은 개인별로 cate를 구분되게 추정하는 것이 목표이고, 이를 사용해 정렬한 후 그룹을 나눠 ATE를 구하면 차이가 나야한다는 것입니다. <figure style=\"text-align: center;\"> <img src=\"/post/Causal_Inference/cumulative_gain_curve.png\" alt=\"cumulative_gain_curve\" /> <figcaption> 그림2. Cumulative gain curve</figcaption> </figure> 그림2는 그림1의 그룹별 ATE결과를 바탕으로 높은 순서대로 정렬한 후에, 누적되는 ATE를 살펴본 것입니다. 비교대상인 랜덤한 경우를 보면, ATE 누적 분포가 직선의 모습을 보이고 있는 것을 확인할 수 있습니다. 반대로 정렬이 잘된 경우라면 이 랜덤한 모델이 그리는 직선보다 더 높게 휘어진 직선을 그리고 있는 것을 확인할 수 있습니다. > Once we have the theoretic random curve, we can use it as a benchmark and compare our other models against it. > All curves will start and end at the same point. > However, the better the model at ordering sensitivity, the more the curve will diverge from the random line in the points between zero and one. 이러한 방법을 통해 모델의 성능을 평가할 수 있습니다."
  },
  {
    "id": "Self_Development/English Study/SPEAK/지나간달/07-23-뭐뭐하긴해도",
    "title": "뭐뭐하긴 해도",
    "date": "2025-07-23",
    "excerpt": "뭐뭐하긴 해도 쓰는 표현들",
    "category": "English Study",
    "tags": [
      "영어공부꾸준히!",
      "SPEAK"
    ],
    "content": "배운 것들 Although, its a bit pricey, the bar has an amazing view at night. Although there is a long wait, it has the best bubble tea in town. Even though, Im not as big fan of the movie, I still enjoyed it. I like chocolate, even though I dont like sweet. I love burgers. Its not healthy though. The coat is too expensive. but its pretty though. Fair enough : 인정 간단한 작문 Although seoul is confused, full of people, its a great place to live. Many 편의시설 in here. Even though Im not a big fan of anime, I love 귀멸의 칼날. I really love burgers. Its not healthy thought. 더 자연스러운 작문 & 피드백 Although Seoul is confusing and crowded, it's a great place to live. → 피드백: \"confused\" 대신 \"confusing and crowded\"로 자연스럽게 수정. \"Many 편의시설 in here.\"는 \"There are many convenient facilities here.\"로 바꾸면 좋아요. Even though I'm not a big fan of anime, I love Demon Slayer. → 피드백: \"귀멸의 칼날\"은 영어 제목 \"Demon Slayer\"로 쓰면 자연스러워요. I really love burgers. It's not healthy though. → 피드백: \"thought\"는 오타, \"though\"가 맞아요."
  },
  {
    "id": "Data Science/law-of-total-expectaion",
    "title": "Law of total expectation",
    "date": "2025-07-23",
    "excerpt": "전체기대법칙에 대해 정리",
    "category": "Data Science",
    "tags": [
      "math"
    ],
    "content": "전체기대법칙, 진짜 생활 버전 > 핵심 아이디어 > “전체 평균 = ‘각 상황별 평균’들을 확률로 가중한 평균” --- 마트 계산대 이야기로 직관 잡기 마트에는 \\\\빠른 계산대(셀프)\\\\와 일반 계산대(직원) 두 줄이 있다. 셀프 계산대를 선택할 확률 70 %, 일반 계산대는 30 %. 셀프에서 걸리는 평균 시간은 2분, 일반 계산대는 6분. “전체 줄 서기 평균 시간”은? 조건부 평균: 셀프 = 2분, 일반 = 6분 가중 평균: $2 \\times 0.7 + 6 \\times 0.3 = 3.2$ 분 3.2 분이 Law of Total Expectation 결과다. ([Wikipedia][1]) > 한 줄 요약 ― “상황별 평균을 구한 뒤, 각 상황이 일어날 확률로 다시 한 번 평균을 내면 전체 평균이 된다.” --- 공식을 뜯어보면 $$ \\mathbb{E}[X] = \\mathbb{E}\\big[\\;\\mathbb{E}[X \\mid Y]\\;\\big] $$ $X$: 알고 싶은 대상(줄 서는 시간). $Y$: 상황을 나누는 열쇠(선택한 계산대). $\\mathbb{E}[X\\mid Y]$: “상황 Y 가 주어졌을 때 평균” — 셀프면 2분, 일반이면 6분. $\\mathbb{E}[\\cdot]$: 그 값들을 다시 평균 — 확률 0.7, 0.3으로 가중. ([Wikipedia][1]) --- ‘3단 요리법’으로 기억하기 단계 해야 할 일 결과 --------- -------------------------- --------- ① 상황 나누기 문제를 쉽게 쪼갤 변수·사건 $Y$ 고르기 ‘셀프 / 일반’ ② 상황별 기대값 $\\mathbb{E}[X\\mid Y=y]$ 계산 2분, 6분 ③ 가중 평균 ②에 $P(Y=y)$ 곱해 다 더하기 3.2분 > 어디에 쓰나? > > 고객 세그먼트별 구매액 산정 > - 보험료 예상(나이대·지역별) > - A/B 테스트 두 그룹 결과 합치기 --- 트리 그림으로 그려 보기 `` 전체 고객 / \\ (70%) (30%) 셀프 계산대 일반 계산대 평균 2분 평균 6분 `` 아래층 평균(2, 6)을 위층 확률(0.7, 0.3)로 끌어올려 위층 평균(3.2)을 만든다. 그래서 이 법칙을 \\\\Tower Rule(탑 규칙)\\\\이라고도 부른다. ([Mathematics Stack Exchange][2]) --- ‘조건을 한 번 더 주어도 OK’ $$ \\mathbb{E}\\!\\big[\\;\\mathbb{E}[X \\mid Y,Z]\\;\\big]=\\mathbb{E}[X] $$ 층을 여러 층 쌓아도, 맨 꼭대기로 올라가면 언제나 $X$의 원래 평균. 정보를 조금 알고(한 층 내려가고) 다시 모른 척(평균)해도, 결국 제자리다. ([The Book of Statistical Proofs][3]) --- 한눈에 끝내는 기억 장치 > “조건부 평균은 곧 ‘부분 평균표’, > 그 표를 다시 평균내면 전체 평균표.” --- 자주 묻는 Q\\&A 질문 답변 ------------------- ----------------------------------------------------------------- 왜 굳이 이렇게 돌려 계산? 복잡한 문제를 작은 블록으로 나눌 때 계산이 훨씬 쉽다. 확률 대신 비율·가중치 써도 되나? 총합이 1이면 어떤 가중치든 무방. 연속형 변수도 되나? 사건 합 대신 적분으로 바뀔 뿐 똑같이 성립한다. ([Everything Explained Today][4]) --- 필요하면 전체분산법칙(Var 버전)이나 베이지안 업데이트에서의 활용 예도 이어서 보여줄 수 있다. [1]: https://en.wikipedia.org/wiki/Law_of_total_expectation?utm_source=chatgpt.com \"Law of total expectation\" [2]: https://math.stackexchange.com/questions/41536/intuitive-explanation-of-the-tower-property-of-conditional-expectation?utm_source=chatgpt.com \"Intuitive explanation of the tower property of conditional expectation\" [3]: https://statproofbook.github.io/P/mean-tot.html?utm_source=chatgpt.com \"Law of total expectation The Book of Statistical Proofs\" [4]: https://everything.explained.today/Law_of_total_expectation/?utm_source=chatgpt.com \"Law of total expectation explained\""
  },
  {
    "id": "Data Science/Causal Inference/what-is-r-learner",
    "title": "R-learner란?",
    "date": "2025-07-23",
    "excerpt": "R-learner의 개념에 대해 정리",
    "category": "Causal Inference",
    "tags": [
      "R-learner",
      "인과추론"
    ],
    "content": "R-learner는 CATE estimation에 사용되는 meta-learner 중 하나입니다. 이에 대해 하나씩 정리헀습니다. CATE estimation이란? --- 인과추론 (Causal Inference)의 목적은 처치의 효과를 추정하는데에 있습니다. 처치가 결과에 어떤 영향을 미치는지 확인하고 이를 통해 더 좋은 결정을 내릴 수 있습니다. 1.1 ATE란? > ATE(Average Treatment Effect)는 전체 집단에서 처치(예: 신약, 정책 등)가 미치는 평균적인 인과 효과를 의미합니다. $$ \\text{ATE} = \\mathbb{E}[Y^{(t)} - Y^{(0)}] $$ 여기서 $$Y^{(t)}$$은 처치를 받았을 때의 잠재적 결과 (Potential Outcome)이고, $$Y^{(0)}$$은 처치를 받지 않았을 때의 잠재적 결과입니다. 즉 처치를 받았을 때의 평균적인 인과효과를 의미합니다. 1.2 CATE란? > CATE(Conditional Average Treatment Effect)는 특정 조건에서 처치가 미치는 평균적인 인과 효과를 의미합니다. $$ \\text{CATE} = \\tau(x) = \\mathbb{E}[Y^{(t)} - Y^{(0)} X = x] $$ 여기서 $$X$$는 조건을 의미하고, $$Y^{(t)}$$는 처치를 받았을 때의 잠재적 결과, $$Y^{(0)}$$는 처치를 받지 않았을 때의 잠재적 결과를 의미합니다. ATE를 통해 처치의 평균적인 인과효과(처치가 결과에 미치는 영향)을 추정했습니다. 다만 개개인별로 인과효과가 다르다는 것은 직관적인데요, 이러한 개별 개체의 처치효과를 ITE라고 합니다. > ITE (Individual Treatment Effect) > - 정의: 개별 개체의 처치 효과 > - 수식: $$\\text{ITE}_i = Y_i^{(1)} - Y_i^{(0)}$$ > - 의미: 특정 개인이 처치를 받았을 때와 받지 않았을 때의 결과 차이 > - 특징: 실제로는 관찰 불가능 (fundamental problem of causal inference) 그리고 이를 추정하는 값이 CATE 입니다. > Estimating heteronenous treatment effects is fundamental in causal inference and provides insights into various fields. > > -> Towards R-learner with Continuous Treatment 개인별 처치효과를 추정하는 일은 다양한 분야에서 핵심적인 역할을 합니다. 학생별 교육효과를 추정해 개인화된 교육 프로그램을 실행하거나, 환자별 처치효과를 추정해 개인화된 처치를 실행할 수 있습니다. CATE estimation에 사용되는 meta-learner들 --- 메타러너 (meta-learner)는 기존 예측 머신러닝 알고리즘을 활용해서 처치효과를 추정하는 간단한 방법입니다. cate estimation을 위해 사용되는 meta-learner에는 대표적으로 T-learner, X-learner, S-learner가 있습니다. 2.1 T-learner 범주형 처치를 다룰 때 사용할 수 있는 메타러너입니다. $$ \\hat{\\mu}_0(x) = \\mathbb{E}[Y T=0, X = x] \\\\ \\hat{\\mu}_1(x) = \\mathbb{E}[Y T=1, X = x] \\\\ \\hat{\\tau}(x) = \\hat{\\mu}_1(x) - \\hat{\\mu}_0(x) $$ <figure style=\"text-align: center;\"> <img src=\"/post/Causal_Inference/T-learner.png\" alt=\"T-learner\" style=\"display: block; margin: 0 auto;\" /> <figcaption style=\"text-align: center;\"> 그림 1 : T-learner 구조<br/> <a href=\"https://matheusfacure.github.io/python-causality-handbook/21-Meta-Learners.html\" target=\"_blank\" style=\"font-size: 0.8em; color: #fff;\">출처: Causal Inference for The Brave and True</a> </figcaption> </figure> 그림1에서 보이는 것처럼, 처치별로 각각의 예측 모델을 만들고 이 모델의 예측결과를 비교해 CATE를 추정합니다. ``python m0 = LGBMRegressor(max_depth=2, min_child_samples=60) m1 = LGBMRegressor(max_depth=2, min_child_samples=60) m0.fit(train.query(f\"{T}==0\")[X], train.query(f\"{T}==0\")[y]) m1.fit(train.query(f\"{T}==1\")[X], train.query(f\"{T}==1\")[y]) estimate the CATE t_learner_cate_train = m1.predict(train[X]) - m0.predict(train[X]) t_learner_cate_test = test.assign(cate=m1.predict(test[X]) - m0.predict(test[X])) ` 2.2 S-learner (aka, the Go-Horse Learner) S러너는 가장 기본적인 방식으로, 단일 머신러닝 모델을 사용하여 추정합니다. $$ \\hat{\\mu}(x) = E[Y X = x] \\\\ \\hat{\\tau}(x) = \\hat{\\mu}(x, T=1) - \\hat{\\mu}(x, T=0) $$ <figure style=\"text-align: center;\"> <img src=\"/post/Causal_Inference/S-learner.png\" alt=\"S-learner\" style=\"display: block; margin: 0 auto;\" /> <figcaption style=\"text-align: center;\"> 그림 2 : S-learner 구조<br/> <a href=\"https://matheusfacure.github.io/python-causality-handbook/21-Meta-Learners.html\" target=\"_blank\" style=\"font-size: 0.8em; color: #fff;\">출처: Causal Inference for The Brave and True</a> </figcaption> </figure> 그림2에서 보이는 것처럼 모든 처치에 대해 예측하는 모델을 만들고, 이 모델을 통해 CATE를 추정합니다. `python s_learner = LGBMRegressor(max_depth=3, min_child_samples=30) s_learner.fit(train[X+[T]], train[y]); s_learner_cate_train = (s_learner.predict(train[X].assign({T: 1})) - s_learner.predict(train[X].assign({T: 0}))) s_learner_cate_test = test.assign( cate=(s_learner.predict(test[X].assign({T: 1})) - # predict under treatment s_learner.predict(test[X].assign({T: 0}))) # predict under control ) ` 이 모델은 CATE estimation에 사용되는 메타러너 중에 가장 쉽게 적용해볼 수 있는 모델이지만, 편향에 가장 취약한 모델이기도 합니다. 2.3 X-learner <figure style=\"text-align: center;\"> <img src=\"/post/Causal_Inference/X-learner.png\" alt=\"X-learner\" style=\"display: block; margin: 0 auto;\" /> <figcaption style=\"text-align: center;\"> 그림 3 : X-learner 구조<br/> <a href=\"https://matheusfacure.github.io/python-causality-handbook/21-Meta-Learners.html\" target=\"_blank\" style=\"font-size: 0.8em; color: #fff;\">출처: Causal Inference for The Brave and True</a> </figcaption> </figure> X-learner는 2단계로 구성되어 있습니다. 1단계에서는 T-learner와 마찬가지로 처치별로 데이터를 나눠 모델을 학습시킵니다. $$ \\hat{M}_0(X) \\approx \\mathbb{E}[Y T=0, X] \\\\ \\hat{M}_1(X) \\approx \\mathbb{E}[Y T=1, X] $$ 2단계에서는 1단계에서 학습시킨 모델로 추정된 CATE를 계산합니다. $$ \\hat{\\tau}(X, T=0) = \\hat{M}_0(X) - Y_{T=0} \\\\ \\hat{\\tau}(X, T=1) = \\hat{M}_1(X) - Y_{T=1} $$ 그 후에 이를 예측하는 모델을 학습시킵니다. $$ \\hat{M}_{\\tau 0}(X) = E[\\hat\\tau(X) T = 0] \\\\ \\hat{M}_{\\tau 1}(X) = E[\\hat\\tau(X) T = 1] $$ 마지막으로 이 모델의 결과를 보완해주기 위해서 propensity score를 사용합니다. 학습을 위한 $\\hat{\\tau}(X, T=0)$ 을 추정할 때 $Y_1$ 이 없기 때문에 $\\hat{M}_1$을 사용해서 이를 추정했습니다. 이때 X가 0일 확률이 높다면 $\\hat{M}_1$의 예측값의 성능이 떨어질 것이고, 이로 인해 $\\hat{\\tau}(X, T=0)$의 추정값도 신뢰가 떨어질 것입니다. 반대로 \\hat{\\tau}(X, T=0)$의 추정값의 신뢰도는 올라갈 것입니다. 이러한 직관을 가지고 propensity score를 사용해서 보완합니다. $$ \\hat{\\tau}(X) = \\hat{M}_{\\tau 0}(X)\\hat e(x) - \\hat{M}_{\\tau 1}(X)(1-\\hat e(x)) $$ `python from sklearn.linear_model import LogisticRegression np.random.seed(123) first stage models m0 = LGBMRegressor(max_depth=2, min_child_samples=30) m1 = LGBMRegressor(max_depth=2, min_child_samples=30) propensity score model g = LogisticRegression(solver=\"lbfgs\", penalty='none') m0.fit(train.query(f\"{T}==0\")[X], train.query(f\"{T}==0\")[y]) m1.fit(train.query(f\"{T}==1\")[X], train.query(f\"{T}==1\")[y]) g.fit(train[X], train[T]); ` `python d_train = np.where(train[T]==0, m1.predict(train[X]) - train[y], train[y] - m0.predict(train[X])) second stage mx0 = LGBMRegressor(max_depth=2, min_child_samples=30) mx1 = LGBMRegressor(max_depth=2, min_child_samples=30) mx0.fit(train.query(f\"{T}==0\")[X], d_train[train[T]==0]) mx1.fit(train.query(f\"{T}==1\")[X], d_train[train[T]==1]); ` `python def ps_predict(df, t): return g.predict_proba(df[X])[:, t] x_cate_train = (ps_predict(train,1)mx0.predict(train[X]) + ps_predict(train,0)mx1.predict(train[X])) x_cate_test = test.assign(cate=(ps_predict(test,1)mx0.predict(test[X]) + ps_predict(test,0)mx1.predict(test[X]))) `` R-learner란? 다른 meta-learner들과 비교 --- R-learner는 FWL-theorem을 meta-learner 형태로 구현한 모델입니다. FWL theorem이란? 조금 더 엄밀하게 이야기하면 double/debiased machine learning이라고 말할 수 있고, 여기에 propensity score를 함께 사용해 편향을 보정하는 모델이 R-learner입니다. 편향을 nuisance function을 통해 잔차화하여 제거하고, CATE를 추정합니다. 이때 nuisance function들은 기존의 예측 모델을 통해 쉽게 구현되며, CATE estimation에 사용되는 모델도 마찬가지입니다. 따라서 다중회귀모델과 다르게 비선형성을 포착할 수 있습니다. R-learner는 다른 meta-learner들과 다르게 이 모델은 CATE를 직접적으로 추정하고 있습니다. 따라서 다른 모델보다 CATE를 더 잘 추정한다고 알려져 있습니다. > CATE estimation을 평가하는 방법에는 2가지정도가 있는데, > 하나는 임의로 데이터셋을 만들어 실제로 잘 추정하는지 확인하는 것과 > 다른 하나는 cate로 정렬해 그룹별로 ATE를 구해 비교하는 것입니다. -> how to evaluate CATE estimation model 또한 회귀모델을 통한 잔차화와 propensity score를 통한 잔차화를 진행해 doubly robust 하다는 장점도 가지고 있습니다. Double robustness란? --- 편향을 제거하기 위한 방법에는 회귀를 통한 잔차화와 propensity score를 통한 방법이 있습니다. 회귀를 통한 잔차화는 FWL-theorem에 기반하고 있습니다. propensity score를 통한 잔차화의 컨셉은 X를 통제할 수 없다면 e(X)를 통제해서, X를 통제한 것과 같은 상태를 만들자는 것입니다. 참고자료 PropensityScoreNotebook.ipynb Causal Inference for The Brave and True - Propensity Score R-leaner는 이 2가지 모두를 사용해 편향을 없애고 있고, 이를 위한 2개의 모델 중 하나의 성능만 보장되면 나머지 하나의 성능이 부족하더라도 CATE estimation의 성능이 보장된다고 합니다. 4.1 ATE에서 doubly robust estimation $$ \\hat{\\text{ATE}} = \\frac{1}{N} \\sum (\\frac{T_i(Y_i - \\hat \\mu_1(X_i))}{\\hat P(X_i)} + \\hat \\mu_1(X_i)) - \\frac{1}{N} \\sum (\\frac{(1-T_i)(Y_i - \\hat \\mu_0(X_i))}{1 - \\hat P(X_i)} + \\hat \\mu_0(X_i)) \\tag{1} $$ 1번 수식에서 앞에 부분은 $\\hat E[Y X, T=1]$ 의 추정값이고, 뒤에 부분은 $\\hat E[Y X, T=0]$ 의 추정값입니다. $\\hat E[Y X, T=1]$에 대해서 doubly robust가 성립하는지 살펴보고 이를 기반해서 $\\hat E[Y X, T=0]$에 대해서는 유추해보록 하겠습니다. $$ \\hat E[Y_1] = \\frac{1}{N} \\sum (\\frac{T_i(Y_i - \\hat \\mu_1(X_i))}{\\hat P(X_i)} + \\hat \\mu_1(X_i)) \\tag{2} $$ $\\hat \\mu_1(X_i)$ 가 정확하고 propensity score가 부정확할 때. 식 2에서 $\\frac{T_i(Y_i - \\hat \\mu_1(X_i))}{\\hat P(X_i)}$ 부분이 0이 되기 때문에 결과가 보장됩니다. $$ \\begin{align} \\hat{\\mathbb{E}}[Y_1] &= \\frac{1}{N} \\sum \\left( \\frac{T_i (Y_i - \\hat{\\mu}_1(X_i))}{\\hat{P}(X_i)} + \\hat{\\mu}_1(X_i) \\right) \\\\\\\\ \\hat{\\mathbb{E}}[Y_1] &= \\frac{1}{N} \\sum \\left( \\frac{T_i Y_i}{\\hat{P}(X_i)} - \\frac{T_i \\hat{\\mu}_1(X_i)}{\\hat{P}(X_i)} + \\hat{\\mu}_1(X_i) \\right) \\\\\\\\ \\hat{\\mathbb{E}}[Y_1] &= \\frac{1}{N} \\sum \\left( \\frac{T_i Y_i}{\\hat{P}(X_i)} - \\left( \\frac{T_i}{\\hat{P}(X_i)} - 1 \\right) \\hat{\\mu}_1(X_i) \\right) \\\\\\\\ \\hat{\\mathbb{E}}[Y_1] &= \\frac{1}{N} \\sum \\left( \\frac{T_i Y_i}{\\hat{P}(X_i)} - \\left( \\frac{T_i - \\hat{P}(X_i)}{\\hat{P}(X_i)} \\right) \\hat{\\mu}_1(X_i) \\right) \\end{align} \\tag{3} $$ propensity score가 정확하고 $\\hat \\mu_1(X_i)$ 가 부정확할 때. 식 3에서 $\\frac{T_i - \\hat{P}(X_i)}{\\hat{P}(X_i)}$ 부분이 0이 되기 때문에 결과가 보장됩니다. 4.2 R-learner에서 doubly robust가 보장되는 방식 Quasi-Oracle Estimation of Heterogeneous Treatment Effects에서 이를 정의하고 있습니다. paper link paper review 기본적인 컨셉은 2개의 nuisance function이 이상적일 때의 error bound와 2개 중 1개만 이상적일 때의 error bound가 같다는 것을 증명하는 것입니다. R-loss가 정의되는 방식 --- Generalized R-loss는 Towards R-learner with Continuous Treatment 논문에서 제안된 손실함수입니다. paper link paper review $$ L_c(h) = E\\left[\\left\\{Y - m(X) - h(X, T) + E_{\\varpi}\\{h(X, T) \\mid X\\}\\right\\}^2\\right] \\tag{generalized R-loss} $$ 이는 다음 수식들에서 유도됩니다. 이 수식들은 인과추론의 기본 가정인 unconfoundedness와 stable unit treatment value assumption을 가정하고 있습니다. full conditional outcome mean model $$ \\mu(x, t) = \\mathbb{E}[Y X = x, T = t] $$ conditional outcome mean $$ \\mu(x) = \\mathbb{E}[Y X = x] $$ generalized propensity score $$ \\varpi(x) = \\mathbb{E}[T X = x] $$ 수식 전개 $$ Y_i^{(T_i)} = \\mu(X_i, T_i) + \\epsilon_i = \\mu(X_i, 0) + \\tau(X_i, T_i) + \\epsilon_i \\\\ m(X_i) = E(Y_i^{(T_i)} X=X_i) = \\mu(X_i, 0) + E_{\\varpi}\\{\\tau(X, T) X=X_i\\} + \\epsilon_i \\\\ Y_i^{(T_i)} - m(X_i) = \\tau(X_i, T_i) - E_{\\varpi}\\{\\tau(X, T) X=X_i\\} + \\epsilon_i \\\\ $$ 마지막 식을 $\\epsilon_i$ 에 대해서 정리하면 loss function을 얻을 수 있습니다. 여기서 $h(X, t)$는 $tau(X, T)$를 추정하는 함수를 의미합니다. 5.1 Binary treatment에 대한 loss function > Quasi-Oracle Estimation of Heterogeneous Treatment Effects에서 정의한 binary treatment에 대한 loss function은 generalized R-loss의 특수한 경우입니다. $$ L_b(h) =E[Y - m(X) - {T-e(X)}h(X, 1)]^2 \\tag{binary treatment} $$ T가 0 또는 1이 존재하는 경우이기 떄문에 T를 풀어서 쓸 수 있고, $h(x, 0) = 0$이라는 가정을 loss function에 녹여낼 수 있습니다."
  },
  {
    "id": "Data Science/Causal Inference/my-fail-experience-graduate-project",
    "title": "졸업 과제로 진행한 프로젝트에 대한 회고",
    "date": "2025-07-23",
    "excerpt": "졸업 과제로 진행한 프로젝트에 대한 회고",
    "category": "Causal Inference",
    "tags": [
      "인과추론",
      "프로젝트"
    ],
    "content": ""
  },
  {
    "id": "Self_Development/English Study/SPEAK/지나간달/07-22-선택의상황",
    "title": "선택의 상황",
    "date": "2025-07-22",
    "excerpt": "선택의 상황에서 쓰는 표현들",
    "category": "English Study",
    "tags": [
      "영어공부꾸준히!",
      "SPEAK"
    ],
    "content": "배운 것들 best-thing ~의 가장 좋은 점은 ~이다. The best thing about iPhone is its camera. best-thing -> 한번에 일기 aBOUT when it comes to ~에 대해서는, ~가 가장 좋을 것이다. When it comes to online shopping, Amazon might be the best option. 간단한 작문 When it comes to smart-watch, Galaxy Fit is the best option. The best thing about Galaxy Fit is price. It is ver cheap, but have good design and good quality. --- 더 자연스러운 버전 & 피드백 자연스러운 버전 When it comes to smartwatches, the Galaxy Fit is the best option. The best thing about the Galaxy Fit is its price. It is very cheap, but it also has a good design and high quality. 피드백 When it comes to smart-watch, Galaxy Fit is the best option. 수정: When it comes to smartwatches, the Galaxy Fit is the best option. 피드백: \"smart-watch\"는 보통 복수형 \"smartwatches\"로 쓰는 것이 자연스럽고, \"the\"를 붙여 특정 제품을 지칭하는 것이 더 명확합니다. The best thing about Galaxy Fit is price. 수정: The best thing about the Galaxy Fit is its price. 피드백: \"its price\"로 소유격을 써서 더 자연스럽게 표현할 수 있습니다. \"the\"를 붙여 제품을 명확히 지칭하세요. It is ver cheap, but have good design and good quality. 수정: It is very cheap, but it also has a good design and high quality. 피드백: \"ver\"는 오타로 \"very\"가 맞습니다. \"have\" 대신 \"has\"를 써야 하고, \"good design and good quality\" 대신 \"a good design and high quality\"로 더 자연스럽게 표현할 수 있습니다. \"also\"를 추가하면 문장이 더 부드럽게 연결됩니다."
  },
  {
    "id": "Data Science/parametric-vs-non-parametric",
    "title": "Parametric vs Non-Parametric, GBDT는 왜 non-parametric일까?",
    "date": "2025-07-22",
    "excerpt": "Parametric과 Non-Parametric에 대한 간단한 설명",
    "category": "Data Science",
    "tags": [
      "parametric",
      "non-parametric",
      "machine-learning",
      "statistics"
    ],
    "content": "Parametric이란? 영어 한국어 설명 ------------------------- ----------- -------------------------------- parametric model 모수적 모델 고정된 수의 파라미터(모수)를 갖는 모델 parametric assumption 모수적 가정 데이터가 특정한 분포 형태(예: 정규분포)를 따른다는 가정 non-parametric model 비모수적 모델 파라미터 수나 함수 형태를 가정하지 않는 유연한 모델 데이터에서 패턴을 근사해내는게 Machine Learning의 핵심이라고 할 수 있습니다. 이때 데이터가 특정한 함수 형태를 따른다고 가정하거나, 모델의 구조(예: 선형 회귀처럼)가 고정되어 있는 경우를 모수적(parametric) 모델이라고 합니다. Parametric vs Non-Parametric 구분 Parametric Non-parametric ------------------- -------------- ------------------------ 모델 구조 사전에 고정됨 유연하고 데이터 기반 모수(parameter) 수 고정 데이터가 많아지면 증가함 복잡도 제어 파라미터 조정 모델 자체의 구조 변화로 조정 예시 선형 회귀, 로지스틱 회귀 GBDT, KNN, 랜덤포레스트, 커널 회귀 반대로 Non-parametric 모델은 모델의 형태나 구조를 사전에 가정하지 않고, 데이터를 통해 모델의 구조를 유연하게 만들어나가는 것을 의미합니다. 왜 GBDT는 non-parametric일까? 이유 설명 --------- --------------------------------- 파라미터 수 증가 데이터가 늘면 트리 개수나 깊이가 커져서 구조 자체가 변화함 구조 유연성 특정 함수 형태를 가정하지 않음 (예: 선형성) 자유도 과적합 위험도 있지만, 그만큼 복잡한 함수도 학습 가능 학습 대상 데이터가 가르쳐주는 방식에 따라 함수 구조 자체가 결정됨 GBDT는 잔차를 보완하는 방식으로 여러 개의 약한 결정 트리를 순차적으로 학습하고 누적하는 구조를 가지지만, 트리의 개수, 깊이, 노드 수, 분할 규칙 등은 데이터 양과 복잡도에 따라 계속 늘어나거나 바뀔 수 있습니다. 이런 점에서 GBDT는 non-parametric 모델이라고 할 수 있습니다."
  },
  {
    "id": "Data Science/bias-variance",
    "title": "Bias-Variance Tradeoff",
    "date": "2025-07-22",
    "excerpt": "Bias-Variance Tradeoff에 대한 간단한 설명",
    "category": "Data Science",
    "tags": [
      "bias-variance",
      "machine-learning",
      "statistics"
    ],
    "content": "Bias-Variance Tradeoff 머신러닝에서 모델의 성능을 평가할 때 가장 중요한 개념 중 하나가 Bias-Variance Tradeoff입니다. 이는 모델의 복잡도와 일반화 성능 사이의 균형을 설명하는 핵심 개념입니다. 기본 개념 Bias (편향) > 학습된 모델의 예측값 평균과 실제 값 간의 차이 정의: 모델이 실제 데이터 생성 과정을 얼마나 잘 근사하는지를 나타내는 지표 높은 Bias: 모델이 너무 단순해서 데이터의 패턴을 제대로 학습하지 못함 낮은 Bias: 모델이 복잡해서 데이터의 패턴을 잘 학습할 수 있음 Variance (분산) > 예측값이 얼마나 흩어졌는지를 나타내는 지표 정의: 모델이 훈련 데이터의 작은 변화에 얼마나 민감한지를 나타내는 지표 높은 Variance: 모델이 훈련 데이터에 과도하게 적합되어 새로운 데이터에 대해 성능이 떨어짐 낮은 Variance: 모델이 훈련 데이터의 노이즈에 덜 민감함 수학적 표현 예측 오차의 분해 $$E[(y - \\hat{f}(x))^2] = \\text{Bias}^2 + \\text{Variance} + \\text{Irreducible Error}$$ 여기서: $y$: 실제 값 $\\hat{f}(x)$: 모델의 예측값 $\\text{Bias}^2 = E[(\\hat{f}(x) - f(x))^2]$: 편향의 제곱 $\\text{Variance} = E[(\\hat{f}(x) - E[\\hat{f}(x)])^2]$: 분산 $\\text{Irreducible Error}$: 데이터 자체의 노이즈로 인한 오차 편향과 분산의 계산 편향과 분산은 다음과 같이 계산됩니다: $$\\text{Bias} = E[\\hat{f}(x)] - f(x)$$ $$\\text{Variance} = E[(\\hat{f}(x) - E[\\hat{f}(x)])^2]$$ Bias-Variance Tradeoff 핵심 아이디어 모델이 단순할수록: 높은 편향, 낮은 분산 모델이 복잡할수록: 낮은 편향, 높은 분산 시각적 예시 <figure style=\"text-align: center;\"> <img src=\"/post/bias_variance/bias_variance_1.png\" alt=\"Bias-Variance Tradeoff\" style=\"width: 100%; max-width: 600px; display: block; margin: 0 auto;\"/> <figcaption>그림 1: Bias-Variance 개념 설명 그림</figcaption> </figure> 그림1은 편향과 분산의 개념을 설명하는 그림입니다. 편향은 데이터의 패턴을 얼마나 잘 학습했는지를 의미합니다. 따라서 편향이 낮으면 패턴을 잘 학습해 파란 원 안에 안에 예측값이 모여있는 것을 확인할 수 있습니다. 분산은 예측값이 얼마나 흩어져있는지를 의미합니다. 따라서 분산이 낮으면 한 곳에 뭉쳐있고, 분산이 높으면 넓게 펴져있는 것을 확인할 수 있습니다. <figure style=\"text-align: center;\"> <img src=\"/post/bias_variance/bias_variance_2.png\" alt=\"Bias-Variance Tradeoff\" style=\"width: 100%; max-width: 600px; display: block; margin: 0 auto;\"/> <figcaption>그림 2: 실제 예측에서의 Bias-Variance Tradeoff - 단순한 모델(높은 편향, 낮은 분산) vs 복잡한 모델(낮은 편향, 높은 분산)</figcaption> </figure> 그림2는 실제 예측에서의 Bias-Variance Tradeoff를 설명하는 그림입니다. 학습하는 데이터셋 안에서 패턴을 잘 찾으면 (편향이 낮을수록) 모델은 복잡해져야 하고, 이때 예측 값이 넓게 퍼져있게 됩니다 (분산이 높아짐) 반대로 학습하는 데이터셋 안에서 패턴을 잘 찾지 못하면 (편향이 높을수록) 모델은 단순해져야 하고, 이때 예측 값이 한 곳에 모여있게 됩니다 (분산이 낮아짐) `` 단순한 모델 (예: 선형 회귀) ├── 높은 Bias: 데이터의 복잡한 패턴을 놓침 └── 낮은 Variance: 새로운 데이터에 대해 안정적 복잡한 모델 (예: 고차 다항식, 딥러닝) ├── 낮은 Bias: 데이터의 복잡한 패턴을 잘 학습 └── 높은 Variance: 새로운 데이터에 대해 불안정 `` 실제 예시 선형 회귀 vs 다항 회귀 선형 회귀 (1차 다항식) 낮은 복잡도 → 높은 편향, 낮은 분산 데이터가 비선형 패턴을 가지고 있다면 성능이 떨어짐 고차 다항 회귀 (예: 10차 다항식) 높은 복잡도 → 낮은 편향, 높은 분산 훈련 데이터에는 완벽하게 적합하지만 새로운 데이터에는 성능이 떨어짐 모델 선택에서의 적용 Underfitting vs Overfitting Underfitting (과소적합) 높은 편향, 낮은 분산 모델이 너무 단순해서 데이터의 패턴을 학습하지 못함 해결책: 모델 복잡도 증가 Overfitting (과적합) 낮은 편향, 높은 분산 모델이 훈련 데이터에 과도하게 적합되어 일반화 성능이 떨어짐 해결책: 모델 복잡도 감소, 정규화, 더 많은 데이터 최적 모델 선택 교차 검증 (Cross-Validation) 훈련 데이터와 검증 데이터를 분리하여 모델의 일반화 성능 평가 편향과 분산의 균형점을 찾는 데 도움 정규화 (Regularization) Ridge Regression (L2 정규화): 분산을 줄여 과적합 방지 Lasso Regression (L1 정규화): 특성 선택을 통한 모델 단순화 실무적 고려사항 데이터 크기의 영향 작은 데이터셋: 분산이 높아 과적합 위험 증가 큰 데이터셋: 편향이 더 중요한 고려사항 특성 엔지니어링 적절한 특성 선택과 변환이 편향-분산 균형에 큰 영향 도메인 지식을 활용한 특성 생성이 중요 결론 Bias-Variance Tradeoff는 머신러닝 모델 설계의 핵심 원칙입니다. 최적의 모델은 주어진 데이터와 문제에 대해 편향과 분산이 적절히 균형을 이루는 모델입니다. 이를 위해서는: 데이터의 특성 이해: 데이터의 복잡도와 노이즈 수준 파악 모델 복잡도 조절: 문제에 적합한 모델 선택 정규화 기법 활용: 과적합 방지를 위한 기법 적용 교차 검증: 모델의 일반화 성능 평가 이러한 원칙을 바탕으로 실무에서 더 나은 머신러닝 모델을 구축할 수 있습니다."
  },
  {
    "id": "Data Science/Causal Inference/Paper Review/Double-Debiased-Machine-Learning-for-Treatment-and-Structural-Parameters",
    "title": "[Paper Review] Double Debiased Machine Learning for Treatment and Structural Parameters",
    "date": "2025-07-22",
    "excerpt": "Double Debiased Machine Learning for Treatment and Structural Parameters",
    "category": "Causal Inference",
    "tags": [
      "Paper Review"
    ],
    "content": "paper link"
  },
  {
    "id": "Self_Development/English Study/SPEAK/지나간달/07-21-고민할때",
    "title": "고민하는 표현들",
    "date": "2025-07-21",
    "excerpt": "",
    "category": "English Study",
    "tags": [
      "영어공부꾸준히!",
      "SPEAK"
    ],
    "content": "On one hand, the Note has a really big screen. On one hand, I havent had Korean food in a while On one hand, taking a cab would be really convenient On the other hand, the new iPhone has a really good camera. On the other hand, Im craving fried chicken. On the other hand, I can walk there in 15 minute. Whether I buy the Note or the new iPhone, I should buy a phone tommorow."
  },
  {
    "id": "Self_Development/Career/Job Transition/25-07-21-남철님-clabi-커피챗",
    "title": "Clabi coffee chat with 남철",
    "date": "2025-07-21",
    "excerpt": "Clabi 채용공고 관련해서 남철님과 커피챗 진행",
    "category": "Career",
    "tags": [
      "Coffee Chat",
      "Clabi"
    ],
    "content": "채용공고 <details> <summary>📋 <strong>커피챗 상세정보</strong></summary> 클라비 기술연구소 AI 개발자 채용 (RAG, LLM, NLP, 인공지능) 모집부문 및 상세내용 공통 자격요건 학력: 무관 채용 프로세스 서류 지원 > 기술 면접(팀장) > 2차 면접 (연구소장님) > 3차 면접 (대표님) AIOps AI 개발자 모집 (기술연구소 0명) 주요업무 LLM 및 RAG 연구를 통한 AI 서비스 고도화 및 신규 기능 개발 프롬프트 엔지니어링을 활용한 챗봇 및 AI 모델 개발 AI 모델 성능 파인튜닝 및 최적화 RAG 파이프라인 구축 및 관련 애플리케이션 개발 대규모 데이터 수집 전처리 및 관리 근무조건 근무형태: 정규직(수습기간 3개월) 근무일시: 주 5일 (월-금) 10:00~17:00 근무지역: (05854) 서울 송파구 법원로 114 엠스테이트 B동 1108호(문정동) 서울 8호선 문정역에서 200m 이내 지원방법 이력서 및 포트폴리오 제출 지원 및 문의 : DM 또는 이메일(ncher@clabi.co.kr) </details> 커피챗 진행 방식 아이펠에서 공부할 때 퍼실님이었던 남철님과 채용관련 커피챗 진행. 온라인으로 1시간정도 진행함. 간단한 근황 이야기와 내가 진행했던 프로젝트에 대해서 설명드리고 회사에 대해 궁금한 점 질문. 유사 경험 (필살기) 설명 회사에서 하는 일과 내가 진행했던 일의 유사성을 설명. 유사 경험이 있고 회사에서 할 일과 비슷한 고민들을 했었다. 챗봇 프로젝트 Clabi의 주요 업무가 RAG SI인데 실제로 RAG를 통해 비즈니스 문제를 해결했던 경험이 있으니까 이를 강조. -> 긍정적인 반응. 아쉬운 점은 진행했던 일의 난이도가 그렇게 높지 않았다는 점. 만약 기술면접을 준비한다면 이 부분을 미리 공부하고 가면 좋을 것 같다. 내가 궁금했던 부분 RAG SI 업무는 진짜 전혀 안끌림. 그래서 이 부분을 벗어나서 확장하려는 부분이 있는지 -> 현재 수익으로 생성형 AI, SasS 부분으로 확장하고 있다고 함 대규모 데이터 처리. 빅데이터 플랫폼. 스마트팜 부분은 어떻게 진행되는지 -> 아마 외부업체가 참여하는 것 같다. 인터뷰하고 느낀 점은 내가 원하는 방향의 커리어는 아니다. 조금 더 데이터를 살펴보고 분석하면서 모델을 만드는, 데싸적인 느낌의 커리어가 나는 더 좋은 것 같다. 그리고 단순히 SI성 일들이 아닌, 좀 더 높은 수준의 난이도를 요구하는 일을 하고 싶다."
  },
  {
    "id": "Self_Development/English Study/SPEAK/지나간달/07-20-조언하는표현Review",
    "title": "Review day",
    "date": "2025-07-20",
    "excerpt": "",
    "category": "English Study",
    "tags": [
      "영어공부꾸준히!",
      "SPEAK",
      "Review day"
    ],
    "content": "오늘 배운거 Try to ~~ Try to cut down on drinking. Try not to skip breakfast. Make sure to ~ Make sure not to eat too much junk foods. Im worried about ~ Im worried about my love life. Im little worried about my bills. Be on the lookout for Be on the lookout for pickpockets. Be careful with ~ Be careful with your phone. Be careful not to burn yourself. Be careful not to catch a cold. Be careful not to cut yourself. By the way By the way, I was the blind date? Well the things is Well the thing is Im not really attracted to her. 간단한 작문 (오늘 배운거 사용도 해보면서 작문하는 연습) Time is so fast. 정신을 차려보면 시간은 한참 지나있다. Acheving something like, get a good english, playing guitar well, 좋은 회사에 취직하는 것 ,... are needs many time in the days. If you cant focus on today looking farway and beding nervous, I never acheive somethings that needs days. You should know that today is so precious. You can do everthing, but you couldn`t do nothing if you don't move. So, make sure to focus on the day you are living. 더 자연스러운 작문 Time flies so fast. Before you know it, a lot of time has passed. Achieving things like getting good at English, playing guitar well, or getting a job at a good company requires many days of effort. If you can't focus on today and keep looking far ahead while getting nervous, you'll never achieve things that take time. You should know that today is precious. You can do anything, but you won't accomplish anything if you don't take action. So, make sure to focus on the day you're living. 피드백 문법 및 표현 수정사항 \"Time is so fast\" → \"Time flies so fast\" \"Time is fast\"는 문법적으로 맞지 않습니다. \"Time flies\"가 자연스러운 표현입니다. \"Acheving\" → \"Achieving\" 철자 오류입니다. \"get a good english\" → \"getting good at English\" \"English\"는 대문자로 시작해야 하며, \"good at English\"가 올바른 표현입니다. \"are needs many time\" → \"requires many days of effort\" 문법적으로 맞지 않는 구조입니다. \"require\"를 사용하고 \"time\" 대신 \"days of effort\"가 더 자연스럽습니다. \"If you cant focus\" → \"If you can't focus\" \"can't\"의 축약형에서 apostrophe가 빠졌습니다. \"looking farway\" → \"looking far ahead\" \"farway\"는 올바른 단어가 아닙니다. \"far ahead\"가 맞습니다. \"beding nervous\" → \"getting nervous\" \"beding\"은 \"being\"의 오타로 보이지만, 맥락상 \"getting nervous\"가 더 자연스럽습니다. \"I never acheive\" → \"you'll never achieve\" 주어를 일관성 있게 \"you\"로 통일하고, 미래 시제를 사용하는 것이 자연스럽습니다. \"somethings\" → \"things\" \"something\"은 셀 수 없는 명사이므로 복수형이 없습니다. \"You can do everthing\" → \"You can do anything\" \"everthing\"은 \"everything\"의 오타입니다. \"couldn't do nothing\" → \"won't accomplish anything\" 이중 부정을 피하고 더 명확한 표현을 사용합니다. \"if you don't move\" → \"if you don't take action\" \"move\"보다 \"take action\"이 더 구체적이고 자연스럽습니다. 오늘 배운 표현 활용도 ✅ \"Make sure to\" 표현을 잘 활용했습니다! \"Make sure to focus on the day you're living.\" 추가 제안사항 더 다양한 표현 사용: \"Try to\", \"I'm worried about\", \"Be careful with\" 등의 표현도 활용해보세요. 문장 연결: \"By the way\", \"Well, the thing is\" 같은 연결어를 사용하면 더 자연스러운 대화체가 됩니다. 구체적인 예시: 추상적인 내용보다 구체적인 상황이나 예시를 들어보세요."
  },
  {
    "id": "Self_Development/Book/만들어진 신 (The God Delusion)/대단히종교적인불신자",
    "title": "대단히 종교적인 불신자",
    "date": "2025-07-20",
    "excerpt": "나는 인격신을 상상하려는 시도는 하지 않는다. 신은 우리의 불충분한 감각으로 세계의 구조를 이해할 수 있도록 함으로써 경외심을 품게 하는 정도면 충분하다. <알베르트 아인슈타인>",
    "category": "Book",
    "tags": [
      "The God Delusion",
      "만들어진 신"
    ],
    "content": "과학자들이 말하는 신은 뭘까? > 나는 인격신을 상상하려는 시도는 하지 않는다. 신은 우리의 불충분한 감각으로 세계의 구조를 이해할 수 있도록 함으로써 경외심을 품게 하는 정도면 충분하다. > > <알베르트 아인슈타인> 과학자들이 말하는 신은 무엇일까? 같은 신이라는 단어로 표현되고 있지만 이를 구분해서 이해할 필요가 있을 것 같다. 아이슈타인은 신을 말하며 우주의 합리성과 질서에 대한 경외심을 들어내고 있다. 예수나 부처와 같은 신을 의미하는게 아닌. > 훨씬 더 불행한 혼란은 아인슈타인식의 종교와 초자연적인 종교를 구분하지 못함으로써 빚어진다. 알베르트 아인슈타인(Albert Einstein)은 종종 신이라는 명칭을 사용함으로써(그런 무신론자 과학자가 그만은 아니다), 그런 유명한 과학자가 자신들의 편이기를 너무나 바라는 초자연주의자들의 오해를 자초하곤 했다. > > <만들어진 신>, 리처드 도킨스 - 밀리의 서재 과학자들이 신을 이야기한다고 이들이 신을 믿는다고 생각하면 안될 듯 하다. > 우리 시대의 위대한 과학자들이 종교적인 말을 하는 듯이 보여도 그들의 신념을 더 깊이 파고 들어가면 대개 그렇지 않다는 사실이 드러난다. > > <만들어진 신>, 리처드 도킨스 - 밀리의 서재 다른 사람들은 몰라도 과학자들 중 신을 믿는 사람들은 왜 있는걸까? 고등학교때 친구를 따라 교회를 1~2년도 다녔던 적이 있다. 그때도 신이라는 존재를 어떻게 믿을 수 있는지에 대해 의문이 들어 주위에 물어봤을 때, 믿음을 믿는다는 이야기를 들었다. 즉 어떤 근거가 있어서 믿는다기 보다는 믿음 자체를 믿는다는 것이다. 그래서 믿을 수 없다는 사람에게는 믿음이 부족하다, 성경을 더 공부하다보면 믿게 된다는 이야기를 한다. 나는 이런 믿음이라는게 굉장히 위험하다고 생각한다. 넷플릭스 시리즈의 \"나는 신이다\"에서 소개되는 JMS 같은 사이비 종교들의 논리와 교회가 다를게 뭔가? 믿음을 우선시 하는 삶의 태도가 나는 도저히 납득이 안간다. 과학을 하는 사람들 중에 신을 믿는 사람들이 많은데, 이들도 종교에 있어서는 믿음을 우선시 하기 때문이 아닐까 싶다. 종교에 있어서는 논리적인 이야기가 필요하지 않은. [이기적 유전자 저자] 리처드 도킨스한테 까인 썰 풀어드림 : 종교는 없어져야 한다 / 최재천의 아마존 유튜브 링크 최재천 교수가 리처드 도킨스와의 인터뷰 기회를 만들어서 만들어진 신에 대해 이야기했던 이야기. 리처드 도킨스가 이야기하는 모태신앙. 이 영상에 있는 댓글 중 기억에 남는 것들 > '개인이 망상에 빠지면 미친 것이지만 집단이 망상에 빠지면 종교이다. > > '-리처드 도킨스 > '종교는 부족의 생존에 도움을 준댜. > > '- 에드워드 윌슨 > 수 백명의 사람이 몇 달동안 믿으면 fake news이지만 수 천만명의 사람들이 수 천년 동안 믿으면 종교이다. > > - 유발 하라리 리처드 도킨스 : 창조론을 반박하는 팩트 , 충코의 철학 유튜브 링크 유전자들 간의 유사성 패턴. 창조론 vs 진화론. 신을 믿는 사람에게는 논쟁을 할 수 없다. 과학적인 근거를 무시한채 성경을 믿으니까. 과학자와 신에 대한 정리 (GPT 시킴) 왜 하나의 ‘과학자 관점’이 존재하지 않는가 현대 연구자들은 개인적 신·비개인적(범-)신·\\\\무신(불가지론 포함)\\\\의 폭넓은 스펙트럼을 이루며, 통계조차 양극화를 보여 준다. 미국 과학자 2,000 여 명을 조사한 Pew Research Center 보고서에 따르면 \\\\과학자의 51 %\\\\가 어떤 형태로든 신적 존재를 인정하지만, \\\\41 %\\\\는 “신이나 영적 힘이 없다”고 응답했다. 일반 대중과 비교하면 무신론 비율이 10 배에 가깝다.([Pew Research Center][1]) --- “과학도 신을 믿는다”―유신론·기독교적 입장 대표 인물 핵심 생각 주요 저술·발언 ------------------------ ------------------------------ ------------------------------------------------------ 프랜시스 콜린스 (유전학자) “진화는 하나님의 창조 도구”―‘유신론적 진화’ The Language of God (2006)([위키백과][2]) 조르주 르메트르 (빅뱅 제안자·사제) “과학은 어떻게를, 신앙은 왜를 다룬다” NYT 인터뷰(1933)([The Society of Catholic Scientists][3]) 그들은 과학 방법론을 준수하면서도, 창조 목적·도덕법 등 ‘궁극적 의미’는 과학 밖(종교)의 범주라고 본다. --- “우주가 곧 신”―범신론·우주적 경외 알베르트 아인슈타인: “나는 개인적 신을 믿지 않는다”면서도 “우주의 신비에 대한 경외를 ‘종교적 감정’이라 부를 수 있다”([Learn Religions][4]) 칼 세이건: “우리는 \\\\별의 먼지(star-stuff)\\\\로 이루어져, 우주가 스스로를 인식하는 방식”이라 표현했다.([Goodreads][5]) 이 흐름은 범신론·범재신론(Spinoza적 신)으로 분류되며, 자연법칙 = 신적 이성과 동등시한다. --- “신이 설 자리는 없다”―무신론·자연주의 인물 주된 논지 ------------ --------------------------------------------------------------- 스티븐 호킹 “시간이 ‘빅뱅 이전’에 존재하지 않았으므로 창조주가 개입할 ‘순간’도 없었다”([Live Science][6]) 리처드 도킨스 “개인적 신은 ‘착각(delusion)’이며, 진화가 설계의 환상을 설명한다”([위키백과][7]) 로런스 크라우스 “양자장과 중력이면 ‘무(無)’에서도 우주가 자연 발생할 수 있다”([위키백과][8]) 이들은 존재론적 자연주의를 채택하며, 초월적 설명은 과잉가설로 본다. --- “판단 유보”―불가지론·과학적 회의 천체물리학자 닐 드그래스 타이슨처럼 “증거 없는 주장엔 확신하지 않는다”는 경험론적 불가지론도 확산 중이다.([A-Z Quotes][9]) --- 다리를 놓으려는 시도: NOMA 원칙 고(故) 스티븐 제이 굴드의 비중첩 교구(NOMA) 모델은 “과학은 사실, 종교는 가치·의미”라는 영역 분리로 충돌을 완화하려 한다.([위키백과][10]) --- 이론적 배경 ① — 방법론적 자연주의(MN) 과학은 실험 가능한 자연 원인만을 탐구해야 한다는 규범이다. 초자연 원인은 검증 불가하므로 연구 설계에서 배제된다. 이 점에서 MN은 “과학의 성공 경험”이 낳은 실용적 전략으로 해석된다.([스프링거링크][11]) > \\\\존재론적 자연주의(ON)\\\\와 달리, MN은 “신 존재 여부에 대해 침묵”하지만, 무신론자는 종종 MN → ON을 연역한다. 논쟁은 바로 여기서 발생한다. --- 이론적 배경 ② — 미세 조정·다중우주·설계 논증 물리 상수들이 생명 탄생에 “절묘하게” 맞춰져 있다는 \\\\미세 조정(fine-tuning)\\\\은 두 갈래 해석을 낳았다. 신적 설계 — 콜린스·폴 데이비스 등은 “우연이라 보기엔 확률이 극미”라고 본다. 다중우주 / 선택 효과 — 호킹·크라우스는 “관측 가능한 우주만 생명 친화적일 뿐”이라 반박한다.([위키백과][12]) --- 역사적 맥락 한눈에 보기 시대 과학 혁신 신 개념 변화 ---------- --------- -------------------------- 17C 뉴턴 기계적 우주관 ‘시계공(Deus ex machina)’ 20C 초 빅뱅(르메트르) “창조 = 시작?” 논쟁 재점화 21C 양자중력·다중우주 무신론·불가지론 강화 vs. 미세조정 논증 강화 --- 종합 · 시사점 다양성: 과학적 업적과 신앙 유무는 직결되지 않는다. 대화 모델: 갈등·독립·대화·융합 — 네 가지 틀 가운데 어느 쪽을 택하느냐에 따라 입장도 분화된다. 철학의 역할: 과학이 “어떻게”를 설명할수록, “왜”에 대한 질문은 철학·신학·윤리로 이동한다. > 결론: “과학자들은 신을 믿는가?”라는 단일 질문 대신, \\\\“어떤 ‘신’ 개념을, 어떤 방법론으로 논의하는가?”\\\\*를 물을 때 비로소 논쟁의 결이 선명해진다. 이 다층적 구도를 염두에 두면, 과학과 종교의 관계는 ‘적대’보다는 창조적 긴장과 상호 보완의 장으로 재해석될 수 있다. [1]: https://www.pewresearch.org/religion/2009/11/05/scientists-and-belief/ \"Scientists and Belief Pew Research Center\" [2]: https://en.wikipedia.org/wiki/The_Language_of_God \"The Language of God - Wikipedia\" [3]: https://catholicscientists.org/articles/lemaitre-follows-two-paths-to-truth-new-york-times-1933-interview-with-lemaitre/ \"\\\"Lemaître Follows Two Paths to Truth\\\" (1933 New York Times Interview with Fr. Lemaître, Father of the Big Bang Theory) - The Society of Catholic Scientists\" [4]: https://www.learnreligions.com/albert-einstein-quotations-249858 \"Albert Einstein Quotes on Science, God, and Religion\" [5]: https://www.goodreads.com/quotes/484665-the-cosmos-is-within-us-we-are-made-of-star-stuff?utm_source=chatgpt.com \"Quote by Carl Sagan: “The cosmos is within us. We are made of star-st...” - Goodreads\" [6]: https://www.livescience.com/63854-stephen-hawking-says-no-god.html \"Stephen Hawking's Final Book Says There's 'No Possibility' of God in Our Universe Live Science\" [7]: https://en.wikipedia.org/wiki/The_God_Delusion \"The God Delusion - Wikipedia\" [8]: https://en.wikipedia.org/wiki/A_Universe_from_Nothing \"A Universe from Nothing - Wikipedia\" [9]: https://www.azquotes.com/author/14904-Neil_deGrasse_Tyson \"TOP 25 QUOTES BY NEIL DEGRASSE TYSON (of 764) A-Z Quotes\" [10]: https://en.wikipedia.org/wiki/Non-overlapping_magisteria \"Non-overlapping magisteria - Wikipedia\" [11]: https://link.springer.com/article/10.1007/s10670-024-00790-y?utm_source=chatgpt.com \"Methodological Naturalism, Analyzed Erkenntnis - Springer\" [12]: https://en.wikipedia.org/wiki/Fine-tuned_universe \"Fine-tuned universe - Wikipedia\""
  },
  {
    "id": "Data Science/Causal Inference/Paper Review/review-Towards-Optimal Doubly-Robust-Estimation-of-Heterogeneous-Causal-Effects",
    "title": "[Paper Review] Towards Optimal Doubly-Robust Estimation of Heterogeneous Causal Effects",
    "date": "2025-07-20",
    "excerpt": "Doubly-Robust Estimation of Heterogeneous Causal Effects 논문 리뷰",
    "category": "Causal Inference",
    "tags": [
      "paper review"
    ],
    "content": "paper link Abstact"
  },
  {
    "id": "Self_Development/Current Affairs/중국문화대혁명과홍위병",
    "title": "중국 문화대혁명과 홍위병",
    "date": "2025-07-17",
    "excerpt": "문화대혁명과 홍위병에 대한 내용들",
    "category": "Current Affairs",
    "tags": [
      "중국",
      "문화대혁명",
      "홍위병"
    ],
    "content": "참고 자료 리뷰엉이 - 삼체에서 가장 중요한 사건 문화대혁명 문화대혁명이란? 문화대혁명(文化大革命, Cultural Revolution)은 정식 명칭이 \"무산계급 문화대혁명\"(無產階級文化大革命, Great Proletarian Cultural Revolution)으로, 1966년부터 1976년까지 10년간 중국에서 일어난 사회정치적 운동이다. 발생 배경 대약진운동의 실패 (1958-1962) 마오쩌둥이 주도한 경제개발 정책인 대약진운동이 참혹하게 실패 2천만 명 이상이 기근으로 사망 마오쩌둥의 권력과 영향력이 크게 약화됨 실용주의 노선의 등장 류샤오치(劉少奇), 저우언라이(周恩來), 덩샤오핑(鄧小平) 등이 실용적 경제 정책 도입 개인 농지 허용 등 시장경제 요소 도입으로 경제 회복 (1962-1965) 마오쩌둥은 이러한 정책이 공산주의 원칙에 위배된다고 판단 문화대혁명의 목표 마오쩌둥이 문화대혁명을 일으킨 주요 목적: 권력 회복: 대약진운동 실패로 잃은 정치적 영향력 되찾기 정적 제거: 류샤오치, 덩샤오핑 등 실용주의 노선 지도자들 축출 혁명 정신 부활: 관료화되고 있는 중국 공산당과 사회에 혁명 정신 주입 \"4구\"(四舊) 타파: 구사상(舊思想) - 옛 사상 구문화(舊文化) - 옛 문화 구풍속(舊風俗) - 옛 풍습 구습관(舊習慣) - 옛 습관 문화대혁명의 전개 과정 1단계: 발발과 혼란 (1966-1968) 1966년 5월: 시작 5.16 통지: 중국 공산당 중앙위원회가 문화대혁명 시작을 공식 선언 부르주아 분자들이 당, 정부, 군대, 문화계에 침투했다고 주장 홍위병(紅衛兵) 조직 주로 학생들로 구성된 준군사조직 마오쩌둥어록(모택동어록, \"빨간책\")을 들고 다니며 숭배 \"혁명 무죄, 조반 유리\"(革命無罪, 造反有理) - \"혁명은 죄가 없고, 반란은 이치가 있다\" 20~30대 학생들이 주를 이뤘고 이때에 엄청난 권력을 가지고 있었다고 한다. 사단장보다 더 높은 권력. 사소한 이유로 사람들을 무자비하게 폭행하고 죽였기 때문에 사람들이 행동을 엄청 조심했었다고 한다. 폭력과 파괴 지식인, 교사, 정부 관리, 문화재 등에 대한 무차별 공격 공자묘, 천단, 명십삼릉 등 문화유산 파괴 학교와 대학 폐쇄 2단계: 권력 투쟁과 군 개입 (1967-1969) 1967년: \"전면적 내전\" 홍위병 파벌 간 무력 충돌 각 지역에서 \"권력 탈취\" 운동 전개 광저우, 베이징 등에서 대규모 폭력 사태 인민해방군의 개입 린뱌오(林彪)가 이끄는 인민해방군이 질서 회복에 나섬 홍위병들을 농촌으로 추방하는 \"상산하향\"(上山下鄉) 운동 시작 3단계: 안정화와 내부 권력 투쟁 (1969-1976) 린뱌오 사건 (1971) 마오쩌둥의 후계자로 지명된 린뱌오가 정치적으로 몰락 마오 암살 시도 후 소련으로 망명 시도 중 몽골에서 비행기 추락사 많은 중국인들이 공산당 지도부에 대한 신뢰 상실 4인방(四人幫)의 등장 장칭(江青, 마오쩌둥의 부인), 장춘차오(張春橋), 야오원위안(姚文元), 왕훙원(王洪文) 문화대혁명 후기의 실질적 권력자들 극좌 노선 추진 문화대혁명의 주요 정책 상산하향 운동(上山下鄉運動) \"산과 시골로 가라\"는 의미 도시 청년 1천만 명 이상을 농촌으로 강제 이주 노동을 통한 \"재교육\" 명목 실제로는 도시 과밀화 해결과 홍위병 해체 목적 교육 제도 파괴 대학 입시 시험 폐지 (1966-1973) \"혁명적 순수성\"이 학력보다 중요시됨 지식인과 과학자들이 \"구지식분자\"로 탄압받음 문화 예술 통제 서구 문학, 음악, 연극 금지 셰익스피어 작품 등 서양 고전 금지 오직 혁명 주제만 허용 문화대혁명의 종료 마오쩌둥의 죽음 (1976년 9월 9일) 27년간 중국을 통치한 마오쩌둥 사망 전국적으로 애도 분위기 4인방 체포 (1976년 10월 6일) 화궈펑(華國鋒)이 4인방을 체포 문화대혁명의 공식적 종료로 간주 4인방을 \"반혁명 범죄\" 혐의로 기소 문화대혁명의 결과와 영향 몇천년의 역사와 문화유산을 다 부쉈다. 공자나 제갈량과 같은 선조들의 무덤을 파헤치고 시신을 불태웠다. 인명 피해 사망자: 약 150만 명에서 200만 명 (추정치는 학자마다 다름) 박해받은 인원: 수천만 명 광시성에서는 식인 행위를 포함한 학살 발생 경제적 피해 1968년 공업 생산량이 1966년 대비 12% 감소 전반적인 경제 발전 지연 사회적 파괴 전통 문화와 역사 유물 대량 파괴 가족, 친구 관계 파괴 교육 시스템 붕괴로 \"잃어버린 세대\" 등장 정치적 영향 중국 공산당의 권위와 신뢰도 크게 실추 1978년 덩샤오핑의 개혁개방 정책으로 이어짐 문화대혁명에 대한 평가 중국 공산당의 공식 입장 (1981년) > \"문화대혁명은 중화인민공화국 건국 이후 당, 국가, 인민이 겪은 가장 심각한 좌절이자 가장 무거운 손실을 초래한 사건이다.\" 현재 중국에서의 취급 \"10년 동란\"(十年動亂) 또는 \"10년 재난\"(十年浩劫)으로 불림 공개적 논의는 여전히 제한적 마오쩌둥의 명성을 보호하기 위해 4인방에게 주로 책임 전가 문화대혁명이 남긴 교훈 권력 집중의 위험성: 개인 독재의 폐해 대중 동원의 한계: 조직화되지 않은 대중 운동의 위험 이데올로기의 맹목성: 현실을 무시한 교조적 사고의 문제 지식과 문화의 중요성: 반지성주의의 참혹한 결과 문화대혁명은 20세기 중국 역사상 가장 비극적인 사건 중 하나로, 중국 사회에 깊은 상처를 남겼으며 그 영향은 오늘날까지도 지속되고 있다. 삼체와의 연결 삼체란? 삼체(三體, The Three-Body Problem)는 중국의 SF 소설가 류츠신(劉慈欣)이 2006년에 발표한 과학소설로, 《지구왕사》(地球往事, Remembrance of Earth's Past) 삼부작의 첫 번째 작품이다. 소설의 성취 2015년 휴고상 수상: 중국 소설 최초로 세계 최고 권위의 SF 문학상 수상 글로벌 베스트셀러: 2014년 켄 류(Ken Liu)의 영어 번역을 통해 전 세계적 인기 획득 \"중국의 스타워즈\"로 불리며 중국 SF 문학의 글로벌 진출 상징 삼체의 줄거리 기본 설정 소설은 지구 근처에 있는 삼성계(三星系, Three-Body System)에 살고 있는 외계 문명 삼체인(三體人, Trisolarians)과 지구의 접촉을 다룬다. 삼체인들은 세 개의 태양이 불규칙하게 움직이는 혼돈스러운 환경에서 살고 있어 멸종 위기에 처해 있다. 주요 인물 예원제(葉文潔, Ye Wenjie): 문화대혁명 시기 물리학자인 아버지를 홍위병에게 잃은 여성 인류에 대한 절망으로 외계 문명과의 접촉을 시도 이야기의 핵심 인물이자 비극적 영웅 영상화 작품들 중국판 드라마 (2023) 제작사: 텐센트(Tencent) 특징: 원작에 충실하되 문화대혁명 장면은 검열로 인해 삭제 평가: 중국 내에서 높은 시청률 기록 넷플릭스 드라마: \"3 Body Problem\" (2024) 제작진: 데이비드 베니오프(David Benioff) D.B. 와이스(D.B. Weiss) - 《왕좌의 게임》 제작진 알렉산더 우(Alexander Woo) 제작비: 1억 6천만 달러 (넷플릭스 사상 최고액 드라마 중 하나) 주요 변화: 배경을 중국에서 영국 런던으로 이전 캐릭터들의 인종 다양화 \"옥스퍼드 파이브\"라는 새로운 인물 관계 창조 문화대혁명과 삼체의 연결 소설 속 문화대혁명 트라우마의 근원: 예원제가 홍위병들에게 아버지를 잃는 장면으로 시작 인류에 대한 절망: 문화대혁명의 폭력성이 예원제로 하여금 인류 전체에 대한 신뢰를 잃게 만듦 외계 문명과의 접촉 동기: 인류보다 나은 문명에 대한 갈망 역사적 의미 과학의 탄압: 문화대혁명 시기 지식인과 과학자들에 대한 박해 이데올로기 vs 진리: 과학적 진실보다 정치적 올바름을 우선시한 결과 집단 광기: 홍위병의 폭력성이 보여주는 군중 심리의 위험성 삼체가 제기하는 철학적 질문들 문명의 충돌 서로 다른 문명이 만났을 때의 필연적 갈등 생존을 위한 도덕적 선택의 딜레마 과학과 정치 과학의 정치적 중립성에 대한 의문 지식인의 사회적 책임 인류의 미래 기술 발전과 도덕적 진보의 불일치 문명의 지속가능성에 대한 근본적 의문 글로벌 수용과 논란 긍정적 평가 과학적 상상력: 정교한 물리학 이론을 바탕으로 한 설정 철학적 깊이: 문명, 과학, 도덕에 대한 깊이 있는 성찰 중국 SF의 세계화: 서구 중심의 SF 장르에 동양적 관점 도입 비판과 논란 넷플릭스 버전에 대한 중국 내 반발: 문화대혁명 장면이 중국을 비하한다는 비판 중국적 요소의 희석에 대한 불만 정치적 해석: 중국 국가주의자들의 \"서구 문화 패권주의\" 비판 문화대혁명 묘사에 대한 검열 우려 삼체가 보여주는 문화대혁명의 영향 개인적 차원 트라우마의 세대 전승: 예원제를 통해 본 개인적 상처 신뢰의 붕괴: 인간과 사회에 대한 근본적 불신 사회적 차원 지식 체계의 파괴: 과학과 학문에 대한 탄압의 결과 도덕적 혼란: 선악의 기준이 무너진 사회의 모습 문명사적 차원 진보에 대한 회의: 인류 문명의 발전 가능성에 대한 의문 외부 구원에 대한 환상: 내부 개혁의 한계와 외부 개입 기대 삼체는 단순한 SF 소설을 넘어서, 문화대혁명이라는 역사적 비극이 어떻게 개인과 문명 전체에 영향을 미칠 수 있는지를 보여주는 우화적 작품이다. 예원제의 선택은 개인적 트라우마가 어떻게 인류 전체의 운명을 바꿀 수 있는지를 극적으로 보여주며, 문화대혁명의 상처가 여전히 중국 사회와 문화에 깊이 각인되어 있음을 시사한다."
  },
  {
    "id": "Data Science/Causal Inference/what-is-ate",
    "title": "What is ATE?",
    "date": "2025-07-17",
    "excerpt": "What is ATE?",
    "category": "Causal Inference",
    "tags": [
      "ATE"
    ],
    "content": "ATE란? --- Average Treatment Effect (ATE)는 모든 사람들이 받은 처치의 평균 효과를 말한다. 즉, 처치받은 결과와 받지 않은 결과의 차이의 평균이라고 이해할 수 있다. ATE 추정 --- $$ \\hat{ATE} = \\frac{1}{N} \\sum_{i=1}^{N} (Y_i(1) - Y_i(0)) \\tag{1} $$ 정의에 따라 ATE는 (1)처럼 정의된다. 하지만 실제로는 모든 사람들이 처치를 받지 않기 때문에 (1)을 직접 계산할 수 없다."
  },
  {
    "id": "Data Science/Causal Inference/double-robustness-explained",
    "title": "Double Robustness: 인과추론의 핵심 개념 완전 정복",
    "date": "2025-07-17",
    "excerpt": "Double Robustness의 이론적 기반부터 실용적 응용까지 완전 해부",
    "category": "Causal Inference",
    "tags": [
      "Double Robustness",
      "Causal Inference",
      "Theory",
      "R-learner"
    ],
    "content": "Double Robustness: 인과추론의 핵심 개념 완전 정복 Double Robustness(이중 강건성)는 현대 인과추론의 핵심 개념 중 하나로, R-learner와 같은 최신 방법론의 이론적 기반이 됩니다. 이 포스트에서는 Double Robustness의 모든 측면을 자세히 살펴보겠습니다. Double Robustness란 무엇인가? 1.1 직관적 이해 Double Robustness는 \"두 가지 모델 중 하나만 정확해도 편향 없는 추정이 가능한 성질\"입니다. 간단한 비유 자물쇠 두 개: 문을 열려면 둘 중 하나만 열면 됨 백업 시스템: 주 시스템이 실패해도 보조 시스템이 작동 이중 보험: 하나가 실패해도 다른 하나가 보장 1.2 인과추론에서의 의미 인과추론에서 우리가 추정해야 하는 두 가지 핵심 요소: Outcome Model (결과 모델): $\\mu(x, w) = \\mathbb{E}[Y X = x, W = w]$ Propensity Score Model (처치 확률 모델): $e(x) = \\text{Pr}(W = 1 X = x)$ Double Robustness: 이 둘 중 하나만 정확해도 처치효과를 편향 없이 추정할 수 있음! 수학적 이론: 핵심 메커니즘 2.1 Potential Outcomes Framework 기본 설정: 잠재결과: $Y_i(0), Y_i(1)$ (처치를 받지 않았을 때/받았을 때의 결과) 관찰결과: $Y_i = Y_i(W_i)$ 개별 처치효과: $\\tau_i = Y_i(1) - Y_i(0)$ 평균 처치효과: $\\tau = \\mathbb{E}[Y(1) - Y(0)]$ 근본적 문제: 같은 개인에 대해 $Y_i(0)$과 $Y_i(1)$을 동시에 관찰할 수 없음! 2.2 Unconfoundedness Assumption $$\\{Y(0), Y(1)\\} \\perp \\!\\!\\! \\perp W \\mid X$$ 의미: 공변량 $X$를 통제하면 처치 할당이 무작위와 같음 이 가정 하에서 다음이 성립: $$\\mathbb{E}[Y(w) X] = \\mathbb{E}[Y X, W = w] = \\mu(X, w)$$ 2.3 Double Robustness의 수학적 표현 핵심 항등식 Average Treatment Effect (ATE)에 대한 doubly robust 추정량: $$\\hat{\\tau}_{DR} = \\frac{1}{n} \\sum_{i=1}^n \\left[ \\frac{W_i Y_i}{\\hat{e}(X_i)} - \\frac{(1-W_i) Y_i}{1-\\hat{e}(X_i)} + \\frac{W_i - \\hat{e}(X_i)}{\\hat{e}(X_i)(1-\\hat{e}(X_i))} \\left\\{ \\hat{\\mu}(X_i, 1) - \\hat{\\mu}(X_i, 0) \\right\\} \\right]$$ 더 간단한 형태 AIPW (Augmented Inverse Propensity Weighting) 추정량: $$\\hat{\\tau}_{AIPW} = \\frac{1}{n} \\sum_{i=1}^n \\left[ \\hat{\\mu}(X_i, 1) - \\hat{\\mu}(X_i, 0) + \\frac{W_i}{\\hat{e}(X_i)} \\{Y_i - \\hat{\\mu}(X_i, 1)\\} - \\frac{1-W_i}{1-\\hat{e}(X_i)} \\{Y_i - \\hat{\\mu}(X_i, 0)\\} \\right]$$ 2.4 왜 \"Double Robust\"인가? 핵심 정리 Theorem: 다음 조건 중 하나만 만족하면 $\\mathbb{E}[\\hat{\\tau}_{AIPW}] = \\tau$: Outcome model이 정확: $\\hat{\\mu}(x, w) = \\mu^(x, w)$ Propensity model이 정확: $\\hat{e}(x) = e^(x)$ 증명의 핵심 아이디어 AIPW 추정량을 다음과 같이 분해할 수 있습니다: $$\\hat{\\tau}_{AIPW} = \\underbrace{\\frac{1}{n} \\sum_{i=1}^n \\{\\hat{\\mu}(X_i, 1) - \\hat{\\mu}(X_i, 0)\\}}_{\\text{Outcome-based}} + \\underbrace{\\frac{1}{n} \\sum_{i=1}^n \\left[\\frac{W_i}{\\hat{e}(X_i)} - \\frac{1-W_i}{1-\\hat{e}(X_i)}\\right] \\{Y_i - \\hat{\\mu}(X_i, W_i)\\}}_{\\text{IPW correction}}$$ 케이스 1: Outcome model이 정확한 경우 첫 번째 항이 정확한 $\\tau$ 제공 두 번째 항의 기댓값이 0 (잔차의 가중평균) 케이스 2: Propensity model이 정확한 경우 두 번째 항이 IPW 추정량으로 정확한 $\\tau$ 제공 첫 번째 항의 오차가 두 번째 항에 의해 상쇄 직관적 이해: 왜 작동하는가? 3.1 Visual Intuition `` 진실한 처치효과: τ = 5 시나리오 1: Outcome Model 정확, Propensity Model 부정확 ┌─────────────────┐ ┌─────────────────┐ │ Outcome Model │ │ Propensity Model│ │ ✅ τ̂ = 5.0 │ + │ ❌ 편향 있음 │ = τ̂ = 5.0 ✅ └─────────────────┘ └─────────────────┘ 시나리오 2: Outcome Model 부정확, Propensity Model 정확 ┌─────────────────┐ ┌─────────────────┐ │ Outcome Model │ │ Propensity Model│ │ ❌ 편향 있음 │ + │ ✅ 정확함 │ = τ̂ = 5.0 ✅ └─────────────────┘ └─────────────────┘ 시나리오 3: 둘 다 정확 ┌─────────────────┐ ┌─────────────────┐ │ Outcome Model │ │ Propensity Model│ │ ✅ τ̂ = 5.0 │ + │ ✅ 정확함 │ = τ̂ = 5.0 ✅ └─────────────────┘ └─────────────────┘ ` 3.2 보상 메커니즘 (Compensation Mechanism) Outcome Model이 정확한 경우 `python Outcome model이 완벽하면 mu_hat(x, 1) - mu_hat(x, 0) ≈ τ IPW correction term은 E[W/e_hat(X) - (1-W)/(1-e_hat(X))] {Y - mu_hat(X,W)} ≈ 0 (잔차의 가중평균은 0에 가까움) ` Propensity Model이 정확한 경우 `python Propensity model이 완벽하면 IPW가 정확한 추정 제공 IPW_term = E[WY/e(X) - (1-W)Y/(1-e(X))] = τ Outcome model의 오차는 IPW correction에 의해 상쇄됨 ` 3.3 실제 데이터 예시 시뮬레이션 설정 `python n = 1000 X = np.random.normal(0, 1, (n, 2)) e_true = expit(X[:, 0]) # true propensity W = np.random.binomial(1, e_true) True outcome model: complex nonlinear Y_0 = X[:, 0]*2 + X[:, 1] + noise Y_1 = Y_0 + 2 + X[:, 0] # treatment effect = 2 + X[:, 0] Y = W Y_1 + (1 - W) Y_0 true_ATE = 2 + np.mean(X[:, 0]) # ≈ 2.0 ` 시나리오별 결과 `python Scenario 1: Good outcome model, bad propensity model mu_hat_good = fit_complex_model(Y, X, W) # R² = 0.95 e_hat_bad = 0.5 # constant (wrong!) AIPW_1 = compute_AIPW(Y, W, X, mu_hat_good, e_hat_bad) Result: 2.03 (거의 정확! ✅) Scenario 2: Bad outcome model, good propensity model mu_hat_bad = fit_linear_model(Y, X, W) # R² = 0.3 (underfit) e_hat_good = fit_logistic_model(W, X) # very accurate AIPW_2 = compute_AIPW(Y, W, X, mu_hat_bad, e_hat_good) Result: 1.97 (여전히 정확! ✅) Scenario 3: Both models bad AIPW_3 = compute_AIPW(Y, W, X, mu_hat_bad, e_hat_bad) Result: 1.2 (편향됨 ❌) ` Double Robustness의 장점과 한계 4.1 핵심 장점 견고성 (Robustness) 모델 오지정에 대한 보험: 하나가 틀려도 안전 실무적 안정성: 완벽한 모델링이 어려운 현실에서 유용 효율성 (Efficiency) 둘 다 정확하면 최고 효율성: 최소 분산 달성 Semiparametric efficiency bound 달성 유연성 (Flexibility) 서로 다른 방법 조합: 각 모델에 최적화된 방법 사용 가능 기계학습 방법 활용: 복잡한 모델도 사용 가능 4.2 한계점 둘 다 틀리면 편향 `python 최악의 시나리오 if outcome_model_wrong and propensity_model_wrong: bias = f(error_outcome, error_propensity) # 편향 발생 ` 분산 증가 가능성 IPW term의 극단값: propensity score가 0 또는 1에 가까우면 분산 급증 Overlap 조건 필요: $0 < e(x) < 1$ for all $x$ 추정 복잡성 두 모델 모두 추정: 계산 부담 증가 교차검증 복잡성: 각 모델의 튜닝이 복잡 R-learner와의 연결 5.1 Robinson's Transformation과 Double Robustness R-learner는 Robinson's transformation을 사용합니다: $$Y_i - m^(X_i) = \\{W_i - e^(X_i)\\} \\tau^(X_i) + \\varepsilon_i$$ 이를 다시 정리하면: $$Y_i = m^(X_i) + \\{W_i - e^(X_i)\\} \\tau^(X_i) + \\varepsilon_i$$ Double Robust Structure R-loss 함수: $$\\hat{L}_n\\{\\tau(\\cdot)\\} = \\frac{1}{n} \\sum_{i=1}^n \\left[ \\left\\{Y_i - \\hat{m}^{(-q(i))}(X_i)\\right\\} - \\left\\{W_i - \\hat{e}^{(-q(i))}(X_i)\\right\\} \\tau(X_i) \\right]^2$$ 핵심: 이 손실함수도 double robust 성질을 가집니다! $\\hat{m}$이 정확하면 첫 번째 항이 정확한 잔차 제공 $\\hat{e}$가 정확하면 두 번째 항이 정확한 가중치 제공 5.2 왜 R-learner가 Quasi-Oracle인가? `python Oracle knows m(x) and e(x) oracle_loss = E[(Y - m(X) - {W - e(X)}τ(X))²] R-learner uses estimates r_loss = E[(Y - m̂(X) - {W - ê(X)}τ̂(X))²] Double robustness ensures: if rate(m̂ - m) rate(ê - e) → 0 faster than oracle_rate: rate(R-learner) ≈ oracle_rate # 🎯 ` 실용적 구현 가이드 6.1 Python Implementation `python import numpy as np from sklearn.ensemble import RandomForestRegressor from sklearn.linear_model import LogisticRegression from sklearn.model_selection import cross_val_predict def doubly_robust_ate(Y, W, X, outcome_model=None, propensity_model=None): \"\"\" Doubly Robust ATE 추정 Parameters: ----------- Y : array-like, shape (n,) Outcome variable W : array-like, shape (n,) Treatment indicator (0 or 1) X : array-like, shape (n, p) Covariates outcome_model : sklearn estimator Outcome regression model propensity_model : sklearn estimator Propensity score model Returns: -------- ate_estimate : float Doubly robust ATE estimate \"\"\" n = len(Y) # Default models if outcome_model is None: outcome_model = RandomForestRegressor(n_estimators=100, random_state=42) if propensity_model is None: propensity_model = LogisticRegression(random_state=42) # Cross-fitting for outcome model mu_1_hat = np.zeros(n) mu_0_hat = np.zeros(n) # Estimate E[Y X,W=1] idx_1 = W == 1 if np.sum(idx_1) > 0: mu_1_hat[idx_1] = cross_val_predict( outcome_model, X[idx_1], Y[idx_1], cv=5 ) outcome_model.fit(X[idx_1], Y[idx_1]) mu_1_hat[~idx_1] = outcome_model.predict(X[~idx_1]) # Estimate E[Y X,W=0] idx_0 = W == 0 if np.sum(idx_0) > 0: mu_0_hat[idx_0] = cross_val_predict( outcome_model, X[idx_0], Y[idx_0], cv=5 ) outcome_model.fit(X[idx_0], Y[idx_0]) mu_0_hat[~idx_0] = outcome_model.predict(X[~idx_0]) # Cross-fitting for propensity score e_hat = cross_val_predict( propensity_model, X, W, cv=5, method='predict_proba' )[:, 1] # Clip propensity scores to avoid extreme weights e_hat = np.clip(e_hat, 0.01, 0.99) # AIPW estimator aipw_components = ( (mu_1_hat - mu_0_hat) + # Outcome-based estimate W (Y - mu_1_hat) / e_hat - # IPW correction for treated (1 - W) (Y - mu_0_hat) / (1 - e_hat) # IPW correction for control ) ate_estimate = np.mean(aipw_components) # Standard error (using influence function) influence_func = aipw_components - ate_estimate se_estimate = np.std(influence_func) / np.sqrt(n) return { 'ate': ate_estimate, 'se': se_estimate, 'ci_lower': ate_estimate - 1.96 se_estimate, 'ci_upper': ate_estimate + 1.96 se_estimate } Usage example def simulate_data(n=1000): \"\"\"Generate simulation data\"\"\" X = np.random.normal(0, 1, (n, 3)) # True propensity score (logistic) e_true = 1 / (1 + np.exp(-(X[:, 0] + 0.5 X[:, 1]))) W = np.random.binomial(1, e_true) # True outcome model (nonlinear) Y_0 = X[:, 0]*2 + X[:, 1] + 0.5 X[:, 2] + np.random.normal(0, 0.5, n) Y_1 = Y_0 + 2 + X[:, 0] # Heterogeneous treatment effect Y = W Y_1 + (1 - W) Y_0 return Y, W, X, 2.0 # True ATE ≈ 2.0 Run example Y, W, X, true_ate = simulate_data() result = doubly_robust_ate(Y, W, X) print(f\"True ATE: {true_ate:.3f}\") print(f\"DR Estimate: {result['ate']:.3f}\") print(f\"95% CI: [{result['ci_lower']:.3f}, {result['ci_upper']:.3f}]\") ` 6.2 Best Practices 모델 선택 가이드라인 `python Outcome Model High flexibility for complex relationships outcome_models = { 'linear': LinearRegression(), 'rf': RandomForestRegressor(n_estimators=200), 'xgb': XGBRegressor(), 'nn': MLPRegressor(hidden_layer_sizes=(100, 50)) } Propensity Model Focus on overlap and calibration propensity_models = { 'logistic': LogisticRegression(C=1.0), 'rf': RandomForestClassifier(n_estimators=200), 'calibrated': CalibratedClassifierCV(LogisticRegression()) } ` 진단 도구 `python def diagnose_overlap(e_hat, W): \"\"\"Check overlap assumption\"\"\" print(f\"Propensity score range: [{e_hat.min():.3f}, {e_hat.max():.3f}]\") print(f\"Extreme scores (< 0.1 or > 0.9): {np.mean((e_hat < 0.1) (e_hat > 0.9)):.1%}\") # Plot distributions import matplotlib.pyplot as plt plt.figure(figsize=(10, 4)) plt.subplot(1, 2, 1) plt.hist(e_hat[W==0], alpha=0.7, label='Control', bins=30) plt.hist(e_hat[W==1], alpha=0.7, label='Treated', bins=30) plt.xlabel('Propensity Score') plt.ylabel('Frequency') plt.legend() plt.title('Overlap Check') plt.subplot(1, 2, 2) plt.boxplot([e_hat[W==0], e_hat[W==1]], labels=['Control', 'Treated']) plt.ylabel('Propensity Score') plt.title('Distribution by Treatment') plt.tight_layout() plt.show() def check_balance(X, W, e_hat): \"\"\"Check covariate balance after weighting\"\"\" weights_1 = W / e_hat weights_0 = (1 - W) / (1 - e_hat) for j in range(X.shape[1]): mean_1 = np.average(X[W==1, j], weights=weights_1[W==1]) mean_0 = np.average(X[W==0, j], weights=weights_0[W==0]) print(f\"Variable {j}: Weighted difference = {mean_1 - mean_0:.4f}\") ` 최신 연구 동향과 확장 7.1 Machine Learning과의 결합 Targeted Maximum Likelihood Estimation (TMLE) One-step correction: 초기 추정값을 업데이트 Cross-validation: 최적 모델 선택 Causal Random Forests Honest splitting: 편향 없는 추정 Local centering: Double robustness 보장 Neural Network Approaches Representation learning: 공통 특성 학습 Domain adaptation: Treatment/control domain 정렬 7.2 고차원 데이터에서의 확장 Debiased Machine Learning (DML) `python Neyman orthogonality + Cross-fitting def debiased_ml_ate(Y, W, X): # Step 1: Estimate nuisance functions theta_0 = estimate_initial(Y, W, X) # Step 2: Compute orthogonal score psi = compute_orthogonal_score(Y, W, X, theta_0) # Step 3: Solve orthogonal equation theta_final = solve_orthogonal_equation(psi) return theta_final ` 7.3 연속 처치와 다중 처치 Continuous Treatment `python GPS (Generalized Propensity Score) + Outcome Model def continuous_dr(Y, T, X): # Estimate treatment density: f(T X) gps_hat = estimate_gps(T, X) # Estimate dose-response: E[Y T,X] outcome_hat = estimate_outcome(Y, T, X) # Double robust estimand dr_estimate = compute_dr_continuous(Y, T, X, gps_hat, outcome_hat) return dr_estimate `` 결론: Double Robustness의 의의 8.1 이론적 기여 편향 없는 추정의 보장: 모델 오지정에도 robust 효율성: 최적 조건에서 semiparametric efficiency bound 달성 유연성: 다양한 기계학습 방법과 결합 가능 8.2 실용적 가치 현실적 해결책: 완벽한 모델링이 어려운 현실에서 안전망 제공 방법론 발전의 기반: R-learner, TMLE, DML 등의 이론적 토대 산업 응용: A/B 테스트, 개인화, 정책 평가 등에서 널리 활용 8.3 미래 전망 Double Robustness는 앞으로도 인과추론 방법론 발전의 핵심 원리로 작용할 것입니다: 딥러닝과의 결합: 표현 학습 기반 double robust 방법 실시간 추론: 온라인 학습에서의 double robustness 복잡한 처치 구조: 네트워크, 시계열에서의 확장 Double Robustness를 이해하는 것은 현대 인과추론의 핵심을 파악하는 것과 같습니다. 이 개념을 바탕으로 더 robust하고 효율적인 인과 추론 방법들이 계속 발전할 것입니다. 🎯 --- 참고문헌: Robins, J.M., Rotnitzky, A., & Zhao, L.P. (1994). Estimation of regression coefficients when some regressors are not always observed. Bang, H. & Robins, J.M. (2005). Doubly robust estimation in missing data and causal inference models. Chernozhukov, V., et al. (2018). Double/debiased machine learning for treatment and structural parameters. Kennedy, E.H. (2020). Towards optimal doubly robust estimation of heterogeneous causal effects."
  },
  {
    "id": "Data Science/Causal Inference/Paper Review/review-Quasi-Oracle-Estimation-of-Heterogeneous-Treatment-Effects",
    "title": "[Paper Review] Quasi-Oracle Estimation of Heterogeneous Treatment Effects",
    "date": "2025-07-17",
    "excerpt": "R-leaner 방법 소개와 이게 가지는 quasi-oracle property에 대해 설명",
    "category": "Causal Inference",
    "tags": [
      "Paper Review"
    ],
    "content": "paper link 논문 리뷰 Abstract > Flexible estimation of heterogeneous treatment effects lies at the heart of many statistical challenges, such as personalized medicine and optimal resource allocation. 개인화된 처치효과를 유연하게 추정하는 것은 많은 분야에서 통계적 문제의 핵심입니다. 개인화된 처치효과를 알고 있으면 개인화된 약처방이나 교육정책 결정, 자원 분배 등 많은 문제에서 좋은 결정을 내릴 수 있습니다. 하지만 이를 추정하는 일은 꽤나 복잡한 일이라서 논문에서는 이를 유연하게 추정할 수 있는 방법을 제시하고 있습니다. 이 논문에서는 marginal effects와 treatment propensity라는 두 가지 nuisance component를 추정하여 개인화된 처치효과를 추정하는 방법을 제시합니다. > we show that our method has a quasi-oracle property: Even if the pilot estimates for marginal effects and treatment propensities are not particularly accurate, we achieve the same error bounds as an oracle who has a priori knowledge of these two nuisance components. 이러한 방법은 quasi-oracle property를 가지고 있다고 합니다. <small> quasi-oracle property : marginal effects와 treatment propensity의 추정이 정확하지 않더라도, 마치 이 두 nuisance component를 미리 알고 있는 것과 같은 오차 경계를 달성할 수 있는 성질</small> Introduction 기존 연구의 한계점: 방법론적 불일치: 관찰 연구에서 기계학습 방법을 처치효과 추정에 어떻게 적용해야 하는지에 대한 포괄적인 답이 아직 확립되지 않음 개발 과정의 복잡성: 인과관계 기계학습 방법을 개발하는 과정이 노동집약적이며, 전문 연구자들의 참여가 필수적 이론적 근거 부족: 대부분의 방법들이 수치적 실험으로만 검증되고, 형식적인 수렴 보장이나 오차 경 이 논문의 새로운 접근법: 자동화된 프레임워크: 임의의 손실 최소화 절차를 통해 개인화된 처치효과 추정기를 완전 자동으로 명세할 수 있는 프레임워크 제공 Oracle 수준의 성능: 데이터 생성 분포에 대한 모든 정보를 알고 있는 oracle 방법과 비교 가능한 오차 경계 달성 이론적 기반: 이중 강건 추정(double robust estimation), oracle 부등식, 교차 검증을 결합하여 일반적인 기계학습 도구로 원리적 통계 추정을 위한 손실 함수 개발 이 논문은 기존의 실용적 한계와 이론적 부족함을 모두 해결하는 새로운 접근법을 제시하고 있습니다. A Loss Function for Treatment Effect Estimation > We formalize our problem in terms of the potential outcomes framework (Neyman, 1923; Rubin, 1974). potential outcomes framework를 사용해 문제를 정의합니다. 데이터 구조: 관찰 데이터: $(X_i, Y_i, W_i)$ for $i = 1, ..., n$ $X_i \\in \\mathcal{X}$: 개인별 특성 (features) $Y_i \\in \\mathbb{R}$: 관찰된 결과 (observed outcome) $W_i \\in \\{0, 1\\}$: 처치 할당 (treatment assignment) 잠재 결과 (Potential Outcomes): 잠재 결과: $\\{Y_i(0), Y_i(1)\\}$ $Y_i(0)$: 처치를 받지 않았을 때의 결과 $Y_i(1)$: 처치를 받았을 때의 결과 관찰된 결과와의 관계: $Y_i = Y_i(W_i)$ 조건부 평균 처치효과 (CATE): 목표 함수: $\\tau^(x) = \\mathbb{E}[Y(1) - Y(0) \\mid X = x]$ 특성 $X = x$인 개인들의 평균 처치효과 식별 조건: Unconfoundedness: 처치 할당이 관찰되지 않은 confounding variable에 의해 영향을 받지 않는다는 가정 이 수식들은 인과추론의 표준적인 잠재결과 프레임워크를 따르며, 개인화된 처치효과 추정을 위한 기본 구조를 정의합니다. > In order to identify $\\tau^(x)$, we assume unconfoundedness, i.e., the treatment assignment is randomized once we control for the features $X_i$ (Rosenbaum and Rubin, 1983). CATE를 추정하기 위해서는 무작위 할당처럼 unconfoundedness 가정을 만족해야 합니다. 이를 위해서 X를 통제할 수 있습니다. Assumption 1 : The treatment assignment $W_i$ is unconfounded, $\\{Y_i(0), Y_i(1)\\} \\perp \\!\\!\\! \\perp W_i \\mid X_i$ Treatment Propensity : $e^(x) = \\Pr(W = 1 \\mid X = x)$ Conditional Response Surfaces : $\\mu^{(w)}(x) = \\mathbb{E}[Y(w) \\mid X = x]$ for $w \\in \\{0, 1\\}$ Error Term : $\\varepsilon_i(w) := Y_i(w) - \\{\\mu^{(0)}(X_i) + w\\tau^(X_i)\\}$ 성질 : unconfoundedness 하에서 $\\mathbb{E}[\\varepsilon_i(W_i) \\mid X_i, W_i] = 0$ Conditional Mean Outcome : $m^(x) = \\mathbb{E}[Y \\mid X = x] = \\mu^{(0)}(x) + e^(x)\\tau^(x)$ $$ Y_i - m^(X_i) = \\{W_i - e^(X_i)\\} \\tau^(X_i) + \\varepsilon_i \\tag{1} $$ (1)에서 *propensity score $e^(X_i)$를 통해 X를 통제합니다. $W_i - e^(X_i)$: 실제 처치 할당에서 예측된 처치 확률을 뺀 값 이는 X를 통제한 후의 \"처치 할당의 편차\"를 나타냄 마치 X가 같은 그룹 내에서 무작위 할당된 것처럼 만듦 따라서 이 등식은 propensity score를 통한 X 통제를 구현한 것입니다. > The goal of this paper is to study how we can use the Robinson’s transfomation (1) for flexible treatment effect estimation that builds on modern machine learning approaches such as boosting or deep learning. 이 논문의 목표는 부스팅이나 딥러닝과 같은 현대적인 기계학습 방법을 기반으로 하는 유연한 처치효과 추정을 위해 Robinson's transfomation (1)을 어떻게 사용할 수 있는지 연구하는 것입니다. > Our main result is that we can use this representation to construct a loss function that captures heterogeneous treatment effects, and that we can then accurately estimate treatment effects—both in terms of empirical performance and asymptotic guarantees—by finding regularized minimizers of this loss function. 이 논문의 주요 결과는 이 표현을 사용하여 개인화된 처치효과를 포착하는 손실 함수를 구성할 수 있으며, 이 손실 함수의 정규화된 최소화 해를 찾아 처치효과를 정확하게 추정할 수 있다는 것입니다. $$ \\tau^(\\cdot) = \\arg\\min_{\\tau} \\mathbb{E}\\left[\\{Y_i - m^(X_i)\\} - \\{W_i - e^(X_i)\\} \\tau(X_i)\\right]^2 \\tag{2} $$ $$ \\tilde{\\tau}(\\cdot) = \\arg\\min_{\\tau} \\left\\{ \\frac{1}{n} \\sum_{i=1}^n \\left( \\{ Y_i - m^(X_i) \\} - \\{ W_i - e^(X_i) \\} \\tau(X_i) \\right)^2 + \\Lambda_n[\\tau(\\cdot)] \\right\\} \\tag{3} $$ where the term $\\Lambda_n[\\tau(\\cdot)]$ is interpreted as a regularizer on the complexity of the $\\tau(\\cdot)$ function > This regularization could be explicit as in penalized regression, or implicit, e.g., as provided by a carefully designed deep neural network. 정규화항은 모델의 설계에 맞춰 적용한다고 합니다. > The difficulty, however, is that in practice we never know the weighted main effect function $m^(x)$ and usually don’t know the treatment propensities $e^(x)$ either, and so the estimator (3) is not feasible. 하지만 어려운 점은 당연하게도 $m^(x)$와 $e^(x)$를 알 수 없다는 점입니다. > Given these preliminaries, we here study the following class of two-step estimators using cross-fitting (Chernozhukov et al., 2018; Schick, 1986) motivated by the above oracle procedure: Cross-fitting을 이용한 2단계 추정 방법: Step 1: 데이터 분할 및 Nuisance Component 추정 데이터를 Q개(보통 5 또는 10)의 균등한 크기의 fold로 분할 $q(\\cdot)$: $i = 1, \\ldots, n$ 샘플 인덱스를 Q개의 fold에 매핑하는 함수 Cross-fitting을 통해 $\\hat{m}$과 $\\hat{e}$를 최적 예측 정확도를 위해 조정된 방법으로 추정 Step 2: Plug-in 추정 (3)의 plug-in 버전을 통해 처치효과 추정 $\\hat{e}^{(-q(i))}(X_i)$ 등은 i번째 훈련 예제가 속한 fold를 사용하지 않고 만든 예측값 $$ \\hat{\\tau}(\\cdot) = \\arg\\min_{\\tau} \\left\\{ \\hat{L}_n[\\tau(\\cdot)] + \\Lambda_n[\\tau(\\cdot)] \\right\\} \\tag{4} $$ $$ \\hat{L}_n[\\tau(\\cdot)] = \\frac{1}{n} \\sum_{i=1}^n \\left[ \\{Y_i - \\hat{m}^{(-q(i))}(X_i)\\} - \\{W_i - \\hat{e}^{(-q(i))}(X_i)\\} \\tau(X_i) \\right]^2 \\tag{4a} $$ > In other words, the first step learns an approximation for the oracle objective, and the second step optimizes it. We refer to this approach as the R-learner in recognition of the work of Robinson (1988) and to emphasize the role of residualization. We will also refer to the squared loss $L_b^n[\\tau(\\cdot)]$ as the R-loss. 1단계: 오라클 목적함수(이론적으로 최적임을 보장하는 함수)의 근사값을 학습 2단계: 그 근사 목적함수를 실제로 최적화 이 전체 과정을 R-learner라 부르고, 손실함수를 R-loss라 부름 논문의 주요 기여: 다양한 방법 적용 및 성능 R-learner를 페널티 회귀, 커널 릿지 회귀, 부스팅 등 다양한 방법에 적용하여 기존 방법들보다 좋은 성능을 보임. 이론적 보장 커널 회귀의 경우, 실제 추정기(plug-in estimator)의 오차 경계가 오라클(이론적 최적) 방법과 거의 일치함을 증명. 특히, nuisance component($m^(x)$, $e^(x)$)의 추정 오차가 충분히 빠르게 줄어들면, 최종 처치효과 추정기의 수렴 속도는 오직 $\\tau^(x)$의 복잡도에만 의존함. 실용적 장점 R-learner는 처치확률과 결과 예측의 상관관계를 손실함수 구조로 분리하여, 두 작업(상관관계 제거, 처치효과 추정)을 명확히 분리함. 이로 인해 다양한 기계학습 도구(예: glmnet, XGBoost, TensorFlow 등)를 손쉽게 활용할 수 있고, 손실함수(R-loss)만 잘 최소화하면 됨. 복잡한 교차검증 없이도 손실함수 기반의 간단한 튜닝이 가능함. Related Work Regularization bias: > However, the fact that both $\\hat{\\beta}^{(0)}$ and $\\hat{\\beta}^{(1)}$ are regularized towards 0 separately may inadvertently regularize the treatment effect estimate $\\hat{\\beta}^{(1)} - \\hat{\\beta}^{(0)}$ away from 0, even when $\\tau^(x) = 0$ everywhere CATE(조건부 평균 처치효과)는 $\\tau^(x) = \\mu^{(1)}(x) - \\mu^{(0)}(x)$로 쓸 수 있음. 흔히 $\\mu^{(1)}(x)$와 $\\mu^{(0)}(x)$를 각각 따로 추정한 뒤, 그 차이로 처치효과를 구하는데, 이때 두 함수를 별도로 정규화(regularization)하면 regularization bias가 발생할 수 있음. 예를 들어, 라쏘(lasso) 회귀를 각각의 집단(처치/비처치)에 따로 적용하면, 두 추정치 모두 0에 가까워지도록 정규화되어 실제로는 처치효과가 없을 때도 $\\hat{\\tau}(x) = \\hat{\\mu}^{(1)}(x) - \\hat{\\mu}^{(0)}(x)$가 0에서 멀어질 수 있음. 특히, 처치군과 대조군의 샘플 수가 다를 때 이 현상이 더 심해짐. $$ \\begin{align} \\hat{\\beta}^{(w)} = \\arg\\min_{\\beta^{(w)}} \\left\\{ \\sum_{i:W_i=w} \\left( Y_i - X_i^\\top \\beta^{(w)} \\right)^2 + \\lambda^{(w)} \\ \\beta^{(w)}\\ _1 \\right\\} \\tag{5} \\end{align} $$ 간단하게 대조군과 통제군을 따로 학습시키고, 그 결과를 비교해서 처치효과를 얻으면 되는거 아니야? 라고 생각할 수 있지만 이렇게 하면 regularization bias라고 하는, 과하게 정규화되어 처치효과가 0일 때도 0에서 멀어질 수 있는 문제가 발생합니다. Regularization Bias를 피하는 최근 방법들: 최근 연구들은 regularization bias 문제를 피하기 위해 다양한 구조적(machine learning 구조 자체의) 개선 방법을 제안함. 예를 들어, Imai & Ratkovic (2013)은 식 (5)처럼 처치군/대조군을 따로 학습하는 대신, 아래와 같이 하나의 라쏘(lasso) 회귀로 동시에 학습하는 방법을 제안함: $$ \\begin{align} \\hat{b}, \\hat{\\delta} = \\arg\\min_{b, \\delta} \\left\\{ \\sum_{i=1}^n \\left( Y_i - X_i^\\top b + (W_i - 0.5) X_i^\\top \\delta \\right)^2 + \\lambda_b \\ b\\ _1 + \\lambda_\\delta \\ \\delta\\ _1 \\right\\} \\tag{6} \\end{align} $$ 여기서 최종 처치효과 추정은 $\\hat{\\tau}(x) = x^\\top \\hat{\\delta}$로 계산함. 이 방법은 $\\delta$에만 희소성(sparsity)을 강제하여, 처치효과의 구조적 특성을 더 잘 반영할 수 있음. 이외에도 신경망 등 다양한 기계학습 방법에서 처치효과 이질성(heterogeneity)을 잘 추정하도록 구조를 설계하는 연구들이 진행되고 있음(예: Shalit et al., 2017). Loss Function(손실함수) 변경을 통한 접근: > Here, instead of trying to modify the algorithms underlying different machine learning tools to improve their performance as treatment effect estimators, we focus on modifying the loss function used to training generic machine learning methods. 최근 연구들은 모델 구조 자체를 바꾸는 대신, 손실함수(R-loss)를 바꿔서 처치효과 추정 성능을 높이는 방법에 주목하고 있음. 이 접근은 van der Laan과 Dudoit(2003) 등에서 시작된 연구 흐름을 기반으로 하며, 이들은 doubly robust objective(이중 강건 목적함수)에 대한 교차검증을 통해 최적의 통계적 규칙을 선택하는 방법을 제안함. Luedtke & van der Laan(2016) 등은 이러한 목적함수를 이용해 개별화 처치규칙(individualized treatment rules)이나 이질적 처치효과(heterogeneous treatment effects)를 학습하는 다양한 유효한 목적함수(oracle loss 등)의 성질을 분석함. 본 논문의 기여는, R-loss를 활용해 범용 기계학습(generic machine learning)으로 처치효과를 추정하는 방법을 제시하고, 커널 힐버트 공간에서의 정규화 회귀 등 널리 쓰이는 비모수적 방법에 대해 강한 이론적 오차 경계(수렴률 보장)를 제공한 것임. meta-learning 방법들: meta learner 관련 설명자료 X-learner (Künzel et al., 2019): 먼저 $\\hat{\\mu}^{(w)}(x)$를 비모수 회귀 방법으로 추정 처치 관찰값에 대해 pseudo-effects $D_i = Y_i - \\hat{\\mu}^{(-i)}{(0)}(X_i)$를 정의하고, 이를 이용해 $\\hat{\\tau}^{(1)}(X_i)$를 비모수 회귀로 추정 대조군에 대해서도 유사하게 $\\hat{\\tau}^{(0)}(X_i)$를 구하고, 두 추정기를 다음과 같이 결합: $$ \\hat{\\tau}(x) = \\{1 - \\hat{e}(x)\\} \\hat{\\tau}^{(1)}(x) + \\hat{e}(x) \\hat{\\tau}^{(0)}(x) \\tag{7} $$ U-learner (Künzel et al., 2019): $U_i = \\frac{Y_i - m^(X_i)}{W_i - e^(X_i)}$에 대해 $\\mathbb{E}[U_i \\mid X_i = x] = \\tau(x)$임을 이용 $U_i$를 $X_i$에 대해 범용 기계학습 방법으로 회귀 Propensity Score 가중 방법들: Athey & Imbens (2016), Tian et al. (2014) 등이 제안 결과나 공변량을 propensity score로 가중하여 처치효과 추정 예: $Y_i\\{W_i - e^(X_i)\\}/\\{e^(X_i)(1-e^(X_i))\\}$를 $X_i$에 대해 회귀 본 논문의 기여: R-learner 방법을 제안하여 다양한 설정에서 baseline보다 의미있는 개선을 제공 Quasi-oracle 오차 경계를 제공하여 $\\hat{\\tau}$의 오차가 $\\hat{e}$나 $\\hat{m}$의 오차보다 빠르게 감소할 수 있음을 이론적으로 보장 관련 연구와 본 논문의 차별점: 가장 유사한 기존 연구: Zhao, Small, and Ertefaie (2017): Robinson 변환과 라쏘(lasso)를 결합해 고차원 선형모형에서 효과 수정(effect modification)에 대한 유효한 사후선택 추론(post-selection inference)을 제공 하지만 일반적인 기계학습 맥락에서 손실함수로 Robinson 변환을 활용한 것은 본 논문이 처음 이론적 기반: 본 논문의 이론적 결과는 Robinson(1988) 등에서 발전된 준모수적 효율성(semiparametric efficiency)과 직교 모멘트(orthogonal moments) 이론에 기반 알고리즘적으로는 Targeted Maximum Likelihood Estimation(TMIE)와 유사: nuisance component를 비모수적으로 추정 이를 활용해 likelihood(또는 손실함수)를 최적화 Cross-fitting(홀드아웃 예측)은 최근 준모수적 추정에서 널리 쓰이는 방법 본 논문의 차별점: 기존 연구들은 주로 단일(또는 저차원) 파라미터 추정에 초점 본 논문은 복잡한 함수적 객체(즉, $\\tau^(\\cdot)$ 전체 함수)를 추정하는 데 초점 최적 처치 할당 규칙(optimal treatment allocation rule) 추정과도 관련 있지만, 목적함수(손실)가 다름 추가 논의: 본 논문은 모집단에서 무작위 추출된 샘플을 가정 엄격한 무작위화 추론(randomization inference) 하에서의 비모수적 처치효과 추정에 대한 추가 연구도 흥미로운 주제임 The R-Learner in Action 4.1 Application to a Voting Study 투표에 관한 연구에 이를 적용해본 사례를 이야기하고 있습니다. 연구 배경 원본 연구: Arceneaux, Gerber, and Green (2006) 연구 주제: 유료 투표 독려 전화가 투표율에 미치는 효과 실제 결과: 투표 독려 전화의 효과가 거의 없음 (1% 미만) 실험 설계 데이터 구성 전체 샘플: 1,895,468개 관측치 처치 그룹:59,264개 (전화 받은 사람) 분석 샘플: 148160개 (모든 처치 그룹 + 랜덤 대조 그룹) 처치 비율: 2/5 (40 데이터 분할 훈련 세트: 1000개 테스트 세트: 25,0개 홀드아웃 세트: 나머지 인공적 처치효과 추가 실제로는 처치효과가 거의 없으므로, 인공적으로 처치효과를 추가: $$ \\tau^(X_i) = -\\frac{\\text{VOTE00}_i}{2 + \\frac{100}{\\text{AGE}_i}} $$ VOTE00_i: 200투표 여부 AGE_i: 나이 목적: 이질적 처치효과 추정을 위한 의미있는 작업 생성 R-learner 적용 과정 Step 1: Nuisance Components 추정 부스팅과 라쏘 두 방법으로 $\\hat{e}(\\cdot)$와 $\\hat{m}(\\cdot)$ 추정 교차검증으로 최적 모델 선택 결과: 부스팅이 두 nuisance components 모두에서 더 나은 성능 Step2 R-loss 최적화 라쏘: R-loss = 00.1816 (훈련), 0.1781 (홀드아웃) 부스팅: R-loss = 00.1818 (훈련), 0.1783홀드아웃) 최종 선택: 라쏘 기반 $\\hat{\\tau}(\\cdot)$ 성능 비교 Oracle Test Set MSE (Mean Squared Error) 방법 MSE ------ ----- R-learner (라쏘) 00.47 ×10⁻³ R-learner (부스팅) 1.2310 Single Lasso 00.61 ×10⁻³ BART 40.05 ×10⁻³ 성능 분석 R-learner (라쏘)가 최고 성능2. 라쏘 vs 부스팅: 라쏘: 편향 있지만 분산 낮음 부스팅: 노이즈 많지만 편향 적음 편향-분산 트레이드오프에서 라쏘가 유리 핵심 발견 하이브리드 접근법의 우수성 Nuisance components: 비모수적 방법 (부스팅) 사용 처치효과 추정: 간단한 방법 (라쏘) 사용 이유: 각 단계에 최적화된 방법 선택 기존 방법들의 한계 Single Lasso: 모든 곳에서 선형 모델링 → 모델 오지정 가능성 BART: 모든 곳에서 비모수적 모델링 → 불안정한 $\\tau(\\cdot)$ 추정 R-learner의 장점 유연성: 각 단계에 적합한 방법 선택 가능 안정성: 교차검증을 통한 안정적인 모델 선택 성능: 기존 방법들보다 우수한 추정 정확도 실용적 교훈 단계별 최적화: 각 단계에 가장 적합한 방법 선택 교차검증의 중요성: 과적합 방지와 모델 선택 편향-분산 트레이드오프: 데이터 크기와 복잡성 고려 실제 데이터 적용: 이론적 방법의 실제 성능 검증 4.2 Model Averaging with the R-Learner 여러 모델을 합치는 stacking 방법을 적용한 시도를 이야기하고 있습니다. 배경과 동기 앞선 섹션에서는 R-learner의 각 단계에서 사용할 추정 전략을 세심하게 고려했습니다. 하지만 실제로는 분석의 시작점으로 기성품(off-the-shelf) 처치효과 추정기를 사용하는 것을 선호하는 경우가 많습니다. 이 섹션에서는 stacking의 변형을 통해 합의 처치효과 추정을 구축하는 R-learning 접근법을 논의합니다. Stacking 기반 합의 추정 기본 설정 $k = 1, \\ldots, K$개의 서로 다른 처치효과 추정기 $\\hat{\\tau}_k$ 보유 훈련 세트에서 out-of-fold 추정치 $\\hat{\\tau}_k^{(-i)}(X_i)$ 접근 가능 신뢰할 수 있는 out-of-fold 추정치 $\\hat{e}^{(-i)}(X_i)$와 $\\hat{m}^{(-i)}(X_i)$ 보유 합의 추정 방법 R-loss에 따라 $\\hat{\\tau}_k(\\cdot)$의 최적 양의 선형 결합을 취하여 합의 추정 $\\hat{\\tau}(\\cdot)$를 구축: $$ \\hat{\\tau}(x) = \\hat{c} + \\sum_{k=1}^K \\alpha_k \\hat{\\tau}_k(x) \\tag{8a} $$ $$ (\\hat{b}, \\hat{c}, \\hat{\\alpha}) = \\arg\\min_{b, c, \\alpha} \\left\\{ \\sum_{i=1}^n \\left[ \\left(Y_i - \\hat{m}^{(-i)}(X_i)\\right) - b - \\left(c + \\sum_{k=1}^K \\alpha_k \\hat{\\tau}_k^{(-i)}(X_i)\\right) \\left(W_i - \\hat{e}^{(-i)}(X_i)\\right) \\right]^2 : \\alpha \\geq 0 \\right\\} \\tag{8b} $$ 수식의 구성 요소 $\\hat{c}$: 상수 처치효과 항 (유연성을 위해 자유롭게 조정) $\\hat{b}$: 절편 ($\\hat{m}$의 잠재적 편향 흡수) $\\alpha_k$: 각 추정기의 가중치 (비음 제약) 실험 설정 데이터 생성 과정 다음과 같은 데이터 생성 분포에서 실험을 수행했습니다: $$ X_i \\sim N(0, I_{d \\times d}), \\quad W_i \\sim \\mathrm{Bernoulli}(0.5) \\tag{9a} $$ $$ Y_i \\mid X_i, W_i \\sim N\\left(\\frac{3}{1 + e^{X_{i3} - X_{i2}}} + (W_i - 0.5) \\tau^(X_i), \\sigma^2\\right) \\tag{9b} $$ 실험 조건: 샘플 크기: $n = 10,000$ (무작위 연구 설계) 차원: $d = 10$ 다양한 $\\tau^(\\cdot)$와 $\\sigma$ 선택 처치효과 함수 두 가지 유형의 처치효과 함수를 고려: 연속 함수: $\\tau^(X_i) = \\frac{1}{1 + e^{X_{i1} - X_{i2}}}$ 불연속 함수: $\\tau^(X_i) = \\frac{\\mathbf{1}\\{X_{i1} > 0\\}}{1 + e^{-X_{i2}}}$ 비교 방법 추정 방법들: BART (Bayesian Additive Regression Trees) Causal Forests (인과관계 숲) Stacking: 식 (8)을 이용한 두 방법의 결합 실험 조건: 데이터가 무작위화되었다는 것을 실험자가 알고 있다고 가정 필요한 곳에서는 $\\hat{e}(x) = 0.5$ 사용 Stacking용 $\\hat{m}(\\cdot)$는 random forest로 추정 실험 결과 (Figure 2) 연속 처치효과 함수의 경우 BART: Causal Forests보다 약간 우수한 성능 Stacking: 노이즈 수준 $\\sigma$가 매우 클 때까지 개별 방법보다 우수 고노이즈 환경: 모든 방법이 상수 처치효과 추정기와 비슷한 수준 불연속 처치효과 함수의 경우 Causal Forests: 낮은 노이즈 수준에서 특히 유리 Stacking: 더 정확한 기본 학습자의 성능을 자동으로 매칭 핵심 발견 Stacking의 자동 적응성 각 설정에서 더 나은 기본 학습자를 자동으로 식별 수동 선택 없이도 최적 성능에 근접 방법론적 유연성 기존 처치효과 추정기들을 그대로 활용 복잡한 알고리즘 수정 없이 성능 개선 실용적 장점 자동화: 복잡한 모델 선택 과정 단순화 견고성: 다양한 데이터 특성에 대한 적응력 효율성: 기존 도구들의 강점을 효과적으로 결합 A Quasi-Oracle Error Bound 이 섹션에서는 R-learner의 핵심 이론적 기여인 quasi-oracle property에 대해 설명합니다. 5.1 Oracle과 Quasi-Oracle의 개념 Oracle Estimator 이상적인 oracle은 다음을 미리 알고 있다고 가정합니다: True marginal effect: $m^(x) = \\mathbb{E}[Y \\mid X = x]$ True propensity score: $e^(x) = \\Pr(W = 1 \\mid X = x)$ Oracle이 이 정보를 알고 있다면, 다음 손실함수를 직접 최소화할 수 있습니다: $$ \\mathcal{L}_n^{\\text{oracle}}[\\tau(\\cdot)] = \\frac{1}{n} \\sum_{i=1}^n \\left[ \\{Y_i - m^(X_i)\\} - \\{W_i - e^(X_i)\\} \\tau(X_i) \\right]^2 $$ R-learner (Quasi-Oracle) 실제로는 $m^(x)$와 $e^(x)$를 모르므로, 추정값 $\\hat{m}(\\cdot)$과 $\\hat{e}(\\cdot)$을 사용: $$ \\hat{\\mathcal{L}}_n[\\tau(\\cdot)] = \\frac{1}{n} \\sum_{i=1}^n \\left[ \\{Y_i - \\hat{m}^{(-q(i))}(X_i)\\} - \\{W_i - \\hat{e}^{(-q(i))}(X_i)\\} \\tau(X_i) \\right]^2 $$ 5.2 Main Theoretical Result 논문의 핵심 이론적 결과는 다음과 같습니다: Theorem (Informal) 적절한 조건 하에서, R-learner $\\hat{\\tau}$는 다음 성질을 만족합니다: $$ \\mathbb{E}\\left[\\ \\hat{\\tau} - \\tau^\\ ^2\\right] \\lesssim \\text{Oracle Rate} + \\text{Nuisance Rate} $$ 여기서: Oracle Rate: oracle이 달성할 수 있는 최적 수렴률 Nuisance Rate: nuisance components 추정 오차의 곱 Quasi-Oracle Property 만약 nuisance components의 추정이 충분히 빠르게 수렴한다면: $$ \\text{Nuisance Rate} = \\ \\hat{m} - m^\\ \\cdot \\ \\hat{e} - e^\\ \\to 0 $$ 이 경우 R-learner는 oracle rate를 달성합니다: $$ \\mathbb{E}\\left[\\ \\hat{\\tau} - \\tau^\\ ^2\\right] \\lesssim \\text{Oracle Rate} $$ 5.3 Why Does This Work? Cross-fitting의 역할 Overfitting 방지: 같은 데이터로 추정과 예측을 하지 않음 Bias 감소: $\\mathbb{E}[\\hat{m}^{(-i)}(X_i) - m^(X_i)] \\approx 0$ Doubly Robust Structure R-loss는 doubly robust 구조를 가집니다: $$ \\mathbb{E}\\left[\\left\\{Y_i - m^(X_i)\\right\\} - \\left\\{W_i - e^(X_i)\\right\\} \\tau^(X_i) \\mid X_i\\right] = 0 $$ 이는 다음을 의미합니다: $m^(x)$ 또는 $e^(x)$ 중 하나만 정확해도 편향이 없음 두 추정의 오차가 곱의 형태로 나타남 Product Form of Error 최종 오차는 다음과 같이 분해됩니다: $$ \\text{Total Error} \\approx \\text{Oracle Error} + \\ \\hat{m} - m^\\ \\times \\ \\hat{e} - e^\\ $$ 따라서 두 nuisance components가 모두 $o(1)$ 속도로 수렴하면, 곱은 더 빠르게 수렴합니다. 5.4 Practical Implications Flexible Method Choice 각 단계에서 서로 다른 기계학습 방법 사용 가능 $\\hat{m}$에는 random forests, $\\hat{e}$에는 logistic regression 등 Robustness 한 nuisance component가 부정확해도 다른 것이 보완 완벽한 추정이 필요하지 않음 Rate Optimality 적절한 조건 하에서 minimax optimal 달성 이론적으로 최선의 성능 보장 논문에서 궁금한 점들 정리 그래서 quasi-oracle property는 어떻게 보장되는건데? 핵심 메커니즘 Robinson's Transformation의 마법 Robinson's transformation (1988)이 핵심입니다: $$ Y_i - m^(X_i) = \\{W_i - e^(X_i)\\} \\tau^(X_i) + \\varepsilon_i $$ 이 변환의 특별한 성질: Orthogonality: $\\mathbb{E}[\\varepsilon_i \\mid X_i, W_i] = 0$ Causal Isolation: 처치효과만 분리됨 Cross-fitting의 핵심 역할 `` Step 1: 데이터를 K개 fold로 분할 Step 2: k번째 fold를 제외하고 m̂, ê 추정 Step 3: k번째 fold에서 τ̂ 추정 Step 4: 모든 fold에 대해 반복 ` 왜 이게 중요한가? Independence: 추정에 사용된 데이터와 예측 데이터가 독립 Bias Reduction: $\\mathbb{E}[\\hat{m}^{(-i)}(X_i) \\mid X_i] \\approx m^(X_i)$ Doubly Robust의 수학적 구조 핵심은 다음 decomposition입니다: $$ \\hat{\\mathcal{L}}_n - \\mathcal{L}_n^{\\text{oracle}} = \\text{Bias Term} + \\text{Variance Term} $$ Bias Term: $$ \\frac{2}{n} \\sum_{i=1}^n \\left[\\{Y_i - m^(X_i)\\} - \\{W_i - e^(X_i)\\}\\tau^(X_i)\\right] \\times \\left[\\{\\hat{m}^{(-i)} - m^\\}(X_i) - \\{\\hat{e}^{(-i)} - e^\\}(X_i)\\tau^(X_i)\\right] $$ Cross-fitting에 의해 이 term의 기댓값이 0에 가까워집니다. Variance Term: $$ \\left\\ \\{\\hat{m} - m^\\} - \\{\\hat{e} - e^\\}\\tau^\\right\\ ^2 $$ 이는 $\\ \\hat{m} - m^\\ \\times \\ \\hat{e} - e^\\ $의 order입니다. 수렴률의 곱셈 구조 만약: $\\ \\hat{m} - m^\\ = O_p(r_m)$ $\\ \\hat{e} - e^\\ = O_p(r_e)$ 그러면: $$ \\ \\hat{\\tau} - \\tau^\\ = O_p(\\max\\{r_{\\text{oracle}}, r_m \\times r_e\\}) $$ 예시: $r_m = r_e = n^{-1/4}$ (느린 수렴) $r_m \\times r_e = n^{-1/2}$ (빠른 수렴!) Oracle rate $r_{\\text{oracle}} = n^{-1/3}$이면 최종 rate = $\\max\\{n^{-1/3}, n^{-1/2}\\} = n^{-1/3}$ ✨ 실제 동작 예시 시나리오 1: 완벽한 Oracle `python Oracle knows true m(x) and e(x) oracle_loss = R_loss(Y, W, X, tau, m_true, e_true) oracle_rate = n^(-1/3) # optimal rate for τ complexity ` 시나리오 2: R-learner with Imperfect Estimates `python Step 1: Estimate nuisances with cross-fitting m_hat = estimate_m_with_crossfit(Y, X) # rate: n^(-1/4) e_hat = estimate_e_with_crossfit(W, X) # rate: n^(-1/4) Step 2: Optimize R-loss tau_hat = optimize_R_loss(Y, W, X, m_hat, e_hat) Achieved rate: max(n^(-1/3), n^(-1/4) × n^(-1/4)) = n^(-1/3) Same as oracle! 🎉 `` 왜 이게 \"Quasi-Oracle\"인가? Oracle과 같은 수렴률: $n^{-1/3}$ 달성 하지만 Oracle이 아님: $m^, e^*$를 실제로는 모름 Automatic: 추가적인 튜닝 없이 자동으로 달성 Robust: nuisance 추정이 완벽하지 않아도 작동 이것이 바로 \"quasi-oracle property\"의 핵심입니다! 🎯"
  },
  {
    "id": "Data Science/Causal Inference/Causal Inference for The Brave and True/PropensityScoreNotebook",
    "title": "Propensity Score Notebook",
    "date": "2025-07-17",
    "excerpt": "Propensity Score Notebook",
    "category": "Causal Inference",
    "tags": [
      "Causal Inference"
    ],
    "content": "--- title: \"Propensity Score Notebook\" date: \"2025-07-17\" excerpt: \"Propensity Score Notebook\" category: \"Causal Inference\" tags: [\"Causal Inference\"] --- Propensity Score # The Psychology of Growth 치료(treatment)와 결과(outcome) 변수 외에도, 이 연구에서는 다음과 같은 다른 특성들도 기록했습니다: schoolid: 학생의 학교 식별자; success_expect: 미래 성공에 대한 자가 보고 기대치, 사전 성취도의 대용 지표로, 무작위 배정 전에 측정됨; gender: 학생이 식별한 성별의 범주형 변수; frst_in_family: 학생의 1세대 대학생 지위에 대한 범주형 변수, 즉 가족 중 대학에 진학한 첫 번째 사람; school_urbanicity: 학교의 도시화 정도에 대한 학교 수준의 범주형 변수, 즉 농촌, 교외 등; school_mindset: 학생들의 고정된 사고방식의 학교 수준 평균, 무작위 배정 전에 보고됨, 표준화됨; school_achievement: 학교 성취 수준, 이전 4개 학년 학생들의 시험 점수와 대학 준비도를 측정한 것으로, 표준화됨; school_ethnic_minority: 학교 인종/민족 소수자 구성, 즉 흑인, 라티노, 또는 아메리카 원주민인 학생 비율, 표준화됨; school_poverty: 학교 빈곤 집중도, 즉 연방 빈곤선 이하 소득을 가진 가정 출신 학생들의 비율, 표준화됨; school_size: 학교의 모든 4개 학년 학생들의 총 수, 표준화됨. import pandas as pd pd.set_option(\"display.max_columns\", None) data = pd.read_csv(\"./data/learning_mindset.csv\") data.sample(5, random_state=5) > Although the study was randomised, it doesn’t seem to be the case that this data is free from confounding > So, although the opportunity to participate was random, participation itself is not. We are dealing with a case of non-compliance here. 마인드셋을 바꾸는 프로그램 참여 여부는 랜덤하게 주어졌지만, 실제로 참석하는데에는 학생들의 개별적인 요인의 영향이 있으니까 data.groupby(\"success_expect\")[\"intervention\"].agg([\"mean\", \"count\"]) > One evidence of this is how the student’s success expectation is correlated with the participation in the seminar. > Students with higher self-reported success expectation are more likely to have joined the growth mindset seminar. 스스로 더 높은 기대가 있는 학생들이 실제로 더 많이 세미나에 참석하더라 -> confounding bias가 존재한다. > Still, let’s see what the difference in means looks like. This will be a useful baseline to compare against. $$ \\hat{ATE} = \\frac{1}{N} \\sum_{i=1}^{N} (Y_i(1) - Y_i(0)) = E[Y_i(1)] - E[Y_i(0)] $$ import statsmodels.formula.api as smf smf.ols(\"achievement_score ~ intervention\", data=data).fit().summary().tables[1] 처치가 0또는 1이기 때문에 처치만을 가지고 결과를 예측하는 회귀식을 통해 $E[Y_i(1)]$과 $E[Y_i(0)]$을 추정할 수 있다. 처치 혹은 개입이 있는 경우 없는 경우보다 평균적으로 0.4723정도 높다. 근데 이정도 차이면 큰건가? > But is this big or small? I know that interpreting standardized outcomes can be challenging, but bear with me for a moment. > I think it is worth going through this because it won’t be the last time you will encounter standardized scores. score가 정규화되었기 때문에 이 단위는 std다. 따라서 0.4723이란 의미는 약 0.5std 정도 차이가 있다는 의미. > Since the treated group has an average standardized score of about 0.5, this means that they fall above 70% in terms of individual achievement. > Or, in other words, they are in the top 30% who achieve more. Here is what this looks like in a picture. import matplotlib.pyplot as plt plt.hist(data[\"achievement_score\"], bins=20, alpha=0.3, label=\"All\") plt.hist(data.query(\"intervention==0\")[\"achievement_score\"], bins=20, alpha=0.3, color=\"C2\") plt.hist(data.query(\"intervention==1\")[\"achievement_score\"], bins=20, alpha=0.3, color=\"C3\") plt.vlines(-0.1538, 0, 300, label=\"Untreated\", color=\"C2\") plt.vlines(-0.1538+0.4723, 0, 300, label=\"Treated\", color=\"C3\") plt.legend() > Of course, we still think this result is biased. > The difference between treated and untreated is probably smaller than this, because we think the bias is positive 과연 이정도 차이 나는게 맞을까? 앞서 확인한 것처럼 편향이 존재한다는 것을 확인했다. 비교군 사이에 스스로 기대하는 정도 (success_expect)가 차이가 있었고, 이는 성공확률에 영향을 미치는 요인이 될 수 있다. # Propensity Score > Propensity score comes from the realisation that you don’t need to directly control for confounders X to achieve conditional independence $(Y_1, Y_0) \\perp T X$ > Instead, it is sufficient to control for a balancing score $E(T X)$ 편향을 제거하고 조건부 독립성을 만족하기 위해서는 X를 통제해야하는데, 이게 어려우니까 이를 대신해서 X일때 T일 확률($e(x)$, propensity score)을 통제하자는 컨셉 $$(Y_1, Y_0) \\perp T e(x)$$ import graphviz as gr g = gr.Digraph() g.edge(\"T\", \"Y\") g.edge(\"X\", \"Y\") g.edge(\"X\", \"e(x)\") g.edge(\"e(x)\", \"T\") g > If I know what e(x) is, X alone tells me nothing more that can help me learn what T would be. > Which means that controlling for e(x) acts the same way as controlling for X directly 데이터의 편향을 생각해보면, success expect가 높은 학생은 본인 일도 열심히하고 세미나에 참석할 확률도 높을 것이다. 따라서 랜덤으로 기회를 줬지만 실제로는 원래 성공할 확률이 높은 학생이 세미나에 참석할 확률이 더 높음. > Think about it. If they have the exact same probability of receiving the treatment, the only reason one of them received it and the other did not is pure chance. > Holding the propensity score constant acts in a way of making the data look as good as random. 참석할 확률을 같게 만든다면, 원래 목적처럼 참석할 확률이 랜덤하게 된다. # Propensity Weighting $$ E[Y X, T = 1] - E[Y X, T = 0] = E[\\frac{Y}{e(x)} X, T = 1]P(T) - E\\frac{Y}{(1 - e(x))} X, T = 0) $$ 처치를 받은 것 중에 처치를 받지 않을 것 같은 샘플 ($e(x)$가 낮은 경우)는 큰 가중치를 주고, 반대로 처치를 받지 않은 것 중에 처치를 받을 것 같은 샘플 ($e(x)$가 높은 경우)는 큰 가중치를 주는. 이러한 가중치는 직관적인 생각과 일치한다. 왜냐하면 처치를 받은 것 중에 처치를 받을 확률이 높은 건 랜덤에 가깝게 하려면 낮춰야 하고, 처치를 받을 확률이 낮은 건 랜덤에 가깝게 하려면 높여야하기 때문이다. > This estimator is called the Inverse Probability of Treatment Weighting (IPTW), since it scales each unit by the inverse probability of the treatment it received. !iptw 적용한 예제"
  },
  {
    "id": "Data Science/Causal Inference/Causal Inference for The Brave and True/PropensityScore",
    "title": "Propensity Score",
    "date": "2025-07-17",
    "excerpt": "Propensity Score",
    "category": "Causal Inference",
    "tags": [
      "Causal Inference"
    ],
    "content": "Propensity Score 이 책의 저자가 참 글을 잘쓴다. 되게 매력적인 주제로 이 내용을 풀어간다. Growth Mindset vs Fixed Mindset 심리학자들은 마인드셋이 인생에 큰 영향을 미친다. 내 능력이 고정되어있지 않고 충분히 변화할 수 있다고 믿는 사람들은, 내 능력이 고정되어있다고 믿는 사람보다 더 성공한다. 나는 이 부분에 크게 공감하고, 성장형 마인드셋을 가지려고 한다. 다만 인과추론을 다루는 입장에서는 이에 다음과 같은 의문을 던져볼 수 있다. > Is it that a growth mindset causes people to achieve more? Or is simply the case that people who achieve more are prone to develop a growth mindset as a result of their success? 진짜 성장형 사고방식이 사람들을 더 성공하게 했나? 아니면 성공한 사람들이 그런 마인드셋을 가지고 있을 확률이 높은건가? 되게 재밌는 질문이다. 이 부분을 위한 실험이 진행된게 있구나. > To settle things, researchers designed the The National Study of Learning Mindsets. It is a randomised study conducted in U.S. public high schools which aims at finding the impact of a growth mindset. > The real data on this study is not publicly available in order to preserve students’ privacy. However, we have a simulated dataset with the same statistical properties provided by Athey and Wager, so we will use that instead. 노트북 참고: Propensity Score Notebook"
  },
  {
    "id": "Data Science/Causal Inference/Causal Inference for The Brave and True/DoublyRobustEstimationNotebook",
    "title": "Doubly Robust Estimation Notebook",
    "date": "2025-07-17",
    "excerpt": "Doubly Robust Estimation Notebook",
    "category": "Causal Inference",
    "tags": [
      "Causal Inference"
    ],
    "content": "--- title: \"Doubly Robust Estimation Notebook\" date: \"2025-07-17\" excerpt: \"Doubly Robust Estimation Notebook\" category: \"Causal Inference\" tags: [\"Causal Inference\"] --- Doubly Robust Estimation import warnings warnings.filterwarnings('ignore') import pandas as pd import numpy as np from matplotlib import style from matplotlib import pyplot as plt import seaborn as sns from sklearn.linear_model import LogisticRegression, LinearRegression %matplotlib inline style.use(\"fivethirtyeight\") pd.set_option(\"display.max_columns\", None) # 학생들의 마인드셋을 향상시키기 위한 세미나를 진행했는데, 이게 어느정도 영향이 있었는지 가상의 데이터 세미나 참석 여부 -> intervention 얼마나 성공했는지 혹은 성공할 확률 -> success_expect data = pd.read_csv(\"./data/learning_mindset.csv\") data.sample(5, random_state=5) # 성공한 정도 (success expect)가 높을수록 세미나 참석 여부(intervention)가 높은지 data.groupby(\"success_expect\")[\"intervention\"].agg([\"mean\", \"count\"]) 학생의 요인에 따라 참석 여부가 결정되고, 또 이 요인이 성공확률을 결정한다. -> confounding variable. 즉, 단순히 참석 여부에 따라 성공확률을 비교해 세미나의 효과를 추정하기엔 어렵다. 학생의 다른 요인들이 영향을 미치고 있으니까 # regression을 통해 편향을 제거하고 세미나의 효과 보기 이를 위해 categorical features를 더미 변수로 변환 categ = [\"ethnicity\", \"gender\", \"school_urbanicity\"] cont = [\"school_mindset\", \"school_achievement\", \"school_ethnic_minority\", \"school_poverty\", \"school_size\"] data_with_categ = pd.concat([ data.drop(columns=categ), # dataset without the categorical features pd.get_dummies(data[categ], columns=categ, drop_first=False) # categorical features converted to dummies ], axis=1) print(data_with_categ.shape)"
  },
  {
    "id": "Data Science/Causal Inference/Causal Inference for The Brave and True/DoublyRobustEstimation",
    "title": "Doubly Robust Estimation",
    "date": "2025-07-17",
    "excerpt": "Doubly Robust Estimation",
    "category": "Causal Inference",
    "tags": [
      "Causal Inference"
    ],
    "content": "Doubly Robust Estimation"
  },
  {
    "id": "Self_Development/English Study/SPEAK/지나간달/07-16-그나저나소개팅어땠어",
    "title": "그나저나 소개팅 어땠어?",
    "date": "2025-07-16",
    "excerpt": "",
    "category": "English Study",
    "tags": [
      "영어공부꾸준히!",
      "SPEAK",
      "고민 및 조언하는 표햔"
    ],
    "content": "배운 것 How was it? 그나저나, 그런데 By the way, how was the blind date? BTW (By The Way) 친구 사이에서 가볍게 쓰는 말 By the way, how was the dinner yesterday? Blind date 소개팅 Well, the thing is he is a vegeterian. 글쎄, 문제는 out of budget to make it somewhere : 어디든 가다 간단한 작문. Simple writing or essay Daily talk to myself as usual. By the way, How was your day? Did you do your best? Well, the thing is condition. Today, I was so tired. So I can fully concentrate. So I think I should have a sleep early. 수정된 버전 (Improved Version) Just having my usual daily conversation with myself. By the way, how was your day? Did you do your best? Well, the thing is my condition wasn't great. Today, I was so tired that I couldn't fully concentrate. So I think I should go to sleep early tonight. 피드백 (Feedback) 주요 수정 사항: \"Daily talk to myself\" → \"Having my usual daily conversation with myself\" 더 완전한 문장 구조로 수정 \"Well, the thing is condition\" → \"Well, the thing is my condition wasn't great\" 불완전한 문장을 완전한 문장으로 수정 소유격 \"my\" 추가 및 구체적인 설명 추가 \"So I can fully concentrate\" → \"So I couldn't fully concentrate\" 맥락상 부정문이 맞음 (피곤해서 집중할 수 없었다는 의미) \"I should have a sleep early\" → \"I should go to sleep early tonight\" \"go to sleep\"이 더 자연스러운 표현 \"tonight\" 추가로 시간 명시 문법 포인트: \"so + 형용사/부사 + that + 주어 + 동사\" 구문 사용 시제 일치 (과거 상황을 설명할 때는 과거형 사용) 자연스러운 영어 표현 사용"
  },
  {
    "id": "Self_Development/Book/만들어진 신 (The God Delusion)/책을읽기시작하면서",
    "title": "책을 읽기 시작하면서",
    "date": "2025-07-16",
    "excerpt": "책을 읽기 전에 어떤 생각을 가지고 있는지 정리",
    "category": "Book",
    "tags": [
      "The God Delusion",
      "만들어진 신"
    ],
    "content": "나는 확실한 무신론자다. 부모님의 영향도 있겠지만, 친구따라 교회에 다녔던 경험, 다양한 매체에서 접한 현상들 등등이 지금 나의 생각을 만들었다. 신이 있는게 많이 되나? 나의 사고방식은 직업적인 영향 (개발자 or 데이터과학자) 때문인지 몰라도 근거에 지배적이다. 근거가 명확하다면 지금도 당장 바뀔 수 있고, 근거가 없다면 백날 설득을 하려해도 전혀 소용이 없을 것이다. 내가 이 책을 읽게 된 이유는 신이 없는 이유를 알고 싶다기 보다는, 사람들이 왜 신을 믿는지가 더 궁금한게 크다. 어쨌든 책에서는 사람들이 신을 믿는 이유를 언급하고 이를 반박할테니까. 이 책의 영어 제목은 되게 파격적이다. 헛웃음이 나올정도로. Delusion, 망상이라는 단어를 쓰다니... > 누군가 망상에 시달리면 정신 이상이라고 한다. > 다수가 망상에 시달리면 종교라고 한다. > -> 로버트 퍼시그 사실 나도 비슷한 생각이긴 하다. 내가 생각하는 신은 공통적으로 그리고 있는 허상이라고 생각한다. 예전에 모시던 호랑이 신과 예수는 사실 같다고 보여진다. 사람들의 편의를 위해 어떤 허상의 개념을 만들고, 이를 함께 믿는 것. 주위에 종교를 가진 친구들이 많은데 그들을 무시하는 생각은 진짜 전혀없다. 그냥 나의 생각이 이럴 뿐. 또 허상이면 어떻나 삶에 도움이 되면 그게 좋은거지 라는 생각도 한다. 어쨌든 책을 읽어나가면서 나의 생각은 어떻게 바뀌고, 또 어떤 관점이 열릴지 기대가 된다. 쭉 읽어봐야겠다."
  },
  {
    "id": "Data Science/Causal Inference/tikhonov-regularization-and-convex-optimization",
    "title": "Tikhonov Regularization과 Convex Optimization: 연속형 처치 R-learner의 이론적 배경",
    "date": "2025-07-16",
    "excerpt": "Ill-posed problem을 해결하는 Tikhonov regularization과 convex optimization의 원리",
    "category": "Causal Inference",
    "tags": [
      "Theory",
      "Optimization",
      "Regularization"
    ],
    "content": "개요 --- 연속형 처치에서 R-learner를 적용할 때 발생하는 non-identification 문제를 해결하기 위해 Tikhonov regularization과 convex optimization 이론이 핵심적인 역할을 합니다. 이 글에서는 이러한 수학적 도구들의 원리와 응용을 자세히 설명합니다. Ill-posed Problem과 Non-identification --- 1.1 Well-posed vs Ill-posed Problem Well-posed problem (잘 정의된 문제) 의 3가지 조건: 존재성 (Existence): 해가 존재한다 유일성 (Uniqueness): 해가 유일하다 안정성 (Stability): 입력의 작은 변화가 해의 작은 변화를 가져온다 Ill-posed problem은 이 중 하나 이상의 조건을 만족하지 않는 문제입니다. 1.2 연속형 처치에서의 Non-identification 연속형 처치 R-learner에서는 유일성 조건이 위반됩니다: $$L_c(h) = E\\left[\\left\\{Y - m(X) - h(X, T) + E_{\\varpi}\\{h(X, T) \\mid X\\}\\right\\}^2\\right]$$ 이 손실함수를 최소화하는 해집합은: $$S = \\{h \\mid h(X, T) = \\tau(X, T) + s(X) \\text{ a.s., for any } s \\in L_2^P(X)\\}$$ > 문제: 무한히 많은 해가 존재하여 유일한 CATE 함수 $\\tau(x, t)$를 식별할 수 없음 Tikhonov Regularization --- 2.1 기본 원리 Tikhonov regularization은 ill-posed problem을 well-posed problem으로 변환하는 방법입니다. 원래 문제: $$\\min_{h} L(h)$$ 정규화된 문제: $$\\min_{h} L(h) + \\rho \\ h\\ ^2$$ 여기서: $\\rho > 0$: 정규화 매개변수 $\\ h\\ ^2$: 정규화 항 (일반적으로 $L_2$ norm) 2.2 연속형 처치 R-learner에서의 적용 $$ \\begin{equation} \\tau_\\rho = \\arg \\min_{h \\in L_2^P(X,T)} \\left[ L_c(h) + \\rho \\ h\\ _{L_2^P}^2 \\right] \\end{equation} $$ 정규화 항의 역할: $\\ h\\ _{L_2^P}^2 = E\\{h^2(X, T)\\}$ 함수의 \"크기\"를 제한하여 과적합 방지 무한히 많던 해를 유일한 해로 수렴시킴 2.3 Tikhonov 정리 정리: 정규화 매개변수 $\\rho > 0$가 주어졌을 때, 정규화된 문제는 유일한 해 $\\tau_\\rho$를 가진다. 증명 아이디어: $L_c(h)$는 convex하지만 strictly convex하지 않음 $\\rho \\ h\\ _{L_2^P}^2$는 strictly convex함 둘의 합은 strictly convex가 되어 유일한 최솟값을 가짐 Convex Optimization --- 3.1 Convex Function의 정의 함수 $f: \\mathbb{R}^n \\to \\mathbb{R}$가 convex하다는 것은: $$f(\\lambda x + (1-\\lambda) y) \\leq \\lambda f(x) + (1-\\lambda) f(y)$$ 모든 $x, y \\in \\text{dom}(f)$와 $\\lambda \\in [0, 1]$에 대해 성립함을 의미합니다. 3.2 Strictly Convex Function 함수 $f$가 strictly convex하다는 것은: $$f(\\lambda x + (1-\\lambda) y) < \\lambda f(x) + (1-\\lambda) f(y)$$ $x \\neq y$이고 $\\lambda \\in (0, 1)$일 때 부등호가 엄격함을 의미합니다. 3.3 Convex Function의 중요한 성질 성질 1: 유일한 최솟값 Convex function: 지역 최솟값 = 전역 최솟값 Strictly convex function: 최솟값이 유일함 성질 2: 최적화의 용이성 경사하강법이 전역 최솟값으로 수렴 보장 수치적 안정성 성질 3: Jensen's Inequality $$E[f(X)] \\geq f(E[X])$$ 3.4 R-learner에서의 Convexity 원래 손실함수 $L_c(h)$: Convex하지만 strictly convex하지 않음 따라서 최솟값이 유일하지 않음 정규화된 손실함수 $L_c(h) + \\rho \\ h\\ ^2$: $\\rho \\ h\\ ^2$가 strictly convex함 전체 함수가 strictly convex가 됨 유일한 최솟값 보장 수학적 증명 --- 4.1 $\\ h\\ _{L_2^P}^2$가 Strictly Convex임을 증명 정리: $\\ h\\ _{L_2^P}^2 = E\\{h^2(X, T)\\}$는 strictly convex하다. 증명: 임의의 $h_1 \\neq h_2$와 $\\lambda \\in (0, 1)$에 대해: $$ \\begin{align} \\ \\lambda h_1 + (1-\\lambda) h_2\\ _{L_2^P}^2 &= E\\{[\\lambda h_1(X,T) + (1-\\lambda) h_2(X,T)]^2\\} \\\\ &= E\\{\\lambda^2 h_1^2(X,T) + 2\\lambda(1-\\lambda) h_1(X,T)h_2(X,T) + (1-\\lambda)^2 h_2^2(X,T)\\} \\\\ &= \\lambda^2 E\\{h_1^2(X,T)\\} + 2\\lambda(1-\\lambda) E\\{h_1(X,T)h_2(X,T)\\} + (1-\\lambda)^2 E\\{h_2^2(X,T)\\} \\end{align} $$ Cauchy-Schwarz 부등식에 의해: $$E\\{h_1(X,T)h_2(X,T)\\} \\leq \\sqrt{E\\{h_1^2(X,T)\\}} \\sqrt{E\\{h_2^2(X,T)\\}}$$ $h_1 \\neq h_2$일 때 부등호가 strict하므로: $$\\ \\lambda h_1 + (1-\\lambda) h_2\\ _{L_2^P}^2 < \\lambda \\ h_1\\ _{L_2^P}^2 + (1-\\lambda) \\ h_2\\ _{L_2^P}^2$$ 4.2 정규화된 손실함수의 Strict Convexity 결론: $L_{c,\\ell_2}(h \\mid \\rho) = L_c(h) + \\rho \\ h\\ _{L_2^P}^2$는 $\\rho > 0$일 때 strictly convex하다. 이유: $L_c(h)$는 convex $\\rho \\ h\\ _{L_2^P}^2$는 strictly convex Convex + Strictly convex = Strictly convex 실제 응용과 의미 --- 5.1 Two-step Procedure Step 1: Tikhonov regularization으로 중간 함수 추정 $$\\tilde{\\tau}_\\rho = \\arg \\min_{h} \\left[ L_c(h) + \\rho \\ h\\ _{L_2^P}^2 \\right]$$ Step 2: Zero-constraining operator로 최종 CATE 추정 $$\\tau(x, t) = \\text{ZeroConstraint}(\\tilde{\\tau}_\\rho(x, t))$$ 5.2 정규화 매개변수 $\\rho$의 역할 $\\rho$가 작을 때: 원래 문제에 가까움 Bias는 작지만 variance가 클 수 있음 $\\rho$가 클 때: 정규화 효과가 강함 Variance는 작지만 bias가 클 수 있음 최적 $\\rho$ 선택: Cross-validation Information criteria (AIC, BIC) Theoretical convergence rate 5.3 수렴 속도와 점근적 성질 정규화된 추정량 $\\hat{\\tau}_\\rho$는 다음과 같은 우수한 성질을 가집니다: Consistency: $\\hat{\\tau}_\\rho \\to \\tau$ as $n \\to \\infty$ Convergence rate: $O_p(n^{-r})$ for some $r > 0$ Asymptotic normality: $\\sqrt{n}(\\hat{\\tau}_\\rho - \\tau) \\xrightarrow{d} N(0, \\Sigma)$ 다른 정규화 방법과의 비교 --- 6.1 Ridge vs Lasso vs Tikhonov 방법 정규화 항 특징 ------ ----------- ------ Ridge $\\lambda \\ \\beta\\ _2^2$ 계수 축소, 변수 선택 X Lasso $\\lambda \\ \\beta\\ _1$ 변수 선택, 희소성 Tikhonov $\\rho \\ h\\ _{L_2^P}^2$ 함수 공간에서의 정규화 6.2 다른 해결 방법들 Alternative 1: Truncated SVD 특이값 분해 후 작은 특이값 제거 수치적 방법 Alternative 2: Iterative methods Landweber iteration Conjugate gradient methods Alternative 3: Bayesian approach Prior distribution 설정 Posterior inference 결론 --- Tikhonov regularization의 핵심 장점: 이론적 보장: Strictly convex optimization으로 유일한 해 보장 수치적 안정성: Well-conditioned 문제로 변환 일반성: 다양한 ill-posed problem에 적용 가능 구현 용이성: 기존 최적화 알고리즘 활용 가능 연속형 처치 R-learner에서의 의미: Non-identification 문제의 근본적 해결 실용적인 CATE 추정 방법 제공 이론적 분석과 실제 구현의 교량 역할 이러한 수학적 도구들은 단순히 기술적 문제를 해결하는 것을 넘어서, 인과추론의 근본적인 어려움을 이해하고 극복하는 방법을 제시합니다. --- 참고 문헌: Tikhonov, A. N. (1963). On the solution of ill-posed problems and the method of regularization Boyd, S., & Vandenberghe, L. (2004). Convex optimization Wahba, G. (1990). Spline models for observational data Engl, H. W., Hanke, M., & Neubauer, A. (2000). Regularization of inverse problems"
  },
  {
    "id": "Self_Development/English Study/TOEFL/DefinitionOfArt",
    "title": "Definition of Art",
    "date": "2025-07-15",
    "excerpt": "TOEFL Reading 문제 공부 - 예술의 정의",
    "category": "English Study",
    "tags": [
      "TOEFL",
      "영어",
      "대학원"
    ],
    "content": "Definition of Art 예술의 정의 Paragraph 1 <button class=\"toggle-button translations\" data-type=\"paragraph1\">🔍 AI 해석 가리기</button> <div class=\"paragraph1-content\"> > How art is defined has varied throughout history, leading to a wide range of sometimes-contradictory meanings. <span class=\"translation\">예술이 어떻게 정의되는지는 역사를 통틀어 변화해왔으며, 때로는 상반되는 의미들의 광범위한 스펙트럼을 만들어냈다.</span> > In the ancient world, the term was used in a broad sense that was not strictly related to visual arts. <span class=\"translation\">고대 세계에서 이 용어는 시각 예술에 엄격하게 국한되지 않는 광범위한 의미로 사용되었다.</span> > The application of the word \"art\" exclusively to works in the form of paintings, sculptures, and prints came about only in the Renaissance, and later, in the eighteenth century, the use of the term expanded to include music and poetry. <span class=\"translation\">\"예술\"이라는 단어를 회화, 조각, 판화 형태의 작품들에만 독점적으로 적용하는 것은 르네상스 시대에 비로소 나타났으며, 이후 18세기에는 이 용어의 사용이 음악과 시를 포함하도록 확장되었다.</span> > Subsequently, in modern times, a new meaning came into fashion, obscuring the distinction between what is art and what is not. <span class=\"translation\">그 후 현대에 들어서는 새로운 의미가 유행하게 되었고, 무엇이 예술이고 무엇이 예술이 아닌지의 구별을 모호하게 만들었다.</span> </div> Paragraph 2 <button class=\"toggle-button translations\" data-type=\"paragraph2\">🔍 AI 해석 가리기</button> <div class=\"paragraph2-content\"> > In the ancient world, there was no clear difference between art and crafts. <span class=\"translation\">고대 세계에서는 예술과 공예 사이에 명확한 차이가 없었다.</span> > In Greek and Latin, the terms techne and ars both translated as \"art,\" and they stood for any activity that had rules and required expertise. <span class=\"translation\">그리스어와 라틴어에서 테크네(techne)와 아르스(ars)라는 용어들은 둘 다 \"예술\"로 번역되었으며, 규칙을 가지고 전문성을 요구하는 모든 활동을 의미했다.</span> > They were thus used in reference to a wide range of fields, from medicine and law to blacksmithing. <span class=\"translation\">따라서 이 용어들은 의학과 법률에서부터 대장장이 일까지 광범위한 분야들을 지칭하는 데 사용되었다.</span> > Those engaged in the production of art were viewed as craftsmen, more similar to manual laborers than artists. <span class=\"translation\">예술 제작에 종사하는 사람들은 장인으로 여겨졌으며, 예술가보다는 육체 노동자에 더 가까웠다.</span> > To the ancients, art was a pursuit necessitating skills that were learned according to rules, but that were believed to require no unique inspiration. <span class=\"translation\">고대인들에게 예술은 규칙에 따라 습득하는 기술을 필요로 하는 추구였지만, 독특한 영감을 요구하지는 않는다고 여겨졌다.</span> > Painting and sculpture had no special place in higher learning, as only music and poetry were taught as academic subjects. <span class=\"translation\">회화와 조각은 고등 학문에서 특별한 자리를 차지하지 못했는데, 음악과 시만이 학문 과목으로 가르쳐졌기 때문이다.</span> > The visual arts were viewed simply as manual crafts, and because the ancients looked down on manual labor, artisans occupied the bottom of the social hierarchy. <span class=\"translation\">시각 예술은 단순히 수공 기술로 여겨졌으며, 고대인들이 육체 노동을 업신여겼기 때문에 장인들은 사회 계층의 맨 아래를 차지했다.</span> </div> Paragraph 3 <button class=\"toggle-button translations\" data-type=\"paragraph3\">🔍 AI 해석 가리기</button> <div class=\"paragraph3-content\"> > The medieval world inherited this view of art, but things began to change during the Renaissance. <span class=\"translation\">중세 세계는 이러한 예술관을 물려받았지만, 르네상스 시대에 상황이 변화하기 시작했다.</span> > At the forefront of this transformation was the elevated position of painters, sculptors, and architects. <span class=\"translation\">이 변혁의 최전선에는 화가, 조각가, 건축가들의 지위 향상이 있었다.</span> > Renaissance artists increasingly employed scientific methods, and mathematics became central to their trade. <span class=\"translation\">르네상스 예술가들은 점점 더 과학적 방법을 사용했으며, 수학이 그들 기예의 중심이 되었다.</span> > Because their work was not simply mechanical but also intellectual, artists argued that they were superior to mere craftsmen, and their call for respect began to sway public opinion. <span class=\"translation\">그들의 작업이 단순히 기계적인 것이 아니라 지적이기도 했기 때문에, 예술가들은 자신들이 단순한 장인들보다 우월하다고 주장했으며, 존경을 요구하는 그들의 외침이 여론을 움직이기 시작했다.</span> > Artists gradually gained acceptance as creative geniuses, and their reputation rose to be on par with that of poets. <span class=\"translation\">예술가들은 점차 창조적 천재로 인정받게 되었으며, 그들의 명성은 시인들과 동등한 수준으로 올라갔다.</span> > Painting, sculpture, and architecture were given their own place in academies, and art became synonymous with the label \"classical art.\" <span class=\"translation\">회화, 조각, 건축은 학원에서 자신들만의 자리를 부여받았으며, 예술은 \"고전 예술\"이라는 라벨과 동의어가 되었다.</span> > During the 1700s, the definition was slightly expanded as the concept of fine art emerged. <span class=\"translation\">1700년대에는 순수 예술의 개념이 등장하면서 정의가 약간 확장되었다.</span> > Collectively, the classical arts, along with music and poetry, came to represent the fine arts. <span class=\"translation\">종합적으로, 고전 예술들은 음악과 시와 함께 순수 예술을 대표하게 되었다.</span> </div> Paragraph 4 <button class=\"toggle-button translations\" data-type=\"paragraph4\">🔍 AI 해석 가리기</button> <div class=\"paragraph4-content\"> > It was also in the Renaissance that the term \"artisan\" first appeared. <span class=\"translation\">\"장인\"이라는 용어가 처음 등장한 것도 르네상스 시대였다.</span> > The word was used to clearly distinguish between arts and crafts. <span class=\"translation\">이 단어는 예술과 공예를 명확히 구별하기 위해 사용되었다.</span> > Art required academic training, and its goal was to create perfect and idealized representations of reality that followed established principles of beauty. <span class=\"translation\">예술은 학문적 훈련을 요구했으며, 그 목표는 확립된 아름다움의 원칙을 따르는 현실의 완벽하고 이상화된 표현을 창조하는 것이었다.</span> > This is in contrast to crafts, like beadwork or basket making, which were fashioned largely for everyday purposes. <span class=\"translation\">이는 구슬 세공이나 바구니 만들기와 같은 공예와 대조되는데, 이들은 주로 일상적인 목적을 위해 제작되었다.</span> > Craftsmen whose production consisted of such practical, or merely decorative, items were called artisans. <span class=\"translation\">그러한 실용적이거나 단순히 장식적인 물품들을 생산하는 장인들은 아티잔이라고 불렸다.</span> > They often learned their trade from master craftsmen, but they did not study art in the academies. <span class=\"translation\">그들은 종종 숙련된 장인들로부터 기술을 배웠지만, 학원에서 예술을 공부하지는 않았다.</span> > The clear division between arts and crafts saw its peak in the eighteenth century. <span class=\"translation\">예술과 공예 사이의 명확한 구분은 18세기에 절정에 달했다.</span> </div> Paragraph 5 <button class=\"toggle-button translations\" data-type=\"paragraph5\">🔍 AI 해석 가리기</button> <div class=\"paragraph5-content\"> > In the nineteenth century, modernists sought to promote the idea of \"art for art's sake\" and rejected classical definitions. <span class=\"translation\">19세기에 모더니스트들은 \"예술을 위한 예술\"이라는 사상을 촉진하려 했으며 고전적 정의들을 거부했다.</span> > Artists felt hindered by the conventions of classicism and began to ignore form in favor of stylistic expression. <span class=\"translation\">예술가들은 고전주의의 관습에 의해 방해받는다고 느꼈으며 형태를 무시하고 양식적 표현을 선호하기 시작했다.</span> > At the same time, they rejected the convictions of some of their contemporaries, who claimed that art should be fundamentally utilitarian and beneficial to society. <span class=\"translation\">동시에, 그들은 예술이 근본적으로 실용적이고 사회에 유익해야 한다고 주장하는 일부 동시대인들의 신념을 거부했다.</span> > Modernists denied that purpose, whether moral or political, was an important criterion for art to have merit. <span class=\"translation\">모더니스트들은 도덕적이든 정치적이든 목적이 예술이 가치를 갖기 위한 중요한 기준이라는 것을 부인했다.</span> > Accordingly, they believed all art had an intrinsic value of its own. <span class=\"translation\">따라서, 그들은 모든 예술이 그 자체로 내재적 가치를 가진다고 믿었다.</span> > In addition, artists experimented with new techniques and subject matter. <span class=\"translation\">또한, 예술가들은 새로운 기법과 주제를 실험했다.</span> > They began to include more impressionistic and abstract designs, emphasizing experimental over learned techniques. <span class=\"translation\">그들은 더 인상주의적이고 추상적인 디자인을 포함하기 시작했으며, 배운 기법보다 실험적인 것을 강조했다.</span> </div> Paragraph 6 <button class=\"toggle-button translations\" data-type=\"paragraph6\">🔍 AI 해석 가리기</button> <div class=\"paragraph6-content\"> > This new perception of art as an end in itself eventually erased the fragmentation between artist and artisan. <span class=\"translation\">그 자체가 목적인 예술에 대한 이 새로운 인식은 결국 예술가와 장인 사이의 분열을 지워버렸다.</span> > In a clear mockery of the classical tradition, the notion of art was extended to include anything a person creates. <span class=\"translation\">고전적 전통에 대한 명백한 조롱으로, 예술의 개념은 사람이 창조하는 모든 것을 포함하도록 확장되었다.</span> > Therefore, it effectively eliminated the distinction between crafts and the so-called fine arts. <span class=\"translation\">따라서, 그것은 공예와 소위 순수 예술 사이의 구별을 효과적으로 제거했다.</span> > A person who produced a basket and a person who painted a canvas in classical style were no different; they were both using their skills to create something. <span class=\"translation\">바구니를 만든 사람과 고전적 양식으로 캔버스에 그림을 그린 사람은 다르지 않았다; 그들은 둘 다 무언가를 창조하기 위해 자신의 기술을 사용하고 있었다.</span> > This meant that any creative work could be viewed as genuine and prestigious. <span class=\"translation\">이것은 모든 창조적 작업이 진정하고 권위 있는 것으로 여겨질 수 있음을 의미했다.</span> > Further, art moved beyond the realm of productive creativity. <span class=\"translation\">더 나아가, 예술은 생산적 창조성의 영역을 넘어섰다.</span> > Some artists randomly collected everyday objects and displayed them, completely unmodified, as \"creative sculpture.\" <span class=\"translation\">일부 예술가들은 일상적인 물건들을 무작위로 수집하여 완전히 수정하지 않은 채로 \"창조적 조각\"으로 전시했다.</span> </div> Paragraph 7 <button class=\"toggle-button translations\" data-type=\"paragraph7\">🔍 AI 해석 가리기</button> <div class=\"paragraph7-content\"> > Conceptions of art have changed remarkably and created much confusion. <span class=\"translation\">예술에 대한 개념들은 현저히 변화했으며 많은 혼란을 만들어냈다.</span> > Today there is no consensus on the meaning of the term, and it is applied very subjectively. <span class=\"translation\">오늘날 그 용어의 의미에 대한 합의가 없으며, 그것은 매우 주관적으로 적용된다.</span> > Evidence can be seen in art museums and galleries devoted to everything from primitive artifacts to video productions to commercial graphics. <span class=\"translation\">증거는 원시 유물에서부터 비디오 제작물, 상업적 그래픽에 이르기까지 모든 것을 다루는 미술관과 갤러리에서 볼 수 있다.</span> > Certainly, the question of what constitutes art has become largely subjective. <span class=\"translation\">확실히, 무엇이 예술을 구성하는가라는 질문은 대체로 주관적인 것이 되었다.</span> </div> --- 📚 핵심 단어 사전 <button class=\"toggle-button vocabulary\" data-type=\"vocabulary\">🔍 단어 뜻 가리기</button> <div class=\"vocabulary-content\"> 🎨 예술사 관련 용어 contradictory <span class=\"meaning\">(상반되는, 모순적인) - 서로 반대되는</span> exclusively <span class=\"meaning\">(독점적으로, 오직) - 다른 것을 배제하고</span> Renaissance <span class=\"meaning\">(르네상스) - 14-16세기 유럽 문예부흥시대</span> obscure <span class=\"meaning\">(모호하게 하다) - 불분명하게 만들다</span> techne <span class=\"meaning\">(테크네) - 그리스어로 \"기술, 기예\"</span> ars <span class=\"meaning\">(아르스) - 라틴어로 \"기술, 예술\"</span> expertise <span class=\"meaning\">(전문성) - 전문적 기술이나 지식</span> blacksmithing <span class=\"meaning\">(대장장이 일) - 철을 다루는 기술</span> craftsmen <span class=\"meaning\">(장인) - 수공업에 종사하는 사람</span> manual laborers <span class=\"meaning\">(육체 노동자) - 손으로 일하는 사람들</span> 🏛️ 학문/교육 관련 용어 academic subjects <span class=\"meaning\">(학문 과목) - 학교에서 가르치는 정규 과목</span> higher learning <span class=\"meaning\">(고등 학문) - 대학 수준의 교육</span> social hierarchy <span class=\"meaning\">(사회 계층) - 사회의 등급 구조</span> academies <span class=\"meaning\">(학원, 아카데미) - 예술이나 학문을 가르치는 기관</span> classical art <span class=\"meaning\">(고전 예술) - 전통적인 양식을 따르는 예술</span> fine arts <span class=\"meaning\">(순수 예술) - 실용성보다 미적 가치를 추구하는 예술</span> 🔧 기술/공예 관련 용어 artisan <span class=\"meaning\">(아티잔, 수공업자) - 숙련된 수공업 종사자</span> beadwork <span class=\"meaning\">(구슬 세공) - 구슬을 이용한 공예</span> basket making <span class=\"meaning\">(바구니 만들기) - 바구니 제작 기술</span> decorative <span class=\"meaning\">(장식적인) - 꾸미는 목적의</span> master craftsmen <span class=\"meaning\">(숙련 장인) - 기술을 완전히 익힌 장인</span> 💭 철학/사상 관련 용어 modernists <span class=\"meaning\">(모더니스트) - 현대주의자들</span> art for art's sake <span class=\"meaning\">(예술을 위한 예술) - 예술의 자율성을 주장하는 사상</span> conventions <span class=\"meaning\">(관습) - 전통적으로 따르는 방식</span> classicism <span class=\"meaning\">(고전주의) - 고전적 양식을 따르는 예술 사조</span> stylistic expression <span class=\"meaning\">(양식적 표현) - 개인적 스타일의 표현</span> utilitarian <span class=\"meaning\">(실용주의적인) - 실용성을 중시하는</span> intrinsic value <span class=\"meaning\">(내재적 가치) - 그 자체가 가진 가치</span> impressionistic <span class=\"meaning\">(인상주의적인) - 인상주의 양식의</span> abstract <span class=\"meaning\">(추상적인) - 구체적이지 않은</span> 🌍 현대 예술 관련 용어 fragmentation <span class=\"meaning\">(분열, 파편화) - 나뉘어진 상태</span> mockery <span class=\"meaning\">(조롱) - 비웃음</span> genuine <span class=\"meaning\">(진정한) - 가짜가 아닌</span> prestigious <span class=\"meaning\">(권위 있는) - 명성이 높은</span> realm <span class=\"meaning\">(영역) - 분야나 범위</span> unmodified <span class=\"meaning\">(수정되지 않은) - 변화시키지 않은</span> consensus <span class=\"meaning\">(합의) - 의견의 일치</span> subjectively <span class=\"meaning\">(주관적으로) - 개인적 견해에 따라</span> primitive artifacts <span class=\"meaning\">(원시 유물) - 고대의 인공 제작물</span> constitutes <span class=\"meaning\">(구성하다) - 이루다, 형성하다</span> </div> --- 💬 중요한 영어 표현들 <button class=\"toggle-button expressions\" data-type=\"expressions\">🔍 표현 뜻 가리기</button> <div class=\"expressions-content\"> 📊 변화/발전 표현 has varied throughout history <span class=\"meaning\">(역사를 통틀어 변화해왔다) - \"How art is defined has varied throughout history\"</span> leading to <span class=\"meaning\">(~로 이어지는) - \"leading to a wide range of meanings\"</span> came about <span class=\"meaning\">(생겨나다, 발생하다) - \"came about only in the Renaissance\"</span> came into fashion <span class=\"meaning\">(유행하게 되다) - \"a new meaning came into fashion\"</span> began to change <span class=\"meaning\">(변화하기 시작했다) - \"things began to change during the Renaissance\"</span> at the forefront of <span class=\"meaning\">(~의 최전선에) - \"At the forefront of this transformation\"</span> 🎯 대조/비교 표현 in contrast to <span class=\"meaning\">(~와 대조적으로) - \"This is in contrast to crafts\"</span> more similar to <span class=\"meaning\">(~에 더 가까운) - \"more similar to manual laborers than artists\"</span> on par with <span class=\"meaning\">(~와 동등한) - \"on par with that of poets\"</span> as opposed to <span class=\"meaning\">(~와는 반대로) - implied in contrasts</span> in a clear mockery of <span class=\"meaning\">(~에 대한 명백한 조롱으로) - \"In a clear mockery of the classical tradition\"</span> ⏰ 시간/순서 표현 subsequently <span class=\"meaning\">(그 후에) - \"Subsequently, in modern times\"</span> gradually <span class=\"meaning\">(점차적으로) - \"Artists gradually gained acceptance\"</span> increasingly <span class=\"meaning\">(점점 더) - \"increasingly employed scientific methods\"</span> eventually <span class=\"meaning\">(결국) - \"eventually erased the fragmentation\"</span> saw its peak <span class=\"meaning\">(절정에 달했다) - \"saw its peak in the eighteenth century\"</span> 🎨 예술 관련 표현 applied exclusively to <span class=\"meaning\">(~에만 독점적으로 적용되다) - \"applied exclusively to works\"</span> became synonymous with <span class=\"meaning\">(~와 동의어가 되다) - \"became synonymous with classical art\"</span> came to represent <span class=\"meaning\">(~를 대표하게 되다) - \"came to represent the fine arts\"</span> in favor of <span class=\"meaning\">(~을 선호하여) - \"in favor of stylistic expression\"</span> beyond the realm of <span class=\"meaning\">(~의 영역을 넘어서) - \"beyond the realm of productive creativity\"</span> 📝 학술적 표현 stood for <span class=\"meaning\">(~를 의미했다) - \"they stood for any activity\"</span> were viewed as <span class=\"meaning\">(~로 여겨졌다) - \"were viewed as craftsmen\"</span> necessitating <span class=\"meaning\">(~를 필요로 하는) - \"necessitating skills\"</span> occupied the bottom of <span class=\"meaning\">(~의 맨 아래를 차지했다) - \"occupied the bottom of the social hierarchy\"</span> inherited this view <span class=\"meaning\">(이 견해를 물려받았다) - \"The medieval world inherited this view\"</span> 🔍 강조/설명 표현 it was also... that <span class=\"meaning\">(~한 것도 바로 ...였다) - \"It was also in the Renaissance that...\"</span> accordingly <span class=\"meaning\">(따라서) - \"Accordingly, they believed\"</span> in addition <span class=\"meaning\">(또한) - \"In addition, artists experimented\"</span> therefore <span class=\"meaning\">(따라서) - \"Therefore, it effectively eliminated\"</span> certainly <span class=\"meaning\">(확실히) - \"Certainly, the question has become\"</span> 💭 의견/판단 표현 argued that <span class=\"meaning\">(~라고 주장했다) - \"artists argued that they were superior\"</span> believed to require <span class=\"meaning\">(~를 요구한다고 여겨졌다) - \"believed to require no unique inspiration\"</span> denied that <span class=\"meaning\">(~라는 것을 부인했다) - \"Modernists denied that purpose\"</span> sought to promote <span class=\"meaning\">(~를 촉진하려 했다) - \"sought to promote the idea\"</span> felt hindered by <span class=\"meaning\">(~에 의해 방해받는다고 느꼈다) - \"felt hindered by the conventions\"</span> </div> --- 문제풀이 TOEFL Reading Comprehension Questions Question 12 Which of the following is consistent with the ancient view of art as described in paragraph 2? (A) Visual art was not an undertaking worthy of esteem. (B) Art was an activity that required special inspiration. (C) Visual art occupied a special place in higher learning. (D) Art applied to any pursuit involving formal education. <button class=\"toggle-button answer\" data-type=\"answer12\">🔍 정답 및 해설 가리기</button> <div class=\"answer12-content\"> 정답: (A) Visual art was not an undertaking worthy of esteem. 해설: 2단락에서 고대인들의 예술관: 핵심 근거: \"The visual arts were viewed simply as manual crafts\" \"because the ancients looked down on manual labor, artisans occupied the bottom of the social hierarchy\" \"Those engaged in the production of art were viewed as craftsmen, more similar to manual laborers than artists\" 고대인들은 시각 예술을 단순한 수공 기술로 여겼고, 육체 노동을 업신여겼기 때문에 시각 예술은 존경받을 만한 일이 아니었습니다. 오답 분석: (B) \"believed to require no unique inspiration\" - 특별한 영감이 필요하지 않다고 여김 (C) \"Painting and sculpture had no special place in higher learning\" - 고등 학문에서 특별한 자리 없음 (D) 공식 교육이 아닌 \"rules and required expertise\"를 요구하는 모든 활동에 적용 </div> Question 13 Which of the following is NOT listed as an example of fine art in paragraph 3? (A) Sculpture (B) Architecture (C) Mathematics (D) Music <button class=\"toggle-button answer\" data-type=\"answer13\">🔍 정답 및 해설 가리기</button> <div class=\"answer13-content\"> 정답: (C) Mathematics 해설: 3단락에서 언급된 순수 예술(fine arts)들: 명시적으로 언급된 것들: \"Painting, sculpture, and architecture were given their own place in academies\" \"Collectively, the classical arts, along with music and poetry, came to represent the fine arts\" 수학의 역할: \"mathematics became central to their trade\"로 언급되지만, 이는 예술가들이 사용하는 도구로서의 수학이지, 수학 자체가 순수 예술로 분류된 것은 아닙니다. 순수 예술로 언급된 것들: (A) Sculpture ✓ - 명시적 언급 (B) Architecture ✓ - 명시적 언급 (D) Music ✓ - \"along with music and poetry\" 언급 </div> Question 14 Which of the following is a distinguishing feature of crafts according to paragraph 4? (A) They were made for decoration. (B) They were produced in large quantities. (C) They were produced by artisans in the academies. (D) They were made to closely follow aesthetic principles. <button class=\"toggle-button answer\" data-type=\"answer14\">🔍 정답 및 해설 가리기</button> <div class=\"answer14-content\"> 정답: (A) They were made for decoration. 해설: 4단락에서 공예의 특징: 핵심 근거: \"This is in contrast to crafts, like beadwork or basket making, which were fashioned largely for everyday purposes\" \"Craftsmen whose production consisted of such practical, or merely decorative, items were called artisans\" 공예는 실용적(practical)이거나 단순히 장식적(decorative)인 목적으로 만들어졌다고 명시되어 있습니다. 예술과의 대조: 예술: \"create perfect and idealized representations of reality that followed established principles of beauty\" 공예: \"fashioned largely for everyday purposes\" + \"merely decorative\" 오답 분석: (B) 대량 생산에 대한 언급 없음 (C) \"they did not study art in the academies\" - 학원에서 공부하지 않음 (D) 미적 원칙을 따르는 것은 예술의 특징 </div> Question 15 The word \"convictions\" in the passage is closest in meaning to (A) intense oppositions (B) strong beliefs (C) wrong assumptions (D) feeble suggestions <button class=\"toggle-button answer\" data-type=\"answer15\">🔍 정답 및 해설 가리기</button> <div class=\"answer15-content\"> 정답: (B) strong beliefs 해설: 5단락의 문맥에서 \"convictions\" 사용: 원문: \"they rejected the convictions of some of their contemporaries, who claimed that art should be fundamentally utilitarian and beneficial to society\" 문맥 분석: 모더니스트들이 거부한 것은 동시대인들의 신념/확신이었습니다. 이들은 예술이 실용적이고 사회에 유익해야 한다고 강하게 믿었던 사람들이었습니다. 어휘 분석: conviction = 확신, 신념 (강한 믿음) (A) intense oppositions: 강한 반대 - 문맥에 맞지 않음 (B) strong beliefs: 강한 믿음 ✓ (C) wrong assumptions: 잘못된 가정 - 가치 판단적 (D) feeble suggestions: 약한 제안 - conviction의 강한 의미와 반대 </div> Question 16 What can be inferred from paragraph 5 about artists in the nineteenth century? (A) Some of them thought that the primary value of art was in its social purpose. (B) Most of them approached art as an academic discipline that required learning. (C) They placed a greater emphasis on aesthetics than did classical artists. (D) They viewed moral and political art as having no intrinsic value. <button class=\"toggle-button answer\" data-type=\"answer16\">🔍 정답 및 해설 가리기</button> <div class=\"answer16-content\"> 정답: (A) Some of them thought that the primary value of art was in its social purpose. 해설: 5단락에서 19세기 예술가들의 상황: 핵심 근거: \"At the same time, they rejected the convictions of some of their contemporaries, who claimed that art should be fundamentally utilitarian and beneficial to society\" 이 문장은 모더니스트들이 거부한 동시대인들의 견해를 설명합니다. 즉, 19세기에는 일부 예술가들이 예술의 주된 가치가 사회적 목적에 있다고 생각했다는 것을 추론할 수 있습니다. 논리 구조: 모더니스트들이 \"art for art's sake\"를 주장 그들이 거부한 것: 예술이 실용적이고 사회에 유익해야 한다는 견해 → 따라서 그런 견해를 가진 사람들이 존재했음을 의미 오답 분석: (B) 모더니스트들은 오히려 전통적 학문적 접근을 거부 (C) 형태보다 양식적 표현을 강조 - 순수 미학적 접근은 아님 (D) 모더니스트들이 거부한 것이지, 모든 예술가가 그런 것은 아님 </div> Question 17 What is the purpose of paragraph 6 in the passage? (A) To introduce the reasons for the changes outlined in the preceding paragraphs (B) To describe the resulting outcome of the ideas described in the previous paragraph (C) To offer supporting evidence for the ideas introduced in the previous paragraph (D) To provide a transition between the preceding paragraphs and the final paragraph <button class=\"toggle-button answer\" data-type=\"answer17\">🔍 정답 및 해설 가리기</button> <div class=\"answer17-content\"> 정답: (B) To describe the resulting outcome of the ideas described in the previous paragraph 해설: 단락들 간의 논리적 연결: 5단락 (원인): 모더니스트들의 사상 \"art for art's sake\" 예술의 내재적 가치 실험적 기법 추구 6단락 (결과): 이러한 사상의 결과 \"This new perception of art as an end in itself eventually erased the fragmentation between artist and artisan\" \"effectively eliminated the distinction between crafts and the so-called fine arts\" 예술 개념의 극단적 확장 논리적 구조: 5단락: 모더니스트 사상 소개 (원인) 6단락: \"This new perception\" → 그 결과 설명 연결어: \"This\" = 앞 단락의 내용을 받음 오답 분석: (A) 변화의 이유 소개 - 5단락에서 이미 다룸 (C) 지지 증거 제공 - 새로운 결과를 설명하는 것 (D) 전환 역할 - 6단락 자체가 실질적 내용을 담고 있음 </div> Question 18 The word \"prestigious\" in the passage is closest in meaning to (A) obscure (B) ubiquitous (C) reputable (D) credulous <button class=\"toggle-button answer\" data-type=\"answer18\">🔍 정답 및 해설 가리기</button> <div class=\"answer18-content\"> 정답: (C) reputable 해설: 6단락의 문맥에서 \"prestigious\" 사용: 원문: \"This meant that any creative work could be viewed as genuine and prestigious\" 문맥 분석: 모든 창조적 작업이 진정하고(genuine) 권위 있는(prestigious) 것으로 여겨질 수 있다는 의미입니다. 여기서 \"prestigious\"는 높은 지위나 명성을 가진이라는 뜻입니다. 어휘 분석: prestigious = 권위 있는, 명성이 높은 (A) obscure: 모호한, 잘 알려지지 않은 - 정반대 의미 (B) ubiquitous: 어디에나 있는 - 관련 없음 (C) reputable: 평판이 좋은, 명성 있는 ✓ (D) credulous: 잘 믿는, 순진한 - 관련 없음 동의어 관계: prestigious ≈ reputable ≈ respected ≈ esteemed </div> Question 19 Look at the four squares [■] that indicate where the following sentence could be added to the passage. Other examples of crafts included studio pottery and metalworking. Where would the sentence best fit? <button class=\"toggle-button answer\" data-type=\"answer19\">🔍 정답 및 해설 가리기</button> <div class=\"answer19-content\"> 적절한 위치: 4단락의 세 번째 [■] 뒤 해설: 삽입할 문장: \"Other examples of crafts included studio pottery and metalworking.\" (공예의 다른 예시들로는 스튜디오 도자기와 금속 공예가 포함되었다.) 4단락의 구조: \"artisan\" 용어의 등장 예술과 공예의 구별 [■ 여기] \"This is in contrast to crafts, like beadwork or basket making...\" 아티잔의 정의 아티잔의 교육 방식 예술과 공예 구분의 절정 가장 적절한 위치 분석: 세 번째 [■] 뒤가 가장 적절: 앞 문장: \"This is in contrast to crafts, like beadwork or basket making, which were fashioned largely for everyday purposes\" 삽입 문장: \"Other examples of crafts included studio pottery and metalworking\" 뒤 문장: \"Craftsmen whose production consisted of such practical...\" 논리적 연결성: 공예의 첫 번째 예시 제시 (beadwork, basket making) → 공예의 추가 예시 제공 (pottery, metalworking) → 이러한 공예품을 만드는 사람들의 명칭 설명 \"Other examples\"라는 표현이 앞서 제시된 예시들을 받아서 추가 정보를 제공하는 역할 </div> Question 20 Directions: An introductory sentence for a brief summary of the passage is provided below. Complete the summary by selecting the THREE answer choices that express the most important ideas in the passage. Some sentences do not belong in the summary because they express ideas that are not presented in the passage or are minor ideas in the passage. This question is worth 2 points. The term \"art\" has changed so much that its meaning has become rather subjective. Answer Choices: (A) In the Latin and Greek worlds, art was looked down upon as a form of manual labor. (B) Artists of the modern period began to experiment by combining classical and abstract techniques in their art. (C) After the medieval period, the number of artists attending academies rose due to increased prestige in the arts. (D) The ancients applied the term in a broad manner to any rule-based activity that required skill. (E) Modernists, hoping to revolutionize the way art was conceived, completely redefined the term. (F) As artists began to gain status, the distinction between arts and crafts became more apparent. <button class=\"toggle-button answer\" data-type=\"answer20\">🔍 정답 및 해설 가리기</button> <div class=\"answer20-content\"> 정답: (D), (E), (F) 해설: 선택된 답안들: (D) The ancients applied the term in a broad manner to any rule-based activity that required skill. ✓ 2단락: \"they stood for any activity that had rules and required expertise\" \"from medicine and law to blacksmithing\" 고대의 광범위한 예술 개념이 주요 주제 (E) Modernists, hoping to revolutionize the way art was conceived, completely redefined the term. ✓ 5-6단락: 모더니스트들의 혁명적 변화 \"art for art's sake\", 예술과 공예의 구분 제거 현대적 예술 개념의 핵심 변화 (F) As artists began to gain status, the distinction between arts and crafts became more apparent. ✓ 3-4단락: 르네상스 시대 예술가 지위 향상 \"artisan\" 용어 등장, 예술과 공예의 명확한 구분 역사적 발전 과정의 중요한 단계 제외된 답안들: (A) 고대에서 예술이 업신여겨진 것은 맞지만, 핵심은 \"광범위한 적용\" (B) 고전과 추상 기법의 결합은 언급되지 않음 (C) 학원 출석자 수 증가는 세부 사항, 주요 아이디어 아님 요약의 논리적 흐름: 고대: 광범위한 적용 (D) 르네상스: 지위 향상과 구분 명확화 (F) 현대: 모더니스트의 재정의 (E) </div>"
  },
  {
    "id": "Self_Development/English Study/SPEAK/지나간달/07-15-정신똑바로차리고있어",
    "title": "정신 똑바로 차리고 있어",
    "date": "2025-07-15",
    "excerpt": "",
    "category": "English Study",
    "tags": [
      "영어공부꾸준히!",
      "SPEAK",
      "고민 및 조언하는 표햔"
    ],
    "content": "배운 것들 Be on the lookout : 정신 똑바로 차려 Be on the lookout for pickpockets Be on the lookout for voicefishing Be careful with Be careful with your bag on the subway. in + 자동차 (타서 앉으면 끝) on + 비행기, 배, 지하철 passport catch a cold Be careful not to catch a cold Be careful not to burn yourself Be careful not to hurt yourself During this outbreak? outbreak: 질병 발생기간 scammers : 사기꾼 Make sure not to go 간단한 작문 As usaul, I talk to myself. Hey MK, be on the lookout for 나태함. Be careful with your habit that do work later (미루는 습관) Nice work today, just keep this pace. But don`t forget happy is around you. Feel happy with 사소한 thing around you, and victories you made in today. 수정된 작문 (Improved Version) As usual, time for my daily self-talk. Hey MK, don't get lazy on me! Stop putting things off - let's break this procrastination habit once and for all. *procrastination: 꾸물거리다 예문: \"Stop procrastinating and start studying!\" (미루지 말고 공부 시작해!) \"Procrastination is the thief of time.\" (미루기는 시간 도둑이다) \"I need to overcome my procrastination habit.\" (미루는 습관을 고쳐야 해) You crushed it today, keep this energy going! And hey, don't forget to enjoy the little things around you. Take a moment to appreciate the small wins and celebrate what you accomplished today. 피드백 (Feedback) 개선된 점들: 문법적 수정 \"As usaul\" → \"As usual\" (철자 오류 수정) \"do work later\" → \"Stop putting things off\" (더 직접적이고 자연스러운 표현) \"happy is around you\" → \"enjoy the little things around you\" (자연스러운 문장 구조) 어휘 선택 개선 (더 캐주얼하고 현대적으로) \"나태함\" → \"don't get lazy on me!\" (친근하고 에너지 넘치는 표현) \"Nice work\" → \"You crushed it\" (현대적이고 임팩트 있는 칭찬) \"keep this pace\" → \"keep this energy going\" (더 자연스러운 표현) \"사소한 thing\" → \"little things\", \"small wins\" (일상적인 표현) 문장 구조 개선 너무 긴 문장을 짧게 나누어 읽기 쉽게 만듦 명령형을 사용해 더 직접적이고 동기부여적으로 표현 실제 자기 대화에서 쓸 법한 자연스러운 톤으로 변경 전체적인 톤 개선 Formal한 표현을 캐주얼하고 친근한 표현으로 변경 감탄사(\"hey\") 추가로 더 생동감 있는 대화체 구현 짧고 임팩트 있는 문장으로 동기부여 효과 극대화 핵심 학습 포인트: 자기 대화는 캐주얼하고 직접적일수록 자연스럽다 현대적인 슬랭 표현(\"crushed it\")도 적절히 활용하기 너무 긴 문장보다는 짧고 명확한 문장이 효과적 감정을 담은 표현(\"don't get lazy on me!\")이 더 동기부여가 된다 앞으로 연습할 점: 한국어와 영어가 섞인 부분을 피하고 완전한 영어 문장으로 작성하기 현대적이고 자연스러운 구어체 표현 더 학습하기 감정을 담은 생동감 있는 표현 연습하기"
  },
  {
    "id": "Data Science/Recommendation/user-based-collaborative-filtering",
    "title": "User-Based Collaborative Filtering",
    "date": "2025-07-15",
    "excerpt": "User-Based Collaborative Filtering 알고리즘에 대한 설명",
    "category": "Recommendation",
    "tags": [
      "추천시스템"
    ],
    "content": "User-Based Collaborative Filtering (사용자 기반 협업 필터링) 개요 User-Based Collaborative Filtering은 추천 시스템에서 가장 오래되고 직관적인 이웃(neighborhood) 기반 방법입니다. 핵심 아이디어는 \"비슷한 취향을 가진 사용자들이 비슷한 아이템을 좋아할 것이다\" 라는 가정에 기반합니다. 기본 개념 사용자-아이템 평점 행렬 $R$: 행은 사용자, 열은 아이템 원소 $r_{u,i}$: 사용자 $u$가 아이템 $i$에 매긴 평점 (또는 암시적 행동) 목표: 사용자 $u$에게 아이템 $i$를 추천할지 결정 알고리즘 절차 유사도(Similarity) 계산 사용자 간 유사도를 계산하는 방법들: Cosine Similarity $$\\text{sim}(u,v) = \\frac{\\mathbf{r}_u \\cdot \\mathbf{r}_v}{\\ \\mathbf{r}_u\\ \\times \\ \\mathbf{r}_v\\ }$$ Pearson Correlation $$\\text{sim}(u,v) = \\frac{\\sum_{i \\in I_{uv}} (r_{u,i} - \\bar{r}_u)(r_{v,i} - \\bar{r}_v)}{\\sqrt{\\sum_{i \\in I_{uv}} (r_{u,i} - \\bar{r}_u)^2} \\times \\sqrt{\\sum_{i \\in I_{uv}} (r_{v,i} - \\bar{r}_v)^2}}$$ 여기서 $I_{uv}$는 두 사용자가 모두 평가한 아이템 집합 Adjusted Cosine Similarity $$\\text{sim}(u,v) = \\frac{\\sum_{i \\in I_{uv}} (r_{u,i} - \\bar{r}_i)(r_{v,i} - \\bar{r}_i)}{\\sqrt{\\sum_{i \\in I_{uv}} (r_{u,i} - \\bar{r}_i)^2} \\times \\sqrt{\\sum_{i \\in I_{uv}} (r_{v,i} - \\bar{r}_i)^2}}$$ 여기서 $\\bar{r}_i$는 아이템 $i$의 평균 평점 Top-K 이웃 선택 사용자 $u$와 유사도가 가장 높은 $K$명의 사용자 이웃 집합 $N_u$ 선택 평점 예측 / 추천 점수 계산 가중 평균 방식 $$\\hat{r}_{u,i} = \\bar{r}_u + \\frac{\\sum_{v \\in N_u} \\text{sim}(u,v) \\times (r_{v,i} - \\bar{r}_v)}{\\sum_{v \\in N_u} \\text{sim}(u,v) }$$ 단순 가중합 방식 $$\\hat{r}_{u,i} = \\frac{\\sum_{v \\in N_u} \\text{sim}(u,v) \\times r_{v,i}}{\\sum_{v \\in N_u} \\text{sim}(u,v) }$$ 추천 리스트 생성 아직 소비하지 않은 아이템 중 $\\hat{r}_{u,i}$가 높은 순으로 $N$개 반환 장점 직관성: 구현이 간단하고 이해하기 쉬움 New Item Cold-Start 대응: 새로운 아이템이 들어와도 비슷한 사용자가 평가했다면 곧바로 추천 가능 미묘한 패턴 포착: 사용자 선호의 세밀한 패턴을 이웃 기반으로 포착 가능 해석 가능성: 왜 이 아이템을 추천했는지 설명 가능 단점 희소성(Sparsity): 평점 행렬이 희소하면 공통 평가 아이템이 적어 유사도 계산이 불안정 확장성(Scalability): 사용자 수가 늘어날수록 전체 유사도 계산 비용 $O( U ^2)$ 사용자 Cold-Start: 새 사용자는 평점이 없어 추천 불가 Popularity Bias: 많은 평점을 남긴 헤비 유저에게 유사도가 집중될 수 있음 Gray Sheep 문제: 독특한 취향을 가진 사용자는 유사한 이웃을 찾기 어려움 개선 기법 Significance Weighting 공통 평가 아이템 수가 적으면 유사도에 패널티 부여 Neighborhood Size 최적화 $K$값 튜닝 유사도 threshold 설정 정규화 및 보정 Normalization (평균·표준편차 제거) Shrinkage Baseline 보정 (글로벌 평균 + user bias + item bias) Hybrid 접근법 사용자 기반 CF + 아이템 기반 CF 결합 콘텐츠 기반 특징과 결합 모델 기반(행렬 분해)과 스위칭 아이템 기반 CF와 비교 구분 User-Based CF Item-Based CF ------ --------------- --------------- 가정 비슷한 사용자가 비슷한 아이템을 좋아함 비슷한 아이템을 소비한 사용자는 향후 비슷한 아이템을 소비 적합한 상황 사용자 행동이 풍부하고 맞춤형 관계 파악 필요 대량 사용자, 상대적으로 적은 아이템 확장성 사용자 수에 따라 성능 저하 아이템 수에 따라 성능 저하 Cold-Start New Item에 강함, New User에 약함 New User에 강함, New Item에 약함 구현 시 고려사항 라이브러리 활용 Scikit-surprise: 다양한 CF 알고리즘 지원 Implicit: 암시적 피드백 기반 CF LightFM: 하이브리드 모델 성능 최적화 오프라인 계산: 유사도 행렬을 미리 계산하여 캐시 샘플링: 대규모 데이터에서 랜덤 샘플링으로 계산량 감소 Locality Sensitive Hashing: 근사 유사도 계산으로 속도 향상 실시간 처리 주기적 재계산 + 캐시로 대응 증분 업데이트 방식 고려 A/B 테스트 $K$값, 유사도 종류, 정규화 방식 튜닝 추천 품질과 성능 간 균형점 찾기 Python 구현 예시 ``python import numpy as np from scipy.spatial.distance import cosine from scipy.stats import pearsonr class UserBasedCF: def __init__(self, k=10): self.k = k self.user_similarities = None def fit(self, ratings_matrix): \"\"\"사용자 유사도 행렬 계산\"\"\" n_users = ratings_matrix.shape[0] self.user_similarities = np.zeros((n_users, n_users)) for i in range(n_users): for j in range(i+1, n_users): # 공통 평가 아이템 찾기 common_items = np.where((ratings_matrix[i] != 0) & (ratings_matrix[j] != 0))[0] if len(common_items) < 2: similarity = 0 else: # Pearson correlation 계산 user_i_ratings = ratings_matrix[i, common_items] user_j_ratings = ratings_matrix[j, common_items] try: similarity, _ = pearsonr(user_i_ratings, user_j_ratings) if np.isnan(similarity): similarity = 0 except: similarity = 0 self.user_similarities[i, j] = similarity self.user_similarities[j, i] = similarity def predict(self, user_id, item_id, ratings_matrix): \"\"\"특정 사용자의 특정 아이템 평점 예측\"\"\" if self.user_similarities is None: raise ValueError(\"Model must be fitted first\") # 사용자의 평균 평점 user_ratings = ratings_matrix[user_id] user_mean = np.mean(user_ratings[user_ratings != 0]) # 이웃 사용자들 찾기 similarities = self.user_similarities[user_id] neighbors = np.argsort(similarities)[::-1][1:self.k+1] numerator = 0 denominator = 0 for neighbor in neighbors: if similarities[neighbor] <= 0: continue neighbor_rating = ratings_matrix[neighbor, item_id] if neighbor_rating == 0: continue neighbor_mean = np.mean(ratings_matrix[neighbor][ratings_matrix[neighbor] != 0]) numerator += similarities[neighbor] * (neighbor_rating - neighbor_mean) denominator += abs(similarities[neighbor]) if denominator == 0: return user_mean predicted_rating = user_mean + (numerator / denominator) return max(1, min(5, predicted_rating)) # 평점 범위 제한 `` 결론 User-Based CF는 추천 시스템의 기본이 되는 직관적이고 효과적인 방법입니다. 하지만 데이터 희소성과 확장성 한계로 인해, 대규모 서비스에서는 다른 기법(아이템 기반, 행렬 분해, 딥러닝)과 결합하여 사용하는 것이 일반적입니다. 실제 적용 시에는 비즈니스 도메인, 데이터 특성, 성능 요구사항을 종합적으로 고려하여 적절한 하이브리드 접근법을 선택하는 것이 중요합니다. --- 참고 자료: Collaborative Filtering for Implicit Feedback Datasets Item-based collaborative filtering recommendation algorithms Matrix Factorization Techniques for Recommender Systems"
  },
  {
    "id": "Data Science/Causal Inference/tilde-tau-explained",
    "title": "Why Do We Introduce the Centered Function tilde_tau(x,t)?",
    "date": "2025-07-15",
    "excerpt": "The role of the intermediate, mean-zero CATE in the continuous-treatment R-learner.",
    "category": "Causal Inference",
    "tags": [
      "Concept",
      "R-learner",
      "Continuous Treatment"
    ],
    "content": "The problem in one sentence R-loss를 그대로 최소화하면 $$ h(x,t) = \\tau(x,t) + s(x) $$ 형태로 x 에만 의존하는 덧붙임 함수 $s(x)$ 가 있어도 손실값이 변하지 않는다. 그래서 최소값이 무한히 많아져 해가 유일하지 않다. --- Where does s(x) come from? R-loss에 $\\mathbb{E}[ h(X,T) \\mid X ]$ 항이 들어가므로 $h(x,t) + s(x)$ 를 넣어도 $s(x)$ 가 자연스럽게 상쇄된다. 그 결과 손실값이 동일하니 $s(x)$ 를 얼마든지 붙일 수 있다. 이것이 non-identification(식별 불능) 문제의 근원이다. --- Idea: “center” the function 중간 함수 $\\tilde{\\tau}(x,t)$ 를 다음처럼 정의한다. $$ \\tilde{\\tau}(x,t) = \\tau(x,t) - \\mathbb{E}[ \\tau(X,T) \\mid X = x ] $$ 즉, 각 x 마다 t 전역 평균이 0 이 되도록 중심화한다. mean-zero 성질 때문에 $h(x,t)$ 와 $h(x,t)+s(x)$ 의 차이점이 R-loss 안에서는 지워지지 않는다. 실제로 $h(X,T)+s(X) - \\mathbb{E}[h(X,T)+s(X)\\mid X] = h(X,T)-\\mathbb{E}[h(X,T)\\mid X]$ 이므로, R-loss 값은 그대로다. 따라서 중심화만으로는 식별 문제가 완전히 사라지지 않는다. 결정적인 열쇠는 다음 단계의 L2 정규화다. L2 패널티 $\\rho\\,\\ h\\ _2^2$ 가 추가되면, $s(x)$ 를 붙이는 순간 노름이 커져서 목적함수가 증가한다. 최적화는 $s(x)=0$ 을 선택해 유일해를 만든다. 즉 $\\tilde{\\tau}$ 는 \"mean-zero\" 조건을 만족하는 후보 중 하나이며, 식별을 완성하는 것은 정규화라는 점을 기억해야 한다. --- How regularisation fits in Step-1 (Tikhonov) 정규화된 최적화 문제를 푼다. $$ \\tau_{\\rho} = \\operatorname{arg\\,min}_{h} \\Bigl\\{ \\text{R-loss}(h) + \\rho \\, \\ h \\ _2^2 \\Bigr\\} $$ L2 패널티가 들어가면 문제가 엄밀히 convex 해져서 유일한 해가 보장된다. Step-2 (Scaling) 이론적으로 $\\tilde{\\tau} = (1 + \\rho)\\, \\tau_{\\rho}$ 임이 증명된다(Theorem 1). Step-3 (Zero-constraining operator) 마지막으로 $$ \\mathcal{C}(f)(x,t) = f(x,t) - f(x,0) $$ 를 적용하면 실제 관심 함수 $\\tau(x,t)$ 를 복원한다. --- Practical take-aways 모델링 – 신경망 같은 유연한 함수 근사기를 쓸 때도 $\\tilde{\\tau}$ 를 학습하면 식별 문제가 자동으로 해결된다. 수치 안정성 – L2 정규화(ρ>0)가 없으면 여전히 ill-posed; ρ 값은 크지 않아도 \"유일 최소\" 확보에 충분하다. 해석 – $\\tilde{\\tau}$ 는 \"x 조건부에서 t 변화만 담은 순수 효과\"라서 $s(x)$(x 전용 편향)와 깔끔히 분리된다. --- Mini-checklist for implementation 두 nuisance 함수 m(x) 와 varpi(t x) 추정 R-loss + L2 패널티로 $\\tau_{\\rho}$ 계산 $$\\tilde{\\tau} = (1 + \\rho)\\, \\tau_{\\rho}$$ $$\\hat{\\tau}(x,t) = \\tilde{\\tau}(x,t) - \\tilde{\\tau}(x,0)$$ --- Related reading Robinson (1988) – partially linear models Nie & Wager (2021) – Quasi-Oracle R-learner Kennedy et al. (2017) – continuous-treatment GPS Tikhonov (1963) – regularisation for ill-posed problems --- 3.5 Why do we still center? L2 정규화가 최종적으로 $s(x)$ 를 제거하더라도, 중심화가 선행돼야 하는 실용적 이유가 있습니다. Canonical representative – 같은 R-loss 값을 갖는 동치류 $\\{h+s(x)\\}$ 중에서 $\\mathbb{E}[h\\mid X]=0$ 인 함수가 가장 작은 $L_2$ 노름을 가지므로, 정규화가 자연스럽게 그 함수를 선택하게 된다. 닫힌 형태 해 – Theorem 1 의 $(1+\\rho)^{-1}$ 스케일 관계는 $\\mathbb{E}[h\\mid X]=0$ 조건이 있어야 성립한다. Zero-constraining operator – 마지막 단계에서 $\\mathcal{C}(f)(x,t)=f(x,t)-f(x,0)$ 를 적용할 때, 중심화돼 있어야 정확히 $\\tau(x,t)$ 로 복원된다. ---"
  },
  {
    "id": "Self_Development/English Study/TOEFL/준비전략서치",
    "title": "어떻게 공부해야할지 서치하고 정리",
    "date": "2025-07-14",
    "excerpt": "OMSCS 지원을 위한 토플 공부",
    "category": "English Study",
    "tags": [
      "TOEFL",
      "영어",
      "대학원"
    ],
    "content": ""
  },
  {
    "id": "Self_Development/English Study/TOEFL/Fact and Negative Fact",
    "title": "Fact와 Negative Fact 차이",
    "date": "2025-07-14",
    "excerpt": "Fact와 Negative Fact 유형 풀이법",
    "category": "English Study",
    "tags": [
      "TOEFL",
      "영어",
      "대학원"
    ],
    "content": ""
  },
  {
    "id": "Self_Development/English Study/TOEFL/BirdDialects",
    "title": "Bird Dialects",
    "date": "2025-07-14",
    "excerpt": "Diagnostic Test 문제 공부",
    "category": "English Study",
    "tags": [
      "TOEFL",
      "영어",
      "대학원"
    ],
    "content": "Bird Dialects 새 다이러렉츠? 새의 방언 Paragraph 1 <button class=\"toggle-button translations\" data-type=\"paragraph1\">🔍 AI 해석 가리기</button> <div class=\"paragraph1-content\"> > Birds learn acoustic information from their parents and environment from an early age. <span class=\"translation\">새들은 어린 나이부터 부모와 환경으로부터 음향 정보를 배운다.</span> > The most complex form of avian vocalization is the birdsong, an often melodic series of communicative sounds produced primarily during breeding. <span class=\"translation\">조류의 발성 중 가장 복잡한 형태는 새의 노래로, 번식기에 주로 발생하는 종종 선율적인 의사소통 소리의 연속이다.</span> > In cases where populations have geographical boundaries, differences in song may appear, and if these geographical limits are distinct, the shared song types within a population are referred to as dialects. <span class=\"translation\">개체군이 지리적 경계를 가진 경우, 노래에서 차이가 나타날 수 있으며, 이러한 지리적 한계가 뚜렷하면, 한 개체군 내에서 공유되는 노래 유형을 방언이라고 부른다.</span> > Ornithologists are keenly interested in how these dialects form and to what extent genetic factors contribute to dialectical variation. <span class=\"translation\">조류학자들은 이러한 방언이 어떻게 형성되는지와 유전적 요인이 방언적 변화에 어느 정도 기여하는지에 깊은 관심을 가지고 있다.</span> > One of the best-studied songbirds in this regard is the white-crowned sparrow, Zonotrichia leucophrys, a species with several subspecies and many dialects. <span class=\"translation\">이와 관련하여 가장 잘 연구된 명금 중 하나는 흰관찰찌새(Zonotrichia leucophrys)로, 여러 아종과 많은 방언을 가진 종이다.</span> </div> Paragraph 2 <button class=\"toggle-button translations\" data-type=\"paragraph2\">🔍 AI 해석 가리기</button> <div class=\"paragraph2-content\"> > In Zonotrichia leucophrys, males demonstrate the greatest dialectical diversity. Therefore, studying male birds offers the best opportunity for understanding dialect formation. <span class=\"translation\">흰관찰찌새(Zonotrichia leucophrys)에서 수컷이 가장 큰 방언적 다양성을 보인다. 따라서 수컷 새를 연구하는 것이 방언 형성을 이해하는 데 가장 좋은 기회를 제공한다.</span> > In order to make sense of birdsongs, scientists break them into smaller units. <span class=\"translation\">새의 노래를 이해하기 위해 과학자들은 그것들을 더 작은 단위로 나눈다.</span> > A phrase, for example, is a large category below the level of song, and specific sound types like whistles, pulses, and buzzes reflect the individual speech parts, or syllables, of a phrase. <span class=\"translation\">예를 들어, 구문은 노래 수준 아래의 큰 범주이며, 휘파람, 펄스, 윙윙거리는 소리와 같은 특정 소리 유형은 구문의 개별 발화 부분, 즉 음절을 반영한다.</span> > The phrases are ordered according to their position in the song so that specific parts can be analyzed separately and compared across different individuals. <span class=\"translation\">구문들은 노래에서의 위치에 따라 순서가 정해져서, 특정 부분들을 개별적으로 분석하고 서로 다른 개체들 간에 비교할 수 있다.</span> </div> Paragraph 3 <button class=\"toggle-button translations\" data-type=\"paragraph3\">🔍 AI 해석 가리기</button> <div class=\"paragraph3-content\"> > Some phrases show more variability than others, and once scientists detect variability in a specific category, they can focus on that section of the songs in future studies. <span class=\"translation\">일부 구문들은 다른 구문들보다 더 많은 변이성을 보이며, 과학자들이 특정 범주에서 변이성을 발견하면, 향후 연구에서 노래의 그 부분에 집중할 수 있다.</span> > In other words, if the terminal phrase shows the greatest inconsistency, recordings can be edited to single it out for comparisons. <span class=\"translation\">다시 말해서, 만약 마지막 구문이 가장 큰 불일치성을 보인다면, 녹음을 편집하여 비교를 위해 그것만 따로 분리할 수 있다.</span> > Most white-crowned sparrow songs begin similarly with one or two whistles; consequently, the initial sequence is generally the most consistent component across subgroups. <span class=\"translation\">대부분의 흰관찰찌새 노래는 하나 또는 두 개의 휘파람으로 비슷하게 시작한다. 결과적으로, 초기 순서는 일반적으로 아종들 간에 가장 일관된 구성 요소이다.</span> > In addition, a convenient feature of male white-crowned sparrows is that individual adults generally sing a single song, making analysis across groups a relatively simple task in comparison to other bird species that routinely learn multiple songs, such as song sparrows (Melospiza melodia). <span class=\"translation\">또한, 수컷 흰관찰찌새의 편리한 특징 중 하나는 개별 성체가 일반적으로 하나의 노래만 부른다는 것으로, 이는 여러 노래를 정기적으로 배우는 노래찌새(Melospiza melodia)와 같은 다른 조류 종에 비해 집단 간 분석을 상대적으로 간단한 작업으로 만든다.</span> </div> Paragraph 4 <button class=\"toggle-button translations\" data-type=\"paragraph4\">🔍 AI 해석 가리기</button> <div class=\"paragraph4-content\"> > Variations present among groups led some scientists to wonder whether there might be a genetic basis for dialectical uniqueness. <span class=\"translation\">집단들 간에 존재하는 변이들은 일부 과학자들이 방언적 고유성에 유전자적인 기저가 있는지 궁금하게 했다.</span> > Perhaps through the evolutionary isolation of some populations (for example, female preference for males of their own dialect), dispersal of the gene pool has been slowed to the point that differences in song reflect expressions of varying genetic compositions. <span class=\"translation\">아마도 일부 개체군의 진화적 격리를 통해 (예를 들어, 암컷이 자신의 방언을 가진 수컷을 선호하는 것), 유전자 풀의 분산이 느려져서 노래의 차이가 다양한 유전적 구성의 표현을 반영하게 되었을 것이다.</span> > Though a genetic explanation seems plausible, laboratory experiments have found that white-crowned sparrow chicks of particular dialect groups can learn the songs of other groups in their own subspecies in addition to dialects of other subspecies. <span class=\"translation\">유전자적 해석이 말이 플러서블 하다고 볼 수도 있지만, 실험에서 하얀 군중 까마귀는 다른 아종의 노래나 방언을 배울 수 있다.</span> > Using recordings of adults, scientists have been able to train fledglings to reproduce multiple dialects, although the maximum number is approximately seven. <span class=\"translation\">성체의 녹음을 사용하여, 과학자들은 어린 새들이 여러 방언을 재현하도록 훈련시킬 수 있었는데, 최대 개수는 약 7개였다.</span> > In addition, comparisons of genetic material taken from blood sample DNA have revealed unsubstantial differences. <span class=\"translation\">또한, 혈액 샘플 DNA에서 추출한 유전 물질의 비교는 실질적이지 않은 차이를 보여주었다.</span> > In some instances, genetic variation among individuals of a dialect group was found to be greater than genetic variation among larger groups, such as subspecies. <span class=\"translation\">어떤 경우에는, 방언 집단 내 개체들 간의 유전적 변이가 아종과 같은 더 큰 집단들 간의 유전적 변이보다 더 큰 것으로 밝혀졌다.</span> </div> Paragraph 5 <button class=\"toggle-button translations\" data-type=\"paragraph5\">🔍 AI 해석 가리기</button> <div class=\"paragraph5-content\"> > If genetic differences are insignificant in comparison to cultural influences, why do sparrows with overlapping territories sing only one song in the field? <span class=\"translation\">만약 유전적 차이가 문화적 영향에 비해 중요하지 않다면, 왜 겹치는 영역을 가진 참새들은 야생에서 단 하나의 노래만 부르는가?</span> > Some, such as those of the sedentary subspecies known as Nuttall's sparrow, do encounter other dialect groups. <span class=\"translation\">일부는, 너탈 참새로 알려진 정주성 아종 같은 경우, 다른 방언 그룹과 마주친다.</span> > Gambell's sparrow, a migratory subspecies, overwinters in the coastal California area that Nuttall's sparrow inhabits. <span class=\"translation\">감벨 참새는, 이동성 아종으로, 너탈 참새가 서식하는 캘리포니아 연안 지역에서 월동한다.</span> > Interestingly, despite contacts between October and March with Gambell's sparrow, male Nuttall's sparrows typically sing their own distinct songs. <span class=\"translation\">흥미롭게도, 10월과 3월 사이에 감벨 참새와 접촉함에도 불구하고, 수컷 너탈 참새들은 일반적으로 자신들만의 독특한 노래를 부른다.</span> > This is because the encounters between the two subspecies occur outside the primary song crystallization period, which occurs during the first two months of a bird's life. <span class=\"translation\">이것은 두 아종 간의 만남이 주요 노래 결정화 기간 밖에서 일어나기 때문인데, 이 기간은 새의 생후 첫 두 달 동안 발생한다.</span> </div> Paragraph 6 <button class=\"toggle-button translations\" data-type=\"paragraph6\">🔍 AI 해석 가리기</button> <div class=\"paragraph6-content\"> > Detailed field research led to the discovery that some exceptional members of the species do master multiple songs, but their knowledge acquisition is contingent on contact with other groups in one of two ways. <span class=\"translation\">상세한 현장 연구는 이 종의 일부 예외적인 구성원들이 여러 노래를 숙달한다는 것을 발견했지만, 그들의 지식 습득은 두 가지 방법 중 하나로 다른 집단과의 접촉에 달려있다.</span> > Either young birds come in contact with migratory subspecies during the formative period of language learning or they live on the margins of dialect borders. <span class=\"translation\">어린 새들이 언어 학습의 형성 기간 동안 이동성 아종과 접촉하거나, 방언 경계의 가장자리에 살고 있다.</span> > Nuttall's sparrows hatching early or late in the season are more likely to be exposed to Gambell's sparrows, but broods hatching after March or before October will mostly only interact with other members of their own kind. <span class=\"translation\">계절에 일찍 또는 늦게 부화하는 Nuttall's sparrow들은 Gambell's sparrow들에 노출될 가능성이 더 높지만, 3월 이후 또는 10월 이전에 부화하는 새끼들은 대부분 자신의 종류의 다른 구성원들과만 상호작용할 것이다.</span> > In like fashion, individuals living near the peripheries of their dialectic range may regularly hear the songs of an adjacent group and develop multilingual abilities. <span class=\"translation\">같은 방식으로, 방언 범위의 주변에 사는 개체들은 인접한 집단의 노래를 정기적으로 듣고 다언어 능력을 개발할 수 있다.</span> </div> Paragraph 7 <button class=\"toggle-button translations\" data-type=\"paragraph7\">🔍 AI 해석 가리기</button> <div class=\"paragraph7-content\"> > In light of these findings, most scientists have concluded that geographic differences may mildly restrict gene flow, but that genetic isolation has not been strong enough to create a rigid linguistic barrier. <span class=\"translation\">이러한 발견을 바탕으로, 대부분의 과학자들은 지리적 차이가 유전자 흐름을 약간 제한할 수 있지만, 유전적 격리가 엄격한 언어적 장벽을 만들 만큼 충분히 강하지 않았다고 결론지었다.</span> > Dialectical variety in birds can thus be viewed as primarily a cultural phenomenon. <span class=\"translation\">따라서 새들의 방언적 다양성은 주로 문화적 현상으로 볼 수 있다.</span> </div> --- 📚 핵심 단어 사전 <button class=\"toggle-button vocabulary\" data-type=\"vocabulary\">🔍 단어 뜻 가리기</button> <div class=\"vocabulary-content\"> 🐦 조류학 관련 용어 avian vocalization <span class=\"meaning\">(조류의 발성) - 새가 내는 소리</span> birdsong <span class=\"meaning\">(새의 노래) - 새가 부르는 복잡한 소리</span> dialect <span class=\"meaning\">(방언) - 지리적 경계에 따른 노래의 차이</span> phrase <span class=\"meaning\">(구문) - 노래의 구성 단위</span> syllable <span class=\"meaning\">(음절) - 구문의 개별 발화 부분</span> whistle <span class=\"meaning\">(휘파람) - 새가 내는 소리 유형</span> pulse <span class=\"meaning\">(펄스) - 새가 내는 소리 유형</span> buzz <span class=\"meaning\">(윙윙거리는 소리) - 새가 내는 소리 유형</span> 🧬 유전학 관련 용어 gene pool <span class=\"meaning\">(유전자 풀) - 집단의 전체 유전적 다양성</span> genetic isolation <span class=\"meaning\">(유전적 격리) - 유전자 교환의 차단</span> subspecies <span class=\"meaning\">(아종) - 종의 하위 분류</span> genetic variation <span class=\"meaning\">(유전적 변이) - 유전적 차이</span> gene flow <span class=\"meaning\">(유전자 흐름) - 집단 간 유전자 교환</span> 🕐 시간 관련 용어 formative period <span class=\"meaning\">(형성 기간) - 학습이 이루어지는 중요한 시기</span> song crystallization period <span class=\"meaning\">(노래 결정화 기간) - 생후 2개월의 핵심 학습 시기</span> overwinter <span class=\"meaning\">(월동하다) - 겨울을 나다</span> 🗺️ 지리 관련 용어 geographical boundaries <span class=\"meaning\">(지리적 경계) - 지역적 한계</span> overlapping territories <span class=\"meaning\">(겹치는 영역) - 서로 겹치는 서식지</span> sedentary <span class=\"meaning\">(정주성) - 한 곳에 머무르는</span> migratory <span class=\"meaning\">(이동성) - 계절에 따라 이동하는</span> peripheries <span class=\"meaning\">(주변부) - 가장자리 지역</span> </div> --- 💬 유용한 영어 표현들 <button class=\"toggle-button expressions\" data-type=\"expressions\">🔍 표현 뜻 가리기</button> <div class=\"expressions-content\"> 🔬 연구/실험 관련 표현 in this regard <span class=\"meaning\">(이와 관련하여) - \"One of the best-studied songbirds in this regard is...\"</span> led to the discovery <span class=\"meaning\">(발견으로 이어졌다) - \"Detailed field research led to the discovery that...\"</span> have been able to <span class=\"meaning\">(할 수 있었다) - \"Scientists have been able to train fledglings...\"</span> have found that <span class=\"meaning\">(발견했다) - \"Laboratory experiments have found that...\"</span> have revealed <span class=\"meaning\">(보여주었다) - \"Comparisons have revealed unsubstantial differences.\"</span> 📊 비교/대조 표현 in comparison to <span class=\"meaning\">(비교했을 때) - \"If genetic differences are insignificant in comparison to cultural influences...\"</span> in addition <span class=\"meaning\">(또한) - \"In addition, a convenient feature...\"</span> though <span class=\"meaning\">(비록...하지만) - \"Though a genetic explanation seems plausible...\"</span> despite <span class=\"meaning\">(에도 불구하고) - \"Despite contacts between October and March...\"</span> in light of <span class=\"meaning\">(을 바탕으로) - \"In light of these findings...\"</span> ⏰ 시간/순서 표현 from an early age <span class=\"meaning\">(어린 나이부터) - \"Birds learn from an early age.\"</span> during <span class=\"meaning\">(동안) - \"Produced primarily during breeding.\"</span> between <span class=\"meaning\">(사이에) - \"Between October and March.\"</span> after/before <span class=\"meaning\">(이후/이전) - \"After March or before October.\"</span> once <span class=\"meaning\">(일단...하면) - \"Once scientists detect variability...\"</span> 🎯 강조/설명 표현 in other words <span class=\"meaning\">(다시 말해서) - \"In other words, if the terminal phrase...\"</span> for example <span class=\"meaning\">(예를 들어) - \"For example, female preference for males...\"</span> such as <span class=\"meaning\">(같은) - \"Such as song sparrows.\"</span> in like fashion <span class=\"meaning\">(같은 방식으로) - \"In like fashion, individuals living near...\"</span> thus <span class=\"meaning\">(따라서) - \"Dialectical variety can thus be viewed as...\"</span> 🔍 조건/가정 표현 in cases where <span class=\"meaning\">(인 경우에) - \"In cases where populations have geographical boundaries...\"</span> if <span class=\"meaning\">(만약) - \"If these geographical limits are distinct...\"</span> whether <span class=\"meaning\">(인지 아닌지) - \"Whether there might be a genetic basis...\"</span> perhaps <span class=\"meaning\">(아마도) - \"Perhaps through the evolutionary isolation...\"</span> may <span class=\"meaning\">(할 수 있다) - \"Geographic differences may mildly restrict gene flow.\"</span> 📝 학술적 표현 referred to as <span class=\"meaning\">(라고 불린다) - \"Are referred to as dialects.\"</span> keenly interested in <span class=\"meaning\">(에 깊은 관심을 가지고 있다) - \"Ornithologists are keenly interested in...\"</span> make sense of <span class=\"meaning\">(이해하다) - \"In order to make sense of birdsongs...\"</span> contingent on <span class=\"meaning\">(에 달려있다) - \"Knowledge acquisition is contingent on contact...\"</span> concluded that <span class=\"meaning\">(라고 결론지었다) - \"Scientists have concluded that...\"</span> </div> 문제풀이 TOEFL Reading Comprehension Questions Question 1 The word \"primarily\" in the passage is closest in meaning to (A) abundantly (B) mainly (C) loudly (D) commonly <button class=\"toggle-button answer\" data-type=\"answer1\">🔍 정답 및 해설 가리기</button> <div class=\"answer1-content\"> 정답: (B) mainly 해설: \"primarily\"는 \"주로, 주된\"이라는 뜻으로 사용됩니다. 지문에서 \"produced primarily during breeding\"은 \"번식기에 주로 발생하는\"이라는 의미입니다. (A) abundantly: 풍부하게 - 양적 의미 (B) mainly: 주로 - 주된 목적이나 시기를 나타냄 (C) loudly: 크게 - 소리의 크기 (D) commonly: 흔히 - 빈도의 의미 </div> Question 2 Which of the sentences below best expresses the essential information in the highlighted sentence in the passage? Incorrect choices change the meaning in important ways or leave out essential information. 원문: \"In cases where populations have geographical boundaries, differences in song may appear, and if these geographical limits are distinct, the shared song types within a population are referred to as dialects.\" (A) Dialects are those song types within a population that are shared by the group. (B) Shared song types within a population with clear geographical boundaries are called dialects. (C) Geographical boundaries may result in differences in song between distinct populations. (D) Populations having clear dialects result from the shared song types within the group. <button class=\"toggle-button answer\" data-type=\"answer2\">🔍 정답 및 해설 가리기</button> <div class=\"answer2-content\"> 정답: (B) Shared song types within a population with clear geographical boundaries are called dialects. 해설: 원문의 핵심 정보는 다음과 같습니다: 지리적 경계가 있는 개체군에서는 노래의 차이가 나타날 수 있다 이러한 지리적 한계가 뚜렷하면, 개체군 내에서 공유되는 노래 유형을 방언이라고 부른다 (A) 방언의 정의만 포함, 지리적 경계 조건 누락 (B) 지리적 경계와 공유된 노래 유형이 방언이라는 핵심 정보 모두 포함 (C) 지리적 경계가 차이를 만든다는 부분만, 방언의 정의 누락 (D) 인과관계가 잘못됨 (방언이 개체군을 만드는 것이 아님) </div> Question 3 According to paragraph 2, scientists attempt to understand birdsongs by (A) dividing them into smaller categories (B) analyzing them as a single unit (C) listening to phrases in reverse order (D) labeling them as male or female <button class=\"toggle-button answer\" data-type=\"answer3\">🔍 정답 및 해설 가리기</button> <div class=\"answer3-content\"> 정답: (A) dividing them into smaller categories 해설: 2단락에서 \"In order to make sense of birdsongs, scientists break them into smaller units\"라고 명시되어 있습니다. 과학자들은 새의 노래를 이해하기 위해 더 작은 단위로 나눈다고 설명하고 있습니다. 구체적으로: 노래(song) → 구문(phrase) → 음절(syllables)로 세분화 휘파람, 펄스, 윙윙거리는 소리 등 특정 소리 유형으로 분류 이는 \"더 작은 범주로 나누는 것\"과 정확히 일치합니다. </div> Question 4 What can be inferred from paragraph 4 about white-crowned sparrow chicks? (A) The simplest dialects are the ones they learn first. (B) The number of songs they can be trained to learn is limited. (C) They learn songs of their own subspecies faster than those of other subspecies. (D) They learn more easily from laboratory recordings than in the wild. <button class=\"toggle-button answer\" data-type=\"answer4\">🔍 정답 및 해설 가리기</button> <div class=\"answer4-content\"> 정답: (B) The number of songs they can be trained to learn is limited. 해설: 4단락에서 \"Using recordings of adults, scientists have been able to train fledglings to reproduce multiple dialects, although the maximum number is approximately seven\"라고 명시되어 있습니다. 과학자들이 어린 새들을 훈련시켜 여러 방언을 재현하게 할 수 있었지만, 최대 개수는 약 7개라고 한정되어 있습니다. 이는 학습할 수 있는 노래의 수가 제한적임을 보여줍니다. (A) 가장 간단한 방언을 먼저 배운다는 언급 없음 (C) 자신의 아종 노래를 더 빨리 배운다는 언급 없음 (D) 실험실 녹음으로 더 쉽게 배운다는 비교 없음 </div> Question 5 According to paragraph 5, which of the following is true of Nuttall's sparrows? (A) They migrate to the same overwintering locations that Gambell's sparrows do. (B) They do not often encounter Gambell's sparrows during the initial period of song formation. (C) They only have contact with Gambell's sparrows during the breeding season. (D) They do not have the same inherent vocalization abilities that Gambell's sparrows do. <button class=\"toggle-button answer\" data-type=\"answer5\">🔍 정답 및 해설 가리기</button> <div class=\"answer5-content\"> 정답: (B) They do not often encounter Gambell's sparrows during the initial period of song formation. 해설: 5단락에서 핵심 정보: Nuttall's sparrow는 정주성(sedentary) 아종 Gambell's sparrow는 이동성(migratory) 아종으로 10월~3월에 Nuttall's 서식지에서 월동 \"This is because the encounters between the two subspecies occur outside the primary song crystallization period, which occurs during the first two months of a bird's life\" 즉, 두 아종의 만남은 주요 노래 결정화 기간(생후 첫 2개월) 밖에서 일어나기 때문에, Nuttall's sparrow는 노래 형성 초기에 Gambell's sparrow와 자주 마주치지 않습니다. (A) Nuttall's는 이동하지 않음 (sedentary) (C) 10월~3월에 접촉 (번식기가 아님) (D) 발성 능력의 차이에 대한 언급 없음 </div> Question 6 The word \"exceptional\" in the passage is closest in meaning to (A) extraordinary (B) perceptual (C) intelligent (D) capable <button class=\"toggle-button answer\" data-type=\"answer6\">🔍 정답 및 해설 가리기</button> <div class=\"answer6-content\"> 정답: (A) extraordinary 해설: 6단락에서 \"some exceptional members of the species do master multiple songs\"라고 사용되었습니다. 문맥상 대부분의 개체들은 하나의 노래만 부르는데, 일부 예외적인 구성원들은 여러 노래를 숙달한다는 의미입니다. (A) extraordinary: 특별한, 예외적인 (B) perceptual: 지각의, 인식의 (C) intelligent: 지능적인 (D) capable: 능력있는 \"exceptional\"은 \"일반적이지 않은, 특별한\"이라는 뜻으로 \"extraordinary\"와 가장 의미가 가깝습니다. </div> Question 7 According to paragraph 6, which of the following does NOT contribute to multilingualism in Nuttall's sparrows? (A) Living on the edges of dialectical boundaries (B) Interacting with other subspecies (C) Hatching early or late in the season (D) Mating between March and October ✓ <button class=\"toggle-button answer\" data-type=\"answer7\">🔍 정답 및 해설 가리기</button> <div class=\"answer7-content\"> 정답: (D) Mating between March and October 해설: 6단락에서 다언어 능력에 기여하는 요인들: 기여하는 것들: (A) 방언 경계의 가장자리에 거주: \"individuals living near the peripheries of their dialectic range may regularly hear the songs of an adjacent group\" (B) 다른 아종과의 상호작용: \"young birds come in contact with migratory subspecies during the formative period\" (C) 계절 초기나 말기에 부화: \"Nuttall's sparrows hatching early or late in the season are more likely to be exposed to Gambell's sparrows\" 기여하지 않는 것: (D) 3월~10월 사이의 짝짓기: 지문에서 언급되지 않았으며, 오히려 \"broods hatching after March or before October will mostly only interact with other members of their own kind\"라고 하여 이 시기에 부화하는 새끼들은 자신의 종류와만 상호작용한다고 명시 </div> Question 8 Why does the author include paragraph 7 in the passage? (A) To argue that genetic factors have nothing to do with linguistic ability in birds (B) To offer a concluding argument for why birds have a variety of dialects (C) To introduce a new issue that has emerged in research on bird dialects (D) To suggest that language acquisition in birds is still poorly understood <button class=\"toggle-button answer\" data-type=\"answer8\">🔍 정답 및 해설 가리기</button> <div class=\"answer8-content\"> 정답: (B) To offer a concluding argument for why birds have a variety of dialects 해설: 7단락은 전체 지문의 결론 단락입니다: \"In light of these findings, most scientists have concluded that geographic differences may mildly restrict gene flow, but that genetic isolation has not been strong enough to create a rigid linguistic barrier. Dialectical variety in birds can thus be viewed as primarily a cultural phenomenon.\" 이 단락에서 저자는: 앞서 제시된 연구 결과들을 종합 유전적 격리보다는 문화적 요인이 더 중요하다고 결론 새들의 방언적 다양성이 주로 문화적 현상이라는 최종 답을 제시 이는 새들이 왜 다양한 방언을 가지게 되는지에 대한 결론적 주장을 제공하는 것입니다. (A) 유전적 요인이 전혀 관련없다고 주장하지 않음 (mildly restrict라고 인정) (C) 새로운 이슈를 소개하는 것이 아님 (D) 언어 습득이 잘 이해되지 않는다고 제시하지 않음 </div> Question 9 Look at the four squares [■] that indicate where the following sentence could be added to the passage. Single adult males of this species have been recorded singing eleven different songs. Where would the sentence best fit? <button class=\"toggle-button answer\" data-type=\"answer9\">🔍 정답 및 해설 가리기</button> <div class=\"answer9-content\"> 적절한 위치: Paragraph 6의 첫 번째 문장 뒤 해설: 삽입할 문장: \"Single adult males of this species have been recorded singing eleven different songs.\" (이 종의 성체 수컷 개체들이 11개의 서로 다른 노래를 부르는 것이 기록되었다.) 가장 적절한 위치는 6단락 첫 문장 뒤입니다: \"Detailed field research led to the discovery that some exceptional members of the species do master multiple songs, but their knowledge acquisition is contingent on contact with other groups in one of two ways. [■ 여기] Either young birds come in contact with migratory subspecies...\" 이유: 논리적 연결: 앞 문장에서 \"일부 예외적인 구성원들이 여러 노래를 숙달한다\"고 하고, 삽입 문장은 그 구체적인 예시(11개 노래)를 제공 구체적 증거: \"some exceptional members\"의 구체적인 사례 문맥의 일관성: 다언어 능력에 대한 논의가 이어지는 자연스러운 위치 다른 위치들은 문맥상 맞지 않습니다. </div> Question 10 Directions: An introductory sentence for a brief summary of the passage is provided below. Complete the summary by selecting the THREE answer choices that express the most important ideas in the passage. Some sentences do not belong in the summary because they express ideas that are not presented in the passage or are minor ideas in the passage. This question is worth 2 points. In some bird populations, there are regional dialects in the birds' songs. Answer Choices: (A) White-crowned sparrows are useful subjects for studying bird dialects because they usually only learn a single song and have many dialects. (B) Using recordings in a laboratory setting, scientists have demonstrated that white-crowned sparrow chicks are capable of learning multiple dialects. (C) Research conducted on Nuttall's sparrows and Gambell's sparrows suggests that the two subspecies have developed different dialects because one is sedentary while the other is migratory. (D) Scientists thought that genetic factors may have contributed to dialectical diversity, but research has shown that genetic factors are limited. (E) Field studies of two Zonotrichia leucophrys subspecies revealed that multilingualism is dependent upon the timing and nature of interactions between dialectical group members. (F) One thing that is clear about the various subspecies of Zonotrichia leucophrys is that they all seem to begin learning songs for the first time after two months of age. <button class=\"toggle-button answer\" data-type=\"answer10\">🔍 정답 및 해설 가리기</button> <div class=\"answer10-content\"> 정답: (A), (B), (D) 해설: 선택된 답안들: (A) White-crowned sparrows are useful subjects for studying bird dialects because they usually only learn a single song and have many dialects. ✓ 1단락: \"One of the best-studied songbirds... is the white-crowned sparrow\" 3단락: \"individual adults generally sing a single song\" 연구 대상으로서의 유용성이 주요 주제 (B) Using recordings in a laboratory setting, scientists have demonstrated that white-crowned sparrow chicks are capable of learning multiple dialects. ✓ 4단락: \"Using recordings of adults, scientists have been able to train fledglings to reproduce multiple dialects\" 실험실 연구의 중요한 발견 (D) Scientists thought that genetic factors may have contributed to dialectical diversity, but research has shown that genetic factors are limited. ✓ 4단락: 유전적 설명이 그럴듯해 보였지만 7단락: \"genetic isolation has not been strong enough... primarily a cultural phenomenon\" 지문의 핵심 결론 제외된 답안들: (C) 정주성/이동성의 차이가 방언 발달의 원인이라고 제시하지 않음 (E) 다언어 능력은 부차적 주제 (F) 2개월 후에 학습을 시작한다는 내용 없음 (오히려 첫 2개월이 중요한 시기) </div>"
  },
  {
    "id": "Self_Development/English Study/SPEAK/지나간달/07-14-걱정하는표현",
    "title": "걱정하는 표현",
    "date": "2025-07-14",
    "excerpt": "",
    "category": "English Study",
    "tags": [
      "영어공부꾸준히!",
      "SPEAK",
      "칭찬하는 표현들"
    ],
    "content": "배운 것들 worried love life : 연애 사업 I'm worried about my love life. worry about : (항상) ~를 걱정해 I worry about my future. 'm worried about : (요즘) 걱정 돼 I'm worried about my love life. I'm worried about my job interview. I'm worried about the traffic. 차가 막힐까바ㅗ I'm worried about my presentation tommorow. 조금 걱정된다 I'm a little worried about 엄청 걱정된다 I'm really worried about 신경쓰인다 I'm concerned about the new flu virus. I'm concerned about the news lately. travel ban What are some things that are on your mind? as well , 나도 간단한 작문 Nowadays, I'm worried about my future of career. 내가 시장 가치가 있을지? 다른 회사에 갈 수 있을지?에 대해 고민을 하고 있어. I'm preparing the job transition, but if fails in the resume screening. So I can believe my self. 앞으로 더 나아질지. My 연봉 can be better than now? I have a some concerns, but what I have to do or I can to is just focus on the today, just step ahead. So 호흡을 가다듬고, 현재에 집중하려고 노력한다. 수정된 영어 글 Nowadays, I'm worried about my career path. I keep wondering if I'm competitive enough in the job market to move to another company. I'm preparing for a job transition, but I'm afraid of failing at the resume screening stage. It makes me doubt myself and wonder if I can actually improve from here. I also question if I can earn a better salary than I do now. Even with these concerns, I know that all I can really do is focus on today and take things one step at a time. So, I'm trying to take a deep breath and concentrate on the present. 피드백 및 해설 my future of career → my career path 피드백: career는 이미 미래의 길(path)이라는 뉘앙스를 포함하고 있어요. my career path (나의 커리어 경로) 또는 my future career (나의 미래 커리어)라고 표현하는 것이 훨씬 자연스러워요. 예시: \"I need some advice on my career path.\" (제 커리어 경로에 대해 조언이 필요해요.) if fails in the resume screening → I'm afraid of failing at the resume screening stage 피드백: 원래 문장은 \"만약 서류 심사에서 떨어지면\"이라는 조건절만 있어서 문법적으로 완전하지 않아요. \"서류 심사 단계에서 떨어지는 것이 두렵다\"는 의미로 I'm afraid of failing...과 같이 완전한 문장으로 만들어주었어요. 팁: afraid of + (동)명사는 \"~하는 것이 두렵다\"는 표현으로 자주 쓰여요. So I can believe my self → It makes me doubt myself 피드백: 문맥상 \"나 자신을 믿을 수 있을까?\"라며 스스로를 의심하는 의미로 해석돼요. doubt myself (나 자신을 의심하다)라는 표현이 더 명확하게 의미를 전달해요. 또한, myself는 항상 한 단어로 붙여 써야 합니다. 예시: \"Don't doubt yourself. You can do it!\" (스스로를 의심하지 마. 넌 할 수 있어!) My 연봉 can be better than now? → if I can earn a better salary than I do now 피드백: \"내 연봉이 지금보다 나아질 수 있을까?\"라는 질문을 if (~인지 아닌지)를 사용해 \"더 나은 연봉을 받을 수 있을지 궁금하다/의문이다\"는 의미로 자연스럽게 문장에 녹여냈어요. 예시: \"I wonder if I can finish this on time.\" (이걸 제시간에 끝낼 수 있을지 모르겠어.) I have a some concerns → Even with these concerns 피드백: a와 some은 함께 쓸 수 없어요. I have some concerns (몇 가지 걱정이 있다)가 맞습니다. 문맥의 흐름을 더 자연스럽게 하기 위해 \"이런 걱정에도 불구하고\"라는 의미의 Even with these concerns로 수정했어요. what I have to do or I can to is... → all I can really do is... 피드백: 원래 문장의 I can to는 문법적으로 틀린 표현이에요. I can do가 맞습니다. 의미를 살려서 \"내가 정말로 할 수 있는 모든 것은\"이라는 all I can really do is...로 다듬었어요. focus on the today, just step ahead → focus on today and take things one step at a time 피드백: today, yesterday, tomorrow 앞에는 보통 the를 붙이지 않아요. just step ahead도 좋은 표현이지만, \"차근차근 나아가다\"라는 의미를 더 잘 살리는 관용구인 take things one step at a time이 이런 상황에 아주 잘 어울려요."
  },
  {
    "id": "Data Science/dependency-injection-pattern",
    "title": "의존성 주입 패턴으로 코드 품질 향상하기",
    "date": "2025-07-14",
    "excerpt": "의존성 주입 패턴을 통해 코드의 결합도를 낮추고 테스트 용이성을 높이는 방법을 실제 예제와 함께 설명합니다.",
    "category": "Data Science",
    "tags": [
      "python",
      "design-pattern",
      "dependency-injection",
      "software-architecture",
      "clean-code",
      "testing"
    ],
    "content": "배경 최근에 대화형 AI 챗봇 프로젝트를 개발하면서 겪었던 코드 구조의 문제점들과, 이를 의존성 주입 패턴으로 개선한 경험을 정리해보았습니다. 프로젝트 상황 FastAPI 기반 웹 애플리케이션 OpenAI GPT 모델을 활용한 대화형 검색 시스템 ChromaDB를 사용한 벡터 검색 사용자별 대화 세션 관리 겪었던 문제점들 강한 결합 (Tight Coupling) 클래스들이 서로 너무 밀접하게 연결되어 있어서, 하나를 수정하면 다른 것들도 함께 수정해야 하는 상황이 발생했습니다. 하드코딩된 설정 모델명, 데이터베이스 경로, API 키 등이 코드에 직접 작성되어 있어서 환경별로 설정을 바꾸기 어려웠습니다. 테스트 어려움 각 컴포넌트를 독립적으로 테스트하기 어려워서, 전체 시스템을 실행해야만 테스트할 수 있었습니다. 관련 개념들 정리 강한 결합 (Tight Coupling) - 쉽게 이해하기 🏠 집 짓기 비유 강한 결합의 예시: ``python 문제가 있는 코드 - 강한 결합 class 집: def __init__(self): # 집이 직접 벽돌공장을 만들어서 벽돌을 가져옴 self.벽돌공장 = 벽돌공장() self.벽돌 = self.벽돌공장.벽돌만들기() # 집이 직접 목수공장을 만들어서 문을 가져옴 self.목수공장 = 목수공장() self.문 = self.목수공장.문만들기() ` 문제점: 집이 벽돌공장과 목수공장을 직접 알고 있어야 함 다른 재료(콘크리트, 알루미늄)로 바꾸려면 집 클래스를 수정해야 함 테스트할 때 진짜 공장 대신 가짜 공장을 사용하기 어려움 해결책 - 느슨한 결합: `python 개선된 코드 - 느슨한 결합 class 집: def __init__(self, 벽돌제공자, 문제공자): # 외부에서 벽돌과 문을 받아옴 self.벽돌 = 벽돌제공자.벽돌만들기() self.문 = 문제공자.문만들기() 사용할 때 집1 = 집(벽돌공장(), 목수공장()) 집2 = 집(콘크리트공장(), 알루미늄공장()) # 쉽게 바꿀 수 있음! ` 실제 코드 예시 `python 강한 결합 - 문제가 있는 코드 class ChatBot: def __init__(self): # 직접 의존성을 생성 self.llm = OpenAI(model=\"gpt-4\") # OpenAI에 강하게 결합 self.database = ChromaDB(path=\"./db\") # ChromaDB에 강하게 결합 self.scheduler = APScheduler() # APScheduler에 강하게 결합 느슨한 결합 - 개선된 코드 class ChatBot: def __init__(self, llm_provider, database, scheduler): # 외부에서 의존성을 주입받음 self.llm = llm_provider self.database = database self.scheduler = scheduler ` 하드코딩된 설정 - 왜 문제인가? 🍕 피자 주문 비유 하드코딩된 설정의 문제: `python 문제가 있는 코드 class 피자집: def __init__(self): self.토핑 = \"페퍼로니\" # 하드코딩! self.크기 = \"라지\" # 하드코딩! self.가격 = 20000 # 하드코딩! 모든 피자가 똑같이 나옴 😞 피자1 = 피자집() # 항상 페퍼로니 라지 20000원 피자2 = 피자집() # 항상 페퍼로니 라지 20000원 ` 개선된 코드: `python 설정 파일 사용 class 피자설정: def __init__(self): self.기본토핑 = \"페퍼로니\" self.기본크기 = \"라지\" self.기본가격 = 20000 class 피자집: def __init__(self, 설정): self.토핑 = 설정.기본토핑 self.크기 = 설정.기본크기 self.가격 = 설정.기본가격 환경별로 다른 설정 사용 가능 개발설정 = 피자설정() 개발설정.기본토핑 = \"치즈\" # 개발환경은 치즈 운영설정 = 피자설정() 운영설정.기본토핑 = \"페퍼로니\" # 운영환경은 페퍼로니 ` 실제 코드 예시 `python 하드코딩된 설정 - 문제가 있는 코드 class AI챗봇: def __init__(self): self.model = \"gpt-4o-mini-2024-07-18\" # 하드코딩! self.api_key = \"sk-1234567890abcdef\" # 하드코딩! self.db_path = \"./db/chroma_db\" # 하드코딩! 개선된 코드 - 설정 파일 사용 import os from pydantic import BaseSettings class Settings(BaseSettings): model: str = \"gpt-4o-mini-2024-07-18\" api_key: str = \"\" db_path: str = \"./db/chroma_db\" class Config: env_file = \".env\" # 환경변수 파일에서 읽어옴 class AI챗봇: def __init__(self, settings: Settings): self.model = settings.model self.api_key = settings.api_key self.db_path = settings.db_path 사용 settings = Settings() 챗봇 = AI챗봇(settings) ` 의존성 주입 (Dependency Injection) - 핵심 개념 🎯 의존성 주입이란? 의존성(Dependency): 객체가 동작하기 위해 필요한 다른 객체들 주입(Injection): 외부에서 그 객체들을 제공해주는 것 🚗 자동차 비유 `python 의존성 주입 없이 - 문제가 있는 코드 class 자동차: def __init__(self): # 자동차가 직접 엔진을 만듦 self.엔진 = 가솔린엔진() # 가솔린엔진에 강하게 결합 self.타이어 = 미쉐린타이어() # 미쉐린타이어에 강하게 결합 문제점: 전기차로 바꾸려면 자동차 클래스를 수정해야 함 테스트할 때 진짜 엔진 대신 가짜 엔진을 사용할 수 없음 다른 브랜드 타이어로 바꾸기 어려움 의존성 주입 사용 - 개선된 코드 class 자동차: def __init__(self, 엔진, 타이어): # 외부에서 엔진과 타이어를 받아옴 self.엔진 = 엔진 self.타이어 = 타이어 사용할 때 가솔린차 = 자동차(가솔린엔진(), 미쉐린타이어()) 전기차 = 자동차(전기엔진(), 한국타이어()) # 쉽게 바꿀 수 있음! 테스트할 때 테스트차 = 자동차(가짜엔진(), 가짜타이어()) # 가짜 부품으로 테스트 가능! ` 실제 코드 예시 `python 의존성 주입 없이 class ChatBot: def __init__(self): self.llm = OpenAI(model=\"gpt-4\") # 직접 생성 self.db = ChromaDB(path=\"./db\") # 직접 생성 의존성 주입 사용 class ChatBot: def __init__(self, llm_provider, database): self.llm = llm_provider # 외부에서 주입 self.database = database # 외부에서 주입 사용할 때 챗봇1 = ChatBot(OpenAI(model=\"gpt-4\"), ChromaDB(path=\"./db\")) 챗봇2 = ChatBot(Anthropic(model=\"claude\"), Pinecone(index=\"my-index\")) 테스트할 때 테스트챗봇 = ChatBot(MockLLM(), MockDatabase()) ` 팩토리 패턴 (Factory Pattern) - 객체 생산 공장 🏭 공장 비유 팩토리 패턴이란? 객체를 만드는 전용 공장을 따로 두는 패턴 `python 팩토리 없이 - 문제가 있는 코드 class 피자집: def __init__(self): # 피자집이 직접 재료를 준비 self.도우 = 밀가루도우() self.소스 = 토마토소스() self.치즈 = 모짜렐라치즈() 문제점: 피자집이 재료 준비 방법을 모두 알아야 함 팩토리 패턴 사용 - 개선된 코드 class 재료공장: def 도우만들기(self): return 밀가루도우() def 소스만들기(self): return 토마토소스() def 치즈만들기(self): return 모짜렐라치즈() class 피자집: def __init__(self, 재료공장): self.공장 = 재료공장 self.도우 = self.공장.도우만들기() self.소스 = self.공장.소스만들기() self.치즈 = self.공장.치즈만들기() 사용 공장 = 재료공장() 피자집 = 피자집(공장) ` 실제 코드 예시 `python LLM Factory class LLMFactory: def __init__(self, config): self.config = config def create_refine_llm(self): return OpenAI( model=self.config.get(\"refine_model\", \"gpt-4o-mini\"), api_key=self.config.get(\"api_key\") ) def create_answer_llm(self): return OpenAI( model=self.config.get(\"answer_model\", \"gpt-4o\"), api_key=self.config.get(\"api_key\") ) 사용 config = {\"refine_model\": \"gpt-4o-mini\", \"answer_model\": \"gpt-4o\"} factory = LLMFactory(config) refine_llm = factory.create_refine_llm() answer_llm = factory.create_answer_llm() ` 싱글톤 패턴 (Singleton Pattern) - 하나만 존재하는 객체 👑 왕 비유 싱글톤 패턴이란? 클래스의 인스턴스가 하나만 존재하도록 보장하는 패턴 `python 일반적인 클래스 - 여러 인스턴스 생성 가능 class 일반사람: def __init__(self, 이름): self.이름 = 이름 사람1 = 일반사람(\"김철수\") 사람2 = 일반사람(\"이영희\") print(사람1 is 사람2) # False - 다른 객체 싱글톤 패턴 - 하나만 존재 class 왕: _instance = None # 클래스 변수로 인스턴스 저장 def __new__(cls): if cls._instance is None: cls._instance = super().__new__(cls) cls._instance.이름 = \"현재왕\" return cls._instance 왕1 = 왕() 왕2 = 왕() print(왕1 is 왕2) # True - 같은 객체! ` 실제 코드 예시 `python 데이터베이스 연결 - 싱글톤 패턴 class DatabaseConnection: _instance = None def __new__(cls): if cls._instance is None: cls._instance = super().__new__(cls) cls._instance.connection = create_database_connection() return cls._instance def get_connection(self): return self.connection 사용 db1 = DatabaseConnection() db2 = DatabaseConnection() print(db1 is db2) # True - 같은 연결 객체 ` 프로토콜 (Protocol) - 인터페이스 정의 📋 계약서 비유 프로토콜이란? 객체가 어떤 메서드를 가져야 하는지 정의하는 \"계약서\" `python 프로토콜 없이 - 문제가 있는 코드 class ChatBot: def __init__(self, llm): self.llm = llm def 대화하기(self, 메시지): # llm이 generate 메서드를 가지고 있다고 가정 return self.llm.generate(메시지) # 런타임에 에러 가능! 문제점: llm 객체가 generate 메서드가 없으면 에러 발생 프로토콜 사용 - 개선된 코드 from typing import Protocol class LLMProvider(Protocol): \"\"\"LLM 제공자는 반드시 generate 메서드를 가져야 함\"\"\" def generate(self, message: str) -> str: ... class ChatBot: def __init__(self, llm: LLMProvider): # 타입 힌트로 검증 self.llm = llm def 대화하기(self, 메시지): return self.llm.generate(메시지) # 안전! 사용 class OpenAI: def generate(self, message: str) -> str: return f\"OpenAI: {message}\" class Anthropic: def generate(self, message: str) -> str: return f\"Anthropic: {message}\" 둘 다 LLMProvider 프로토콜을 만족하므로 사용 가능 챗봇1 = ChatBot(OpenAI()) 챗봇2 = ChatBot(Anthropic()) ` 실제 코드 예시 `python from typing import Protocol, List, Dict, Any class Retriever(Protocol): \"\"\"검색기 인터페이스\"\"\" def search(self, query: str, max_results: int) -> List[Dict[str, Any]]: \"\"\"쿼리로 문서를 검색\"\"\" ... class ChromaRetriever: def search(self, query: str, max_results: int) -> List[Dict[str, Any]]: # ChromaDB로 검색하는 실제 구현 return [{\"content\": \"검색된 문서\", \"score\": 0.9}] class PineconeRetriever: def search(self, query: str, max_results: int) -> List[Dict[str, Any]]: # Pinecone으로 검색하는 실제 구현 return [{\"content\": \"검색된 문서\", \"score\": 0.8}] 둘 다 Retriever 프로토콜을 만족하므로 같은 방식으로 사용 가능 def search_documents(retriever: Retriever, query: str): return retriever.search(query, max_results=5) 사용 chroma_results = search_documents(ChromaRetriever(), \"검색어\") pinecone_results = search_documents(PineconeRetriever(), \"검색어\") ` 의존성 주입 패턴으로 코드 품질 향상하기 개요 의존성 주입(Dependency Injection, DI)은 객체가 필요로 하는 의존성을 외부에서 제공받는 디자인 패턴입니다. 이 패턴을 통해 코드의 결합도를 낮추고, 테스트 용이성을 높이며, 유지보수성을 개선할 수 있습니다. 현재 코드의 문제점 강한 결합 (Tight Coupling) `python 문제가 있는 코드 예시 class MyApp: def __init__(self): self.app = FastAPI() # 직접 의존성 생성 - 강한 결합 self.retriever = ChromadbRetriever(\"./db/chroma_db\") self.scheduler = BackgroundScheduler(timezone=\"Asia/Seoul\") self.llm = LLM_openai(model=\"gpt-4o-mini-2024-07-18\") ` 문제점: 모든 의존성을 클래스 내부에서 직접 생성 다른 구현체로 교체하기 어려움 테스트 시 Mock 객체 주입 불가능 하드코딩된 설정 `python class ConversationalRetrievalChain: def __init__(self, retriever: ChromadbRetriever): # 하드코딩된 모델명들 self.refine_llm = LLM_openai(model=\"gpt-4o-mini-2024-07-18\", system_message=\"\") self.answer_llm = LLM_openai(model=\"gpt-4o-2024-05-13\", system_message=\"\") self.lang_detect_llm = LLM_openai(model=\"gpt-4o-mini-2024-07-18\", system_message=\"\") ` 문제점: 모델명이 코드에 하드코딩됨 환경별 설정 변경 어려움 설정 관리의 중앙화 부족 의존성 주입 패턴 적용 인터페이스 정의 (Protocol 사용) 먼저 의존성들의 인터페이스를 정의합니다: `python interfaces/llm_provider.py from typing import Protocol, List, Dict, Any class LLMProvider(Protocol): \"\"\"LLM 제공자 인터페이스\"\"\" def generate(self, user_message: str) -> str: \"\"\"단일 메시지 생성\"\"\" ... def generate_with_chat_history(self, history: List, user_message: str) -> str: \"\"\"채팅 히스토리와 함께 메시지 생성\"\"\" ... class Retriever(Protocol): \"\"\"검색기 인터페이스\"\"\" def get_docs_with_decomposition(self, query: str, max_k: int, threshold: float, lang: str) -> Dict[str, Any]: \"\"\"쿼리 분해를 통한 문서 검색\"\"\" ... class Scheduler(Protocol): \"\"\"스케줄러 인터페이스\"\"\" def add_job(self, func, trigger, kwargs): \"\"\"작업 추가\"\"\" ... def get_job(self, job_id: str): \"\"\"작업 조회\"\"\" ... def start(self): \"\"\"스케줄러 시작\"\"\" ... ` Factory 클래스들 생성 의존성 생성을 담당하는 Factory 클래스들을 만듭니다: `python factories/llm_factory.py from typing import Dict from utils.llm_providers import LLM_openai from interfaces.llm_provider import LLMProvider class LLMFactory: \"\"\"LLM 인스턴스 생성을 담당하는 Factory\"\"\" def __init__(self, config: Dict[str, str]): self.config = config def create_refine_llm(self) -> LLMProvider: \"\"\"정제용 LLM 생성\"\"\" return LLM_openai( model=self.config.get(\"refine_model\", \"gpt-4o-mini-2024-07-18\"), system_message=\"\" ) def create_answer_llm(self) -> LLMProvider: \"\"\"답변용 LLM 생성\"\"\" return LLM_openai( model=self.config.get(\"answer_model\", \"gpt-4o-2024-05-13\"), system_message=\"\" ) def create_lang_detect_llm(self) -> LLMProvider: \"\"\"언어 감지용 LLM 생성\"\"\" return LLM_openai( model=self.config.get(\"lang_detect_model\", \"gpt-4o-mini-2024-07-18\"), system_message=get_lang_detect_message(type=\"system\") ) factories/retriever_factory.py from chains.custom_retriever import ChromadbRetriever from interfaces.retriever import Retriever class RetrieverFactory: \"\"\"검색기 인스턴스 생성을 담당하는 Factory\"\"\" def __init__(self, db_path: str): self.db_path = db_path def create_retriever(self) -> Retriever: \"\"\"검색기 생성\"\"\" return ChromadbRetriever(self.db_path) ` 설정 관리 개선 중앙화된 설정 관리를 위해 Pydantic을 사용합니다: `python config/settings.py from pydantic import BaseSettings from typing import Dict class Settings(BaseSettings): \"\"\"애플리케이션 설정\"\"\" # LLM 설정 refine_model: str = \"gpt-4o-mini-2024-07-18\" answer_model: str = \"gpt-4o-2024-05-13\" lang_detect_model: str = \"gpt-4o-mini-2024-07-18\" # 데이터베이스 설정 chroma_db_path: str = \"./db/chroma_db\" # 스케줄러 설정 timezone: str = \"Asia/Seoul\" # API 설정 api_host: str = \"0.0.0.0\" api_port: int = 8000 class Config: env_file = \".env\" case_sensitive = False 전역 설정 인스턴스 settings = Settings() ` 의존성 컨테이너 생성 의존성들을 관리하는 컨테이너를 만듭니다: `python di/container.py from typing import Dict from fastapi import FastAPI from apscheduler.schedulers.background import BackgroundScheduler from factories.llm_factory import LLMFactory from factories.retriever_factory import RetrieverFactory from config.settings import settings class DependencyContainer: \"\"\"의존성 주입 컨테이너\"\"\" def __init__(self): self._services: Dict[str, object] = {} self._factories: Dict[str, object] = {} self._setup_factories() def _setup_factories(self): \"\"\"Factory 초기화\"\"\" self._factories[\"llm\"] = LLMFactory({ \"refine_model\": settings.refine_model, \"answer_model\": settings.answer_model, \"lang_detect_model\": settings.lang_detect_model }) self._factories[\"retriever\"] = RetrieverFactory(settings.chroma_db_path) def get_retriever(self): \"\"\"검색기 인스턴스 반환 (싱글톤 패턴)\"\"\" if \"retriever\" not in self._services: self._services[\"retriever\"] = self._factories[\"retriever\"].create_retriever() return self._services[\"retriever\"] def get_scheduler(self): \"\"\"스케줄러 인스턴스 반환 (싱글톤 패턴)\"\"\" if \"scheduler\" not in self._services: scheduler = BackgroundScheduler(timezone=settings.timezone) scheduler.start() self._services[\"scheduler\"] = scheduler return self._services[\"scheduler\"] def get_llm_factory(self): \"\"\"LLM Factory 반환\"\"\" return self._factories[\"llm\"] def reset(self): \"\"\"테스트용 리셋 메서드\"\"\" self._services.clear() 전역 컨테이너 인스턴스 container = DependencyContainer() ` 리팩토링된 MyApp 클래스 의존성 주입을 적용한 MyApp 클래스: `python app.py (리팩토링 후) from fastapi import FastAPI from di.container import container from interfaces.retriever import Retriever from interfaces.scheduler import Scheduler class MyApp: \"\"\"의존성 주입이 적용된 메인 애플리케이션 클래스\"\"\" def __init__(self, retriever: Retriever = None, scheduler: Scheduler = None): self.app = FastAPI() # 의존성 주입 self.retriever = retriever or container.get_retriever() self.scheduler = scheduler or container.get_scheduler() # 사용자별 세션 관리 self.user_conversations: Dict[str, ConversationalRetrievalChain] = {} # 구글 스프레드시트 연동 self.sheet = None self.setup_events() def setup_events(self): \"\"\"이벤트 설정\"\"\" select_sheet(self) self.scheduler.add_job( select_sheet, \"cron\", hour=0, minute=0, args=[self], id=\"create new sheet\" ) def get_conversation_chain(self, user_id: str) -> ConversationalRetrievalChain: \"\"\"사용자별 대화 체인 반환\"\"\" if user_id not in self.user_conversations: self.user_conversations[user_id] = ConversationalRetrievalChain( retriever=self.retriever ) return self.user_conversations[user_id] 테스트용 팩토리 함수 def create_app(retriever=None, scheduler=None) -> MyApp: \"\"\"애플리케이션 인스턴스 생성 (테스트용)\"\"\" return MyApp(retriever=retriever, scheduler=scheduler) 애플리케이션 인스턴스 생성 myapp = create_app() ` 리팩토링된 ConversationalRetrievalChain 클래스 의존성 주입을 적용한 체인 클래스: `python chains/main_chain.py (리팩토링 후) from interfaces.retriever import Retriever from factories.llm_factory import LLMFactory from di.container import container class ConversationalRetrievalChain: \"\"\"의존성 주입이 적용된 대화형 검색 체인\"\"\" def __init__(self, retriever: Retriever, llm_factory: LLMFactory = None): self.retriever = retriever # Factory를 통한 의존성 생성 factory = llm_factory or container.get_llm_factory() self.refine_llm = factory.create_refine_llm() self.answer_llm = factory.create_answer_llm() self.lang_detect_llm = factory.create_lang_detect_llm() # 체커 체인들 self.checker_runnable_executor = get_combined_checker_chain( model_name=settings.lang_detect_model ) self.checker_reservation_runnable_executor = get_combined_checker_chain_reservation( model_name=settings.lang_detect_model ) self.chat_history = [] def process_query(self, user_message: str, user_id: str) -> str: \"\"\"사용자 쿼리 처리\"\"\" # 언어 감지 detected_lang = self.detect_language(user_message) # 문서 검색 docs = self.retriever.get_docs_with_decomposition( query=user_message, max_k=5, threshold=0.7, lang=detected_lang ) # 답변 생성 response = self.generate_response(user_message, docs) # 히스토리 업데이트 self.update_chat_history(user_message, response) return response ` 테스트 용이성 향상 Mock 객체를 사용한 단위 테스트 `python tests/test_myapp.py import pytest from unittest.mock import Mock, MagicMock from app import create_app class TestMyApp: \"\"\"MyApp 클래스 테스트\"\"\" def test_app_initialization_with_mocks(self): \"\"\"Mock 객체를 사용한 초기화 테스트\"\"\" # Mock 객체 생성 mock_retriever = Mock() mock_scheduler = Mock() # 의존성 주입으로 앱 생성 app = create_app(retriever=mock_retriever, scheduler=mock_scheduler) # 검증 assert app.retriever == mock_retriever assert app.scheduler == mock_scheduler assert isinstance(app.app, FastAPI) def test_conversation_chain_creation(self): \"\"\"대화 체인 생성 테스트\"\"\" mock_retriever = Mock() app = create_app(retriever=mock_retriever) # 사용자별 체인 생성 chain = app.get_conversation_chain(\"user123\") assert chain is not None assert chain.retriever == mock_retriever tests/test_conversational_chain.py class TestConversationalRetrievalChain: \"\"\"ConversationalRetrievalChain 클래스 테스트\"\"\" def test_chain_initialization_with_mock_factory(self): \"\"\"Mock Factory를 사용한 초기화 테스트\"\"\" mock_retriever = Mock() mock_factory = Mock() # Mock LLM 인스턴스들 mock_refine_llm = Mock() mock_answer_llm = Mock() mock_lang_detect_llm = Mock() mock_factory.create_refine_llm.return_value = mock_refine_llm mock_factory.create_answer_llm.return_value = mock_answer_llm mock_factory.create_lang_detect_llm.return_value = mock_lang_detect_llm # 체인 생성 chain = ConversationalRetrievalChain( retriever=mock_retriever, llm_factory=mock_factory ) # 검증 assert chain.retriever == mock_retriever assert chain.refine_llm == mock_refine_llm assert chain.answer_llm == mock_answer_llm assert chain.lang_detect_llm == mock_lang_detect_llm ` 통합 테스트 `python tests/test_integration.py import pytest from di.container import container class TestIntegration: \"\"\"통합 테스트\"\"\" def setup_method(self): \"\"\"테스트 전 컨테이너 리셋\"\"\" container.reset() def test_container_dependency_resolution(self): \"\"\"컨테이너 의존성 해결 테스트\"\"\" retriever = container.get_retriever() scheduler = container.get_scheduler() llm_factory = container.get_llm_factory() assert retriever is not None assert scheduler is not None assert llm_factory is not None # 싱글톤 패턴 검증 retriever2 = container.get_retriever() assert retriever is retriever2 ` 환경별 설정 관리 환경 변수 설정 `bash .env.development REFINE_MODEL=gpt-4o-mini-2024-07-18 ANSWER_MODEL=gpt-4o-2024-05-13 LANG_DETECT_MODEL=gpt-4o-mini-2024-07-18 CHROMA_DB_PATH=./db/chroma_db_dev TIMEZONE=Asia/Seoul API_HOST=0.0.0.0 API_PORT=8000 ` `bash .env.production REFINE_MODEL=gpt-4o-2024-05-13 ANSWER_MODEL=gpt-4o-2024-05-13 LANG_DETECT_MODEL=gpt-4o-mini-2024-07-18 CHROMA_DB_PATH=/data/chroma_db_prod TIMEZONE=Asia/Seoul API_HOST=0.0.0.0 API_PORT=80 ` 설정 로딩 개선 `python config/settings.py (개선된 버전) import os from pydantic import BaseSettings from typing import Dict class Settings(BaseSettings): \"\"\"환경별 설정 관리\"\"\" # 환경 설정 environment: str = \"development\" # LLM 설정 refine_model: str = \"gpt-4o-mini-2024-07-18\" answer_model: str = \"gpt-4o-2024-05-13\" lang_detect_model: str = \"gpt-4o-mini-2024-07-18\" # 데이터베이스 설정 chroma_db_path: str = \"./db/chroma_db\" # 스케줄러 설정 timezone: str = \"Asia/Seoul\" # API 설정 api_host: str = \"0.0.0.0\" api_port: int = 8000 class Config: env_file = f\".env.{os.getenv('ENVIRONMENT', 'development')}\" case_sensitive = False settings = Settings() `` 장점과 효과 테스트 용이성 Mock 객체를 쉽게 주입할 수 있음 단위 테스트와 통합 테스트 분리 가능 테스트 격리 보장 유연성 런타임에 다른 구현체로 교체 가능 새로운 LLM 제공자 추가 용이 설정 변경 시 코드 수정 불필요 유지보수성 중앙화된 설정 관리 명확한 의존성 관계 단일 책임 원칙 준수 확장성 새로운 기능 추가 시 기존 코드 영향 최소화 플러그인 아키텍처 구현 가능 마이크로서비스 전환 용이 결론 의존성 주입 패턴을 적용함으로써 코드의 품질을 크게 향상시킬 수 있습니다. 특히: 결합도 감소: 클래스 간의 의존성이 명시적으로 관리됨 테스트 용이성: Mock 객체 주입으로 격리된 테스트 가능 설정 관리: 중앙화된 설정으로 환경별 관리 용이 확장성**: 새로운 기능 추가 시 기존 코드 영향 최소화 이러한 패턴은 대규모 프로젝트에서 특히 유용하며, 코드의 장기적인 유지보수성을 보장합니다. 참고 자료 Python Protocol Classes Pydantic Settings Management FastAPI Dependency Injection Clean Architecture by Robert C. Martin"
  },
  {
    "id": "Data Science/Causal Inference/Industry Application/why-we-need-causal-inference",
    "title": "인과 추론 도입배경",
    "date": "2025-07-14",
    "excerpt": "인과추론을 왜 사용해야하는지 설명하고 이를 도입하기 위해 설득하는 글",
    "category": "Causal Inference",
    "tags": [
      "ICL-Lenze-sizing"
    ],
    "content": "Abstract - 배경, 요약 --- 환자에게 렌즈 삽입술을 위한 최적의 렌즈 사이즈를 추천하는, 렌즈 사이징 문제는 예측 모델을 고도화하는 방향으로 연구가 진행되어왔다. 환자의 눈의 조건과 삽입한 렌즈 사이즈를 입력 받아 수술결과(vaulting, 렌즈 후면과 수정체 전면까지의 거리)를 예측하는 모델을 개발하고, 이 모델의 예측값을 통해 최적의 렌즈 사이즈를 제안하는 방식이다. 하지만 기존 예측 모델은 한계점이 존재한다. 이번 보고서를 통해 기존 예측 모델의 한계점을 분석하고 이를 해결하기 위한 방법을 제안한다. 기존 예측 모델의 한계점을 요약하면 렌즈 사이즈가 결과에 영향을 주는 인과적인 영향도를 추정하지 못하며, 단순히 예측 평가지표만을 고려하고 있어 추천의 신뢰도를 보장하지 못한다는 것이다. 이러한 한계점을 극복하기 위해 인과추론 방법론을 도입할 것을 제안한다. 이때 기대되는 효과는 다음과 같다. 개인화된 처치 효과를 추정할 수 있고 이를 통해 개인화된 최적의 렌즈 사이즈를 제안할 수 있다. 그리고 측정되지 않은 데이터에 대한 평가를 고려하여 추천의 신뢰도를 보장할 수 있다. Introduction - 기존 연구의 한계점 분석 --- 렌즈 삽입술을 위한 최적의 렌즈 사이즈를 찾는 일은 의사의 높은 수준의 경험과 노하우에 의존하는 일이다. 이를 도와주기 위해 최적의 렌즈 사이즈를 추천하는 모델이 개발되어왔다. 기존의 최적의 사이즈를 찾기 위한 렌즈 사이징 문제는 예측 모델을 고도화하는 방향으로 연구가 진행되어왔다. 환자의 눈의 조건과 삽입한 렌즈 사이즈를 입력 받아 수술결과(vaulting, 렌즈 후면과 수정체 전면까지의 거리)를 예측하는 모델의 성능을 향상시키는 방향을 진행되었다. 대표적으로 MAE와 같이 실제 값과 예측값의 차이를 평가하는 예측평가지표를 통해 모델의 성능을 평가하고 이를 개선하는 방향으로 연구가 진행되었다. MAE: Mean Absolute Error, 실제 값과 예측값의 차이의 절대값의 평균 하지만 예측 모델 기반의 렌즈 사이징 모델인 기존 연구는 분명한 한계점이 존재한다. 먼저 이를 이해하기 위해서는 예측 문제와 선택의 문제를 이해하고 구분해야 한다. 1.1 예측 문제와 선택의 문제 차이 --- 예측 문제와 선택의 문제는 근본적으로 다른 성격을 가진다. 먼저 예측 문제는 주어진 입력에 대해 결과를 예측하는 문제를 말한다. 예를 들어 \"환자 A가 12.6mm 렌즈로 수술을 받으면 vaulting이 얼마가 될까?\"와 같은 문제가 예측 문제에 해당한다. 예측 문제의 목표는 정확한 예측이다. 예측 문제의 성능 지표는 MAE, RMSE, R² 등이 있다. 선택의 문제는 여러 옵션 중 최적의 선택을 하는 문제를 말한다. 예를 들어 \"환자 A에게 12.1mm, 12.6mm, 13.2mm 중 어떤 렌즈를 추천할까?\"와 같은 문제가 선택의 문제에 해당한다. 선택 문제의 목표는 최적의 선택이다. 선택 문제의 성능 지표는 처치 효과, 개인화된 추천 정확도 등이 있다. 예측 문제와 선택 문제의 가장 큰 차이점은 통제 변수(Control Variable)의 존재 여부이다. 통제 변수는 연구자가 직접 조작할 수 있는 변수로, 실험 설계에서 핵심적인 역할을 한다. 이는 인과추론에서 처치(Treatment)와 동일한 개념으로, 연구자가 의도적으로 변화시킬 수 있는 독립변수를 의미한다. 렌즈 사이징 문제에서는 렌즈의 사이즈가 처치에 해당하며 처치가 결과에 미치는 영향을 처치효과라고 한다. 예측 문제에서는 모든 입력 변수가 주어진 값으로 고정되어 있다. 즉, 모델의 목표는 주어진 조건 하에서 결과를 정확히 예측하는 것이다. 예를 들어, \"환자 A가 12.6mm 렌즈로 수술을 받으면 vaulting이 얼마가 될까?\"라는 질문에서 렌즈 사이즈(12.6mm)는 이미 결정된 고정값이며, 이를 변경할 수 없다. 이 경우 모델은 환자의 눈 조건과 고정된 렌즈 사이즈를 입력으로 받아 vaulting 값을 예측하는 함수를 학습한다. 선택 문제에서는 통제 변수가 핵심 역할을 한다. 연구자는 여러 옵션 중에서 최적의 선택을 하기 위해 통제 변수의 값을 변화시킬 수 있다. \"환자 A에게 12.1mm, 12.6mm, 13.2mm 중 어떤 렌즈를 추천할까?\"라는 질문에서 렌즈 사이즈는 통제 변수로, 여러 옵션 중에서 선택할 수 있는 변수이다. 이 경우 모델은 각 렌즈 사이즈 옵션에 대한 결과를 예측하고, 최적의 선택을 제안하는 함수를 학습해야 한다. 예측 문제는 조건부 확률 $P(Y X)$를 추정하는 문제이고, 선택 문제는 조건부 평균 처치 효과 $E[Y(T=t) X]$를 추정하는 문제이다. 여기서 $T$는 통제 변수(처치)를, $X$는 환자 특성을, $Y$는 결과를 나타낸다. 조건부 평균 처치 효과란 통제 변수가 주어졌을 때 처치 효과의 평균을 의미한다. 렌즈 사이징은 본질적으로 선택의 문제이다. 환자에게 최적의 렌즈를 추천하는 것이 목표이기 때문이다. 하지만 기존 연구는 예측 모델의 성능 향상에만 집중하여 선택의 문제를 제대로 해결하지 못한다. 1.2 예측 모델이 선택의 문제에 활용되기 어려운 이유 --- 렌즈 사이징이 선택의 문제임을 확인했으므로, 이제 예측 모델이 선택의 문제에 활용되기 어려운 이유를 분석한다. 예측 모델이 가지는 한계점은 무엇인지, 이를 기반으로 선택을 할 때의 위험성에 대해 이야기한다. 1.2.1 상관관계에 기반한 예측 모델의 한계 예측 모델은 주어진 데이터에서 변수 간의 동시 변동 패턴, 즉 상관관계를 학습하여 결과를 예측한다. 상관관계는 두 변수 사이에 일정한 패턴이나 동반 변동이 존재함을 의미하며, 한 변수가 커질 때 다른 변수가 일정하게 커지거나 작아지는 경향을 보이는 통계적 관계를 말한다. 예측 모델은 상관관계만을 학습하므로 숨겨진 교란변수(Confounding Variable)의 존재를 인식하지 못한다. 교란변수(Confounding Variable) : 처치(Treatment)와 결과(Outcome) 모두에 영향을 미치는 제3의 변수로, 처치와 결과 사이의 인과관계를 왜곡시키는 변수를 의미한다. 교란변수는 처치 선택과 결과에 동시에 영향을 주어 가짜 인과관계를 만들어내거나 실제 인과관계를 숨길 수 있다. 교란편향(Confounding Bias) : 교란변수로 인해 발생하는 통계적 편향으로, 처치와 결과 사이의 실제 인과관계가 왜곡되어 나타나는 현상을 의미한다. 이는 처치 그룹 간에 교란변수의 분포가 다를 때 발생하며, 처치 효과의 정확한 추정을 방해한다. 예를 들어, 숙박 가격과 매출 데이터에서 가격이 높을수록 매출이 높아 보이는 패턴이 관찰되면, 예측 모델은 \"가격을 올리면 매출이 오른다\"고 결론을 내린다. 하지만 이 패턴 뒤에는 성수기/비수기 여부라는 숨겨진 교란변수가 존재할 수 있다. 실제로는 성수기에 가격과 매출이 동시에 상승하고, 비수기에 가격과 매출이 동시에 하락하는 것이며, 가격과 매출 사이에는 직접적인 인과관계가 없다. 이러한 상관관계를 인과관계로 오해하면 \"매출을 올리려면 가격을 올려야 한다\"는 잘못된 결론에 이를 수 있고, 실제 효과가 있는 개입(예: 비수기 프로모션) 대신 부적절한 가격 정책을 선택하게 만든다. 인과관계: 한 변수가 변할 때 다른 변수가 그 변화에 의해 직접적·체계적으로 영향을 받아 변화하는 관계를 의미 예측 모델의 예측 성능이 좋다고 해서 인과관계를 잘 찾았다는 보장이 없으며, 렌즈 사이징과 같은 선택 문제에서는 인과관계가 필요하지만 예측 모델은 이를 제공하지 못한다. 따라서 예측 모델에 기반해 선택을 하는 것은 위험하며, 인과관계를 직접적으로 추론할 수 있는 방법론이 필요하다. 인과관계를 직접적으로 추정하는 모델을 통해 처치 (통제변수, 렌즈사이즈)가 결과에 미치는 영향을 직접적으로 추정할 수 있고 이를 통해 올바른 선택을 할 수 있다. 1.2.2 데이터 안에 존재하는 통계적 편향 앞서 언급한 것처럼 데이터에 통계적 편향(교란편향)이 존재하면 예측 모델은 잘못된 패턴, 즉 인과관계가 아닌 패턴을 학습할 수 있다. 렌즈 사이징 문제에서 데이터는 통계적 편향을 가지고 있다. 이는 렌즈 크기별(처치별)로 환자의 분포가 다르다는 의미이며, 데이터에서 확인된다. <figure> <img src=\"/post/what-is-statistical-bias/처치별_Feature_DensityPlot.png\" alt=\"처치별 Feature Density Plot\"> <figcaption>그림 1: 처치별 환자 눈의 크기 분포 비교</figcaption> </figure> 그림 1은 처치(렌즈 사이즈)별로 환자의 눈 크기에 대한 분포를 시각화한 것이다. 그림 1에서 볼 수 있듯이, 처치별로 환자의 눈 크기 분포(ATA, ACD)가 명확히 다르다. 이는 의사가 환자의 개별 특성을 고려하여 적절한 렌즈를 선택하는 임상적 판단에 따른 결과이다. 예를 들어, 눈이 작은 환자에게는 작은 렌즈를, 눈이 큰 환자에게는 큰 렌즈를 선택하는 경향이 있다. 이러한 선택 편향은 교란편향을 유발한다. 환자의 눈 크기, 나이, 각막 두께 등은 렌즈 선택과 수술 결과 모두에 영향을 미치는 교란변수이기 때문이다. 앞서 1.2.1에서 언급한 바와 같이, 데이터에 통계적 편향이 존재할 경우 예측 모델은 인과관계가 아닌 잘못된 패턴을 학습할 수 있으며, 이러한 패턴에 기반한 선택은 위험하다. 또한 통계적 편향은 렌즈의 크기가 결과에 미치는 영향인 처치효과를 왜곡한다. 렌즈 사이즈별로 환자 눈의 분포가 다르기 때문에 단순히 결과만 비교해서는 렌즈 사이즈의 효과를 알 수 없다. 환자의 개별 특성을 동일하게 맞춘 상태에서 렌즈 효과를 비교해야 한다. 이는 실험을 설계할 때 대조군과 처치군을 동일하게 맞춰야 하는 것과 같다. 대조군과 실험군을 동일하게 맞춰야만 실험 조건만의 영향을 추정할 수 있기 때문이다. 하지만 처치효과를 추정하기 위해 무작위 대조 실험(RCT, Randomized Controlled Trial)을 진행할 수 없다. 무작위 대조 실험 : 대조군과 실험군을 무작위로 선택하여 실험을 진행하는 방법 따라서 처치 효과를 추정하기 위해서는 통계적 편향을 제거하고 인과관계를 직접적으로 추론해야 한다. 인과추론 방법론은 이러한 교란편향을 통계적으로 제거하여 실제 처치 효과를 추정할 수 있는 방법을 제공한다. 구체적인 방법은 다음 섹션에서 다룬다. 1.3 예측 평가지표의 한계 --- 예측 모델의 또 다른 한계는 측정되지 않은 데이터(반사실, Counterfactual)에 대한 평가를 고려하지 않는다는 점이다. 기존 연구들은 예측 모델을 고도화하는 방향으로 진행되었으며, 예측 성능지표를 통해 모델의 신뢰도를 보장하고 있다. 하지만 최적의 렌즈를 추천하기 위해서는 수술받은 렌즈 외에 다른 렌즈 크기에 대한 결과도 예측해야 한다. 예측 모델의 한계는 실제로 일어나지 않은 상황에 대한 평가가 불가능하다는 점이다. 예를 들어, 환자 A가 12.6mm 렌즈로 수술을 받고 이에 결과를 얻었다고 가정한다. 이때 추천 모델이 증명해야 하는 것은 \"만약 이 환자가 13.2mm 렌즈로 수술을 받았다면 어떤 결과가 나왔을까?\"이다. 하지만 이 환자는 이미 12.6mm 렌즈로 수술을 받았기 때문에, 13.2mm 렌즈의 결과는 알 수 없다. 이렇게 실제로는 관찰되지 않은 가상의 상황을 \"반사실(Counterfactual)\"이라고 한다. 기존 예측 모델들은 관찰된 데이터만으로 학습하기 때문에, 이런 반사실적 상황에 대한 추정이 불가능하다. 그리고 이에 대한 평가지표를 고려하지 않는다. 인과추론은 이런 반사실적 상황을 통계적으로 추정할 수 있는 방법론을 제공하며, 이에 대한 평가지표도 함께 고려해 신뢰도를 확보한다. Method & Result - 인과추론에 대한 소개와 인과추론을 통해 이를 해결한 방법 소개 --- 앞서 언급한 것처럼 선택의 문제에서 예측 모델은 한계점을 가진다. 이를 극복하기 위해 인과추론 방법론을 도입하고자 한다. 인과추론이란 의학, 마케팅, 교육 등에서 자주 사용되는 방법론으로 정책 및 비즈니스에 수반된 수많은 의사결정들의 원인과 결과를 분석하는 방법이다. 인과추론은 인과관계를 분석하고 처치 효과를 추정하여 의사결정을 돕는 방법론이다. 예를 들어 정밀의학에서는 환자별 처치 효과를 추정하여 수술방법을 선택을 결정하고, 교육에서는 학생별 처치 효과를 추정하여 교육 방법을 결정하고, 온라인 마케팅에서는 사용자별 처치 효과를 추정하여 맞춤형 광고를 제공하고, 오프라인 정책 평가에서는 지역별 처치 효과를 추정하여 정책을 결정할 수 있다. 여기서 처치란 인과추론에서 의사결정의 대상(예: 수술 방법, 약물 투여, 교육정책 등)을 의미한다. 렌즈 사이징 문제에서는 렌즈 사이즈가 처치에 해당한다. 인과추론을 통해 렌즈의 사이즈와 결과의 인과관계를 분석하고 처치효과를 추정할 수 있다. 그리고 이를 통해 최적의 렌즈 사이즈를 결정하는데 도움을 줄 수 있다. 인과추론을 도입함으로써 다음과 같은 효과를 기대할 수 있다. 첫째, 통계적 편향을 제거하고 인과관계를 직접적으로 추론할 수 있어 렌즈 크기가 결과에 미치는 실제 영향을 정확히 추정할 수 있다. 둘째, 측정되지 않은 데이터(반사실적 상황)에 대한 평가를 고려하여 모델의 신뢰도를 확보할 수 있다. 셋째, 개인화된 처치 효과(Heterogeneous Treatment Effects)를 추정하여 환자별로 최적화된 렌즈 사이즈를 제안할 수 있다. 이번 보고서에서는 통계적 편향을 제거한 결과에 대해서만 소개하며, 개인화된 처치 효과를 추정하여 개인화된 추천을 하는 방법에 대해서는 추후에 다루도록 한다. 2.1 인과추론 방법을 통해 통계적 편향을 제거 렌즈 사이즈가 결과에 미치는 영향인 처치효과를 추정하기 위해서는 대조군과 실험군처럼 렌즈 사이즈를 제외한 나머지 변수는 통제해야 한다. 즉 렌즈 사이즈별로 환자의 눈의 크기에 대한 분포가 같아야 한다. 하지만 앞서 확인한 것처럼 데이터에는 편향이 존재하며, 처치효과를 추정하기 위해 RCT를 수행할 수 없다. 이때 인과추론 방법론을 통해 통계적 편향을 제거할 수 있다. <figure> <img src=\"/post/what-is-statistical-bias/처치별결과비교.png\" alt=\"처치별 결과 비교\"> <figcaption>그림 2: 처치별 결과 분포 비교</figcaption> </figure> 그림 2는 처치별 결과의 분포를 시각화한 것이다. 앞서 설명한 것처럼 처치별로 환자의 눈의 분포가 다르기 때문에 처치별 분포를 비교해 처치효과를 추정할 수 없다. 처치효과를 추정하기 위해서는 통계적 편향을 제거해야 한다. <figure> <img src=\"/post/what-is-statistical-bias/사이즈별잔차분포.png\" alt=\"결과에서 교란변수에 대한 영향 제거후 분포\"> <figcaption>그림 3: 잔차화를 통해 통계적 편향을 제거한 결과 분포</figcaption> </figure> 그림 3은 그림 2의 결과에서 잔차화를 통해 통계적 편향을 제거한 것이다. 잔차화란 결과(vaulting)에 렌즈 사이즈를 제외한 다른 변수(교란변수)가 미치는 영향을 제거해 교란변수를 통제한 것과 같은 효과를 만드는 방법론이다. 잔차화를 통해 통계적 편향을 제거하면 렌즈 사이즈별로 환자의 눈의 분포가 같아지므로 렌즈 사이즈가 결과에 미치는 영향을 추정할 수 있다. 이처럼 인과추론 방법론은 데이터가 가지고 있는 통계적 편향을 확인하고 이를 제거해 처치의 효과를 추정하고 인과적인 관계를 추론하는 방법론이다. Conclusion - 연구 요약 및 향후 계획 --- 본 연구에서는 렌즈 사이징 문제에서 기존 예측 모델의 한계점을 분석하고, 이를 해결하기 위한 인과추론 방법론의 도입을 제안하였다. 기존 예측 모델은 선택의 문제에서 통계적 편향을 고려하지 못하고 인과관계를 직접적으로 추론하지 못하는 한계를 가지고 있다. 이러한 한계를 극복하기 위해 인과추론 방법론을 도입하여 통계적 편향을 제거하고 처치 효과를 추정하는 방법을 제시하였다. 인과추론 방법론의 도입을 통해 다음과 같은 효과를 기대할 수 있다. 첫째, 통계적 편향을 제거하여 렌즈 크기가 결과에 미치는 실제 인과적 영향을 정확히 추정할 수 있다. 둘째, 측정되지 않은 데이터(반사실적 상황)에 대한 평가를 고려하여 모델의 신뢰도를 확보할 수 있다. 셋째, 개인화된 처치 효과(Heterogeneous Treatment Effects)를 추정하여 환자별로 최적화된 렌즈 사이즈를 제안할 수 있다. 향후 연구에서는 개인화된 처치 효과 추정을 통한 개인화된 추천 시스템 개발에 집중할 예정이다. 이를 통해 환자별 특성을 고려한 맞춤형 렌즈 사이즈 추천이 가능한 모델을 구축하고자 한다."
  },
  {
    "id": "Self_Development/Fitness/Workout Log/250713",
    "title": "간단한 달리기 + 산책",
    "date": "2025-07-13",
    "excerpt": "운동일지",
    "category": "Workout Log",
    "tags": [],
    "content": "확실히 런닝 자주 안하니까 진짜 안뛰어진다. 꾸준히 뛰어보자."
  },
  {
    "id": "Self_Development/English Study/TOEFL/토플준비",
    "title": "TOEFL 100점 이상 목표로 공부",
    "date": "2025-07-13",
    "excerpt": "OMSCS 지원을 위한 토플 공부",
    "category": "English Study",
    "tags": [
      "TOEFL",
      "영어",
      "대학원"
    ],
    "content": "배경 OMSCS를 지원하기 위해서는 토플 100점 이상이 필요한데요, 이를 위해서 토플 공부를 시작했습니다. 공부하면서 어떻게 공부해야할지 정리해나가고 있습니다. 목표 기간은 3~4개월 정도입니다. 올해 11월부터는 OSMC에 서류를 넣으려고 합니다. 학습 계획 세워보기 공부 전략 유튜브 링크 - 🍀토플 독학을 마음먹으신 분들을 위한 첫 번째 가이드 (시험 이해, 공부 방법, 두려움 극복, 참고 링크) 명확한 목표 기간을 잡고 집중해서 공부하기 시험구성에 대해 정확히 이해하고 시작하기 시험 구성 Reading 2개 지문 x 10문제. 지문하나당 약 700단어. 총 35분정도. Listening 2개 대화 (각 3분) x 5문제 3개 강의 (각 3-5분) x 6문제 총 36분 정도. Speaking (1) 독립형 (15초 준비, 45초 답변) (2), (3) 통합형 - 읽+듣+말 (30초 준비, 60초 답변) (4) 통합형 - 듣+말 (20초 준비, 60초 답변) 총 16분 정도. Writing (1) 통합형 - 읽+듣+쓰 (20분) (2) 토론형 - 읽+쓰 (10분) 총 30분정도. 참고 사이트 🔗참고 사이트 링크 ETS TOEFL 공식 웹사이트 시험 구성 및 문제 유형 안내 https://www.ets.org/toefl/test-takers... ETS TOEFL TestReady 웹사이트 (모의고사, 액티비티) https://testready.ets.org/test-prep-l... 테스트글라이더 웹사이트 https://www.testglider.com/ko/toefl 참고자료 [[토플공부/토플 공부법] 초보자를 위한 토플 독학 가이드 : A to Z](https://beyondourlimit.tistory.com/68) : 블로그, 기본적인 개념 알기 좋다"
  },
  {
    "id": "Self_Development/English Study/SPEAK/지나간달/07-13-조언하는 표현",
    "title": "조언하는 표현",
    "date": "2025-07-13",
    "excerpt": "",
    "category": "English Study",
    "tags": [
      "영어공부꾸준히!",
      "SPEAK",
      "칭찬하는 표현들"
    ],
    "content": "배운 것들 Try to drink more water Drink more water (X, 명령하는 느낌이 남) 발음 팁! t -> d Try to get more sleep Try to cut down on smoking cut down on : ~을 줄이다 Try not to skip breakfast. Make sure to + Make sure to take probiotics every day. Make sure to take Vitamin C. Make sure not to eat too much junk food. wipe down : 말끔히 닦다 come to work stock up : 대량으로 사놓다. 간단한 작문 I read a book , atomic habits that tell me how to make habit. The book says that try to split the things to very small things. Because it make me to do more. So the lesson in the book is that make sure to make things, clear, attractive, easy. 피드백. AI 작문 피드백: \"I read a book , atomic habits\" → 쉼표 앞 공백 제거, 책 제목은 따옴표 사용 \"that tell me\" → 단수 주어이므로 \"tells me\" \"how to make habit\" → \"how to build habits\" (복수형, 더 자연스러운 표현) \"says that try to\" → \"says to try to\" 또는 \"says that I should try to\" \"split the things to very small things\" → \"break things down into smaller pieces\" \"Because it make me to do more\" → \"makes\" (단수), \"make me do\" (to 불필요) \"make sure to make things, clear, attractive, easy\" → 문장 구조 개선 필요 수정된 작문: I read a book called \"Atomic Habits\" that tells me how to build habits. The book says to try to break things down into smaller pieces. This makes me do more because it reduces the psychological burden. So the lesson in the book is to make sure to make things clear, attractive, and easy. 영어 작문 연습 (한글 내용 기반) I think habits are the most important thing in life. According to research by Professor Wendy Wood at Duke University, about 45% of our behavior comes from habits. The book \"Atomic Habits\" suggests the 2-minute rule. Try to break down what you need to do into very small tasks that can be finished in 2 minutes. I applied this to my life for about 1-2 months and it was really effective. The biggest reason is that it reduces psychological burden. Usually, we procrastinate because of psychological pressure. When I break down tasks into small 2-minute pieces, this burden almost disappears. By achieving small things, I can gradually do more things with that sense of accomplishment. For breaking bad habits, you should make them difficult to do. Human willpower has limits, so environment is the most important thing. I had a bad habit of looking at my phone late at night and sleeping late. To solve this, I bought an alarm clock. Now I don't bring my phone to bed and turn it off as soon as I get home. The key lessons are: Try to break tasks into very small pieces to reduce psychological burden Make sure to create an environment where you can't do bad habits Remember that willpower is limited, so focus on changing your environment"
  },
  {
    "id": "Self_Development/Book/아주 작은 습관의 힘 (Atomic Habits)/골디락스의 법칙",
    "title": "골디락스의 법칙",
    "date": "2025-07-13",
    "excerpt": "지금보다 조금 더 어려운 일에 도전하자",
    "category": "Book",
    "tags": [
      "atomic habits",
      "아주 작은 습관의 힘"
    ],
    "content": "'아주 작은 습관의 힘'에서는 꾸준함을 어떻게 이어갈 것인지, 그리고 이에 도움을 주는 도구들을 소개하고 있습니다. 이 중에서 '골디 락스의 법칙'에 대해 이야기한 부분을 정리해봅니다. <figure> <img src=\"/post/골디락스의법칙/골디락스의법칙_그래프_이미지.jpg\" alt=\"골디락스의 법칙 그래프\" /> <figcaption>그림1.골디락스의 법칙: 너무 쉬우면 지루하고, 너무 어려우면 포기하게 된다. 적당히 도전적인 수준이 가장 효과적이다.</figcaption> </figure> 골디락스의 법칙(Goldilocks Rule)의 법칙이란 일의 난이도가 너무 쉬우면 지루하고, 너무 어려우면 포기하게 되기 때문에, 조금 어려운 정도의 난이도가 일에 몰입하는데 효과적이라는 이야기입니다. > 골디락스의 법칙이란 인간은 자신이 할 수 있는 적합한 일을 할 때 동기가 극대화되는 경험을 한다는 것이다. > 지나치게 어려워서도 안되며 지나치게 쉬워서도 안된다. 딱 들어맞아야 한다. > > — 아주 작은 습관의 힘 어떤 일을 꾸준히 하기 위해서는 이 법칙을 이해하고 활용할 수 있습니다. 특히 어떤 일을 처음 시작하는거라면, 그 자체로 심리적 부담감이 크고 난이도가 어렵다고 느껴지기 때문에 정말 쉬운 일로 작게 쪼개는게 효과적일 것입니다. 그 후에 어느정도 반복하면서 습관이 되었다면 조금씩 난이도를 올려가야 지루함을 느끼지 않고 꾸준히 할 수 있을 것입니다. 이 골디락스의 법칙은 뇌의 긴장도를 어떻게 유지할 것인지와도 연결됩니다. 예르크스-도드슨 법칙과의 연결 골디락스의 법칙은 심리학의 \"예르크스-도드슨 법칙(Yerkes-Dodson Law)\"과 밀접한 관련이 있습니다. <figure> <img src=\"/post/골디락스의법칙/여키스도슨법칙_그래프.png\" alt=\"예르크스-도드슨 법칙 그래프\" /> <figcaption>그림2. 예르크스-도드슨 법칙: 긴장도(각성 수준)와 성과의 관계. 적절한 긴장도에서 최고의 성과를 보이지만, 너무 낮거나 높은 긴장도에서는 성과가 떨어진다.</figcaption> </figure> > 예르크스-도드슨 법칙이란 긴장도(각성 수준)와 성과 간의 관계를 설명하는 법칙으로, 적절한 긴장도에서 최고의 성과를 보이지만, 너무 낮거나 높은 긴장도에서는 성과가 떨어진다는 것을 말합니다. 너무 쉬운 일: 긴장도가 낮아서 지루함을 느끼고 성과가 떨어짐 너무 어려운 일: 긴장도가 너무 높아서 스트레스와 불안으로 성과가 떨어짐 적당히 도전적인 일: 적절한 긴장도를 유지하여 최고의 성과와 몰입을 경험 사람마다 최적의 긴장도 수준이 다르기 때문에, 자신에게 맞는 난이도를 찾아가는 것이 중요합니다. 처음에는 쉬운 것부터 시작해서 점진적으로 난이도를 높여가며 자신만의 \"골디락스 존\"을 찾아가는 것이 효과적입니다. 정리 골디락스의 법칙을 실생활에 적용하는 방법: 난이도 조절 전략 지루함을 느낄 때: 난이도를 10-15% 높여서 도전감을 만들어라 압도당할 때: 난이도를 낮추고 더 작은 단위로 쪼개라 적정 수준: 약간의 긴장감이 있지만 포기하지 않을 수 있는 수준 실천 방법 습관 형성 초기: 정말 쉬운 것부터 시작 (예: 매일 1분 명상) 습관 안정화 후: 점진적으로 난이도 상승 (예: 5분 → 10분 → 15분) 지속적 모니터링: 자신의 몰입도와 동기를 체크하며 조절 핵심 원칙 > \"너무 쉬우면 지루하고, 너무 어려우면 포기한다. 적당히 도전적인 수준이 가장 효과적이다.\""
  },
  {
    "id": "Self_Development/Guitar/Practice Log/250713",
    "title": "델리스파이스 고백",
    "date": "2025-07-12",
    "excerpt": "기타연습일지",
    "category": "Practice Log",
    "tags": [],
    "content": "크로매틱 80bpm 16bit. 처음엔 잘 안된다가 나중에 손풀리니까 잘 됨 스케일 0~4. 이제 다 외울 때가 됐는데.. ㅎㅎ 곡 연습 델리스파이스 고백. 막 빡세게는 안하고 그냥 한번씩 쳐보는 정도?"
  },
  {
    "id": "Self_Development/Guitar/Practice Log/250712",
    "title": "어떻게",
    "date": "2025-07-12",
    "excerpt": "기타연습일지",
    "category": "Practice Log",
    "tags": [],
    "content": "연습 체크 7월 12. 토 [ ] 크로메틱"
  },
  {
    "id": "Self_Development/Book/아주 작은 습관의 힘 (Atomic Habits)/습관추적",
    "title": "습관추적에 대하여",
    "date": "2025-07-12",
    "excerpt": "습관추적은 어떤 습관을 만들기 위한 훌륭한 도구다",
    "category": "Book",
    "tags": [
      "atomic habits",
      "아주 작은 습관의 힘"
    ],
    "content": "'아주 작은 습관의 힘'에서 이야기하는 컨셉은 아주 명확합니다. 어떤 일을 꾸준히 하기 위해서는 '명확해야 하며', '하기 쉬워야 하고', '만족감을 줘야 한다'. 그리고 이렇게 만들기 위한 좋은 방법 중 하나로 습관 추적을 설명하고 있습니다. 습관을 추적한다는 건 내가 어떤 일을 꾸준히 하고 있는지와 어떤 일을 해야하는지를 적고 확인해나가는 것입니다. 내가 어떤 일을 해야하는지 적어서 해야할 일을 명확히 만들고, 했을 때는 이를 기록하면서 성취감을 느낄 수 있습니다. > 꾸준히 하기 위해서는 성취감을 받아야 한다. 이를 위해 습관추적은 좋은 도구다. 특히 저에게는 매일 해나가면서 꾸준히 쌓이는 느낌이 강력한 동기부여로 작용합니다. 개발을 하는 입장에서 가장 대표적인게 깃헙의 잔디밭이라고 생각합니다. <figure> <img src=\"/post/습관추적/깃헙잔디밭.png\" alt=\"깃헙 잔디밭\"> <figcaption>깃헙 잔디밭</figcaption> </figure> 내가 꾸준히 커밋(코드 작업)을 하고 있는게 한눈에 보이고, 이게 이 일을 더 꾸준히 하는데 동기부여를 해줍니다. > 꾸준히 쌓여가는 느낌은 굉장한 동기부여를 제공한다. 또한 이렇게 쌓여가는 느낌을 받기 위해 블로그도 작성하기도 합니다. 공부한 것들을 글로 작성하는 연습을 하기도 하고, 또 이렇게 공부한 것들이 하나씩 쌓여가는게 눈에 보이기 때문에 성취감을 줍니다. 그래서 그냥 공부하는 것보다 저는 블로그에 글로 남기면서 하나씩 쌓여가는 걸 눈으로 볼 때 더 큰 성취감과 동기부여를 받습니다."
  },
  {
    "id": "Self_Development/English Study/SPEAK/지나간달/07-11-긍정적인피드백주기",
    "title": "긍정적인 피드백 주는 표현들 복습",
    "date": "2025-07-11",
    "excerpt": "",
    "category": "English Study",
    "tags": [
      "영어공부꾸준히!",
      "SPEAK",
      "칭찬하는 표현들"
    ],
    "content": "리뷰 데이 I like the way I appreciate it I know that its hard I want you to know that you call me any time. This too shall pass. I was really impressed with. It couldnt be any better I couldnt have done it without you. You did a great job on work Im happy to see that I can tell that I believe in you Youve made it this far. You`re almost there"
  },
  {
    "id": "Self_Development/Book/아주 작은 습관의 힘 (Atomic Habits)/만족스럽게만들어라",
    "title": "만족스럽게 만들어라",
    "date": "2025-07-11",
    "excerpt": "지속하기 위해서는 즉각적인 보상이, 그만두기 위해서는 즉각적인 페널티가 필요하다",
    "category": "Book",
    "tags": [
      "atomic habits",
      "아주 작은 습관의 힘"
    ],
    "content": "어떤 일을 지속하기 위해 중요한 건 뭘까? 많은 사람들이 원하는 결과를 얻기 위해서는 '꾸준함'이 가장 중요하다고 말합니다. 이 꾸준함은 어떻게 만들 수 있을까요? 강력한 의지와 다짐이 필요한 걸까요? '아주 작은 습관의 힘'에서는 원하는 습관을 만들기 위한 구체적인 방법들을 제시하고 있습니다. 그 중 하나는 해야하는 일을 아주 작게 쪼개라는 것입니다. 쉬워야 달라진다/쉬워야달라진다) 이에 이어서 저자는 어떤 일을 꾸준히 하기 위해서는 만족스럽게 만들어라 라고 말하고 있습니다. 우리의 뇌를 이해해보자 우리의 뇌는 과거에 맞춰져 있습니다. 뇌과학에서 밝혀진 바에 따르면, 인간의 뇌는 수십만 년 동안 수렵채집 시대의 환경에 최적화되어 진화했습니다. 우리가 현대 문명에 살기 시작한 것은 불과 몇 천 년에 불과하기 때문입니다. 이러한 진화적 배경 때문에 우리의 뇌는 장기적인 목표보다는 즉각적인 보상에 훨씬 더 강하게 반응하도록 설계되어 있습니다. 원시 시대에는 지금 당장 얻을 수 있는 음식, 안전, 번식 기회가 생존에 직결되었기 때문입니다. 따라서 우리가 장기적인 목표를 달성하려면 이러한 뇌의 특성을 이해하고 활용해야 합니다. > 우리의 뇌는 당장 즐거운면 하고 당장 고통스러우면 안한다. 우리의 의지력은 한계가 있기 때문에, 이를 이해하고 활용해서 꾸준히 할 수 있는 환경 혹은 시스템을 만들어야 합니다. > 우리는 본능의 씨앗들에 반기를 들지 못하며 그것들과 함께 나아가야 한다. 가장 최선의 방법은 장기적으로 보상을 주는 습관에는 즉시적인 기쁨의 조각들을 덧붙이고, 그렇지 않은 습관에는 고통의 조각들을 덧붙이는 것이다. > > - 《아주 작은 습관의 힘》 원하는 습관을 만들려면 즐겁게 만들자 > 습관을 계속 유지하기 위해서는 성공했다는 느낌을 필수적으로 받아야 한다. 비록 아주 사소한 방식일지라도 말이다. 성공했다고 느끼는 것은 습관이 성과를 냈고, 그 일이 노력할 만한 가치가 있다는 신호이기 때문이다. > > - 《아주 작은 습관의 힘》 우리는 즉각적으로 즐거움을 느낄 수 있는 일을 하게 됩니다. 하지만 원하는 목표들은 지연적인 보상을 제공하는 일들이 많습니다. 이를 위해 원하는 목표로 가는 길을 아주 잘게 쪼개고, 각 단계에서 즉각적인 보상을 받도록 설계해야합니다. 가장 좋은 건 \"성공했다는 느낌\"을 받도록 설계하는 것입니다. > 실제로 저는 이 전략으로 운동하는 습관을 만들었고, 6년정도 꾸준히 이어서 하고 있습니다. 많은 사람들이 운동을 시작할 때 \"진짜 운동 열심히 할거야, 진짜 빡세게 해야지\" 등의 다짐을 하고 시작하게 됩니다. 하지만 막상 운동을 하게 되면 힘들고 피곤하기 때문에 부정적인 감정을 경험하게 되고 행동을 이어가지 못합니다. 제가 운동을 시작할 때의 목표는 \"헬스장에 들어가서 푸쉬업 1개만 하고 칭찬하기\" 였습니다. 그래서 아무 생각없이 헬스장에 가서 진짜 푸쉬업 1개만 하고 \"성공했다는 느낌\"을 받으며 스스로를 칭찬했습니다. 이러다보니 헬스장에 가는 건 저에게 성취감을 주는 재밌는 일이 되었고, 점점 욕심을 느껴 강도를 늘려나갔습니댜. 푸쉬업을 기준으로 보면 처음에는 한번에 10개정도 밖에 못했지만 지금은 100개정도는 할 수 있는, 10배 이상의 근력을 얻을 수 있었습니다. 정리하면 원하는 목표를 달성하기 위해서는 즉각적인 보상을 받도록 설계해야 합니다. 그런 환경, 시스템을 만들어야합니다. 매일할 수 있는 작은 목표들로 쪼개고, 이를 했을 때 \"성공했다는 느낌\"을 받도록 설계 해야하고, 이때 이를 이어갈 수 있습니다. 나쁜 습관을 만들려면 페널티를 주자 반대로 나쁜 습관을 없애려면 보상을 지연시키거나 패널티를 주면 됩니다. 하지만 제 생각에 이 부분은 적용하기 어려웠습니다. 휴대폰이나 노트북으로 너무나도 쉽게 즉각적인 보상을 얻을 수 있는 세상이고, 이를 지연시킬 수 있는 방법은 아직 찾지 못했습니다. 그래서 제가 나름대로 적용하고 있는 부분은 \"회의적인 생각\"을 적용하는 것입니다. \"유튜브 봐서 뭐해? 재미도 없는거\" 이런식으로 피해야하는 행동들에 대해서는 하고 싶지만 참는게 아닌 하는게 의미가 없다고 생각하려고 하고 있습니다. 실제로 이런 생각을 가지고 나니, 해봤자 의미없는 행동들은 하지 않게 되었고, 실질적으로 나에게 성취감을 주는 행동들에 집중할 수 있게 되었습니다. 정리 우리의 뇌는 즉각적인 보상에 집중한다. 미래의 보상에는 집중하지 못한다. 이를 활용해 전략을 세우고 환경을 만들자. 의지력의 문제가 아니다! 작은 목표들로 쪼개고 이를 해나가며 \"성공했다는 느낌\"에 집중하자 피해야 하는 일들에는 회의적인 생각을 적용해 불편한 느낌을 가지도록 하자"
  },
  {
    "id": "Data Science/Causal Inference/ill-conditioned-matrix-theory",
    "title": "Ill-conditioned 행렬과 고유값: 연속형 처치 R-learner의 이론적 배경",
    "date": "2025-07-11",
    "excerpt": "연속형 처치에서 발생하는 non-identification 문제와 ill-conditioned 행렬, 고유값의 관계를 자세히 설명",
    "category": "Causal Inference",
    "tags": [
      "Theory",
      "Linear Algebra",
      "Matrix Analysis"
    ],
    "content": "Ill-conditioned 행렬과 고유값: 연속형 처치 R-learner의 이론적 배경 개요 연속형 처치 R-learner에서 발생하는 non-identification 문제는 수학적으로 ill-conditioned 행렬 문제로 나타납니다. 이 글에서는 이 개념들을 단계별로 자세히 설명합니다. 고유값(Eigenvalue)이란? 1.1 기본 개념 고유값은 행렬의 중요한 특성을 나타내는 스칼라 값입니다. 수학적 정의: 행렬 A에 대해, 0이 아닌 벡터 v와 스칼라 λ가 다음을 만족할 때: $$Av = \\lambda v$$ λ를 A의 고유값, v를 고유벡터라고 합니다. 1.2 직관적 이해 고유값은 행렬이 벡터를 어떤 방향으로 얼마나 늘리거나 줄이는지를 나타냅니다. 예시: $$ A = \\begin{bmatrix} 2 & 0 \\\\ 0 & 3 \\end{bmatrix} $$ 고유값: $\\lambda_1 = 2$, $\\lambda_2 = 3$ 고유벡터: $v_1 = [1, 0]$, $v_2 = [0, 1]$ λ₁ = 2: x축 방향으로 2배 늘림 λ₂ = 3: y축 방향으로 3배 늘림 1.3 고유값의 의미 λ > 1: 해당 방향으로 확대 0 < λ < 1: 해당 방향으로 축소 λ = 0: 해당 방향으로 완전히 압축 (정보 손실) λ < 0: 해당 방향으로 반전 Ill-conditioned 행렬이란? 2.1 조건수(Condition Number) 조건수는 행렬이 얼마나 \"불안정한지\"를 측정하는 지표입니다. 정의: $$ \\kappa(A) = \\ A\\ \\times \\ A^{-1}\\ $$ 여기서 $\\ A\\ $는 행렬 A의 노름(norm)입니다. 2.2 Ill-conditioned의 의미 Well-conditioned: 조건수가 작음 (≈ 1) Ill-conditioned: 조건수가 큼 (≫ 1) 2.3 왜 문제가 되는가? Ill-conditioned 행렬에서는 작은 입력 변화가 큰 출력 변화를 야기합니다. 예시: $$ A = \\begin{bmatrix} 1 & 1 \\\\ 1 & 1.001 \\end{bmatrix} $$ $$ A^{-1} \\approx \\begin{bmatrix} 1001 & -1000 \\\\ -1000 & 1000 \\end{bmatrix} $$ 조건수 $\\approx 4000$ (매우 큼!) 입력에 작은 노이즈가 있으면 해가 크게 달라집니다. 연속형 처치에서 Ill-conditioned가 발생하는 이유 3.1 Non-identification 문제 연속형 처치에서는 무한히 많은 처치 수준이 존재합니다: 이진 처치: $T \\in \\{0, 1\\}$ (2개 값) 연속형 처치: $T \\in [0, 1]$ (무한 개 값) 3.2 Generalized R-loss의 특성 이진 처치 R-loss: $$L(\\tau) = \\mathbb{E}[(Y - \\mu_0(X) - \\tau(X)(T - \\pi(X)))^2]$$ 연속형 처치 R-loss: $$L(\\tau) = \\mathbb{E}[(Y - \\mu_0(X) - \\tau(X,T)(T - \\pi(X)))^2]$$ 3.3 핵심 차이점 이진 처치: τ(X)는 X에만 의존 (유한차원) 연속형 처치: τ(X,T)는 X와 T 모두에 의존 (무한차원) 3.4 행렬로 표현하면 연속형 처치를 행렬로 표현하면: $$ \\begin{bmatrix} \\tau(x_1,t_1) & \\tau(x_1,t_2) & \\cdots & \\tau(x_1,t_n) \\\\ \\tau(x_2,t_1) & \\tau(x_2,t_2) & \\cdots & \\tau(x_2,t_n) \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\tau(x_m,t_1) & \\tau(x_m,t_2) & \\cdots & \\tau(x_m,t_n) \\end{bmatrix} $$ 이 행렬은 매우 큰 크기를 가지며, 많은 행들이 거의 선형 종속입니다. 고유값이 0에 가까워지는 이유 4.1 선형 종속성 연속형 처치에서 τ(x,t) 함수들은 서로 매우 유사합니다: $$\\tau(x, 0.1) \\approx \\tau(x, 0.11) \\approx \\tau(x, 0.12) \\cdots$$ 이는 행렬의 행들이 거의 선형 종속임을 의미합니다. 4.2 고유값의 의미 고유값이 0에 가까움 = 해당 방향의 정보가 거의 없음 예시: 행렬 A의 고유값: $\\lambda_1 = 10$, $\\lambda_2 = 0.001$, $\\lambda_3 = 0.0001$ $\\lambda_1 = 10$: 이 방향은 정보가 풍부 $\\lambda_2 = 0.001$: 이 방향은 정보가 거의 없음 $\\lambda_3 = 0.0001$: 이 방향은 거의 정보 없음 4.3 연속형 처치에서의 상황 연속형 처치에서는: 대부분의 고유값이 0에 가까움 몇 개의 고유값만 의미 있음 행렬이 거의 특이(singular)에 가까움 왜 문제가 되는가? 5.1 수치적 불안정성 작은 노이즈 → 큰 오차 원래 문제: $Ax = b$ 노이즈가 있는 문제: $(A + \\epsilon)\\tilde{x} = b + \\delta$ 결과: $\\ x - \\tilde{x}\\ $가 매우 클 수 있음 5.2 해의 유일성 부족 무수히 많은 해가 존재: $$\\tau(x,t) = \\tau_0(x,t) + \\epsilon(x,t)$$ 여기서 $\\epsilon(x,t)$는 R-loss를 거의 변화시키지 않는 함수 5.3 추정의 어려움 어떤 해가 \"정답\"인지 알 수 없음 해결 방법: Tikhonov 정규화 6.1 기본 아이디어 정규화 항 추가: $$L(\\tau) = \\mathbb{E}[(Y - \\mu_0(X) - \\tau(X,T)(T - \\pi(X)))^2] + \\lambda\\ \\tau\\ ^2$$ 6.2 수학적 효과 행렬 표현: $$(A^TA + \\lambda I)x = A^Tb$$ 고유값 변화: 원래 고유값: $\\lambda_i$ 정규화 후: $\\lambda_i + \\lambda$ 6.3 왜 도움이 되는가? 0에 가까운 고유값들이 λ만큼 증가 행렬이 더 안정적(well-conditioned)이 됨 유일한 해 보장 실제 예시 7.1 간단한 예시 연속형 처치 함수: $$\\tau(x,t) = 2t + 0.1\\sin(10t)$$ 문제: sin(10t) 항이 R-loss에 거의 영향을 주지 않음 해결: 정규화를 통해 \"부드러운\" 함수 선호 7.2 수치적 예시 원래 행렬 A의 고유값: $[10, 0.1, 0.01, 0.001, \\ldots]$ 정규화 후 ($\\lambda=1$): $[11, 1.1, 1.01, 1.001, \\ldots]$ 조건수가 크게 개선됩니다. 결론 연속형 처치 R-learner에서 발생하는 non-identification 문제는: 무한차원 함수 공간에서 발생 Ill-conditioned 행렬로 수학적 표현 고유값들이 0에 가까움으로 특징 Tikhonov 정규화로 해결 이러한 이해는 연속형 처치 효과 추정의 이론적 기반을 제공합니다. 참고 자료 추천 도서: Golub, G. H., & Van Loan, C. F. (2013). Matrix computations. JHU press. Trefethen, L. N., & Bau, D. (1997). Numerical linear algebra. SIAM. 핵심 논문: Tikhonov, A. N. (1963). On the solution of ill-posed problems and the method of regularization. Hansen, P. C. (1998). Rank-deficient and discrete ill-posed problems: numerical aspects of linear inversion. 온라인 자료: MIT OpenCourseWare: Linear Algebra Khan Academy: Eigenvalues and Eigenvectors"
  },
  {
    "id": "Data Science/Causal Inference/Paper Review/review-Towards-R-learner-with-Continuous-Treatments",
    "title": "[Paper Review] Towards R-learner with Continuous Treatments",
    "date": "2025-07-11",
    "excerpt": "연속형 처치를 위한 R-learner를 어떻게 구현할 수 있는지에 대한 논의",
    "category": "Causal Inference",
    "tags": [
      "Paper Review"
    ],
    "content": "paper link 논문의 배경 --- Quasi-Oracle Estimation of Heterogeneous Treatment Effects 에서 개인화 처치 효과를 추정하는 방법을 제안했습니다. <small> * 개인화 처치효과 : 어떤 처치를 했을 때 개인별로 어떤 효과가 있을지 추정한 것</small> 개인화 처치효과를 추정하는 건 인과추론의 가장 핵심적인 문제이며, 이는 다양한 분야에서 통찰을 제공합니다. 예를 들어 정밀의학에서는 환자별 처치 효과를 추정하여 처치 선택을 결정하고, 교육에서는 학생별 처치 효과를 추정하여 교육 방법을 결정하고, 온라인 마케팅에서는 사용자별 처치 효과를 추정하여 맞춤형 광고를 제공하고, 오프라인 정책 평가에서는 지역별 처치 효과를 추정하여 정책을 결정할 수 있습니다. > 즉, 개인화 처치효과를 알게 되면 어떤 선택에 대한 근거를 제공할 수 있습니다. 기존 논문에서는 이진 처치의 개인화 처치효과를 추정하는 방법을 이야기했고, 이 논문에서는 이를 확장해서 연속형 처치에 대해서도 이를 적용하기 위한 방법론을 이 논문에서 이야기하고 있습니다. [[Paper Review] Quasi-Oracle Estimation of Heterogeneous Treatment Effects](/posts/Data%20Science/Causal%20Inference/Paper%20Review/review-Quasi-Oracle-Estimation-of-Heterogeneous-Treatment-Effects) <- 이 논문에 대한 리뷰는 여기서 확인할 수 있습니다. > 기존의 방법을 확장할 때 발생하는 문제와 이를 해결한 방법론에 대한 이야기에 집중해서 이 논문을 이해했습니다. 간단히 요약하면 다음과 같습니다 이진 처치에서는 처치효과를 추정하는 방법이 있었는데, 이를 연속형 처치로 확장하면 문제가 발생한다. (유일해를 가지지 않는 문제) 이를 해결하기 위해서 2가지 방법을 제안한다. Tikhonov regularization zero-constraining operator를 통해서 해결한다. 논문 내용 정리 --- Abstract --- > However, extending the R-learner framework from binary to continuous treatments introduces a non-identifiability issue, as the functional zero constraint inherent to the conditional average treatment effect cannot be directly imposed in the R-loss under continuous treatments 이 논문의 핵심 주장입니다. > binary 를 continuous로 확장하면 non-identifiability issue가 발생한다. 이걸 해결하기 위한 과정을 identification strategy라고 칭하고 있습니다. 2가지 과정을 통해 이를 구현한다고 합니다. Tikhonov regularization zero-constraining operator 왜 이슈가 발생하고 어떻게 해결했는지를 이해하는게 이 논문의 핵심이라고 이해됩니다. 그리고 이 논문에서 generalized R-loss를 정의했는데, 이 수식이 어떻게 유도되는지를 이해하는 부분도 큰 도움이 됩니다. Introduction --- > Estimating heterogeneous treatment effects is fundamental in causal inference and provides insights into various fields, including precision medicine, education, online marketing, and offline policy evaluation 개인별 처치효과를 추정하는 건 다양한 분야에서 중요한 정보를 제공해줄 수 있기에 중요한 문제입니다. The treatment effect heterogeneity can be quantified by: $$ \\begin{equation} \\tau(x, t) = E[Y^{(t)} - Y^{(0)} X = x] \\end{equation} $$ $t = 0$ : reference treatment level heterogeneous treatment effects는 conditional average treatment effect (CATE)로 정의됩니다. 이는 조건부로 처치효과를 계산한 값을 의미합니다. (환자의 조건이 x일 때의 ATE) > On the contrary, the R-learner and its variants (Kennedy, 2023) target the treatment effect estimatio Towards Optimal Doubly Robust Estimation of Heterogeneous Causal Effects 기존의 다른 연구들은 이 CATE를 직접적으로 추정하지 않았지만 R-learner 모델은 이를 직접적으로 추정하고 있습니다. > The R-learner capitalizes on the decomposition of the outcome model initially proposed by Robinson (1988) in partially linear models and extends for machine learning-based treatment effect estimation (Nie and Wager, 2021) R-learner는 partially linear model에서 제안한 수학적 분해 방법을 기반으로 삼아서 이를 머신러닝 기반 처치효과 추정으로 확장된 개념입니다. 이에 대한 간단한 정리는 What is FWL?에서 확인할 수 있습니다. 참고 논문: Robinson, P. M. (1988). Root-N-consistent semiparametric regression. Econometrica, 56(4), 931-954. [논문 링크] Nie, X., & Wager, S. (2021). Quasi-oracle estimation of heterogeneous treatment effects. Biometrika, 108(2), 299-319. [논문 링크] > Notably, when using the two nuisance functions estimated under flexible models, the R-learner preserves the oracle property of treatment effect estimation as though the nuisance functions were known. Despite these advantages, the current R-learner framework applies only to binary or categorical treatments. R-learner의 중요한 특징은 유연한 모델을 통해 두 개의 nuisance function을 추정하더라도, 마치 이 함수들이 정확히 알려진 것처럼 처치효과 추정의 oracle 성질을 유지한다는 점입니다. 하지만 이러한 장점에도 불구하고, 현재 R-learner 프레임워크는 이진형 또는 범주형 처치에만 적용할 수 있다는 한계가 있습니다. > In this article, we extend the R-learner framework to estimate the conditional average treatment effect flexibly with continuous treatments. This extension is nontrivial in both identification and estimation. Echoing the approach of Nie and Wager (2021), we focus on adapting the generalized R-learner loss function with continuous treatments. 이 논문에서는 R-learner 프레임워크를 연속형 처치에 대해서 확장해서 CATE를 추정하는 방법을 제안합니다. 이 확장은 식별과 추정 모두에서 어려운 문제입니다. Nie와 Wager (2021)의 접근 방식을 따라서 연속형 처치에 대한 일반화된 R-learner 손실 함수를 적용하는 방법을 중점적으로 다룹니다. 이진처치 ($T = 1$ or $T = 0$ 이 존재하는 경우)와 다르게 연속형일 경우에 발생하는 어려움들에 대해 이야기하며 이를 해결하기 위한 방법을 제안합니다. > Unlike the binary-treatment case, we demonstrate that directly minimizing the generalized R-loss does not uniquely identify $\\tau (x, t)$ but instead identifies a broad class of functions. 이진처치와 달리, 연속형 처치에서는 R-loss를 최소화하는 것만으로는 유일한 CATE 함수를 식별할 수 없고, 대신 함수들의 넓은 집합만을 식별할 수 있다고 설명합니다. 이것이 바로 non-identifiability issue의 핵심입니다. 이진처치의 경우 zero condition ($\\tau (x, t): \\tau (x, 0) \\equiv 0$)을 만족하는 것이 쉽지만, 연속형 처치의 경우에는 이를 만족하는 것이 쉽지 않기 때문입니다. 간단하게 설명해보면, 이진처치의 경우 zero condition을 만족하고 이게 cate function을 유일하게 추정하도록 해주지만, 연속형 처치의 경우에는 zero condition을 만족하는 것이 쉽지 않기 때문에 이를 만족하는 함수들의 넓은 집합만을 추정하게 된다고 이해할 수 있습니다. 논문에서는 이 non-identifiability 문제를 해결하기 위해 ℓ2-정규화된 R-learner를 제안합니다. 이 방법은 Tikhonov 정규화 원리를 기반으로 합니다. Tikhonov 정규화란? Tikhonov 정규화는 ill-posed problem(잘 정의되지 않은 문제)을 해결하기 위한 방법입니다. 연속형 처치에서 발생하는 non-identifiability 문제가 바로 이런 ill-posed problem의 대표적인 예입니다. 핵심 아이디어: 문제가 너무 유연해서 해가 무수히 많을 때 추가적인 제약조건(정규화)을 도입하여 해를 유일하게 만듦 수학적으로는 f ² 같은 정규화 항을 손실 함수에 추가 2단계 추정 과정 논문의 핵심은 2단계 추정 과정을 통해 문제를 해결하는 것입니다: 1단계: 중간 함수 추정 $$\\tilde{\\tau}(x, t) = \\tau(x, t) - \\mathbb{E}\\{\\tau(X, T) \\mid X = x\\}$$ 2단계: Zero-constraining operator를 통한 변환 $$\\tau(x, t) = \\text{변환}(\\tilde{\\tau}(x, t))$$ Zero-constraining operator의 역할 이 operator는 추정된 함수가 항상 zero condition을 만족하도록 보장합니다: τ(x, 0) = 0 (기준 처치 수준에서의 효과는 0) 이를 통해 유일한 해를 찾을 수 있음 Sieve 방법론 Sieve 방법은 무한차원 함수 공간을 유한차원으로 근사하는 방법입니다: 기본 아이디어: 무한차원 함수를 유한개의 기저 함수들의 선형결합으로 근사 예: 다항식, 스플라인, 푸리에 급수 등 수학적 표현: $$\\tau(x, t) \\approx \\sum_i \\beta_i \\phi_i(x, t)$$ 여기서 $\\phi_i(x, t)$는 기저 함수들입니다. 저차원 행렬과 Non-identification 일반적인 sieve 회귀와 달리, 이 논문에서는 저차원 행렬이 등장합니다. 이는 연속형 처치에서 발생하는 non-identification 문제의 수학적 표현입니다. 핵심 개념: Generalized R-loss의 non-identification 특성 때문에 행렬이 ill-conditioned가 됨 행렬의 고유값들이 0에 가까워져서 수치적 불안정성 발생 이는 행렬 교란 이론(matrix perturbation theory)과 스펙트럴 분석이 필요한 이유 자세한 이론적 배경: Ill-conditioned 행렬과 고유값: 연속형 처치 R-learner의 이론적 배경 수렴 속도의 특징 핵심 결과: > \"nuisance 함수들이 oP(n^(-1/4)) 수렴 속도로 근사될 수 있다면, 추정량의 수렴 속도는 결과 모델의 매끄러움에 의존하지 않고, 오직 CATE와 propensity score 함수의 매끄러움에만 의존한다\" 의미: 결과 모델의 복잡성에 관계없이 좋은 성능 보장 CATE와 propensity score만 잘 추정되면 됨 이는 double robustness의 연속형 버전 점근적 정규성과 추론 점근적 정규성: 추정량이 정규분포로 수렴 이를 통해 신뢰구간과 가설검정 가능 닫힌 형태 분산 추정량: 복잡한 부트스트랩 없이도 분산 계산 가능 계산 효율성 향상 참고 논문: Tikhonov, A. N. (1963). On the solution of ill-posed problems and the method of regularization. Doklady Akademii Nauk SSSR, 151(3), 501-504. [논문 링크] Bhatia, R. (2013). Matrix analysis. Springer Science & Business Media. [책 링크] Chen, X. (2007). Large sample sieve estimation of semi-nonparametric models. Handbook of econometrics, 6, 5549-5632. [논문 링크] 핵심 개념들: Ill-posed problem: 해가 유일하지 않거나 불안정한 문제 Tikhonov regularization: 정규화를 통한 ill-posed problem 해결 Sieve method: 무한차원을 유한차원으로 근사하는 방법 Matrix perturbation theory: 행렬의 작은 변화가 고유값에 미치는 영향 연구 Spectral analysis: 행렬의 고유값과 고유벡터 분석 1.1 Setup and notation 이론적 배경과 관련한 수식을 정리합니다. $\\{Z_i = (X_i, T_i, Y_i)\\}_{i=1}^n$ : independent and identically distributed samples from the distribution of $(X, T, Y)$ $X = (X^{(1)}, \\ldots, X^{(d)})$ : $d$-dimensional vector of covariates. $Y^{(t)}$ : potential outcome had the unit received treatment level $T = t \\in \\mathbb{R}$ $\\tau(x, t)$ : causal estimand defined in (1) Under Rubin's causal model framework (Rubin, 1974), $$ \\begin{equation} \\tau(x, t) = E[Y^{(t)} - Y^{(0)} X = x] \\end{equation} $$ > Due to the fundamental problem in causal inference that not all potential outcomes can be observed for a particular unit, $\\tau(x, t)$ is not identifiable without further assumptions. We employ common assumptions for continuous treatments (Kennedy et al., 2017). 인과추론에서는 모든 관측값을 확인할 수 없는 상태에서 처치효과를 추정하기 위해서 3가지의 가정이 존재합니다. Assumption 1 (No unmeasured confounding). We have $\\{Y^{(t)}\\}_{t \\in \\mathcal{T}} \\perp\\!\\!\\!\\perp T \\mid X$ Assumption 2 (Stable unit and treatment value). When $T = t \\in \\mathcal{T}$, we have $Y = Y^{(t)}$ Assumption 3 (Positivity). There exists an $\\epsilon > 0$ such that the generalized propensity score $f(T = t \\mid X = x) \\in (\\epsilon, 1/\\epsilon)$ for any $(x, t) \\in \\mathcal{X} \\times \\mathcal{T}$. Notation: For any vector $v$, $\\ v\\ $ denotes its $\\ell_2$ norm For any random variable $W \\in \\mathcal{W}$, $f(w)$ and $P(w)$ denote its probability density function and probability measure For any function $g(w)$: $P_n\\{g(W)\\} = \\frac{1}{n}\\sum_{i=1}^n g(W_i)$ denotes its empirical expectation $\\ g\\ _{L_2} = \\left\\{\\int_{w \\in \\mathcal{W}} g^2(w) dw\\right\\}^{1/2}$ denotes its $L_2$ norm $\\ g\\ _{L_2^P} = \\left\\{\\int_{w \\in \\mathcal{W}} g^2(w) dP(w)\\right\\}^{1/2}$ denotes its $L_2^P$ norm $\\ g\\ _{\\mathcal{W}} = \\sup_{w \\in \\mathcal{W}} g(w) $ denotes its $L_\\infty$ norm $L_2^P(\\mathcal{W})$ represents the function space of all $g(w)$ with a bounded $L_2^P$ norm When $g(w)$ is a multivariate function, denote $\\ g\\ _{\\mathcal{W}} = \\sup_{w \\in \\mathcal{W}} \\ g(w)\\ $ Nuisance Functions: Conditional outcome mean: $m(x) = E(Y \\mid X = x)$ Generalized propensity score: $\\varpi(t \\mid x) = f(T = t \\mid X = x)$ Full conditional outcome mean model: $$\\mu(x, t) = E(Y \\mid X = x, T = t)$$ Observation noises: $$\\varepsilon_i = Y_i - \\mu(X_i, T_i), \\quad i = 1, \\ldots, n$$ where $E(\\varepsilon_i \\mid X_i, T_i) = 0$, following the definition of $\\mu(x, t)$. Generalized R-learner --- 2.1 The generalized R-loss --- > We first generalize the idea of the Robinson's residual (Robinson, 1988; Nie and Wager, 2021) to the continuous-treatment scenario. 이번 절에서는 일반화된 R-loss를 어떻게 유도하는지에 대해 설명합니다. The unconfoundedness and stable unit and treatment value imply: $$ \\begin{equation} Y_i^{(T_i)} = \\mu(X_i, T_i) + \\varepsilon_i = \\mu(X_i, 0) + \\tau(X_i, T_i) + \\varepsilon_i \\tag{3} \\end{equation} $$ > 해석: > - 첫 번째 등식: Assumption 2와 equation (2)에서 유도 > - 두 번째 등식: Assumption 1과 $\\tau(x, t)$의 정의에서 유도 > - 특징: 비모수적 모델이며 추가적인 구조적 가정이 없음 Step 2: 조건부 기댓값 계산: Given $X_i$, taking the conditional expectation on (3) leads to: $$ \\begin{equation} m(X_i) = E\\left[Y_i^{(T_i)} \\mid X = X_i\\right] = \\mu(X_i, 0) + E_{\\varpi}\\{\\tau(X, T) \\mid X = X_i\\} \\tag{4} \\end{equation} $$ > 전체 기댓값 법칙 적용: > $$E(\\varepsilon_i \\mid X_i) = E\\left[E(\\varepsilon_i \\mid X_i, T_i) \\mid X_i\\right] = E[0 \\mid X_i] = 0$$ 일반화된 Propensity Score 기댓값: The notation $E_{\\varpi}\\{\\tau(X, T) \\mid X = X_i\\}$ in (4) highlights the dependency of the conditional expectation on the generalized propensity score as: $$E_{\\varpi}\\{\\tau(X, T) \\mid X = X_i\\} = \\int_{t \\in \\mathcal{T}} \\tau(X_i, t) \\varpi(t \\mid X_i) dt$$ > 핵심: 연속형 처치에서는 적분을 통해 모든 처치 수준에 대한 가중 평균을 계산 Step 3: 잔차 도출: By subtracting (4) from (3) on both left- and right-hand sides, we have: $$ \\begin{equation} Y_i^{(T_i)} - m(X_i) = \\tau(X_i, T_i) - E_{\\varpi}\\{\\tau(X, T) \\mid X = X_i\\} + \\varepsilon_i \\tag{5} \\end{equation} $$ > 해석: > - 좌변: 관찰된 결과에서 조건부 평균을 뺀 값 (Robinson's residual) > - 우변: 처치효과에서 평균 처치효과를 뺀 값 + 노이즈 Step 4: 손실 함수 도출: By treating the left-hand side of (5) as the response and the right-hand side except $\\varepsilon_i$ as the mean function, we derive the following population loss function: $$ \\begin{equation} L_c(h) = E\\left[\\left\\{Y - m(X) - h(X, T) + E_{\\varpi}\\{h(X, T) \\mid X\\}\\right\\}^2\\right] \\tag{6} \\end{equation} $$ > 핵심 특징: > - 최적해: $h = \\tau$에서 최소화됨 > - 일반화: 이진 처치 R-learner의 자연스러운 확장 > - 참고: Nie and Wager (2021, §7)의 다중 처치 설정에서 유사한 손실함수 등장 이진 처치와의 연결: > In particular, under the binary-treatment case, $\\tau(x, t)$ reduces to $\\{\\tau(x, 0), \\tau(x, 1)\\}$, where $\\tau(x, 0) = E(Y^{(0)} - Y^{(0)} \\mid X = x) = 0$ for any $x \\in \\mathcal{X}$, and $\\tau(x, 1)$ is the conditional average treatment effect of interest. It suffices to estimate $\\tau(x, 1)$ by solving the $h(\\cdot, 1)$ that minimizes (6), after imposing a zero condition of $h(\\cdot, 0)$: $$ \\begin{equation} h(x, 0) = 0, \\quad \\text{for any } x \\in \\mathcal{X} \\tag{7} \\end{equation} $$ > Zero condition: 기준 처치 수준에서의 효과는 0으로 설정 이진 처치 R-loss로의 환원: 유도된 일반화된 R-loss가 기존의 이진 처치에서의 loss function으로 유도될 수 있음을 설명합니다. > More specifically, observing that under (7) one has $h(X, T) - E_e\\{h(X, T) \\mid X\\} = \\{T - e(X)\\}h(X, 1)$ a.s., where $e(x) = \\text{pr}(T = 1 \\mid X = x)$ is the propensity score, the R-loss function (6) reduces to: $$ \\begin{equation} L_b(h) = E\\left[\\left\\{Y - m(X) - \\{T - e(X)\\}h(X, 1)\\right\\}^2\\right] \\tag{8} \\end{equation} $$ > 핵심: > - 조건: $h(x, 0) = 0$ (zero condition) > - 결과: $h(X, T) - E_e\\{h(X, T) \\mid X\\} = \\{T - e(X)\\}h(X, 1)$ > - 의미: 일반화된 R-loss가 이진 처치의 고전적 R-loss로 환원됨 > 핵심: T가 1 or 0인 상황에서 zero condition을 고려해 (6)번 수식을 전개하면 기존의 이진 처치에서의 손실함수 수식과 같은 (8)번 수식을 얻을 수 있습니다. 2.2 Non-identification of the generalized R-loss --- > The R-learner for continuous treatment will have poor estimation performance, due to the non-unique identifiability of the generalized R-loss 핵심 문제: 이 절에서는 non-identification 문제에 대해 설명합니다. 연속형 처치에서 일반화된 R-loss를 직접 최소화하면 유일한 해를 찾을 수 없다는 것이 핵심 문제입니다. 해집합 정의: $$ \\begin{equation} S = \\{h \\mid h(X, T) = \\tau(X, T) + s(X) \\text{ a.s., for any } s \\in L_2^P(X)\\} \\tag{9} \\end{equation} $$ > 해석: $S$는 목표 함수 $\\tau(X, T)$에 공변량 $X$의 함수 $s(X)$를 더한 모든 함수들의 집합 검증 과정: > It is easy to check that for any $h \\in S$: $$ Y - m(X) - [h(X, T) - E_{\\varpi}\\{h(X, T) \\mid X\\}] = Y - m(X) - [\\tau(X, T) - E_{\\varpi}\\{\\tau(X, T) \\mid X\\}] \\text{ a.s.} $$ > 의미: $S$에 속한 모든 함수 $h$가 동일한 손실값을 가짐 Non-identification 문제: > From (6), any function $h \\in S$ minimizes the generalized R-loss $L_c(\\cdot)$. Therefore, when $T$ is continuous, directly minimizing the generalized R-loss fails to uniquely identify the target estimand $\\tau(x, t)$, as there are infinitely many solutions in $S$. > 핵심 문제: > - 연속형 처치에서는 무한히 많은 해가 존재 > - 유일한 CATE 함수를 식별할 수 없음 > - 이는 ill-posed problem의 전형적인 예 이론적 근거: > This result theoretically substantiates the ill-posedness of estimating $\\tau(x, t)$ by minimizing the empirical counterpart of $L_c(\\cdot)$ using nonparametric estimators, and also explains the failure-to-estimate issue illustrated in Fig. 1. > Part (i) of Proposition 1 below rigorously proves that $S$ in fact contains all minima of $L_c(\\cdot)$ in $L_2^P(X, T)$. 이진 처치와의 대비: > In contrast, minimizing the binary-treatment R-loss (8) which incorporates the zero condition (7), can successfully identify $\\tau$, because (7) narrows the general solution set $S$ into: $$ \\begin{equation} S^\\natural = \\{h \\mid h(X, T) = \\tau(X, T) \\text{ a.s.}\\} \\tag{10} \\end{equation} $$ > 핵심 차이: > - 연속형: $S$ (무한히 많은 해) > - 이진형: $S^\\natural$ (유일한 해) > - 원인: Zero condition (7)이 해집합을 좁혀줌 Proposition 1 - Suppose Assumptions 1–2 hold. Then, the following statements hold: 이 부분은 generalized loss function (6) 을 최소화하면 h는 다양한 해를 가지지만, zero-condition을 녹여내 정리한 binary loss function (8) 을 최소화하면 h는 유일한 해를 가진다는 것을 보여줍니다. > Part (i): 처치 T가 연속형인 경우, S는 다음 최적화 문제의 해답해다. > - 최적화 문제: $$ \\begin{equation} \\arg\\min_{h \\in L_2^P(X,T)} L_c(h) \\tag{11} \\end{equation} $$ > - 해집합: $S$ > Part (ii): 처치 T가 이진형인 경우, S는 다음 최적화 문제의 해답해다. > - 최적화 문제: $\\arg\\min_{h \\in \\mathcal{L}_b} L_b(h)$ > - 해집합: $S^\\natural$ > 결과: 관심 함수들의 집합 $\\mathcal{L}_b = \\{h \\mid h(\\cdot, 1) \\in L_2^P(X) \\text{ and } h(X, 0) = 0 \\text{ a.s.}\\}$ 중에서, (10)의 $S^\\natural$가 다음 최적화 문제의 해집합이다: > - 최적화 문제: $\\arg\\min_{h \\in \\mathcal{L}_b} L_b(h)$ > - 해집합: $S^\\natural$ > 의미: 이진형 처치에서는 zero condition이 적용된 R-loss $L_b(h)$의 최소화가 유일한 해 $S^\\natural$를 제공 핵심 차이점: 구분 연속형 처치 이진형 처치 ------ ------------- ------------- 최적화 문제 $\\arg\\min_{h \\in L_2^P(X,T)} L_c(h)$ $\\arg\\min_{h \\in \\mathcal{L}_b} L_b(h)$ 해집합 $S$ (무한히 많은 해) $S^\\natural$ (유일한 해) 제약조건 없음 $h(X, 0) = 0$ (zero condition) 식별 가능성 ❌ 불가능 ✅ 가능 2.3 One-step nonparametric identification with a functional zero constraint > 이진 처치의 경우 zero-condition를 loss function에 녹여낼 수 있어 유일해를 얻을 수 있었지만, 연속 처치의 경우 유일해를 얻지 못한다. 그럼 optimization problem을 풀 때 zero condition을 적용하면 되지 않을까? 라고 생각해볼 수 있습니다. $$ \\begin{equation} \\arg \\min_{h \\in L_2^P(X,T) \\cap \\{h \\mid h(x,0) = 0 \\text{ for any } x \\in \\mathcal{X}\\}} L_c(h) \\tag{12} \\end{equation} $$ 그러나 Proposition 2는 이 전략도 $\\tau(x, t)$의 비모수적 식별을 달성하는 데 계속 실패한다는 것을 보여줍니다. Proposition 2. Assumptions 1–2가 성립하고, $(X, T)$가 유계 밀도함수를 가진다고 가정하자. 즉, $$\\sup_{(x,t) \\in \\mathcal{X} \\times \\mathcal{T}} f(x, t) < \\infty$$ $\\tau^{\\vee}(x, t \\mid s)$를 다음과 같은 형태를 취하는 함수라고 하자: $$ \\begin{equation} \\tau^{\\vee}(x, t \\mid s) = \\begin{cases} \\tau(x, t) + s(x) & \\text{when } t \\neq 0 \\\\ 0 & \\text{when } t = 0 \\end{cases} \\tag{13} \\end{equation} $$ 여기서 $s$는 $L_2^P(X)$의 임의의 함수이다. 그러면 임의의 $s \\in L_2^P(X)$에 대해 $\\tau^{\\vee}(x, t \\mid s)$는 (12)를 해결한다. > 핵심: 임의의 $\\tau^{\\vee}(x, t \\mid s)$는 zero condition (7)을 만족하면서도 여전히 집합 $S$에 속할 수 있다. 즉, zero condition을 최적화문제에 강제로 적용해도 $t \\neq 0$인 부분에서는 여전히 같은 non-identification 문제를 보이고 있습니다. 2.4 Two-step Tikhonov identification and ℓ₂ regularization R-learner --- 2.3에서 강제로 zero condition을 적용해서 문제를 해결하는데 실패했고, 이제 정규화항을 도입해 문제를 해결하는 방법을 제안합니다. Step I: 모집단 수준에서 주어진 $\\rho > 0$에 대해 (11)의 $\\ell_2$-정규화 변형을 해결합니다: $$ \\begin{equation} \\tau_\\rho = \\arg \\min_{h \\in L_2^P(X,T)} L_{c,\\ell_2}(h \\mid \\rho) = \\arg \\min_{h \\in L_2^P(X,T)} \\left[ L_c(h) + \\rho \\ h\\ _{L_2^P}^2 \\right] \\tag{14} \\end{equation} $$ > The new loss $L_{c,\\ell_2}(h \\mid \\rho)$ is strictly convex over $L_2^P(X, T)$ due to the addition of a strictly convex functional $\\rho \\ h\\ _{L_2^P}^2 = \\rho E\\{h^2(X, T)\\}$. > Thus minimizing $L_{c,\\ell_2}(h \\mid \\rho)$ becomes well-posed and yields a unique functional minimum $\\tau_\\rho$. Theorem 1 explicitly characterizes this unique minimum. 강한 (엄격한) convex function을 loss function에 추가하여, loss function을 convex하게 만들어 문제를 해결할 수 있다는 이야기입니다. 이론적 배경: Tikhonov regularization과 convex optimization의 자세한 원리는 Tikhonov Regularization과 Convex Optimization에서 확인할 수 있습니다. Theorem 1. 집합 $S$ 내에서 다음과 같은 중간 함수를 정의하자: $$ \\begin{equation} \\tilde{\\tau}(x, t) = \\tau(x, t) - E\\{\\tau(X, T) \\mid X = x\\} \\tag{15} \\end{equation} $$ Assumptions 1–2가 성립하고 $\\tau \\in L_2^P(X, T)$일 때, 주어진 $\\rho > 0$에 대해 (14)의 해집합은 다음과 같다: $$S_\\rho = \\{h \\mid h(X, T) = \\tau_\\rho(X, T) \\text{ a.s.}\\}$$ 여기서 $$\\tau_\\rho(x, t) = (1 + \\rho)^{-1} \\tilde{\\tau}(x, t)$$ Theorem 1의 의미: Theorem 1은 $\\tau_\\rho$에 $(1 + \\rho)$ 인수를 곱하여 집합 $S$ 내의 중간 함수 $\\tilde{\\tau}$를 식별할 수 있음을 의미합니다: $$\\tilde{\\tau} = (1 + \\rho)\\tau_\\rho$$ 이 $\\tilde{\\tau}$는 원래 R-loss $L_c(h)$의 해가 됩니다. Step II: Zero-constraining Operator Step II에서는 $\\tilde{\\tau}$를 zero-constraining operator $\\mathcal{C}(\\cdot): L_2^P(X, T) \\to L_2^P(X, T)$를 통해 변환합니다: $$ \\begin{equation} \\mathcal{C}(h)(x, t) = h(x, t) - h(x, 0) \\quad \\text{for any } h \\in L_2^P(X, T) \\end{equation} $$ 따라서: $$\\mathcal{C}(\\tilde{\\tau})(x, t) = \\mathcal{C}((1 + \\rho)\\tau_\\rho)(x, t) = (1 + \\rho)\\{\\tau_\\rho(x, t) - \\tau_\\rho(x, 0)\\}$$ Zero-constraining Operator의 역할: Zero-constraining Operator의 핵심 원리: 연산자 $\\mathcal{C}(\\cdot)$는 변환을 거치는 모든 함수가 zero condition (7)을 만족하도록 보장 $\\tau$는 집합 $S$에서 zero condition (7)을 만족하는 유일한 함수 따라서 해집합 $S$의 임의 함수를 변환하면 $\\tau$를 식별할 수 있음 $\\tilde{\\tau} \\in S$이므로, Step II의 $\\mathcal{C}(\\tilde{\\tau})$는 궁극적으로 $\\tau$를 식별함 > 핵심: 2단계 과정을 통해 non-identification 문제를 해결하고 유일한 CATE 함수 $\\tau(x, t)$를 추정할 수 있습니다. Supplementary material for \"Towards R-learner with Continuous Treatments\" S1 : $l_2$ regularization R-learner : Formal algorithm and more discussions 논문에서 의문이 들었던 부분들 정리 --- 왜 이진 처치에서는 Zero Condition이 적용되고, 연속 처치에서는 적용되지 않을까? 이진 처치에서의 Zero Condition 이진 처치의 특성: 처치 수준: $T \\in \\{0, 1\\}$ (이산적) 목표: $\\tau(x, 1)$ (처치 효과)만 추정 기준점: $T = 0$ (통제 그룹) Zero Condition의 자연스러운 적용: $$\\tau(x, 0) = E[Y^{(0)} - Y^{(0)} \\mid X = x] = 0$$ > 이유: > - $T = 0$은 \"처치를 받지 않은 상태\"를 의미 > - 같은 상태에서의 차이는 당연히 0 > - 이는 자연스러운 제약조건이 됨 수학적 효과: 해집합 $S$에서 $h(x, 0) = 0$ 조건을 추가 $S^\\natural = \\{h \\mid h(X, T) = \\tau(X, T) \\text{ a.s.}\\}$로 축소 유일한 해 보장 연속 처치에서의 문제 연속 처치의 특성: 처치 수준: $T \\in \\mathbb{R}$ (연속적) 목표: $\\tau(x, t)$ for all $t \\in \\mathcal{T}$ (모든 처치 수준에서의 효과) 기준점: $T = 0$이 임의적일 수 있음 Zero Condition 적용의 한계: > $L_b$를 통해 이진처치에서는 zero-condtion을 loss 함수에 녹여낼 수 있었는데, 연속형에서는 이를 loss function에 녹여낼 수 없다. 문제는 “zero condition을 R-loss 안에서 직접 구현하기 어렵다”는 점입니다. Binary T에서는 T∈{0, 1}이라 (T-e(X))h(X,1) 형태로 식을 재정리하면 h(x,0)=0이 자동으로 내재됩니다. 핵심 차이점 요약 구분 이진 처치 연속 처치 ------ ----------- ----------- 처치 특성 이산적 $\\{0, 1\\}$ 연속적 $\\mathbb{R}$ 기준점 $T = 0$ (자연스러움) $T = 0$ (임의적) Zero Condition 수식에서 쉽게 강제 가능 무한차원 제약 → 구현 난이도 높음 해집합(이론) $S^\\natural$ (유일) $S$ (무한) 식별 가능성(실전) ✅ 가능 ❌ 추가 장치 필요 \"h(x, 0)=0만 강제하면 되지 않나?\" – 왜 실전에서는 안 통할까? --- 수학적으로는 $h(x,0)=0$을 정확히 부과하면 $s(x)=−\\tau(x,0)=0$이 되어 해가 유일합니다. 문제는 모델 학습 단계에서 이 무한차원 제약을 그대로 구현하기 어렵다는 점에 있습니다. 실무에서는 $h$를 신경망·트리·커널 등 유연한 함수 근사기로 파라미터화하고, 손실을 확률적 경사하강법으로 최소화합니다. 이때 “$t=0$에서 반드시 0”이라는 제약을 네트워크 출력 전체에 강제하기가 쉽지 않습니다. 그래서 학습 과정에서는 $\\hat{h}(x,t) = \\tau(x,t) + s(x)$ 꼴의 함수도 손실을 동일하게 만들 수 있습니다. 이유: R-loss 안의 $E[h(X,T)\\mid X]$ 항에서 $s(x)$가 상쇄되기 때문입니다. 즉, zero condition을 코드에 명시하지 않으면 여전히 식별 실패(ill-posed)가 발생합니다. 따라서 저자들은 다음과 같은 두 단계 절차를 제안합니다. 1단계: 제약 없이 $\\tilde{h}$를 학습 2단계: 특수한 사상(\"zero-constraining operator\")으로 $\\tilde{h}$를 $t=0$에서 0이 되도록 변환 추가로 Tikhonov 정규화를 넣어 수치적 안정성을 확보합니다. 왜 theorem 1에서 중간함수를 정의하는거지? 왜 굳이 ‘중간 함수(tilde tau)’를 한 번 더 정의하느냐를 한마디로 요약하면 다음과 같아요. 비식별(non-identification)의 원인 R-loss를 그대로 최소화하면 $$h(x,t) = τ(x,t) + s(x)$$ 처럼 “x 에만 의존하는 함수”가 얼마든지 덧붙어도 손실값이 똑같습니다. 이 s(x) 때문에 최소값이 무한히 많아져서 해가 유일하지 않아요. 아이디어: ‘x 평균을 0으로 만드는’ 함수로 중심화(center)하기 s(x)는 t 와 무관합니다. 그렇다면 τ 에서 “x 에 따른 평균치”만 쏙 빼버리면 s(x)가 더 이상 붙을 수 없겠죠? 그게 바로 $$\\tilde{\\tau}(x,t) = \\tau(x,t) − E[ \\tau(X,T) X=x ]$$ 입니다. 이렇게 하면 tilde tau 는 어떤 x 에 대해서도 t 값 전체를 평균 내면 0 이 됩니다. 즉 “덧붙일 수 있는 s(x)” 여지가 사라집니다. Why Do We Introduce the Centered Function tilde_tau(x,t)? 정규화와의 연결 L2 정규화(Tikhonov)로 $$argmin_h { R-loss(h) + \\rho‖h‖_2^2 }$$ 를 풀면 유일한 해 $\\tau_\\rho$ 가 나옵니다. Theorem 1 은 “그 유일한 해가 바로 tilde tau 를 (1+ρ) 로 나눈 것”임을 보여줍니다. 즉 $\\tilde{\\tau} = (1+\\rho)\\tau_\\rho$. 결국 1단계에서 정규화로 유일하게 찾은 τ_ρ 로부터 2단계에서 다시 (1+ρ)을 곱해 tilde tau 를 복원하고, 마지막으로 zero-constraining operator 로 원래 τ 를 얻습니다. 한 줄 결론 중간 함수 tilde tau 를 쓰는 이유는 “x 에만 의존하는 불필요한 s(x)를 제거해 식별 문제를 깨끗하게 만들어 주기”입니다. 그렇게 중심화한 뒤 정규화를 걸어야 유일한 해를 안전하게 찾을 수 있어요. 추정값이 작아지는 걸 보완하기 위해 (1+ρ)을 곱하는 이유 아래 순서대로 ‘왜 (1 + ρ)를 곱해야 하나?’를 처음부터 다시 풀어볼게요. (여기서 ρ는 정규화 세기, p라고 쓰였던 기호입니다.) ────────────────── 아주 단순한 1-차원 예로 시작 ────────────────── • 목표 : 어떤 “진짜 값” θ 를 알아내고 싶다. • 하지만 문제(데이터)가 불안정해서 정규화를 넣어 풀기로 했다. 정규화된 최소화 문제 (평균제곱오차 + ρ × 값^2) ↓ F(h) = (h − θ)² / 2 + ρ h² → 여기서 h가 우리가 구할 추정치. ────────────────── 이 문제를 직접 풀어보자 ────────────────── F(h)를 h에 대해 미분해서 0으로 두면 (h − θ) + 2ρh = 0 ⇒ h (1 + 2ρ) = θ ⇒ h = θ / (1 + 2ρ) ※ 논문·포스트에서는 2 대신 1이 붙도록 (1/2)계수 등으로 맞춰 놓았기 때문에 최종계수는 “1 + ρ”가 됩니다. 이름만 다르고 본질은 같아요. 결국 정규화를 넣고 최소화하면 h = θ / (1 + ρ) 즉, 진짜 값이 (1 + ρ)배만큼 작아져 버린 결과를 얻는다. ────────────────── 왜 작아지나? 직관 ────────────────── • 정규화 항 ρ h² 는 “h 값을 0에 가깝게 끌어당기는 스프링” 같은 역할. • 손실식은 ① (h−θ)² → “진짜 값 θ와 가까워져라” ② ρ h² → “값이 클수록 페널티, 0이 좋다” 두 힘의 타협점이 θ의 축소판 h = θ/(1+ρ) 로 나타난 것. ────────────────── 축소(shrinkage) 편향을 어떻게 없앨까? ────────────────── 방법은 간단하다. 정규화를 넣어서 얻은 결과 h를 다시 (1 + ρ)배 키워 주면 된다. θ (원래 값) = (1 + ρ) × h (정규화 해) 그래서 정규화 뒤 보정 단계에서 (1 + ρ)를 곱한다. ────────────────── 함수(tilde τ, τρ) 로 돌아와서 ────────────────── • 함수 전체가 스칼라 θ 대신 “tilde_tau(x,t)” 라고 생각하면 위 계산이 점마다 동시에 일어난다. • 정규화가 끝나고 얻은 함수 τρ(x,t)는 tilde_tau(x,t) / (1 + ρ). • 그러므로 원하는 tilde_tau를 되찾으려면 tilde_tau = (1 + ρ) · τρ. ← 바로 이 식이었죠. ────────────────── ‘꼭 곱해야 하나?’에 대한 결론 ────────────────── • 절대 크기가 중요한 문제(예: 의약 용량, 가격 책정)라면 축소된 값을 그대로 쓰면 효과를 과소평가 → 잘못된 의사결정. • ρ가 아주 작아서 (1+ρ) ≈ 1 라면 생략해도 큰 영향은 없음. • 그러나 일반적으로는 정규화 → 축소 → (1+ρ) 배 되돌리기 순서를 지켜 주는 것이 편향 없는 추정을 보장한다. 즉, (1 + ρ)를 곱해 주는 이유는 “정규화가 만든 ‘축소 편향’을 정확히 반대로 상쇄해 원래 스케일(tilde_tau), 더 나아가 최종 τ(x,t)을 되찾기 위해서”입니다."
  },
  {
    "id": "Self_Development/English Study/SPEAK/지나간달/07-10-격려와신뢰한다는표현",
    "title": "격려와 신뢰한다는 표현",
    "date": "2025-07-10",
    "excerpt": "",
    "category": "English Study",
    "tags": [
      "영어공부꾸준히!",
      "SPEAK",
      "칭찬하는 표현들"
    ],
    "content": "오늘 배운 것들 정리 I believe in you. I believe in your ability to come out ahead. I believe in your ability to stay focused. I believe in your ability to persevere. You've made it this far. You're almost there. 간단한 작문 As I did yesterday (어제처럼), I wanna talk to myself. Because I need some 격려. I believe in you MK. I believe in your ability to come out ahead. 지금은 힘들더라도, you will made it. Youve made it this far. Just focus on today, one step ahead. Youre almost there. 피드백 잘한 점들 ✨ 학습한 표현 활용: 오늘 배운 \"I believe in you\" 시리즈를 실제 작문에 바로 적용한 점이 훌륭합니다 감정 표현: 자신에게 격려가 필요하다는 솔직한 마음을 영어로 표현한 것이 자연스럽습니다 개인적 메시지: MK라는 이름을 넣어서 더 개인적이고 진심어린 느낌을 만들어냈습니다 개선할 부분 🔧 문법 오류: you will made it → you will make it (동사원형 사용) Youve → You've (올바른 아포스트로피 사용) 어조 통일: wanna → want to (좀 더 격식있는 표현) 한영 혼용을 좀 더 자연스럽게 표현 개선: one step ahead → one step at a time` (더 일반적인 표현) 수정 제안 📝 원문 유지하되 이렇게 쓸 수도 있어요: As I did yesterday, I want to talk to myself in English. Because I need some encouragement right now. I believe in you, MK. I believe in your ability to come out ahead. Even though it's tough right now, you will make it through. You've made it this far, and that's already incredible. Just focus on today, one step at a time. You're almost there. 총평 💭 영어로 자신에게 격려하는 습관이 정말 좋습니다! 배운 표현을 바로 사용하려는 적극성이 인상적이에요. 문법적인 부분만 조금씩 다듬어가면 더욱 자연스러운 영어 표현력을 기를 수 있을 것 같습니다. 계속 이런 식으로 연습하세요! 🌟"
  },
  {
    "id": "Self_Development/Career/Job Transition/25-07-10-lunit-cancer-screening",
    "title": "(Seoul) Research Engineer · AutoML ",
    "date": "2025-07-10",
    "excerpt": "루닛 채용공고 분석과 준비과정",
    "category": "Career",
    "tags": [
      "루닛 채용공고"
    ],
    "content": "채용공고 <details> <summary>📋 <strong>채용공고 상세정보</strong></summary> 링크 Lunit, a portmanteau of ‘Learning unit,' is a medical AI software company devoted to providing AI-powered total cancer care. Our AI solutions help discover cancer and predict cancer treatment outcomes, achieving timely and individually tailored cancer treatment. 🗨️ About The Team AutoML team at Lunit automates AI product development processes to streamline time-consuming tasks and advance cutting-edge AutoML research. By combining engineering expertise with state-of-the-art deep learning techniques, our team plays an important role in accelerating product development for cancer detection and treatment. Join us in our mission to Conquer Cancer Through AI where your contributions will directly influence AI innovations that improve patient outcomes worldwide In short, we're a team that maximizes AI tech to create AI models with extreme efficiency 🗨️ About The Position As a research engineer, you will work closely with the team to develop and optimize platforms for automating medical AI model research workflows Your responsibilities will involve implementing an automated product development framework for the medical domain, covering data ingestion, model training, packaging and inference You will collaborate with both research and engineering teams to bring cutting-edge AI research into real-world applications This position is ideal for someone with a strong research engineering background and deep understanding of the AI model development process 🚩 Roles & Responsibilities Develop and implement tailored AutoML platforms to automate medical AI model research workflows Integrate AutoML pipelines into AI agent which includes data ingestion, model training, hyperparameter optimization and inference Enhance the maintainability, reliability, and efficiency of both new and existing frameworks Build robust AI infrastructure using Kubernetes, Docker, and cloud computing services (GCP, AWS, Azure) Keep up with the latest advancements in AI agents, LLMs, and AutoML research to drive innovation 🚩 Tools Used Development Related: Django, Django REST Framework, React, Next.js, MySQL, PostgreSQL, Redis, Celery, Nginx, Go ML framework: PyTorch, Optuna Infrastructure: Google Cloud Platform, Kubernetes, Git, Docker, Helm, ArgoCD, Terraform General: Slack, Confluence, Jira Requirements 🎯Qualifications 3+ years of experience in research engineering in the AI industry Master's, or Ph.D. in Computer Science or a related field Proficiency in Python, unit/integration testing, documentation, Git, collaborative code development, and Docker Solid knowledge of software design and system architecture, with a strong understanding of RESTful API design Hands-on experience with developing and operating scalable AI platforms and infrastructure, including DevOps Effective communication skills: Ability to clearly and efficiently convey information, thoughts, and ideas to other developers Proven ability to take ownership and drive projects from concept to deployment Highly responsible and detail-oriented, with a strong motivation to build high-quality, reliable solutions in line with current best practices 🏅 Preferred Experiences Familiarity with web development, including both backend and frontend Deep insight into automating and orchestrating ML workflows Experience in designing or developing automated AI platforms Experience in designing or developing AI agents or LLM-based automation (e.g., fine-tuning, prompt engineering) Knowledge of cloud computing services (GCP, AWS, or Azure) Publications in AI or computer vision conferences, or active participation in the research community Ability to collaborate effectively as a team player in a cross-functional research-engineering environment Proactive in sharing knowledge, initiating collaborations, and promoting a positive research environment Passion for high-quality programming and software engineering to produce and maintain reliable code for the training and evaluation of models 📝 How To Apply CV (resume, free format) 🏃‍♀️ Hiring Process Document Screening → Technical Interview(Teams) → Assignment → PT Interview → Culture-fit Interview → Onboarding After the final interview, we may proceed with reference checks if needed. 🤝 Work Conditions and Environment Work type: Full Time Work location : Lunit HQ (5F, 374, Gangnam-daero, Gangnam-gu, Seoul) Salary: After Negotiation 🎸 ETC If you misrepresent your experience or education or provide false or fraudulent information in or with your application, it may be grounds for cancellation of the employment Lunit is committed in providing the preferential processing to those eligible for employment protection (national merits and people with disabilities) relevant to related laws and regulations Benefits 🌻 Benefits & Perks The office is at a very convenient location, just a minute away from Gangnam Station Exit 3 Meal Allowance is provided (up to 12,000 KRW per meal) when working at the office Up to 300,000 KRW is covered upon joining to decorate your personal workspace Latest computer models, such as Macs and 4K monitors are provided and can be renewed every three years Seminar registration fees and book purchases are covered Regular in-house AI and medical seminars are held Korean lessons are provided for Lunitians who do not speak Korean as their first language In-house English lessons (aka Luniversal) is provided for English development Access to high-quality AI learning resources & deep learning DevOps system Up to 1.2 million KRW worth of benefits points can be claimed annually Holiday Allowances are provided in the form of gifts or vouchers for Korean National holidays, Seollal and Chuseok Congratulatory and Condolence allowances, along with paid time off are provided Annual medical checkups and employee accident insurance are provided Expenses for monthly employees gatherings are partially covered </details> 준비해야하는 것들 일단 내 분야와 겹치는 의료쪽 채용공고고, 여기서 했던 ML개발들에 대한 경험을 살릴 수 있겠다. 이것도 이번주 주말에 이거에 맞게 이력서 쓰기. 여기에 너가 생각하는 준비하면 좋은 것들 추가해줘 🎯 핵심 준비사항 AutoML 전문성 강화 Optuna 실습: 하이퍼파라미터 최적화 프레임워크 경험 쌓기 AutoML 파이프라인: MLflow, DVC 등을 활용한 ML 워크플로우 자동화 경험 Neural Architecture Search (NAS) 관련 논문 및 구현 경험 Meta-learning 기초 개념 학습 의료 AI 도메인 지식 의료 영상 분석: DICOM 포맷, 의료 영상 전처리 기법 학습 Cancer detection papers: 루닛의 주요 논문들 읽어보기 (arXiv, 의료 AI 컨퍼런스) FDA 승인 AI 의료기기: 규제 요구사항 및 품질 관리 기준 이해 Medical imaging datasets: ChestX-ray, MIMIC 등 공개 데이터셋 경험 인프라/DevOps 스킬 업그레이드 Kubernetes 실습: 로컬 클러스터 구축 및 ML 워크로드 배포 Docker 고급 활용: Multi-stage builds, 최적화 기법 Cloud ML 서비스: GCP AI Platform, Vertex AI 실습 CI/CD for ML: GitHub Actions로 모델 학습/배포 파이프라인 구축 웹 개발 스킬 (Preferred 요구사항) Django REST Framework: API 개발 실습 React/Next.js 기초: 간단한 ML 모델 데모 페이지 구축 데이터베이스: PostgreSQL, Redis 활용 경험 포트폴리오 프로젝트 제안 의료 영상 AutoML 플랫폼: 간단한 AutoML 시스템 구축 MLOps 파이프라인: 모델 학습부터 배포까지 자동화 API 서버: ML 모델 서빙 REST API 개발 Kubernetes 배포: 위 프로젝트들을 K8s로 배포 이력서 작성 포인트 정량적 성과: 모델 성능 개선, 처리 시간 단축, 인프라 비용 절감 등 수치로 표현 의료 AI 관련 경험: 직접적이지 않더라도 헬스케어 데이터 다룬 경험 강조 AutoML/MLOps 키워드: 파이프라인 자동화, 모델 최적화 경험 부각 협업 경험: 연구팀과 개발팀 간 브릿지 역할 경험 면접 준비 기술 면접: AutoML 개념, PyTorch 심화, 시스템 설계 문제 과제: 간단한 AutoML 파이프라인 구현 또는 의료 영상 분석 태스크 예상 PT 면접: 본인의 프로젝트를 AutoML 관점에서 설명할 수 있도록 준비 컬처핏: 의료 AI로 환자에게 도움이 되고 싶다는 동기, 연구와 개발 사이의 균형감 추가 학습 자료 논문: \"Efficient Neural Architecture Search via Parameter Sharing\" (ENAS) 책: \"Hands-On Machine Learning\" (AutoML 챕터) 강의: CS330 (Stanford Meta-Learning), MLOps 관련 온라인 강의 블로그: Google AI Blog의 AutoML 관련 포스트들 네트워킹 의료 AI 커뮤니티: 한국 의료 AI 학회, 관련 밋업 참여 루닛 직원: LinkedIn으로 현직자와 커피챗 요청 컨퍼런스: MICCAI, SPIE Medical Imaging 등 의료 AI 컨퍼런스 논문 읽기 📅 주차별 준비 계획 (4주 가정) 1주차: AutoML 기초 학습 + Optuna 실습 2주차: 의료 AI 논문 리뷰 + Docker/K8s 실습 3주차: 포트폴리오 프로젝트 구현 4주차: 이력서 완성 + 면접 준비 나의 관련 직무경험과 필살기 준비하기"
  },
  {
    "id": "Self_Development/Career/Job Transition/25-07-10-hyundai-autoever",
    "title": "현대 오토에버 MLOps / AI 검색 엔지니어",
    "date": "2025-07-10",
    "excerpt": "현대 오토에버 채용공고 분석과 준비과정",
    "category": "Career",
    "tags": [
      "현대 오토에버 채용공고"
    ],
    "content": "채용공고 <details> <summary>📋 <strong>채용공고 상세정보</strong></summary> [Tech] Machine Learning Engineer - MLOps / AI 검색 엔지니어 📃 누구나 ​마음 ​속에 ​이력서 한 ​장은 있으니까, ⚡ 1분 ​컷 ​지원으로 현대오토에버로의 ​여정을 시작하세요. (이력서 ​자율양식) ✅ MLOps ​/ ​AI 검색 엔지니어 🚀 ​합류하실 ​팀을 ​소개해요 언어AI기술팀 💻 합류하시면 함께 ​할 ​업무예요 AI 대화형 서비스를 ​위한 ​데이터베이스 ​설계 및 개발 AI ​검색 엔진 ​개발 ​및 운영 MLOps ​구축 및 ​운영 🔍 ​이런 분과 함께 ​하고 싶어요 검색 ​/ 챗봇 관련 모듈 및 서비스 개발 경험 Docker / Kubernetes 활용 개발 및 배포 경험 Python / JAVA 개발 경력 3년 이상 혹은 그에 준하는 실력 🔍 이런 분이라면 더욱 좋아요 정보검색/SW공학 관련 석사 이상 ELK(Elasticsearch, Kibana, Kubernetes, Kafka) 구성 설계 및 운영 경험자 Neo4j / Redis 기반 DB 설계 및 구축 경험자 벡터 DB (Milvus / qdrant / faiss 등) 경험자 ES 플러그인 개발 경험자 ⌛ 이렇게 합류해요 서류 접수 → 서류 검토 → 직무역량테스트(코딩 또는 과제테스트) 및 인성검사 → 1차면접 → 2차면접 → 처우협의 및 채용검진 → 최종 합격🎉 📍 만나게 될 근무지는 여기예요 서울 강남 📌 참고해 주세요 채용 시 마감되는 상시 채용 공고로 운영되며, 채용 절차와 일정은 변동될 수 있어요. 사회적 배려 대상자(보훈 취업지원대상자, 장애인)는 관계 법령과 내규에 따라 우대해요. 모집 분야 및 담당 업무에 따라 영어 구술평가, 레퍼런스 체크, 또는 기타 전형이 실시될 수 있어요. 지원자의 경험과 역량을 고려하여 다른 포지션이 더 적합하다고 판단되는 경우 지원 분야가 변경될 수 있어요. 배치 부서 및 근무지는 회사 사정에 따라 변경될 수 있어요. 아래의 경우, 합격이 취소되거나 전형 진행에서 불이익을 받으실 수 있어요. 지원서가 사실과 다르거나 증빙이 불가할 경우 해외여행 결격 사유가 있는 경우 (남성의 경우, 회사가 지정한 입사일까지 병역 필 또는 면제 필요) 최종 합격 후 회사가 지정하는 입사일에 입사 불가한 경우 </details> 준비해야하는 것들 기본 계획 ✅ 이력서 & 포트폴리오 준비 내가 한 경험들 중에서 채용공고에 필요한 경험 뽑아서 정리 이력서랑 포트폴리오 만들기 코딩테스트 준비 기출문제 뽑아서 정리하고 모르는 개념 정리하기 보완 계획 💡 기술 스택 실무 준비 MLOps 도구 실습 Docker/Kubernetes 실습 프로젝트 CI/CD 파이프라인 구축 경험 검색 엔진 학습 Elasticsearch 학습 및 실습 검색 엔진 토이 프로젝트 구축 벡터 DB 경험 Milvus, qdrant 등 벡터 데이터베이스 학습 구체적 실행 계획 포트폴리오 프로젝트 목록 작성 MLOps 파이프라인 구축 프로젝트 AI 검색 시스템 구현 프로젝트 데이터베이스 설계 경험 정리 코딩테스트 영역 세분화 검색 알고리즘 (이진탐색, 문자열 처리) ML 관련 알고리즘 시스템 설계 문제 타임라인 설정 1주차: 이력서/포트폴리오 초안 작성 2-3주차: 기술 스택 실습 프로젝트 4주차: 코딩테스트 집중 준비 실무 프로젝트 아이디어 미니 MLOps 파이프라인: 간단한 ML 모델 배포 자동화 검색 엔진 프로젝트: 문서 검색 시스템 구현 벡터 DB 활용: 임베딩 기반 유사도 검색 시스템"
  },
  {
    "id": "Self_Development/Career/Graduate School/대학원에대한고민",
    "title": "대학원을 진학해야할까? 하면 어디로?",
    "date": "2025-07-10",
    "excerpt": "나의 다음 선택지는 어디로?",
    "category": "Career",
    "tags": [
      "대학원"
    ],
    "content": "커리어 선배형에게 물어본 내용들 ㅇㅇ 내가 자주보는 괜찮은 ds관련 공고사이트줄테니까, 일단 있는 공고들 쫘-악 훑어봐봐. 그리고 공통적인 키워드들이 있을테니까 그거위주로 생각해보든가. (ex. LLM, RAG, agent, ML serving, triton 등) zighang offercent bzpp"
  },
  {
    "id": "Self_Development/Career/Graduate School/고려대야간대학원",
    "title": "고려대 야간대학원 관련 정리",
    "date": "2025-07-10",
    "excerpt": "기회비용과 기대되는 가치",
    "category": "Career",
    "tags": [
      "대학원"
    ],
    "content": "배경 제가 원하는 커리어의 방향을 생각해볼 때 대학원에 대한 선택을 늘 고민하게 됩니다. AI/ML 리서처나 관련 연구를 하는 일들을 하기 위해서는 최소 석사 이상의 학력을 요구하는 경우가 많기 때문입니다. 늦었나? 지금 나이가 만으로 26정도, 내년 전기에 시작해도 29~30에 끝나니까 그렇게 늦은 시기도 아니라고 생각이 듭니다. 그리고 나이가 더 많았더라도 이걸 통해 얻을 수 있는게 분명하다면, 기회비용보다 더 크다고 판단된다면 늦은 시기란 없지 않을까 싶습니다. 기회비용 (시간과 가격) 학비가 대력 4천정도. 일단 돈이 정말 많이 듭니다. 아직 3천만원도 모아본 적 없는 제가 이렇게 큰 비용을 감당할 수 있을까? 라는 생각도 듭니다. (학자금 대출 받고 조금씩 갚으면 언젠간 갚겠죠...?) 그리고 시간도 많이 필요합니다. 퇴근 후에는 온전히 시간을 다 쏟아야 하고 좋은 결과를 위해서는 주말에도 이 부분만 보고 있지 않을까 싶습니다. 2년 반정도의 시간도 고려해야 합니다. 기대되는 가치 제가 원하는 커리어의 방향에 도움이 됩니다. 학력 석사라는 학력은 사실상 필수적이지 않을까 싶습니다. 사이드 프로젝트를 하면서 만나는 다른 분들을 봐도 다 석사 이상의 학력을 가지고 있습니다. 논문 그리고 좋은 논문을 작성할 수 있어야만 단순 학위에 그치지 않고 진짜 도움이 될 것 같습니다. 지원시기와 준비할 것들 올해 후기 지원은 놓쳤고 내년 전기에 지원하지 않을까 싶습니다. 다른 블로그들을 살펴보니 준비해야하는 건 기본지식(통계, 선형대수 등등)과 연구계획서 정도입니다. 기본지식 통계, 선형대수와 같은 질문들을 면접때 받는다고 합니다. 경쟁률이 약 6:1정도 된다고 하니, 이런 질문에 대한 대답을 미리 철저하게 준비할 필요가 있어보입니다. 연구계획서 이 부분에 대한 고민이 많이 필요합니다. > 그래서 어떤 연구를 하고 싶은거지? 이 부분이 많이 비어있어서 꾸준히 채워나가보려고 합니다. 참고 자료들 Hello New World - 고려대학교 SW AI 대학원 면접 후기 귀퉁이 서재 - 고려대학교 AI 야간대학원 면접 후기 From data - 재직자 빅데이터/인공지능 대학원 정리"
  },
  {
    "id": "Self_Development/Career/25-07-10-visuworks-thoughts-of-my-career",
    "title": "나의 현재 커리어 상황에 대한 생각",
    "date": "2025-07-10",
    "excerpt": "나의 현재 커리어에 대한 고찰",
    "category": "Career",
    "tags": [
      "내 커리어는 어디로 가야하나"
    ],
    "content": "현재 나의 상황 요즘 정말 커리어에 대한 걱정과 고민이 많습니다... ㅎㅎ 지금 다니고 있는 회사의 도메인에 묶여있진 않을지. 여기서 이룬 성과들이 나의 커리어에 도움이 될지. 사실 생각만하면 정리가 안되는 부분들이 많기 때문에 글로 적어보면서 고민들에 대한 나름의 대답들을 적어보려고 합니다. 저는 산업공학을 전공하고, 6개월정도 부트캠프에서 컴퓨터 비전 부분을 공부하고, 의료 도메인에서 일하고 있습니다. 지금 다니고 있는 회사(visuworks)는 시력교정병원 (비앤빛 안과)를 주된 고객사로 삼고 있고 이 병원에서 만들어졌다고도 볼 수 있습니다. 여기서 지금까지 한 프로젝트는 OCR pipeline 개발 고객 상담용 챗봇 개발 렌즈 사이징 추천 서비스 개발 정도가 있습니다. 문제 상황들 제가 생각하는 문제들을 정리해보고 어떻게 해결해볼 수 있을지에 대한 생각들을 정리해보려고 합니다. 연봉이 이렇게 적나? 되게 단순하게 일을 일단 시작하는 마음으로 이 회사에 고민없이 입사했는데, 연봉이 생각보다 현저히 적어서 조금 놀랐습니다. 더 정확히는 연봉이 낮지만 일단 경력을 쌓자는 마음으로 입사했습니다. 8개월정도 일하고 나름 2개의 프로젝트를 성공적으로 끝낸 시점에서, 연봉협상을 했지만 큰 폭으로 오르지는 못했습니다. > 연봉 테이블이 좋은 회사로 빠르게 옮겨야겠다. 하지만 쉽지 않네요... ㅠ 지금 4~5개월정도 이직을 준비하고 있는데 대부분의 기업에서 떨어지고 있습니다. 그냥 이정도 가치를 가진 능력인가?라는 의구심이 들지만 보완해야할 점들을 보완하면서 이직을 준비 중입니다."
  },
  {
    "id": "Self_Development/Book/아주 작은 습관의 힘 (Atomic Habits)/쉬워야달라진다",
    "title": "쉬워야 달라진다",
    "date": "2025-07-10",
    "excerpt": "어떻게 좋은 습관을 만들고, 나쁜 습관은 버릴 것인가",
    "category": "Book",
    "tags": [
      "atomic habits",
      "아주 작은 습관의 힘"
    ],
    "content": "습관의 중요성 인생을 살아가면서 여러 중요한 요소들이 있겠지만, 가장 중요한 건 습관인 것 같습니다. 듀크 대학의 Wendy Wood 교수가 수행한 연구에 따르면, 우리 행동의 약 45%가 습관에 의한 것이라고 합니다. 제가 가장 좋아하는 문구도 다음과 같습니다. > Habit is second nature 이렇게 중요한 습관을 어떻게 관리할 수 있을까요? 좋은 습관을 많이 만들고, 나쁜 습관을 버려 좋은 시스템을 만들어 나간다면 제가 원하는 삶에 가까워질 것이라 생각합니다. 쉬워야 달라진다 '아주 작은 습관의 힘'이라는 책에서는 2분 법칙을 제시합니다. 해야하는 일을 아주 작게 쪼개라며 2분안에 끝낼 수 있는 일로 나누라고 말합니다. 1~2달정도 이 부분을 삶에 적용해봤는데 정말 효과가 많았습니다. 가장 큰 이유는 심리적 부담감을 줄여주기 때문이라고 생각합니다. 보통 일을 미루는 이유를 생각해보면 심리적 부담감 때문입니다. 특히 저는 일을 시작하기에 부담스러워서 시작조차 못하고 미루기만 했던 경험이 많습니다. 그런데 해야할 일을 2분안에 끝낼 수 있는 작은 일들로 쪼개니까 이런 부담감이 거의 없어졌고, 작은 일들을 성취하면서 그 성취감에 점점 더 많은 일들을 할 수 있게 됐습니다. > 아주 작은 일들로 쪼개자. 2분안에 끝낼 수 있는 일들로. 이건 제 삶의 하나의 원칙처럼 되었습니다. 아 미루지 말자 라고 생각하는게 아니라, 왜 미루는지 이해하고, 작은 일들로 쪼개기 시작했습니다. 그리고 이렇게 작은 성취들이 모여 노력하지 않아도 자동으로 실행이 되는 습관이 되어갑니다. 어떻게 나쁜 습관을 없앨까 좋은 습관을 만드는 것과 반대로 하기 어렵게 만들면 됩니다. 사람의 의지력은 한계가 있기 때문에 환경이 가장 중요하다고 생각합니다. Roy Baumeister의 연구에 의하면 의지력은 제한된 자원이라고 합니다. 의지력은 근육처럼 작동하며, 사용하면 피로해지고 휴식이 필요해지게 됩니다. > 의지력은 한계가 있다. 환경이 중요함! Massachusetts General Hospital 연구에서는 병원 카페테리아의 물의 위치만 바꿨는데도 탄산음료 판매 11.4% 감소, 생수 판매 25.8% 증가했다고 합니다. 따라서 나쁜 습관이 발견됐다면, 이를 할 수 없는 환경을 어떻게 만들지 고민해야 합니다. 저는 밤에 휴대폰을 보면서 늦게 자는 습관이 있어서 이를 해결하기 위해 자명종을 샀습니다. 그래서 알람 때문에 휴대폰을 침대에 들고 가지 않고 집에 들어오면 바로 꺼버립니다. > 나쁜 습관을 할 수 없는 환경을 만들자 집에서 아에 휴대폰을 보지 않게 되었고, 늦게 자는 습관도 해결할 수 있었습니다. 정리 해야할 일을 아주 작게 쪼개 심리적 부담감을 없애자 -> 작은 성취들을 맛보며 꾸준히 이어가자 실제로 해보니 그동안 미루던 많은 일들을 이어가고 있다. 의지력은 한계가 있으니, 나쁜 습관을 할 수 없는 환경을 만들자 알람은 자명종으로 대체하고, 휴대폰은 집에 오면 바로 꺼버리기! -> 늦게까지 휴대폰 보는 습관 제거됨"
  },
  {
    "id": "Data Science/Causal Inference/Paper Review/review-HETEROGENEOUS-TREATMENT-EFFECTS-ESTIMATION-WHEN-MACHINE-LEARNING-MEETS-MULTIPLE-TREATMENT-REGIME",
    "title": "[Paper Review] Heterogeneous Treatment Effects Estimation: When Machine Learning Meets Multiple Treatment Regime",
    "date": "2025-07-10",
    "excerpt": "HETEROGENEOUS TREATMENT EFFECTS ESTIMATION: WHEN MACHINE LEARNING MEETS MULTIPLE TREATMENT REGIME",
    "category": "Causal Inference",
    "tags": [
      "Paper Review"
    ],
    "content": "paper link"
  },
  {
    "id": "Data Science/Causal Inference/Paper Review/review-Causal-Effect-Inference-for-Structured-Treatments",
    "title": "[Paper Review] Causal Effect Inference for Structured Treatments",
    "date": "2025-07-10",
    "excerpt": "Causal Effect Inference for Structured Treatments",
    "category": "Causal Inference",
    "tags": [
      "Paper Review"
    ],
    "content": "paper link"
  },
  {
    "id": "Self_Development/English Study/SPEAK/지나간달/07-09-격려하는표현",
    "title": "격려하는 표현",
    "date": "2025-07-09",
    "excerpt": "You did a great job on, I'm happy to see that",
    "category": "English Study",
    "tags": [
      "영어공부꾸준히!",
      "SPEAK"
    ],
    "content": "오늘 배운거 You did a great job on the speaking practice. I'm happy to see that you're improving. I'm happy to see that you've overcome your fear of English. I can tell that she's sad. I could tell that she broke up the her boyfriend. I can tell that you put a lof of thought into this. 간단한 작문 Today I wanna complement myself. You did a great job on the solving problem. Working on company 1년 조금넘게, I solved a lot of problems. On the OCR project, I solve communicate problem and make greak OCR pipeline. On the chatbot project, I made chatbot which 만족하다 고객사s needs. And then, I'm happy to see that youve overcome of 비교하면서 뒤쳐진다고 느끼는 fear. When I was 21-25, I was just frozen because of fear that 난 뒤쳐졌고 인생은 망했다. I can tell that your life is great. I 일인분의 삶은 살아간다. And normal life is always wonderful. claud-4-sonnet 피드백 > gemini-2-pro보다 나은 듯 수정된 버전: Today I want to compliment myself. You did a great job at problem-solving. Working at a company for a little over a year, I have solved many problems. On the OCR project, I solved communication issues and built a great OCR pipeline. On the chatbot project, I created a chatbot that satisfied the client's needs. I'm happy to see that you've overcome the fear of comparing yourself to others and feeling behind. When I was 21-25, I was frozen because of the fear that I was falling behind and my life was ruined. I can tell that your life is great. You're living a fulfilling life. And a normal life is always wonderful. 피드백: 잘한 점: 배운 표현들 (You did a great job on, I'm happy to see that, I can tell that)을 실제 상황에 적용하려고 노력했어요 자신의 경험을 바탕으로 진정성 있는 내용을 썼어요 자기 격려라는 주제를 잘 선택했어요 개선점: 단어 선택: \"complement\" → \"compliment\" (칭찬하다) 문법: \"on the solving problem\" → \"at problem-solving\" 시제 일관성: 과거와 현재완료 시제를 상황에 맞게 사용 한영 혼용: 한국어 부분을 영어로 완전히 번역하여 자연스럽게 표현 전치사: \"overcome of\" → \"overcome\" (overcome은 전치사 없이 사용) 다음에 시도해볼 것: 한 문장 안에서는 한 언어로 통일하기 문장을 쓰기 전에 전체 구조를 영어로 먼저 생각해보기 배운 표현을 더 다양한 상황에 적용해보기"
  },
  {
    "id": "Data Science/Causal Inference/Industry Application/what-is-statistical-bias",
    "title": "통계적인 편향과 이를 제거하기 위한 방법론",
    "date": "2025-07-09",
    "excerpt": "실제 데이터에서 통계적 편향을 확인하고 이를 잔차화를 통해 제거하는 과정",
    "category": "Causal Inference",
    "tags": [
      "편향",
      "통계적",
      "bias"
    ],
    "content": "배경 --- 인과추론의 기본적인 개념은 통계적 편향 (Statistical Bias)을 제거하는 것입니다. 인과추론을 더 잘 이해하고 효과를 확인하기 위해서는, 이 통계적 편향을 이해하고 확인하는 과정이 필요하다고 생각합니다. 정의 --- > 통계적 편향(Statistical Bias)은 통계 분석 과정에서 발생하는 체계적인 오류로, 측정이나 추정 과정에서 실제 모집단의 모수(parameter)와 표본 통계량 사이에 일관된 차이가 발생하는 현상을 말합니다. 체계적(systematic) 오류란? 측정 방법이나 분석 방법에 문제가 있어 발생하는 오류 무작위가 아닌, 일정한 패턴이나 방향성을 가짐 체계적 오류 (Systematic Error) vs 무작위 오류 (Random Error) 체계적 오류 (Systematic Error): 항상 같은 방향으로 발생 (예: 항상 실제값보다 높게 측정) 측정 횟수를 늘려도 줄어들지 않음 측정 도구나 방법의 결함에서 비롯됨 무작위 오류 (Random Error): 방향이 불규칙함 (때로는 높게, 때로는 낮게) 측정 횟수를 늘리면 평균적으로 상쇄됨 우연한 변동에서 비롯됨 제가 이해한 개념은, 랜덤 노이즈가 아닌 구조상의 문제가 있어 결과를 확인하는데 오해를 만드는 것이라고 생각합니다. 예를 들어 보면: 구조상 문제: 온라인 설문조사로만 의견을 수집 → 디지털 기기 사용이 어려운 고령층 의견 누락되고 젊은 층의 의견만 반영됨 결과의 오해: \"젊은 층의 의견이 전체 의견\"이라고 잘못 해석할 수 있습니다. 통계적 편향의 종류와 설명 선택 편향 (Selection Bias) > 연구 대상을 선택하는 과정에서 발생하는 편향으로, 표본이 모집단을 제대로 대표하지 못할 때 발생합니다. 예시: 병원 데이터만으로 질병 연구를 할 때 → 중증 환자만 포함되어 질병의 심각성이 과대평가됨 자발적 참여자만으로 설문조사 → 특정 관심사를 가진 사람들만 참여하여 결과가 편향됨 제가 앞서 예시를 든 경우가 이에 해당합니다. 한국 남자의 평균 푸쉬업 개수를 측정한다고 할 때, 헬스장에서 푸쉬업 개수를 측정한다면 이는 한국 남자를 대표할 수 있을까요? 교란변수 편향 (Confounding Bias) > 원인변수와 결과변수 모두에 영향을 미치는 제3의 변수(교란변수)를 고려하지 않아 발생하는 편향입니다. 인과추론에서 가장 중요한 편향입니다. 예시: 커피 소비와 심장병의 관계 연구에서 흡연을 고려하지 않은 경우 교육과 소득의 관계에서 가정 배경을 고려하지 않은 경우 정보 편향 (Information Bias) > 데이터 수집 과정에서 발생하는 편향으로, 측정 오류나 분류 오류로 인해 발생합니다. 하위 유형: 회상 편향 (Recall Bias): 과거 사건을 기억하는 정확도 차이 관찰자 편향 (Observer Bias): 연구자의 주관적 판단이 개입 측정 편향 (Measurement Bias): 측정 도구나 방법의 결함 예시: 질병 환자가 건강한 사람보다 과거 노출을 더 잘 기억하는 경우 연구자가 가설을 알고 있어 결과를 주관적으로 해석하는 경우 생존 편향 (Survivorship Bias) > 성공하거나 살아남은 사례에만 집중하고, 실패하거나 탈락한 사례를 고려하지 않아 발생하는 편향입니다. 예시: 성공한 기업가들만 인터뷰하여 \"창업 성공 요인\" 분석 졸업생만 대상으로 한 대학 교육 효과 연구 (중도 탈락자 제외) 발표 편향 (Publication Bias) > 통계적으로 유의한 결과나 긍정적인 결과만 발표되고, 그렇지 않은 결과는 발표되지 않아 발생하는 편향입니다. 예시: 약물 효과가 있는 연구만 논문으로 발표되고, 효과가 없는 연구는 발표되지 않음 성공적인 정책 사례만 보고되고, 실패한 정책은 보고되지 않음 시간 관련 편향 (Time-related Bias) > 시간의 흐름과 관련하여 발생하는 편향입니다. 하위 유형: 시대 효과 (Period Effect): 특정 시점의 환경적 요인 코호트 효과 (Cohort Effect): 특정 세대의 공통 경험 연령 효과 (Age Effect): 나이에 따른 자연스러운 변화 탈락 편향 (Attrition Bias) > 연구 진행 중 참여자가 탈락하여 발생하는 편향입니다. 예시: 장기 추적 연구에서 건강한 사람들만 계속 참여하고, 아픈 사람들은 탈락 온라인 교육 효과 연구에서 학습 능력이 높은 사람들만 끝까지 참여 결과를 해석할 때 이런 편향들은 오해를 만듭니다. 따라서 이러한 편향을 고려하고 결과를 해석해야하며, 이런 편향을 찾고 제거하는 방법이 인과추론의 주된 목적입니다. 내가 다루고 있는 데이터에서의 통계적 편향 --- 저는 시력교정병원의 의료 데이터를 분석하고 있습니다. 주요 연구 목적은 환자들에게 다양한 수술 방법을 적용했을 때의 결과를 비교하여, 수술의 효과를 검증하는 것입니다. 당연히 환자마다 눈의 상태가 다르기 때문에 동일한 수술을 해도 결과는 달라집니다. 이러한 개인차를 고려하지 않고 수술 효과를 평가하면, 앞서 설명한 편향이 발생하여 잘못된 결론을 내릴 수 있습니다. 수술마다 환자의 분포가 다르고 이 환자들에 대해 결과를 비교하는 건 문제가 있을 수 있다고 생각해볼 수 있습니다. 그리고 이는 혼동 편향 (Confounding Bias)이라고 생각해볼 수 있습니다. 왜 Confounding Bias인가? 구조: 원인변수: 수술 방법 (A수술 vs B수술) 결과변수: 수술 결과 (시력 개선 정도) 혼동변수: 환자의 눈 상태 (근시 정도, 각막 두께, 나이 등) 문제점: 눈 상태가 수술 방법 선택에 영향을 미침 예: 각막이 얇은 환자는 특정 수술만 가능 근시가 심한 환자는 다른 수술 방법 선택 눈 상태가 수술 결과에도 직접 영향을 미침 예: 각막이 두꺼운 환자가 일반적으로 결과가 좋음 젊은 환자가 회복이 빠름 결과: 눈 상태를 통제하지 않으면, 수술 방법 자체의 효과가 아닌 환자 특성의 차이를 수술 효과로 잘못 해석하게 됩니다. 이를 어떻게 보여줄 수 있을까? --- 요즘 가장 많은 고민을 하고 있는 부분입니다. > 논리적으로 편향이 발생하는 구조이고, 이를 해결하기 위해 인과추론을 도입했다. > 그래서 결과는? 어느정도 좋아졌는데? 어떤 방법을 도입한 후의 결과를 명확하게 보여줘야 하는데, 이를 어떻게 보여줄 수 있을지에 대한 고민입니다. 제가 보고 있는 데이터에 대한 설명을 추가적으로 하자면 다음과 같습니다. 수술방법의 차이 : 렌즈삽입술에서 사용하는 렌즈 크기 [12.1, 12.6, 13.2] 환자 눈의 조건 : [나이, ATA(눈의 가로길이), ACD(눈의 세로길이), CLR(수정체의 상태)] 수술방법 별로 눈의 조건 분포를 확인하기 --- <small>처치 : 인과추론에서 연구자가 조작하는 변수(예: 수술 방법, 약물 투여). 처치 그룹과 대조 그룹을 비교하여 효과를 평가합니다.</small> > 처치(수술방법, 삽입하는 렌즈크기)별로 환자 눈의 분포가 같은가? <figure> <img src=\"/post/what-is-statistical-bias/처치별_Feature_DensityPlot.png\" alt=\"처치별 Feature Density Plot\"> <figcaption>그림 1: 처치별 Feature 분포 비교</figcaption> </figure> <figure> <img src=\"/post/what-is-statistical-bias/boxplot_grouped_by_size.png\" alt=\"Boxplot Grouped by Size\"> <figcaption>그림 2: 크기별 그룹화된 박스플롯</figcaption> </figure> ata와 clr의 경우 분포의 차이가 명확히 보이고 있습니다. > 처치별 환자 눈의 분포가 다르다. 따라서 환자 눈의 조건을 통제하지 않고 수술 효과를 평가하면 오해를 만들 수 있다. 즉 ata와 clr은 처치와 결과변수 모두에 영향을 주는 교란변수 (confounding variable)이라고 할 수 있습니다. 그리고 처치별 결과 차이는 이 교란변수에 의해 왜곡될 수 있습니다. <figure> <img src=\"/post/what-is-statistical-bias/처치별결과비교.png\" alt=\"처치별 결과 비교\"> <figcaption>그림 3: 처치별 결과 분포 비교</figcaption> </figure> > 단순히 처치별 분포의 차이를 통해 처치가 결과에 미치는 영향을 판단할 수 없다. 같은 크기의 눈에 3가지 종류의 렌즈를 모두 넣은 결과가 있다면, 이를 통해 렌즈 크기가 결과에 미치는 영향을 판단할 수 있습니다. 하지만 그림1과 2에서 확인한 것처럼 렌즈별로 다른 크기의 눈에 렌즈를 넣어 결과를 얻었기 때문에, 이를 통해서는 렌즈 크기가 결과에 미치는 영향을 판단할 수 없습니다. 처치가 결과에 미치는 영향을 실질적으로 분석하기 위해서는 통계적 편향을 제거할 필요가 있습니다. 예측 모델의 한계점 --- 예측 모델은 상관관계에 기반해 패턴을 찾습니다. 인과추론이란? 상관관계와 인과관계 이때 confounding variable은 인과관계가 아닌 상관관계를 만들 수 있습니다. ata가 커질수록 렌즈를 더 큰 걸 사용했고, 따라서 결과 (vaulting)가 더 커진 경향이 있습니다. 이때 모델은 ata가 커지면 vaulting이 커진다고 예측할 수 있습니다. 이런 상황에서 예측 모델에 기반해 처치를 결정하는 건 굉장히 위험합니다. > 처치와 결과변수 간의 인과관계를 모델링할 필요가 있고, 이를 통해 처치를 결정할 때 신뢰할 수 있는 결과를 얻을 수 있습니다. 인과추론으로 이를 해결하는 방법 --- > 교란변수들을 제거하고 처치와 결과변수 간의 인과관계를 모델링해야 합니다. 즉 처치(T)와 결과(Y)에 모두 영향을 미치는 변수를 $X$라고 했을 때, $X$가 $Y$에 미치는 영향을 제거하고 $X$가 $T$에 미치는 영향을 제거하고 $Y$와 $T$ 간의 인과관계를 모델링해야 합니다. 교란변수를 제거하는 방법은 여러가지가 있지만 그 중에 하나가 잔차화 방법입니다. FWL 정리 에서 설명한 것처럼 잔차화 방법을 통해 교란변수를 통제할 수 있습니다. 잔차화를 하게 되면 다음과 같은 결과를 얻을 수 있습니다. <figure> <img src=\"/post/what-is-statistical-bias/사이즈별잔차분포.png\" alt=\"결과에서 교란변수에 대한 영향 제거후 분포\"> <figcaption>그림 4: 잔차화를 통해 교란변수에 대한 영향을 제거한 결과 분포</figcaption> </figure> 그림3과 비교하면, 처치(렌즈 크기)를 제외한 나머지 교란변수들의 영향을 제거한 결과를 확인할 수 있습니다. 그림4를 통해 렌즈 크기가 결과에 미치는 영향을 확인할 수 있습니다. 잔차화가 잘되었는지는 잔차가 정규분포 형태를 띄는지와 잔차가 교란변수와 독립인지를 확인하면 됩니다. 정규분포 형태를 띄고 있다는 부분은 그림4를 통해 확인할 수 있고, 교란변수와 독립인지는 교란변수로 잔차를 예측하는 모델을 만들어 확인할 수 있습니다. <figure> <img src=\"/post/what-is-statistical-bias/조건부독립성검사.png\" alt=\"교란변수로 잔차를 예측하는 모델 결과\"> <figcaption>그림 5: 교란변수로 잔차를 예측하는 모델 결과</figcaption> </figure> 모델이 잔차를 전혀 예측하지 못하는 것을 통해 더 이상 X에 대한 정보가 Y에는 포함되어있지 않다고 생각해볼 수 있습니다. 이 결과를 좀 더 직관적을 해석해보면 <figure> <img src=\"/post/what-is-statistical-bias/같은렌즈크기_같은결과_다른눈.png\" alt=\"같은렌즈크기_같은결과_다른눈\"> <figcaption>그림 6: 같은 렌즈 크기에 같은 결과를 얻었지만 다른 눈을 가진 경우</figcaption> </figure> 같은 결과를 얻었고 같은 사이즈를 사용했기 때문에, 눈이 결과에 미치는 영향을 고려하지 않으면 렌즈 크기의 영향을 제대로 판단할 수 없습니다. > 직관적으로 너무나도 당연한 말이지만, 앞서 설명드린 것처럼 이러한 통계적인 편향들을 제거하지 않고 결과를 분석하게 되면 잘못된 결과를 도출할 수 있습니다. 잔차화하는 코드는 잔차화 코드 확인해볼 수 있습니다. 정리 처치 (수술방법, 렌즈크기) 별로 환자의 눈의 분포가 다르다는 것을 확인할 수 있었습니다. 수술을 받은 환자의 눈의 분포가 다르기 때문에 수술 결과를 비교하는 것은 문제가 있습니다. 정확히 수술 결과를 비교하기 위해서는 결과에서 교란변수의 영향 (통계적 편향) 을 제거한 후 비교해야 합니다."
  },
  {
    "id": "Self_Development/Reflections/2025-07-08-optimization-pitfall",
    "title": "최적화의 함정에 대하여",
    "date": "2025-07-08",
    "excerpt": "패배주의에서 벗어나자",
    "category": "Reflections",
    "tags": [
      "이런저런 생각들"
    ],
    "content": "배경 저는 꽤나 오랜시간 일종의 패배주의에서 벗어나지 못하고 고통스러워하며 시간을 보냈습니다. 저보다 훨씬 뛰어난 사람들을 보며 나는 저런 길을 걸어오지 않았으니까 안될 것 같다는 생각들에 사로잡혀 있었습니다. 이러한 사고방식을 어떻게 정의할 수 있을지 몰랐는데, \"뉴욕털게\"님의 영상들을 보면서 \"최적화의 함정\"에 빠졌다고 정의할 수 있었습니다. 최적화의 함정이란? 인생에는 어떤 최적화된 길이 있고, 이 길을 따라가야하며, 따라가지 못한 나는 패배재자라고 생각하는 것입니다. 그래서 최적화된 길을 찾으려고 하면서 완벽주의에 빠지게 되는 것입니다. 완벽한 계획에 대해 고민하면서 시간을 보내고, 막상 앞으로 한발자국도 나아가지 못하는 상황에 빠지게 됩니다. 뉴욕털게님 영상 링크 >계획이 원대해지면 내 하루는 비참해진다. 가장 인상깊은 말이자, 제 과거 삶을 관통하는 말입니다. 뉴욕털게님의 사고방식 뉴욕털게님이 말씀하시는 부분들을 제 삶에 정말 많은 도움이 되고 있습니다. 여러가지 개념들을 말씀해주시는데, 공통적인 개념은 \"수용의 자세\"가 아닐까 싶습니다. 이는 제가 좋아하는 \"법륜스님\"의 말씀과 비슷한 점이 많습니다. 과거, 어쩌면 지금도 제가 고통받는 이유를 생각해보면 제가 원하는 이상적인 상을 그려놓고 이것과 비교하면서 제 하루하루를 비참하게 생각했기 때문이 아닐까 싶습니다. 역설적으로 제 삶을 부정하고 원대한 계획을 세울수록 삶은 나아지지 않는 것 같습니다. 그저 비참한 하루를 보내며 시간을 보내기만 할 뿐입니다. 그래서 이 수용의 자세는 삶을 살아가는데 굉장히 중요한 자세가 아닐까 싶습니다. 지금 내 모습이 내가 상상했던 모습은 아니지만, 충분히 훌륭하다. 1인분의 삶을 온전히 살아나가고 있고 조금씩 나아가고 있다. 이렇게 지금 삶을 온전히 수용할 때, 비로소 발전할 수 있는 내가 된다고 생각합니다. 나의 삶에 적용해보기 원하는 회사에 지원하고 있지만 계속해서 떨어지고 있습니다. 나의 이상적인 상과 비교하며 나는 안되는 인생인가보다 하며 고정적이고 패배적인 사고방식을 가질 수도 있지만, 지금의 상황을 수용하고 앞으로 나아가기 위한 방법을 찾아보는게 더 좋아 보입니다. 이 수용의 자세를 떠올리며 삶을 살아가보려 합니다."
  },
  {
    "id": "Self_Development/Reflections/2025-07-08-how-to-write-resume",
    "title": "이력서는 어떻게 적어야할까?",
    "date": "2025-07-08",
    "excerpt": "이력서를 적으며 했던 나의 고민들",
    "category": "Reflections",
    "tags": [
      "이런저런 생각들"
    ],
    "content": "나의 배경 일한지 1년이 조금 넘는 시점에서 이직을 준비하고 있습니다. 이력서를 준비하며 나를 어떻게 표현하면 좋을지에 대한 고민들을 하고 있습니다. 모르는 내용을 공부하고 좋은 코드를 작성하고 좋은 모델을 만드는 일들은 어렵지만 그 길이 나름 명확합니다. 이런 과정을 적어도 5년이상 거쳐왔으니 자신이 있습니다. 하지만 나를 표현하는 부분들은 정말 어렵게 느껴집니다. 나는 진짜 경쟁력이 있는지에 대한 의구심부터, 내가 했던 일들을 어디서부터 어디까지 설명해야하는지 등등 이런 과정에서 했던 고민들을 하나씩 정리해봅니다. 내 이력서에 대한 피드백 사이드프로젝트를 같이하는 개발자분 > 임팩트가 없다. 이력서를 더 짧게 쓰고 포트폴리오를 풍부하게 가져가는게 좋겠다. 이 피드백에 동의하는 부분이 많았습니다. 내가 한 프로젝트의 결과를 수치적으로 표현하는데에만 집중했지, 진짜 어떤 문제를 풀어서 어떤 영향을 줬는지에 대한 내용이 부족한 것 같다고 느꼈습니다. 특히 포트폴리오를 따로 준비하지 않았던 부분은 꼭 수정이 핗요하다고 느껴집니다."
  },
  {
    "id": "Self_Development/English Study/SPEAK/지나간달/07-08-칭찬하는표현",
    "title": "칭찬하는 표현",
    "date": "2025-07-08",
    "excerpt": "I was really impressed, It couldn`t be any better, I couldn`t have done it without you",
    "category": "English Study",
    "tags": [
      "영어공부꾸준히!",
      "SPEAK",
      "칭찬하는 표현들"
    ],
    "content": "오늘 배운거 I was really impressed I was really impresed with your exhibit It couldnt be any better I couldnt have done it without you I couldnt have graduate without you 이거 사용해서 간단한 작문 Today, I attend side-project 모임. We talked about recommmend system. The topic was, how to delete data noise, how to check '가정', distribute tasks for project. After that 동료 ,who 프로젝트를 같이하는 사람, give me advice. Because nowadays I fall 서류탈락, so I ask them how can I improve my 이력서. I was really impressed with their advice. They 고민하다 for me. How to improve my resume. It couldnt be any better. I was so 감동받다. I always appreciate this project. They gave me so many 도움. I couldnt have be better person without them. 문장수정 (gemini-2.5-pro) Today, I attended a side-project meeting. We talked about recommendation systems. The main topics were how to remove noisy data, how to test our assumptions, and how to distribute tasks for the project. After the meeting, a teammate who is working on the project with me gave me some advice. Recently, I've been getting rejected at the resume screening stage, so I asked them for tips on how to improve my resume. I was really impressed with their advice. They thoughtfully considered how I could improve my resume. It couldn’t have been any better. I was so moved. I always appreciate being a part of this project. They have been so helpful to me. I couldn’t have become a better person without them. 피드백 (gemini-2.5-pro) 전반적으로 전달하려는 의미가 명확해서 좋았습니다! 몇 가지 문법적인 부분과 더 자연스러운 표현을 중심으로 피드백을 정리했습니다. 시제 일치: 과거의 경험에 대해 이야기하고 있으므로 동사는 과거형으로 일치시키는 것이 좋습니다. (예: attend → attended) 자연스러운 표현: side-project 모임 → a side-project meeting 처럼 한국어 단어를 영어로 바꾸고, 명사 앞에 관사(a/an/the)를 적절히 사용하면 문장이 더 자연스러워집니다. '서류 탈락하다'는 fail the resume screening 또는 get rejected at the resume screening stage와 같이 구체적으로 표현할 수 있습니다. '고민하다'는 thoughtfully considered 또는 took the time to think about 등으로 표현하면 '나를 위해 신중하게 생각해 주었다'는 뉘앙스를 잘 살릴 수 있습니다. 문법: '도움(help)'은 셀 수 없는 명사라 many 대신 much를 사용합니다. (so much help) I couldn't have be better person → I couldn't have become a better person 처럼 조동사 뒤에 동사 원형의 과거분사형(p.p.)을 사용하고, 명사 앞에 관사를 붙여주면 문법적으로 완전한 문장이 됩니다. 오타: recommmend → recommendation`과 같은 오타를 주의하면 더 완성도 높은 글이 될 것 같습니다."
  },
  {
    "id": "Data Science/Recommendation/2025-07-08-thoughts-on-review-quality",
    "title": "리뷰 노이즈에 대한 고민",
    "date": "2025-07-08",
    "excerpt": "카카오맵 리뷰 데이터의 노이즈들에 대하여",
    "category": "Recommendation",
    "tags": [
      "사이드프로젝트정리",
      "추천시스템",
      "추천시나리오"
    ],
    "content": "배경 데이터과학자로 1년 조금 넘게 일하면서 가장 크기 느끼는 부분은, 데이터의 중요성입니다. 모델은 데이터 안에서 패턴을 찾을 뿐, 그 안에 패턴이 없거나 노이즈가 크면 모델은 제 역할을 못하게 된다고 생각합니다. 그래서 데이터를 뜯어보고 그 안의 노이즈를 살펴보는 일은 굉장히 중요한 일입니다. > 리뷰 데이터에는 어떤 노이즈가 있는지 살펴보고 이를 정리했습니다 <small>같이 사이즈 프로젝트를 하는 '신보현'님의 분석 결과를 참고해 정리헀습니다.</small> 문제 상황들 여러 노이즈들이 존재하는데 그 중 가장 심각하다고 느끼는 부분들에 대해 정리했습니다. 장소(음식점)과 상관없는 이유인 부정적/긍정적인 리뷰들 가장 눈에 띈 부분은 계엄과 그 후의 시위들과 관련된 리뷰들입니다. 계엄을 찬성하거나 반대할 경우 관련된 사람들이 '댓글 테러'를 하는 경우를 발견했습니다. 그 외에도 제가 다니고 있는 헬스장에 여자 트레이너가 뚱뚱하다는 이유로 부정적인 리뷰를 남기는 경우도 있었습니다. 마케팅 목적으로 작성된 리뷰들 마케팅을 위해 의도적으로 작성된 리뷰들입니다. 예전에 알바했던 음식점에서도 이런 마케팅을 진행했었습니다. AI로 작성해서 문체에 티가 나는 경우라면 다르게 접근할 수도 있겠지만, 사람이 작성한 듯한 댓글이 많아서 이를 어떻게 거를 수 있는지도 고민할 필요가 있습니다. 그래서? 이런 부분을 상쇄할만큼 리뷰가 많으면 이게 상쇄가 되는지, 혹은 모델로 이를 극복할 수 있을지. 데이터를 필터링할 수 있는 부분들을 고민해야할지에 대한 논의가 추가로 필요한 상황입니다. 이 부분들에 대한 내용도 추가로 정리할 예정입니다."
  },
  {
    "id": "Data Science/Recommendation/2025-07-08-thoughts-on-deciding-scenario",
    "title": "시나리오를 정하기 위한 고민",
    "date": "2025-07-08",
    "excerpt": "추천시스템을 구현하는 사이드 프로젝트를 진행하면서 추천 시나리오는 어떻게 정하면 좋을지에 대한 논의를 정리했습니다.",
    "category": "Recommendation",
    "tags": [
      "사이드프로젝트정리",
      "추천시스템",
      "추천시나리오"
    ],
    "content": "배경 사이드 프로젝트를 진행하며 추천 서비스를 구현해보고 있습니다. 구현하면서 필요한 여러 고민 중 하나는 어떤 상황에서 어떻게 추천을 해줄 것인지에 대한 고민입니다. 이를 추천 시나리오라고 정의하고 이를 구체화하는 과정에 있습니다. 콜드 유저에 대해 어떻게 추천할 것인가 서비스를 새롭게 만들게 된다면 이 서비스를 사용하는 유저는 콜드 유저일 것입니다. 이에 대해 어떻게 대처할 수 있을지에 대한 논의가 주된 논의였습니다. 인기도 기반 추천 + 필터링 가장 대표적으로 사용되는 방법입니다. 여기에 추가로 날씨라던지, 위치라던지, 특정 필터링을 붙이는 방식입니다. 유저 프로필 완성 (온보딩 기반 추천) 유저에게 정보를 완성하도록 요청하고, 이를 바탕으로 추천을 하는 방식입니다. 대표적으로 왓챠나 넷플릭스의 경우, 처음에 본인이 좋아하는 영화를 선택하도록 구성하고 그 후 이를 바탕으로 추천을 해줍니다. 이런식으로 유저 정보를 받을 수 있는 서비스에 대한 논의를 했습니다."
  },
  {
    "id": "Data Science/Recommendation/2025-07-08-cold-start-solution",
    "title": "Cold Start 해결 방법에 대한 고민",
    "date": "2025-07-08",
    "excerpt": "사이드프로젝트에서 진행한 cold start 해결방안과 데이터의 한계점 극복 고민",
    "category": "Recommendation",
    "tags": [
      "사이드프로젝트정리",
      "추천시스템"
    ],
    "content": "배경 모두의 연구소에서 \"쩝쩝LAB\"이라는 이름으로 진행한 사이드 프로젝트에 대한 정리입니다. 맛집 추천 시스템을 구현하고 있습니다. 여러 과제 중 Cold Start를 어떻게 해결할지에 대해 논의한 내용들을 정리해봤습니다. Cold Start Problem이란? > 사용자나 아이템에 대한 정보가 없거나 희소한 문제 이 중에서 유저에 대한 cold start 문제를 어떻게 풀지에 대해 고민하고 있습니다. <small>같이 사이즈 프로젝트를 하는 '이윤선'님의 분석 결과를 참고해 정리헀습니다.</small> 기본적인 추천의 컨셉 > Popularity Model에서 Context를 반영하여, 유저가 만족할만한 음식을 추천해주고 싶다. 콜드 유저에게 인기도 기반 추천을 내주는 것처럼, 계절과 날씨를 고려해 추천을 내주면 좋을 것 같다는 아이디어입니다. (예시) 상황 유저의 생각 추천 가능 음식 --- --- --- 맑고 청명한 날 “밖에 나가서 먹고 싶어” 샌드위치, 김밥, 분식 흐리고 습한 날 “뭔가 시원한 게 땡긴다” 냉면, 물회, 아이스커피 비 올 것 같은 날 “집에 일찍 가고 싶어” 국물 요리, 칼국수, 해장국 겨울철 “대게가 제철이네?” 대게찜, 어탕국수, 전골류 계졀 날씨 데이터를 모델에 포함시켜야 하는 이유로 3가지를 제시했습니다. 왜 계절 날씨 데이터를 모델에 포함해야 할까? 개인화 추천 강화 → 동일한 유저도 날씨에 따라 선택이 달라짐 → ‘유저 + 날씨’ 조합 기반의 더 똑똑한 추천 가능 모델의 정밀도 향상 → 기존 모델에 컨텍스트 데이터를 추가함으로써 예측 정확도 향상 Cold Start 상황에서도 강력한 보완 → 유저 정보가 없을 때도, 그날의 날씨 + 인기 메뉴로 합리적인 추천 가능 여기에 추가로 저는 추천의 근거를 제시해줄 수 있기 때문에, 사용자가 추천의 결과를 더 신뢰할 수 있을 것이라고 생각합니다. 구현상황에서의 문제점, 데이터의 한계 사용하고 있는 데이터는 카카오맵을 크롤링하여 만든 데이터입니다. 카카오맵에 있는 리뷰는 사용자가 서비스를 이용한 후에 바로 작성하는게 아니기 때문에, 작성 시점과 실제 사용한 시점이 다릅니다. 따라서 사용한 시점의 날씨를 알 수 없다는 문제가 있습니다. 이를 확인하기 위한 EDA 결과를 발표자님께서 발표해주셨습니다. > 리뷰 날짜와 방문날짜가 같다는 가정을 타당하게 만들기 위한 방법 리뷰어 중에 매일 리뷰를 쓰는 사람만 고르자 > 작성한 리뷰들의 일자의 차이가 평균적으로 1일정도 나는 유저, 즉 매일 리뷰를 작성하는 리뷰어들을 통해 데이터를 통해 이를 해결하자 즉 리뷰 날짜와 방문날짜가 같다고 추정되는 유저만 필터링하는 방법을 선택합니다. 이렇게 되면 데이터의 한계를 어느정도는 극복할 수 있습니다."
  },
  {
    "id": "Data Science/Codility Study/공부방향",
    "title": "코딩테스트 공부 방향",
    "date": "2025-07-08",
    "excerpt": "코딩테스트 공부 방향에 대한 정리",
    "category": "Codility Study",
    "tags": [
      "고민정리"
    ],
    "content": "배경 잠깜 공부하다가 내려놓고 다시 공부를 시작하려고 합니다. 주니어, 혹은 시니어더라도 코딩테스트는 선택이 아닌 필수가 아닐까 싶습니다. (적어도 10년 이하까지는?) 그래서 꾸준히 공부해보려고 하는데 어떤 방향으로 잡을지에 대한 정리를 해보려고 합니다. 또 사이드 프로젝트를 같이 하는 '신보현'님의 경험을 들어보니, 라이브코테는 필수적으로 보고 난이도가 꽤 있어서 꾸준한 준비가 필요하다고 합니다. 지금부터라도 꾸준히 공부해보려고 합니다. 코테 공부하기 좋은 곳 (GPT 정리) > 와 엄청 정리 잘해주네요... 코딩 테스트(코테) 공부에 도움이 되는 좋은 사이트들을 아래에 용도별로 정리해드릴게요. 각 사이트마다 특성이 다르니, 본인의 학습 목적(기초 다지기, 문제 풀이, 실전 대비 등)에 맞춰 선택하시면 됩니다. --- ✅ 1. 문제 풀이 중심 백준 온라인 저지 (BOJ) URL: https://www.acmicpc.net/ 특징: 국내 코테 준비자들이 가장 많이 사용하는 사이트. 다양한 알고리즘 분류, 난이도별 문제 제공. 단계별로 풀어보기, 문제집 기능으로 체계적인 학습 가능. C++, Python, Java 등 다양한 언어 지원. 프로그래머스 (Programmers) URL: https://programmers.co.kr/learn/challenges 특징: 실제 기업 코딩테스트 문제 수록 (카카오, 네이버 등). 실전 감각을 기르기에 적합. 레벨별로 분류되어 있어서 입문자부터 고급자까지 활용 가능. Python, JavaScript 등 실무에 많이 쓰는 언어에 최적화. LeetCode URL: https://leetcode.com/ 특징: 글로벌 IT 기업(FAANG) 코테 문제 다수 수록. 난이도 다양 (Easy, Medium, Hard). 영어 기반이지만, 알고리즘 실력을 실질적으로 끌어올리기에 효과적. 문제마다 디스커션과 솔루션이 잘 되어 있음. --- ✅ 2. 알고리즘 개념/이론 학습 알고리즘 비주얼라이저 URL: https://visualgo.net/ 특징: 자료구조 및 알고리즘 동작 원리를 시각적으로 보여줌. DFS, BFS, 정렬, 힙, 트리 등 기초 개념 정립에 탁월. Tistory / velog 블로그 검색 활용 방법: \"[문제 이름] + 알고리즘 풀이\"로 검색하면, 풀이 과정 + 시간 복잡도 분석까지 설명된 블로그 글이 많음. 이론 + 구현을 연결지어 학습하기 좋음. --- ✅ 3. 모의 코딩 테스트 / 실전 연습 코드업 (CodeUp) URL: https://codeup.kr/ 특징: 입문자에게 적합한 기초 문제부터 알고리즘 문제까지 제공. 단계별 학습으로 알고리즘 실력을 자연스럽게 끌어올림. Codeforces URL: https://codeforces.com/ 특징: 주기적인 온라인 대회 운영. 실전 감각 및 속도, 구현 능력 향상에 매우 효과적. 러시아 기반 커뮤니티이나 영어 지원. --- ✅ 4. 문제 추천/가이드 자료 GitHub 저장소 예시: https://github.com/tony9402/baekjoon 백준 알고리즘 분류 기반 추천 문제 모음 https://github.com/ellynhan/boj-algorithm-practice 기초 → 고급 순서로 정리된 백준 문제집 --- 🔍 코테 준비 방법 요약 (이론적 배경) 기초 개념 습득: 시간 복잡도, 정렬, 탐색, 재귀, DP, 그리디 등 이론 학습. 문제 유형별 학습: 구현 → 정렬 → 탐색(BFS/DFS) → 스택/큐 → DP → 그래프 순서 추천. 문제 풀이 + 복습: 오답 노트 필수. 같은 문제를 여러 번 반복해서 풀어보는 것이 중요. 실전 모의 테스트: 실제 시험 시간처럼 제한 시간 안에 푸는 연습이 효과적. 내 생각은? 기초부터 하나씩 습득하는 것도 좋지만 원하는 회사 기출문제부터 풀어보면서 채워나가는 것도 좋은 방향인 것 같습니다. 당장 7월에 있는 현대 오토에버 지원하고 여기 코테 기출문제부터 풀어보려고 합니다. 관련 내용들을 하나씩 정리해보곘습니다."
  },
  {
    "id": "Self_Development/Reflections/2025-07-03-importance-of-numbers",
    "title": "수치의 중요성",
    "date": "2025-07-03",
    "excerpt": "수치로 표현하는게 왜 중요한지에 대한 생각 정리",
    "category": "Reflections",
    "tags": [
      "이런저런 생각들"
    ],
    "content": ""
  },
  {
    "id": "Data Science/Causal Inference/what-is-fwl",
    "title": "FWL(Frisch-Waugh-Lovell) 정리란?",
    "date": "2025-07-02",
    "excerpt": "통계적 편향을 제거하기 위한 방법론",
    "category": "Causal Inference",
    "tags": [
      "Causal Inference"
    ],
    "content": "참고자료 실무로 통하는 인과추론 with python 네이버블로그_ (선형모형) 04 Frisch-Waugh-Lovell 정리, 수식 풀이가 잘되어 있음 배경 설명 --- 인과추론이란 \"원인 -> 결과\"의 패턴인 \"인과관계\"를 찾는데에 목적이 있습니다. 이 패턴을 찾는건 어려운 일인데, 그 이유 중 하나는 원인과 결과에 모두 영향을 주는 교란변수 때문입니다. 교란변수(confounding variable)란 종속변수와 독립변수에 모두 영향을 줘 잘못된 인과관계를 찾도록 만드는 변수를 말합니다. 즉 교란변수가 잘못된 패턴을 찾도록 유도하기 때문입니다. !confounding variable 예시그림 가장 대표적인 예시로 \"아이스크림 판매량\"과 \"상어 어택횟수\"를 생각해볼 수 있습니다. \"기온\"이라는 변수는 \"아이스크림 판매량\"과 \"상어의 공격횟수\"에 모두 영향을 줍니다. 그래서 \"기온\"이 올라가서 \"아이스크림 판매량\"이 증가하고 \"상어의 공격횟수\"가 증가한 것인데, \"아이스크림 판매량\"이 증가해서 \"상어의 공격횟수\"가 증가했다는 생각을 하게 됩니다. 즉 \"교란 변수\"는 변수간의 관계를 잘못 해석할 가능성을 만들게 됩니다. 따라서 변수간의 관계를 볼 땐 교란변수를 제거해주는게 굉장히 중요합니다. 그렇다면 다음과 같은 질문을 해볼 수 있습니다. > 교란변수를 없애야 한다는 건 이해했어, 그러면 이걸 어떻게 없앨 건데? 가장 좋은 건 교란변수를 파악하고 실험 설계를 통해 없애는 것입니다. 위의 예시에서는 \"기온\"이라는 교란편수를 파악하고, 이를 통제한 후에 두 변수 간의 관계를 살펴볼 수 있습니다. 하지만 교란변수를 파악하더라도 이를 통제할 수 없을 때가 있습니다. 예를 들어 수술방법(독립변수)과 수술 후 결과(종속변수)의 관계에서는 나이, 생활습관 등의 교란변수가 있습니다. 교란변수를 파악하지만 이를 통제할 수 없습니다. > 이를 위해 교란변수의 영향을 \"통계적\"으로 제거해주는 방법이 제안되었습니다. FWL Theorem 이란? --- > 앞서 설명한 교란변수의 영향, 즉 편향을 보정하기 위한 방법입니다. FWL 정리의 이론적 배경은 다중회귀의 강력함에 있습니다. > 다중 회귀 분석에서 회귀 계수의 의미는 모델의 다른 변수들의 효과를 고려한 후 얻은 동일 설명변수의 이변량계수다. 이는 다중회귀모형에서 특정 관심 변수의 OLS 추정계수는, (1) 모든 설명변수를 한꺼번에 포함하여 회귀분석한 결과와, (2) 통제 변수들에 대해 종속변수와 관심 변수 각각의 잔차를 구한 뒤 이 잔차들 간에 회귀분석한 결과가 동일하다는 의미입니다. 수학적 표현 다중회귀 모델을 다음과 같이 표현할 수 있습니다: $$Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\cdots + \\beta_k X_k + \\epsilon$$ 여기서 $Y$는 종속변수, $X_1$은 관심 변수, $X_2, \\ldots, X_k$는 통제 변수들입니다. FWL 정리에 따르면, $\\beta_1$의 OLS 추정치는 다음 두 방법으로 동일하게 구할 수 있습니다: 방법 1: 전체 모델에서 직접 추정 $$\\hat{\\beta}_1 = \\frac{\\text{Cov}(X_1, Y)}{\\text{Var}(X_1)}$$ 방법 2: 잔차화를 통한 추정 $Y$를 $X_2, \\ldots, X_k$에 대해 회귀하여 잔차 $e_Y$ 계산 $X_1$을 $X_2, \\ldots, X_k$에 대해 회귀하여 잔차 $e_{X_1}$ 계산 $e_Y$를 $e_{X_1}$에 대해 회귀하여 $\\hat{\\beta}_1$ 추정 $$e_Y = Y - \\hat{Y}_{X_2,\\ldots,X_k}$$ $$e_{X_1} = X_1 - \\hat{X_1}_{X_2,\\ldots,X_k}$$ $$\\hat{\\beta}_1 = \\frac{\\text{Cov}(e_{X_1}, e_Y)}{\\text{Var}(e_{X_1})}$$ 실제로 수식적으로도 같고 (참고자료 2 참고) 테스트를 해봐도 같습니다. 인과추론에서 다중회귀는 예측 모델이 아닌 인과관계를 찾는 모델로 사용됩니다. R-learner, 인과추론 모델로 구현하기 --- 정리하면 FWL이란 잔차화를 통해 교란변수를 직교화 시키는 방법입니다. FWL을 meta learner 형태로 구현한게 R-learner입니다. 따라서 잔차화를 위한 2개의 nuisance function이 필요하고, CATE를 추정하는 모델이 필요합니다. R-learner의 목적 함수는 다음과 같습니다: $$\\mathcal{L}(\\tau) = \\mathbb{E}\\left[\\left(Y - m(X) - \\tau(X)(T - e(X))\\right)^2\\right]$$ 여기서: $m(X) = \\mathbb{E}[Y X]$: 결과 모델 (outcome model) $e(X) = \\mathbb{E}[T X]$: 처리 모델 (treatment model) $\\tau(X)$: 조건부 평균 처리 효과 (CATE) 다중회귀와 비교해서 FWL은 meta leaner로 구현할 때의 장점은 '비선형적인 패턴'을 학습할 수 있다는 점입니다. 이렇게 구현된 R-learner를 통해 CATE(Conditional Average Treatment Effect)를 추정할 수 있습니다."
  },
  {
    "id": "Data Science/Causal Inference/correlation-vs-causation",
    "title": "상관관계와 인과관계의 이해",
    "date": "2025-06-28",
    "excerpt": "상관관계와 인과관계의 차이점을 이해하고, 예측 모델의 한계와 인과추론의 중요성에 대한 이야기",
    "category": "Causal Inference",
    "tags": [
      "상관관계",
      "인과관계",
      "인과추론"
    ],
    "content": "> 상관관계와 인과관계를 이해하고 구분하는 건 결과를 해석할 때 중요한 점입니다. 상관관계란, 두 변수 사이에 일정한 패턴이나 동반 변동이 존재함을 의미하며, 한 변수가 커질 때 다른 변수가 일정하게 커지거나(양의 상관), 작아지는(음의 상관) 경향을 보이는 통계적 관계를 말합니다. 인과관계란, 한 변수가 변할 때 다른 변수가 그 변화에 의해 직접적·체계적으로 영향을 받아 변화하는 관계를 의미합니다 보통 두 변수간의 관계를 살펴볼 때 상관관계를 살펴보곤 합니다. 하지만 상관관계를 인과관계로 해석하지 않도록 주의해야 합니다. 예를 들어 아이스크림 판매량과 일일 기온 사이에는 높은 기온일수록 판매량이 증가하는 강한 양의 상관관계가 관찰되지만, 이는 기온이 아이스크림 판매량을 직접 “원인”한다고 단정할 수 없으며, 사람들이 더운 날씨에 밖에 나와 판매량이 늘어나는 등 다양한 제3의 요인이 동시에 작용했을 가능성을 배제할 수 없습니다. > 예측 모델은 주어진 데이터에서 변수 간의 동시 변동 패턴, 즉 상관관계를 학습해 결과를 예측합니다. 이 모델의 예측결과는 인과관계를 보장하지 못합니다. 가격 매출 --- --- --- 1 100 1000 2 150 900 3 600 10000 4 700 12000 예를 들어 숙박 가격과 매출이 주어진 데이터에서 가격이 높을수록 매출이 높아 보인다면, 모델은 “가격이 오르면 매출이 오른다”고 예측할 것입니다. 하지만 이 패턴 뒤에는 “성수기/비수기 여부”라는 숨겨진 외부 요인이 있을 수 있습니다. 가격이 비수기에 낮아지고 성수기에 올라가는 동시에 매출도 함께 변했다면, 실제로는 계절성이 매출을 결정짓는 진짜 원인인데, 단순 예측 모델은 이를 구분하지 못합니다. 따라서 상관관계에 기반한 예측 결과를 인과관계로 오해하면 “매출을 올리려면 가격을 올려야 한다”는 잘못된 결론에 이를 수 있고, 실제 효과가 있는 개입(예: 비수기 프로모션) 대신 부적절한 가격 정책을 선택하게 만듭니다. 인과추론은 이러한 숨겨진 교란 요인까지 고려해, 조작 가능한 원인이 실제로 결과에 미치는 영향을 통계적으로 분리·추정함으로써 올바른 의사결정을 가능하게 합니다."
  },
  {
    "id": "Data Science/Causal Inference/what-is-causal-inference",
    "title": "인과추론이란?",
    "date": "2025-06-20",
    "excerpt": "인과추론의 개념에 대해 소개하는 이야기",
    "category": "Causal Inference",
    "tags": [
      "상관관계",
      "인과관계",
      "인과추론"
    ],
    "content": "“인과추론” (Causal Inference)은 최근에 의료 분야, 마케팅 분야 등 선택에 대한 분석이 필요한 곳에 자주 사용되는 개념입니다. 인과추론은 다음과 같은 질문들에 답을 합니다. “마케팅 비용을 늘렸더니 매출이 증가했네, 마케팅 비용을 늘려서 그런건가?” . “환자에게 A라는 약물을 처방했더니 상태가 괜찮아졌어. A 덕분인가?” 이러한 질문들은 전통적으로 대조군과 실험군을 통해 증명되어왔습니다. 실험하려는 조건 외에 다른 조건은 모두 통제한 후에 실험결과를 비교합니다. 예를 들어 새로 개발한 비료의 효과를 검증하려고 합니다. 같은 품종의 옥수수 묘목 100포기를 두 그룹으로 나누어, 실험군에는 새 비료를 표준량만큼 투입하고 대조군에는 기존 비료(혹은 비료를 전혀 주지 않음)를 동일한 방식으로 처리합니다. 이때 물주기, 일조량, 토양 성분, 온도 등 나머지 재배 조건은 두 그룹에서 완전히 동일하게 유지합니다. 일정 기간 후 두 그룹의 생장 속도, 수확량, 작물 건강 상태를 비교하면, 오로지 “비료 종류”의 차이만이 결과에 영향을 미쳤다고 판단할 수 있게 됩니다. 이러한 접근법은 가장 합리적이지만, 현실 문제에 적용하기엔 어려움이 있습니다. 마블의 멀티버스 세계관이 아니라면, 2025년 7월 1일에 마케팅 비용을 100만원과 1000만원을 모두 사용할 수 없습니다. 한 명의 환자에게 렌즈 사이즈를 12.1를 삽입한 후 결과를 확인하고, 렌즈를 뺀 후 12.6를 삽입해 결과를 확인할 수 없습니다. 즉, 대조군과 실험군을 설정하는데 어려움이 있습니다. 인과추론은 이를 통계적으로 보완하여 결과를 추정하는 방식입니다. 예를 들면, 온라인 쇼핑몰에서 A라는 광고 캠페인이 판매량에 미친 영향을 알고 싶을 때, 실제로는 동일한 고객에게 광고를 보여주지 않은 상태와 보여준 상태를 모두 경험시킬 수 없으므로 인과추론 기법을 활용합니다. 이때 고객의 연령, 성별, 과거 구매 이력 등 다양한 고객 특성을 보고, 광고를 본 그룹과 보지 않은 그룹 간에 이 특성 분포를 비슷하게 맞춰(예: 성향점수 매칭) 가상의 대조군을 만듭니다. 이후 두 그룹의 평균 구매액 차이를 계산하면, “광고 효과”만을 통계적으로 분리해 추정할 수 있습니다. 이렇게 하면 실제 실험을 수행하기 어려운 상황에서도 마치 무작위대조시험과 유사한 수준의 인과적 해석을 얻을 수 있습니다. 렌즈 사이즈를 추천할 때도, 마치 광고 효과를 분석하듯이 환자마다 나이·굴절도·각막 두께 같은 특징들을 고려해 “12.1, 12.6, 13.2 크기 렌즈”를 쓴 환자들과 비슷한 조건의 가상의 대조군을 만들어 비교합니다. 예를 들어, 30대 근시 환자 중에 12.6mm 렌즈를 사용한 그룹과 12.1mm 렌즈를 사용한 그룹이 비슷한 눈 구조와 시력치를 갖고 있도록 통계적으로 조정한 뒤, 두 그룹의 수술 후 시력 개선 정도 차이를 분석하면 “12.6mm 렌즈를 쓰면 시력이 얼마나 더 좋아지는지”를 인과적으로 추정할 수 있습니다. 이렇게 얻은 결과를 바탕으로, 실제로는 써보지 않은 12.3mm 같은 중간 크기의 렌즈가 가져올 효과도 예측할 수 있고, 최종적으로는 각 환자에게 가장 효과적인 렌즈 크기를 과학적으로 추천해 줄 수 있습니다."
  },
  {
    "id": "Data Science/Causal Inference/Paper Review/review-Multi-Study-R-Learner-for-Estimating-Heterogeneous-Treatment-Effects-Across-Studies-Using-Statistical-Machine-Learning",
    "title": "[Paper Review] Multi-Study R-Learner for Estimating Heterogeneous Treatment Effects Across Studies Using Statistical Machine Learning",
    "date": "2025-01-16",
    "excerpt": "Multi-Study R-Learner 논문에 대한 리뷰 및 분석",
    "category": "Causal Inference",
    "tags": [
      "R-Learner",
      "Heterogeneous Treatment Effects",
      "Multi-Study",
      "Statistical Machine Learning",
      "Paper Review"
    ],
    "content": "paper link"
  },
  {
    "id": "Self_Development/Career/Graduate School/OMSCS관련",
    "title": "OMSCS(Georgia Tech 온라인 CS 석사) 지원 준비 계획",
    "date": "2025-01-15",
    "excerpt": "세계 최고 가성비 CS 석사 프로그램 분석과 지원 전략",
    "category": "Career",
    "tags": [
      "대학원",
      "OMSCS",
      "Georgia Tech",
      "컴퓨터사이언스"
    ],
    "content": "배경 데이터 사이언스 분야에서 더 깊이 있는 커리어를 쌓기 위해 석사 과정을 고려하던 중, OMSCS(Georgia Tech Online Master of Science in Computer Science)라는 혁신적인 프로그램을 발견했다. 세계 톱급 CS 프로그램을 온라인으로, 그것도 극도로 저렴한 비용으로 이수할 수 있다는 점이 매력적이다. OMSCS란? 📊 기본 정보 정식명칭: Georgia Institute of Technology Online Master of Science in Computer Science 개설연도: 2014년 (Udacity, AT&T와 협력) 총 비용: 약 $7,000-$8,500 (한화 900만-1,100만원) 학위: 캠퍼스와 동일한 Georgia Tech MS in Computer Science (온라인 표기 없음) 기간: 평균 2-3년 (파트타임으로 진행 가능) 과정 구성: 10개 과정 (30학점) 합격률: 약 70% ✅ 주요 장점 압도적인 가성비 전체 프로그램 비용이 $7,000-$8,500 (한화 900만-1,100만원) 타 명문대 온캠퍼스 프로그램 대비 1/5~1/10 수준 명문대 브랜드 + 동등한 학위 Georgia Tech는 CS 분야 세계 8위 (US News 2024) 졸업장에 \"온라인\" 표기 없음 실리콘밸리에서 인정받는 브랜드 다른 블로그 글들이나 링크드인 봤을 때 job interview 기회도 확실히 더 얻을 수 있다. 해외 이직도 고려하고 있으니까 지금 상황에서 할 수 있는 가장 좋은 선택이 아닐까. 유연성 풀타임 직장과 병행 가능 자신의 페이스로 진도 조절 전 세계 어디서나 수강 가능 보통 1과목당 주당 20~40시간정도 필요하다고 함. 실무 중심 커리큘럼 Machine Learning, AI, Computer Vision 등 현업 엔지니어들이 직접 활용할 수 있는 스킬 프로젝트 기반 학습 ⚠️ 단점 및 고려사항 높은 자기관리 요구 온라인 특성상 강한 자기 동기부여 필요 시간 관리와 학습 계획 수립 능력 중요 졸업이 어려움 네트워킹 제한 교수나 동료들과의 직접적인 만남 부족 연구 기회나 인턴십 연결 어려움 Redis에서 활발하게 이야기가 나오고 있긴 함. 그래도 네트워킹은 많이 부족함. 한국에서의 인식 아직 국내에서는 인지도가 낮음 전통적인 한국 기업에서는 평가 불분명 그래도 알고 있는 사람들은 충분히 좋게 봐주는 걸로 이해 중 언어 장벽 모든 수업이 영어로 진행 TOEFL 100점 이상 필요 토플 준비가 가장 급하다. 지원 일정 및 전략 📅 지원 일정 Spring 학기 지원 마감일: 8월 15일 Fall 학기 지원 마감일: 3월 1일 Priority Decision: 마감일 이전부터 순차적 합격 발표 내년 가을 학기 목표로 3월까지 준비 서류 갖추기 준비해야 하는 것들 [x] OMSCS 프로그램 상세 조사 완료 [ ] TOEFL 기존 점수 확인 또는 응시 일정 잡기 [ ] 추천인 3명에게 연락 (8월 10일까지 제출 요청) 추천인들에게 리마인더 메시지 필요한 정보 즉시 제공 [ ] 대학교 영문 성적증명서 발급 신청 [ ] Personal Statement 초안 작성 시작 [ ] 데이터 사이언스 경험 + OMSCS 지원 동기 명확히 [ ] 온라인 샘플들 참고하여 빠르게 작성 [ ] 이력서 OMSCS 맞춤 업데이트 기술 프로젝트, 프로그래밍 경험 강조 📅 합격 후 계획 (2025.9 ~ 2026.1) [ ] TOEFL 점수 향상 (합격 후에도 계속) 실제 수업에서 필요한 Speaking/Writing 실력 [ ] CS 기초 지식 보강 자료구조/알고리즘 체계적 복습 Python, Java 등 프로그래밍 언어 숙련도 향상 [ ] OMSCS 커뮤니티 활동 합격자 그룹 참여 첫 학기 수강 과목 리서치 [ ] 수학 기초 강화 선형대수, 확률통계, 이산수학 복습 [ ] Foundational Course 선택 처음에는 1개 과목만 수강 권장 CS 6515 (Algorithms) 또는 CS 6601 (AI) 고려 [ ] 학습 환경 구축 온라인 학습에 최적화된 환경 설정 시간 관리 시스템 구축 --- 🎯 핵심 우선순위 🔥 HIGH (필수) TOEFL 100점 이상 - 가장 중요한 정량적 지표 Personal Statement - 합격을 좌우하는 핵심 요소 추천서 3개 - 제3자 관점에서의 검증 📈 MEDIUM (중요) CS 기초 지식 - 면접이나 추가 질문 대비 프로그래밍 프로젝트 - 실무 역량 증명 성적증명서 - 기본 자격 요건 💡 LOW (플러스 요소) OMSCS 커뮤니티 활동 - 추가 정보 수집 기술 블로그 - 학습 의지 표현 --- ⏰ 주간 학습 계획 (예시) 평일 (월-금) 아침 1시간: 영어 공부 (TOEFL 준비) 저녁 1시간: CS 기초 또는 프로그래밍 주말 토요일 3-4시간: 지원서 작성 및 프로젝트 일요일 2-3시간: 복습 및 다음 주 계획 총 주당 약 10-12시간 투자 커리어에 미칠 영향 긍정적 영향 기술적 깊이: 현재 실무 경험에 이론적 백그라운드 추가 글로벌 네트워크: 전 세계 OMSCS 동문들과의 연결 경력 발전: ML 엔지니어, 리서치 사이언티스트 포지션 진출 가능 브랜드 가치: Georgia Tech 학위의 신뢰도 현실적 고려사항 시간 투자: 주당 15-20시간 학습 시간 필요 업무 병행: 현재 직장과의 균형 유지 전략 필요 ROI 관점: 학위 취득 후 실제 연봉 상승 및 커리어 기회 증가 여부 결론 OMSCS는 현재 내 상황에 매우 적합한 선택지로 보인다. 특히: 경제적 부담 최소화: 기존 직장 유지하면서 진행 가능 실무 연계: 현재 데이터 사이언스 업무와 직접적 연관 미래 가치: AI/ML 분야 전문성 강화로 커리어 확장 다만 성공적인 완주를 위해서는 철저한 시간 관리와 학습 계획이 필수적이다. 무엇보다 왜 이 프로그램을 해야 하는지에 대한 명확한 동기부여가 가장 중요할 것 같다. Spring 2026 입학을 목표로 체계적인 준비를 시작해보자! 🎯 --- 참고 자료 OMSCS 공식 웹사이트 OMSCS 지원 가이드라인 OMSCS 커뮤니티 및 후기"
  },
  {
    "id": "Self_Development/Portfolio/chatbot",
    "title": "AI Chatbot Project",
    "date": "2024-12-01",
    "excerpt": "",
    "category": "",
    "tags": [],
    "content": "AI Chatbot Project 프로젝트 개요 병원 상담 업무를 자동화하기 위한 RAG(Retrieval-Augmented Generation) 기반 지능형 챗봇 시스템을 개발했습니다. 카카오톡 채널을 통해 고객에게 제공되며, 반복적인 상담 질문에 대한 자동 응답을 통해 상담사의 업무 효율성을 크게 향상시켰습니다. 주요 기능 RAG 기반 답변 생성: 문서 검색과 생성 모델을 결합한 정확한 답변 제공 맥락 인식 대화: 대화 히스토리를 활용한 연속적인 상담 지원 다국어 지원: 한국어 및 영어 지원 실시간 응답: 빠른 응답 속도로 사용자 경험 향상 자동 모니터링: LLM 기반 대화 품질 자동 평가 시스템 기술 스택 Backend: Python, FastAPI NLP: Transformers, spaCy, OpenAI GPT Vector Database: Qdrant, ChromaDB Embedding: BGE-m3 Deployment: Docker, AWS Monitoring: Slack API 핵심 기술적 도전과 해결책 문서 검색 성능 최적화 문제: 의미적 검색의 한계로 인한 낮은 검색 정확도 해결책: 벡터 데이터베이스 구축: Qdrant를 활용한 고성능 벡터 검색 시스템 구축 메타데이터 필터링: 의사별, 진료과별 메타데이터 기반 정밀 검색 구현 임베딩 모델 선정: BGE-m3 모델을 다양한 옵션과 비교하여 최적 성능 확인 키워드 기반 필터링: 고유명사(의사 이름 등) 처리 개선을 위한 키워드 추출 및 필터링 질문 세분화: 복합 질문을 단순 질문으로 분해하여 검색 정확도 향상 대화 맥락 반영: Chat history를 활용한 질문 재정의 결과: 검색 정확도 95% 이상 달성 사용자 만족도 향상 문제: 챗봇이 답변할 수 없는 질문에 대한 반복 응답으로 인한 사용자 불만 해결책: 질문 분류 모델: 답변 가능/불가능 질문을 사전 판별하는 분류 모델 추가 상담사 연결: 답변 불가 질문 시 즉시 실제 상담사로 연결하는 시스템 구현 결과: 사용자 만족도 90% 이상 달성 유지보수 비용 최적화 문제: 수동 모니터링으로 인한 높은 운영 비용 (하루 30분 이상 소요) 해결책: 자동 모니터링 시스템: LLM 기반 대화 품질 평가 자동화 핵심 지표 추적: 답변 출처 적합성: 답변이 검색된 문서에서 생성되었는지 평가 질문-문서 연관성: 질문과 검색된 문서 간의 관련성 평가 임계치 기반 알림: 품질 점수가 임계치 이하인 대화만 알림 전송 결과: 모니터링 비용 80% 감소 답변 생성 최적화 프롬프트 엔지니어링 다음 3가지 관점에서 프롬프트를 최적화했습니다: 문서 사용성: 답변이 얼마나 문서에 기반했는지 친절성: 얼마나 친절하고 상냥하게 응답하는지 정확도: 얼마나 질문에 맞는 답변을 하는지 할루시네이션 방지 의료 정보의 정확성은 매우 중요하므로: 검색된 문서에서만 답변 생성하도록 강제 RAGAS 컨셉을 활용한 답변 기반성 자동 평가 LLM이 추출한 명제/개념의 문서 기반성 검증 결과 및 성과 답변 정확도: 95% 이상 달성 사용자 만족도: 90% 이상 달성 모니터링 자동화: 유지보수 비용 80% 감소 업무 효율성: 기존 상담 중 65% 챗봇으로 대체 응답 속도: 평균 0.5초 이내 학습한 점 RAG 시스템의 실제 적용 방법과 한계점 사용자 경험을 고려한 챗봇 설계의 중요성 자동화된 모니터링 시스템의 구축 방법 의료 분야에서의 AI 시스템 신뢰성 확보 방법"
  },
  {
    "id": "Self_Development/Portfolio/lenze_size_rec",
    "title": "Lens Size Recommendation System",
    "date": "2024-11-15",
    "excerpt": "",
    "category": "",
    "tags": [],
    "content": "Lens Size Recommendation System 프로젝트 개요 시력교정센터에서 렌즈 삽입술을 위한 최적의 렌즈 크기를 추천하는 머신러닝 기반 시스템을 개발했습니다. 의사의 경험과 노하우에 의존하던 렌즈 선택 과정을 데이터 기반으로 객관화하여, 환자별 맞춤형 렌즈 사이즈를 추천하는 서비스를 제공합니다. 주요 기능 예측 모델: 환자 정보와 렌즈 크기를 입력받아 수술 결과(Vault) 예측 인과추론 기반: 통계적 편향을 제거한 신뢰할 수 있는 예측 제공 의학적 직관 반영: 단조 증가/감소 조건을 만족하는 모델 설계 해석 가능성: 예측 결과에 대한 근거와 설명 제공 실시간 추론: BentoML 기반 고성능 모델 서빙 기술 스택 Backend: Python, Flask, FastAPI Machine Learning: Scikit-learn, LightGBM, XGBoost Causal Inference: Orthogonalization, Double ML Model Serving: BentoML, Docker Database: PostgreSQL Monitoring: Airflow, Flask Dashboard 핵심 기술적 도전과 해결책 신뢰할 수 있는 예측 모델 구축 문제: 단순한 예측 성능만으로는 선택의 신뢰도를 보장할 수 없음 해결책: 인과추론 적용: 교란편향 등 통계적 편향을 제거하여 인과적 관계 기반 예측 직교화(Orthogonalization): 예측 변수와 교란 변수를 분리하여 편향 제거 의학적 직관 반영: 단조 증가/감소 조건을 만족하는 모델 설계 결과: 결정계수(R²) 0.7 달성으로 예측 신뢰도 확보 사용자 신뢰도 및 만족도 향상 문제: 높은 평가지표가 사용자 신뢰와 만족을 보장하지 않음 해결책: 도메인 지식 기반 근거 제시: AI 예측 결과와 함께 의학적 근거 제공 사용자 피드백 반영: 주기적인 피드백 수집 및 UI/리포팅 기능 개선 차별화 증명: 연구 내용을 학술 논문으로 작성하여 제품 차별점 입증 결과: 사용자 친화적인 서비스 설계로 신뢰도 향상 데이터 품질 및 특성 분석 문제: 다양한 소스의 데이터 품질과 일관성 확보 해결책: 종합적 EDA: 좌안/우안 차이, 검사 장비 오류, 의사별 차이 등 분석 데이터 검증: OCR 결과, 수기 입력 데이터의 완전성 검증 피처 엔지니어링: 렌즈 회전각도, 종류, 두께 등 도메인 지식 기반 피처 추가 결과: 데이터 품질 향상 및 예측 성능 개선 모델링 접근법 모델링 조건 설정 서비스 목표에 맞는 모델 조건을 다음과 같이 정의했습니다: 단조성 조건: 특정 변수와 예측값 간의 단조 증가/감소 관계 유지 해석 가능성: 모델이 해석 가능하거나 결과를 추정할 수 있어야 함 모델 선택 및 최적화 Linear Regression 계열: Lasso, Ridge, ElasticNet (회귀 계수로 단조성 확보) GBDT 계열: LightGBM, XGBoost, CatBoost (monotonic constraint 적용) 앙상블: Voting과 Stacking을 통한 성능 향상 하이퍼파라미터 튜닝: Bayesian optimization 활용 일반화 성능 확보 Data Leakage 방지: 시간 기반 test set 구성 및 unknown 처리 의학적 논리 검증: 회귀 계수, feature importance, SHAP 분석을 통한 정성평가 정기적 성능 확인: 특정 주기로만 test set 확인하여 과적합 방지 시스템 아키텍처 모델 서빙 BentoML 활용: Docker 이미지로 패키징하여 버전 관리 온프레미스 배포: 기존 서버 리소스 활용한 추론 서버 구축 데이터 일관성 확보 Feature Store 구축: 학습과 추론에서 동일한 로직으로 데이터 처리 FastAPI 기반: ORM을 활용한 데이터 관리 시스템 모니터링 시스템 Flask Dashboard: 모델 성능 및 데이터 분포 실시간 모니터링 Airflow 스케줄링: 정기적인 모니터링 데이터 업데이트 현재 연구 및 개선 방향 한계점 인식 현재 모델의 성능 한계를 다음과 같이 분석했습니다: 측정 한계: 검사 장비는 홍채 윗부분만 측정 가능 구조적 요소: 실제 렌즈 삽입 위치(섬모체 낭) 정보 부족 모델 한계: Linear/GBDT 모델로는 latent space 구성 어려움 향후 연구 방향 구조적 요소 추정: 보이지 않는 해부학적 구조를 추정할 수 있는 모델 개발 Latent Space 모델링: 복잡한 구조적 관계를 학습할 수 있는 고급 모델 연구 결과 및 성과 예측 신뢰도: 결정계수(R²) 0.7 달성 통계적 편향 제거: 인과추론 기반 신뢰할 수 있는 예측 제공 사용자 만족도: 도메인 지식 기반 근거 제시로 신뢰도 향상 시스템 안정성: 자동화된 모니터링으로 안정적인 서비스 운영 학습한 점 인과추론을 통한 예측 모델의 신뢰성 확보 방법 의료 분야에서의 AI 시스템 설계 및 검증 방법 사용자 중심의 서비스 설계 및 피드백 반영 과정 대용량 데이터 처리 및 모델 서빙 시스템 구축"
  },
  {
    "id": "Self_Development/Portfolio/segmentation",
    "title": "Segmentation Model",
    "date": "2024-10-20",
    "excerpt": "",
    "category": "",
    "tags": [],
    "content": "당뇨병성 망막병증 탐지 모델 프로젝트 개요 당뇨병성 망막병증은 당뇨병 환자에게 자주 발생하는 합병증으로, 혈관 손상과 새로운 혈관 생성으로 인해 실명까지 유발할 수 있는 심각한 질환입니다. 초기 진단이 매우 중요한 이 병증을 안저사진을 통해 탐지하는 서비스를 개발했습니다. 안저사진은 눈의 안쪽(망막 부분)을 촬영하여 혈관 상태를 관찰할 수 있게 해주는 의료 영상입니다. !안저사진 이 프로젝트는 의사들의 진단을 지원하는 목적으로 개발되었으며, 입사 전 부트캠프 기간 중 기업연계 프로젝트로 시작하여 입사 후에도 지속적으로 발전시켰습니다. 관련 링크: 프로젝트 Github 발표영상 유튜브 데이터 현황 및 도전과제 프로젝트 진행 중 가장 큰 이슈는 데이터 부족이었습니다. 초기 데이터 상황 오픈 데이터셋 활용: 약 1,500개 이미지 레이블 보유율: 전체의 80% 정도 데이터 품질 문제: 부적절한 레이블 다수 존재 데이터 확보 과정 입사 후 임상팀과 협업하여 데이터 검수 및 추가 확보를 진행했지만, 여전히 제한된 데이터 환경에서 프로젝트를 진행해야 했습니다. 모델링 전략 및 성능 개선 모델 선택: U-Net 기반 데이터의 특징상 전체 이미지 중 레이블(마스크)이 포함된 부분이 매우 작은 의료 도메인의 특성상, U-Net 계열 모델이 가장 높은 성능을 보이는 것을 확인했습니다. 실제 연구 결과와 프로젝트 내 비교 실험에서도 U-Net이 최고 성능을 달성했습니다. 성능 향상을 위한 핵심 기법들 전처리: CLAHE 적용 명암대비 향상 기법인 CLAHE를 적용하여 데이터의 특징을 더 명확하게 만들었습니다. !CLAHE 적용 결과 육안으로도 특징이 더 명확하게 보이며, 실제 성능도 향상되었습니다. 다만 과도한 명암대비 향상은 false positive를 증가시키므로 실험을 통해 적정 수준을 설정했습니다. Contrastive Learning 기반 사전학습 ImageNet 사전학습 가중치가 안저사진과 같은 특수한 의료 영상에는 효과적이지 않다는 것을 실험을 통해 확인했습니다. 대신 회사 내 보유한 대량의 안저사진(레이블 없음)을 활용하여 contrastive learning 기반 사전학습을 진행했습니다. 결과: 성능 10-15% 향상 달성 Multi-Task Learning U-Net의 인코더-디코더 구조를 활용하여 segmentation 외에 reconstruction task를 추가로 수행하는 multi-task learning을 적용했습니다. 모델 서빙 및 배포 배포 전략 서비스 초기 단계의 특성을 고려하여 빠른 모델 배포가 가능한 방법을 채택했습니다. 기술 스택 모델 최적화: TensorRT engine 변환 서빙 플랫폼: Triton Server 장점: 모델 추론 최적화 용이 GPU 자원 관리 자동화 요청/응답 처리 간소화 프로젝트 성과 항목 내용 ------ ------ 프로젝트명 당뇨병성 망막병증 병변 탐지 모델링 및 서비스 개발 기간 2024년 4월 ~ 2025년 6월 (3개월) 주요 성과 • Contrastive Learning 적용으로 일반화 성능 향상<br>• 제한된 데이터에서도 모델 판별력 개선<br>• Multi-Task Learning으로 병변 탐지 성능 최적화<br>• Segmentation 성능: IoU 개선, Dice Score 0.8 달성 역할 • 최신 연구 분석 및 모델 설계 적용<br>• 데이터 부족 문제 해결을 위한 기법 적용<br>• 데이터 품질 개선 및 정제<br>• 모델 최적화 및 하이퍼파라미터 튜닝 기술 스택 PyTorch, Triton-Server, gRPC, Docker"
  },
  {
    "id": "Self_Development/Portfolio/ocr_pipeline",
    "title": "OCR Pipeline System",
    "date": "2024-10-20",
    "excerpt": "",
    "category": "",
    "tags": [],
    "content": "OCR Pipeline System 프로젝트 개요 병원 검사 결과 이미지에서 실시간으로 데이터를 추출하여 DB에 자동 적재하는 OCR 파이프라인 시스템을 구축했습니다. 기존 수작업으로 진행되던 데이터 입력 과정을 자동화하여 검안사의 업무 효율성을 크게 향상시켰습니다. 주요 기능 실시간 OCR 처리: 검사 완료 즉시 이미지에서 데이터 추출 고정 이미지 최적화: 검사 장비별 고정된 이미지 구조 활용 다중 OCR 엔진: TrOCR 기반 고정밀 텍스트 인식 데이터 품질 자동화: 분포 분석 및 이상치 탐지 자동화 시스템 일관성 검증: 고객번호 등 고정값들의 무결성 검증 자동 모니터링: Slack 기반 실시간 에러 알림 및 작업 요약 안정적 파이프라인: 1% 미만 에러율의 안정적인 서비스 운영 기술 스택 OCR Engine: TrOCR (Microsoft) Image Processing: OpenCV, PIL Backend: Python, gRPC, FastAPI Model Serving: Triton Server Containerization: Docker Monitoring: Slack API Database: PostgreSQL 핵심 기술적 도전과 해결책 OCR 정확도 99% 달성 문제: 검사 결과의 정확성이 매우 중요하므로 높은 OCR 정확도 필요 해결책: 고정 이미지 구조 활용: 검사 장비별 고정된 이미지 레이아웃을 활용하여 Text Detection 단계 생략 TrOCR 모델 적용: Text Recognition에 특화된 TrOCR 모델 사용으로 정확도 향상 이미지 전처리: 노이즈 제거, 대비 개선 등 전처리 과정 최적화 결과 후처리: OCR 결과 정제 및 검증 로직 구현 데이터 품질 자동화: 각 값의 분포 분석 및 이상치 탐지 자동화 시스템 구축 일관성 검증: 고객번호 등 고정값들의 일관성 검증 로직 개발 결과: OCR 정확도 99% 달성 안정적인 파이프라인 구축 문제: 실시간 데이터 추출을 위한 안정적인 서비스 운영 필요 해결책: 객체 지향 설계: 각 기능을 담당하는 객체들로 파이프라인 구성 단계별 에러 처리: 이미지 송수신, 전처리, OCR, 후처리, DB 적재 각 단계별 명확한 에러 처리 비동기 처리: 1초 이내 응답을 위한 비동기 처리 구조 구현 자동 모니터링: 각 객체별 모니터링 자동화 결과: 에러율 1% 미만의 안정적인 파이프라인 구축 기존 프로세스 방해 최소화 문제: 검안사의 기존 업무 프로세스에 변화를 주지 않으면서 OCR 서비스 추가 해결책: Client-Server 구조: 병원 컴퓨터의 client가 이미지를 전송 후 기존 \"아이리더\" 프로그램에 자동 적재 gRPC 통신: 빠른 이미지 전송을 위한 gRPC 프로토콜 사용 권한 문제 해결: 다양한 병원 환경에 맞는 배포 방식 (Python/Go) 응답 속도 최적화: 1초 이내 응답으로 기존 프로세스 지연 최소화 결과: 기존 프로세스에 방해 없이 OCR 서비스 성공적 통합 시스템 아키텍처 Client 프로그램 목적: 기존 프로세스 방해 없이 OCR 서버로 이미지 전송 기술: gRPC를 통한 고속 이미지 전송 환경 대응: 다양한 병원 컴퓨터 환경에 맞는 배포 (Python/Go) 자동화: 이미지 전송 후 기존 \"아이리더\" 프로그램에 자동 적재 OCR Server 비동기 처리: 이미지 수신 즉시 응답 후 백그라운드에서 OCR 처리 모델 서빙: Triton Server를 통한 TrOCR 모델 고성능 서빙 GPU 활용: 온프레미스 GPU 서버를 통한 고속 추론 고정 이미지 처리: 검사 장비별 pixel 기반 조건문으로 Text Detection 생략 모니터링 시스템 Slack 알림: 에러 발생 시 실시간 알림 작업 요약: 하루 작업량 및 성공률 자동 보고 객체별 모니터링: 각 기능별 독립적인 모니터링 로그 관리: 깔끔한 로그 구조로 쉬운 문제 진단 핵심 최적화 포인트 Text Detection 생략 검사 결과 이미지가 고정된 구조를 가지고 있다는 특성을 활용: 검사 장비별 이미지 버전 및 페이지 구분 Pixel 값 기반 조건문으로 영역 분할 Text Recognition 단계에만 집중하여 처리 속도 향상 TrOCR 모델 선택 다양한 OCR 모델 비교 후 TrOCR 선택: 정확도: 벤치마크에서 98% 정확도 실제 성능: 숫자 인식 100% 정확도 한국어 지원: 문자 인식은 단위 정보로 고정 위치 활용 비동기 처리 구조 사용자 경험을 위한 응답 속도 최적화: 이미지 수신 즉시 응답 (1초 이내) 백그라운드에서 OCR 처리 상담 시점까지 충분한 처리 시간 확보 결과 및 성과 OCR 정확도: 99% 달성 에러율: 1% 미만의 안정적인 파이프라인 구축 처리 속도: 1초 이내 응답으로 기존 프로세스 지연 최소화 유지보수 효율: 코드 구조 개선으로 유지보수 효율 10배 증가 모니터링 비용: 자동화를 통한 모니터링 시간 90% 감소 학습한 점 고정 이미지 구조를 활용한 OCR 최적화 방법 실시간 데이터 처리 파이프라인의 안정성 확보 방법 기존 프로세스와의 통합 시 사용자 경험 고려의 중요성 객체 지향 설계를 통한 유지보수성 향상 자동화된 모니터링 시스템의 구축 및 운영 방법"
  },
  {
    "id": "Data Science/Recommendation/2024-07-05-recommendation-system-interest",
    "title": "추천시스템에 관심있는 이유",
    "date": "2024-07-04 23:30:00 +0900",
    "excerpt": "",
    "category": "Recommendation",
    "tags": [
      "Recommendation"
    ],
    "content": "잠깐 추천시스템을 공부했었는데, 다시 공부를 시작하면서 프로젝트를 하나씩 쌓아가려고 한다. 그 전에 내가 왜 관심이 있는지, 또 어떤 프로젝트를 해보고 싶은지 정리해보려 한다. 추천시스템이란? 추천시스템은 검색과 비슷한 목적을 가지고 있다. > 많은 정보 속에서 필요한 정보를 필터링하는 것 \"진짜 많은 정보들, 컨텐츠들이 있는데 유저에게 어떤 것을 보여줘야할까?\"에 대한 답을 하는 것이다. 왜 중요할까? 추천시스템이 필요한 곳은 대표적으로 OTT 회사들이 떠오른다. 소비자는 언제 구독을 그만둘까? > 당연하게도 더 이상 볼게 없다고 느껴질때 그만둘 것이다. 전체 컨텐츠에 비해 소비한 컨텐츠는 소수일텐데 왜 볼게 없다고 느껴질까? > 뭘 봐야할지 모르겠어서, 어떤게 내 재밌을지 몰라서. 그래서 소비자에게 취향에 맞는 컨텐츠를 꾸준히 노출해줘야하고, 그래야 소비자가 떠나지 않도록 만들 수 있다. 어려운 점 내가 생각했을 때 추천시스템을 구성하는데 가장 어려운 것은 소비자의 평가 데이터가 적기 때문인 것 같다. 어떤 사람이 평가한게 적으면 당연히 취향을 분석하기 어렵고, 그래서 추천해주기도 어렵다. 평가 데이터가 많은 사람에게 잘 추천해주는 것도 굉장히 중요하지만, 평가 데이터가 부족한 사람에게 어떻게 추천해줄지에 대한 문제를 해결하는게 가장 중요한 것 같다. 해보고 싶은 프로젝트 요즘 해보려는 프로젝트는 LLM을 이용해서 소비자의 취향을 알아내는 것이다. 구체적으로는 Multi-Agent-System으로 추천시스템을 구축해보려고 하고, 맨 앞단에 취향을 분석하는 Agent를 구축해 사용해보려고 한다. 먼저 영화로 시작해서 책과 같은 분야로도 확장해보려고 한다. 취향을 분석한다는게 굉장히 애매한 부분인 것 같아서 고민이 많이 필요할 것 같다. 이게 가능해진다면 많은 산업에서 정말 매력적으로 느끼는 기술이 아닐까? 총 3명이서 이 프로젝트를 진행할 것 같은데 그 과정을 블로그에 남겨보려고 한다."
  },
  {
    "id": "Self_Development/Reflections/2024-07-04-interest-concerns",
    "title": "관심사에 대한 고민",
    "date": "2024-07-04 19:49:00 +0900",
    "excerpt": "",
    "category": "Reflections",
    "tags": [
      "Interest"
    ],
    "content": "현재 나의 상황 이제 데이터과학자로 일한지 3개월정도 되었다. 아이펠이라는 모두의 연구소에서 운영하는 부트캠프를 진행했었는데, 이때 기업연계프로젝트로 진행했던 기업에 취업을 했다. 분야는 안과의료분야이며, 비앤빛 밝은세상 안과로부터 만들어진 스타트업이다. 이때 진행한 프로젝트는 당뇨병성 망막병증의 병변들을 탐지해내는 모델을 만드는 것이었다. 이에 대한 링크는 다음과 같다. 발표자료 발표링크 결과적으로는 의료 데이터를 가지고 Segmentation 작업을 수행하고 발전시켜볼 수 있어서 좋았다. 또한 이게 어떻게 쓰일 수 있을지에 대한 고민도 해볼 수 있어서 좋았다. 그렇게 인공지능을 통해 건강에 기여할 수 있겠다는 꿈을 가지고 입사를 하게 되었다. 대부분의 스토리가 그러하듯, 나 역시 기대와 많이 다른 회사생활을 하게 되었다. 안과 분야에서의 인공지능 개발현황 의료 분야 중에서 특히 안과에 대해서만 알고, 그래서 안과에 대해서만 한정해서 이야기하려고 한다. 비쥬웍스 내가 일하고 있는 비쥬웍스라는 기업은 내가 느끼기에 가장 성취가 적다. 의료인증을 받은 모델도 없고, 받으려면 아직 멀었다. 자세하게 이야기할 수는 없지만, 회사의 방향도 당장의 수익을 만드는 것에 집중하고 있다. 따라서 내가 원했던 부분과는 많이 다르게 일을 하고 있다. 다른 회사로 이직하면 되는 걸까? 선두기업들은 어떻게 하고 있을까? 뷰노 뷰노에서는 안저사진을 통한 질병 분류 모델을 출시하고, 결과에 CAM도 같이 보여준다. (CAM을 통해 모델이 어느 부분을 집중적으로 보고 있는지 '추정'할 수 있음) 병원에 있는 의사분께 듣기로는 전혀 안쓰인다고 한다. 정확도가 낮고, 몇번 정확도가 낮다는 생각이 들면 바로 안쓰게 된다고 한다. 굳이? 이런 마음이 큰 것 같다. 메디비전 가장 재미있어 보이는 기업이다. 안저사진을 통해 심질환 위험도 예측, 콩팥 위험도 예측을 진행한다. 시리즈B(100억)투자를 받고, 쟁쟁한 이사진들과 함께 모델을 개발하고 의료인증을 진행하고 있다. 아마도 국내는 수가가 낮고 보수적이라는 이유 때문에 미국 FDA 승인을 진행 중이며, 콩팥 모델의 경우에는 승인을 받은 것으로 알고 있다. 링크드인을 팔로잉하며 보고 있는데, 학문적인 발표도 많이 하는 것으로 보인다. 홈페이지에서도 발행한 논문들을 확인할 수 있다. 다만 과연 수익이 날까? 에 대해서는 궁금하고 났으면 좋겠다. 나의 진로에 대한 고민 이런 상황속에서 나는 나의 흥미에 대해 한번 더 생각해보게 됐다. 그리고 이런 흥미에 따라 진로를 결정하게 되었다. 건강에 기여하고 싶은가? 과연 나는 진짜 건강에 기여하고 싶을까? 당장에 나의 영향이 전혀 느껴지지 않는 상황에서, 이런 꿈을 가지고 개발을 이어나갈 수 있을까? 나의 대답은 \"아니, 전혀\" . 항상 느끼지만 나는 소비자와 밀접한 분야에서 개발을 하고 싶다. 내가 만든 것들이 바로 사람들에게 영향을 미쳤으면 좋겠다. 그렇다면 어느 분야? 고3때 내 꿈은 PD 였다. 물론 이과였지만, 컨텐츠들을 소비하며 삶을 이어나갈 수 있었고 많은 영감을 받았기 때문이다. 나도 좋은 컨텐츠를 만들어 다른 사람에게 긍정적인 영향을 주고 싶었다. 핑계지만 이런 생각을 발전시킬 상황이 아니었고 자연스럽게 흘러갔다. 시간이 지나 인공지능으로 컨텐츠를 만드는 세상이 왔다. 직접적으로 컨텐츠를 생성하는 일을 하는 것도 좋지만, 내가 원하는 컨텐츠들을 쉽게 생성할 수 있는 도구를 개발하는 것도 재밌을 것 같다는 생각이 많이 든다. 준비할 것들 정리하자면 의료분야 데이터 과학자에서 생성형 인공지능을 개발하는 쪽으로 커리어를 이어나가고 싶다. 혹은 컨텐츠를 다루는 기업의 데이터 과학자도 괜찮을 것 같다. 어쨌든 컨텐츠를 다루는 쪽으로 커리어를 가지고 싶다. 이를 위해 크게 2가지 방향으로 준비하려고 한다. 생성형 인공지능 추천시스템 이를 위해 지금 하고 있는 것은 생성형 인공지능 스터디 (모두의 연구소 풀잎스쿨) 추천시스템 (프로젝트, 개인공부) 정리 앞으로 공부해야할 것들이 많다. 탑을 쌓아가는 과정을 꾸준히 블로그에 남기려고 한다. 하나씩 하다보면 못하는 일은 거의 없다고 생각한다. 꾸준히 준비해서 내가 원하는 커리어를 만들어 나가자!"
  },
  {
    "id": "Data Science/Tableau/2024-07-01-tableau-python-cloud-upload",
    "title": "태블러 python으로 데이터 cloud 업로드",
    "date": "2024-07-01 12:00:00 +0900",
    "excerpt": "",
    "category": "Tableau",
    "tags": [
      "Tableau",
      "Python"
    ],
    "content": "태블러 prep을 이용해 데이터 파이프라인을 구축해 태블러 클라우드에 데이터 웨어하우스를 구축할 수도 있지만, 버그도 많고 제한사항이 많다고 느껴져 파이썬에서 처리한 후 업로드하는 것을 선택했습니다. 업로드 하기 위해서는 2가지 과정이 필요합니다. csv to hyper hypter to cloud 순서대로 코드를 공유하면서 간단히 설명하겠습니다. csv to hyper 태블러 클라우드에는 hyper 데이터타입이 들어가야해서 정제된 csv 파일을 hyper로 바꿔줘야 합니다. csv 파일을 바꾸는 것만 다루지만 다른 파일들도 쉽게 응용할 수 있을 것이라 생각합니다. 3개의 인자를 받는데 csv 경로, hyper 저장할 경로, csv 파일 타입 정의한 객체 경로. csv로 저장하는 과정에서 맘대로 데이터타입이 바뀌는 문제가 있어서 타입을 정의한 객체도 따로 저장한 후에 불러올 때 참고하도록 했습니다. hyper 타입 데이터를 방식은 빈 테이블을 하나 만들고 채워나가는 것입니다. 따라서 어떤 테이블을 만들 것인지를 정의해줘야합니다. 이를 위해 columns 리스트를 정의해줍니다. 그 다음으로는 어떤 값을 추가할지 정의해줘야합니다. 이게 row 리스트를 정의하는 이유입니다. 여기서 주의깊게 봐야할 것은 null값을 처리하는 방식인데 pandas dataframe의 NaN값을 None으로 바꿔서 넣어줘야합니다. 그렇지 않으면 데이터타입이 맞지 않다는 오류가 발생합니다. ``python def csv_to_hyper(csv_file_path, hyper_file_path, dtype_dict_path): # CSV 파일 읽기 dtype_dict = load_data(dtype_dict_path) df = pd.read_csv(csv_file_path, dtype=dtype_dict) # 테이블 정의 해주기 columns = [] for index, value in df.dtypes.items(): value = str(value) if value == 'object': sql_type = SqlType.text() elif \"float\" in value: sql_type = SqlType.double() elif \"int\" in value: sql_type = SqlType.int() columns.append(TableDefinition.Column(index, sql_type, Nullability.NULLABLE)) # Hyper에 추가할 값 계산하기 rows = [] for row in df.itertuples(index=False, name=None): tmp_row = [] for item in row: if pd.isna(item): tmp_row.append(None) else: tmp_row.append(item) rows.append(tuple(tmp_row)) with HyperProcess(telemetry=Telemetry.SEND_USAGE_DATA_TO_TABLEAU) as hyper: with Connection(endpoint=hyper.endpoint, database=hyper_file_path, create_mode=CreateMode.CREATE_AND_REPLACE) as connection: # 스키마 생성 connection.catalog.create_schema('Extract') # 테이블 정의 table_definition = TableDefinition( table_name=TableName(\"Extract\", \"Extract\"), columns=columns ) connection.catalog.create_table(table_definition) # 데이터를 Hyper 파일로 삽입 with Inserter(connection, table_definition) as inserter: inserter.add_rows(rows=rows) inserter.execute() ` hyper to cloud 여러 라이브러가 있지만 개인적으로는 \"tableau_api_lib\"을 추천합니다. 관련해서는 다음 블로그를 참고하면 쉽게 사용할 수 있습니다. 참고하면 좋은 블로그 `python def hyper_to_cloud(hyper_file_path, datasource_name): config = { 'tableau_prod': { 'server': 'https://prod-apnortheast-a.online.tableau.com', 'api_version': '3.23', # 'username': '<YOUR_PROD_USERNAME>', # 'password': '<YOUR_PROD_PASSWORD>', 'personal_access_token_name': '토근 이름', 'personal_access_token_secret': '토근 정보', 'site_name': '사이트이름', 'site_url': '사이트이름' } } conn = TableauServerConnection(config_json=config, env='tableau_prod') conn.sign_in() # 데이터 소스 업로드 response = conn.publish_data_source( datasource_file_path=hyper_file_path, datasource_name=datasource_name, project_id='프로젝트 아이디', embed_credentials_flag=False ) # 업로드 결과 확인 if response.status_code == 201: print(f\"Datasource '{datasource_name}' published successfully.\") else: print(f\"Failed to publish datasource: {response.json()}\") `` 이렇게 2가지 함수를 통해 태블러에 데이터 웨어하우스를 업로드하고 있습니다."
  },
  {
    "id": "Self_Development/Reflections/2024-04-10-job-hunting-important-things",
    "title": "취준할 때 중요한 것",
    "date": "2024-04-10 12:00:00 +0900",
    "excerpt": "",
    "category": "Reflections",
    "tags": [
      "취준"
    ],
    "content": "저는 현재 의료인공지능 회사에서 데이터과학자로 일하고 있습니다. 제가 데이터과학자를 준비하면서 가장 중요하게 생각했고, 도움이 됐던 생각을 공유해보려 합니다. > 회사와 비슷한 고민을 하고 내가 가진 자원으로 해결해보는 것 데이터과학자 데이터과학자란 문제를 정의하고 이걸 데이터로 해결해나가는 사람을 뜻합니다. 이는 크게 2가지 과정으로 나눠볼 수 있습니다. 문제를 정의 내가 가진 자원과 기술로 해결 프로젝트를 하고 이를 포트폴리오를 만들 때는 이 2가지 과정이 꼭 잘 담겨있어야 합니다. > 어떻게 문제를 정의했으며, 이를 해결하기 위한 과정에서 어떤 고민들을 헀는지. 회사 회사는 문제를 정의하고 그걸 해결해나가며 수익을 내는 집단입니다. 회사에서 일하는 데이터과학자들은 본인이 정의하거나 운영진에서 정의한 문제를 회사의 자원과 본인의 기술들로 해결해나갑니다. > 데이터과학자를 준비하는 사람과 회사에서 데이터과학자로 일하는 사람의 과정은 완전히 동일하다고 할 수 있습니다. 중요한 부분 결국 중요한 것은 나의 과정들과 회사의 과정이 얼마나 겹치는지 입니다. 이 교집합이 클수록 본인의 프로젝트 혹은 포트폴리오는 매력적으로 보이게 됩니다. 즉, 내가 생각했을 때 이런 문제가 있고 또는 중요하다고 생각한다. 그래서 나는 이런 문제를 이렇게 풀어봤다. 푸는 과정에서는 이런 어려움이 있었고 이렇게 해결해나갔다. 이게 포트폴리오에 잘 담겨있어야하며, 취업을 준비할 때 가장 중요한 점이라고 생각합니다. 실제로 저도 제가 정의하고 해결했던 문제가 현재 제가 회사에서 해결하고 있는 문제입니다. 면접에서도 이걸 가장 좋게 봐주셨고 취업에 가장 도움이 많이 됐다고 생각합니다. 만약 제가 다른 분야로 이직을 준비한다면, 위에서 언급한 것처럼 사이드 프로젝트를 준비할 것입니다. 당연해보이는 생각이지만, 생각보다 많이 놓칠 수 있어 한번 정리해봤습니다. 취업을 준비하시는 분들이 좋은 결과를 얻었으면 좋겠습니다!"
  },
  {
    "id": "Self_Development/Reflections/2024-03-12-aifell-review",
    "title": "아이펠 후기",
    "date": "2024-03-12",
    "excerpt": "6개월 동안의 아이펠 후기",
    "category": "Reflections",
    "tags": [
      "아이펠",
      "이런저런 생각들"
    ],
    "content": "저는 23.9 ~ 24.2 동안 아이펠 6기 리서치 과정을 수료했고, 회고 겸 후기를 적어보려 합니다. !졸업증 신청했을 때의 나의 상황 일단 제가 어떤 상태에서 아이펠을 들었는지 설명드리겠습니다. 일단 저는 산업공학을 전공했고, 통계학을 부전공했습니다. 학부생때 ML에 관심이 많아서 혼자서 공부했었고, 관련 프로젝트도 진행했습니다. DL 부분은 잘 몰랐는데, 시작하기 1달전에 \"밑바닥부터 시작하는 딥러닝\" 2회독정도 했습니다. 제 배경지식은 통계학 + 컴퓨터공학 + DL 조금. 정도로 정리할 수 있겠습니다. 내가 생각하는 난이도 처음 1~2달 정도는 그 전에 공부했던 것들이라 복습하는 느낌으로 공부했고, 나머지는 개념정도만 아는 상태에서 공부를 했습니다. 그래서 따라가는데 어려움은 없었습니다. 다만, 양이 워낙 많아서 평균적으로 추가공부를 3~4시간, 적어도 1시간씩은 했던 것 같습니다. 배경지식이 전혀 없는 분이 리서치 과정을 수료하려면 적어도 매일 6시간씩은 추가공부해야할 것 같습니다. 공부방식 선생님이 있는게 아닌, 공부자료가 주어지고 같이 공부하는 사람들과 함께 알아가는 방식입니다. 공부의 방향을 \"퍼실\" 분들이 잡아주고, 모르는 부분을 해소해주는 방식으로 도움을 주십니다. 이게 보통 스터디 같은 경우 나보다 더 잘아는 사람과 해야지 얻는게 많을 것이라 생각하는데, 경험해보니 반대였던 것 같습니다. > 왜 선생님이 가장 많이 배운다고 하잖아요, 저는 배경지식이 있어 \"선생님\" 역할을 맡을 때가 많았는데 정말 많이 배웠습니다. 어느정도 알던 개념들이 설명을 하면서 완성되곤 했습니다. 특히 아에 모르던 개념들도 어떻게 해야 빠르게 습득하고 하나의 지식으로 만들 수 있는지 많이 배웠습니다. 또 토의, 토론을 정말 많이 했는데, 이를 통해 제 지식을 점검할 수 있었고 오류가 난 부분을 많이 찾을 수 있었습니다. 처음에는 어색했던 방법인데, 정말 만족했고 많이 배울 수 있었습니다. 프로젝트 6개월 과정 중 마지막 1~2개월에 최종 프로젝트(아이펠톤)를 진행하게 됩니다. 그 전 4개월동안 짧게 프로젝트를 진행했는데 (하루 or 3일), 이 때 연습한게 최종 프로젝트에 도움이 많이 됐습니다. 아이펠톤에는 기업이 참여하기도 하며, 참여기업이 있을 경우 주제를 들어보고 괜찮다고 판단되면 참여해 기업프로젝트를 진행하게 됩니다. 저는 해보고 싶었던 아이디어가 있어서 그걸 발제했고, 선정이 됐지만 기업프로젝트를 진행했습니다. 명확한 결과를 내고 싶었고, 기업의 관점이 궁금했습니다. 또 채용 가능성도 있어서 매력적으로 느껴졌습니다. 채용에 대해서는 기업소개때 같이 언급해주십니다. (보통 맘에 들면 채용할 수도 있다는 식입니다) 아이펠에서는 멘토를 각 프로젝트에 배정해주는데, 이 부분이 도움이 많이 됐습니다. 선택의 갈림길에서 조언을 많이 구했고, 피드백을 많이 받았습니다. 다만, 멘토님이 모두 좋지는 않았던 것 같습니다. 다른 팀에서는 되게 불만족스러웠다고 이야기하더라구요. 약 2개월동안 주제를 정하고, 문제를 해결해나가면서 결과를 완성했습니다. 왜 프로젝트 경험이 중요하다고 이야기하는지 정말 많이 느꼈고, 포트폴리오에 하나가 추가되어서 좋았습니다. 회고 시간이 참 빠른 것 같습니다. 6개월이 진짜 빨리 지나갔고, 그 과정에서 많이 배우고 좋은 인연을 얻었습니다. 아이펠에 만족하냐고 묻는다면, 저는 진짜 대만족입니다. 정말 좋은 분들이 계시고, 많은 도움을 받았습니다. 아이펠의 처음 목적은 \"딥러닝의 원리를 이해하는 것\" 이었는데, 목적을 달성했습니다. 단순히 코드 중심으로 결과를 내는게 아닌, 개념에 대해 토론하면서 개념을 깊이 이해할 수 있었습니다. 6개월이 지났고, 이 과정에서 배운 것들을 이용해 문제를 정의하고 해결하면서 꾸준히 성장하려고 합니다."
  }
]